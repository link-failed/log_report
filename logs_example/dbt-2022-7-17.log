

============================== 2022-07-16 17:06:16.327963 | 2d826656-3a4e-42bd-ba48-1049a0e46e49 ==============================
17:06:16.327983 [info ] [MainThread]: Running with dbt=1.1.1
17:06:16.328740 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:06:16.328974 [debug] [MainThread]: Tracking: tracking
17:06:16.337318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7c6c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7c6460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7c61f0>]}
17:06:16.454304 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:06:16.454668 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:06:16.457168 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:06:16.464639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7537c0>]}
17:06:16.483555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7a4280>]}
17:06:16.484075 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:06:16.484527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee7a4040>]}
17:06:16.492358 [info ] [MainThread]: 
17:06:16.493545 [debug] [MainThread]: Acquiring new postgres connection "master"
17:06:16.499277 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:06:16.513755 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:06:16.514360 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:06:16.514860 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:06:16.526297 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:06:16.530993 [debug] [ThreadPool]: On list_postgres: Close
17:06:16.537114 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:06:16.546433 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:06:16.546775 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:06:16.547022 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:06:16.551031 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:06:16.551291 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:06:16.551504 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:06:16.556734 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:06:16.565889 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:06:16.566295 [debug] [ThreadPool]: On list_postgres_public: Close
17:06:16.579096 [debug] [MainThread]: Using postgres connection "master"
17:06:16.579320 [debug] [MainThread]: On master: BEGIN
17:06:16.579550 [debug] [MainThread]: Opening a new connection, currently in state init
17:06:16.584406 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:06:16.584694 [debug] [MainThread]: Using postgres connection "master"
17:06:16.584912 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:06:16.592044 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:06:16.596277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48f05edc70>]}
17:06:16.596790 [debug] [MainThread]: On master: ROLLBACK
17:06:16.597345 [debug] [MainThread]: Using postgres connection "master"
17:06:16.597633 [debug] [MainThread]: On master: BEGIN
17:06:16.598089 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:06:16.598336 [debug] [MainThread]: On master: COMMIT
17:06:16.598441 [debug] [MainThread]: Using postgres connection "master"
17:06:16.598672 [debug] [MainThread]: On master: COMMIT
17:06:16.599213 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:06:16.599546 [debug] [MainThread]: On master: Close
17:06:16.600283 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:06:16.600603 [info ] [MainThread]: 
17:06:16.605766 [debug] [Thread-1  ]: Began running node model.mimic.abx_prescriptions_list
17:06:16.606104 [info ] [Thread-1  ]: 1 of 107 START table model public.abx_prescriptions_list ....................... [RUN]
17:06:16.606995 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.abx_prescriptions_list"
17:06:16.607304 [debug] [Thread-1  ]: Began compiling node model.mimic.abx_prescriptions_list
17:06:16.607601 [debug] [Thread-1  ]: Compiling model.mimic.abx_prescriptions_list
17:06:16.611711 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.abx_prescriptions_list"
17:06:16.612273 [debug] [Thread-1  ]: finished collecting timing info
17:06:16.612601 [debug] [Thread-1  ]: Began executing node model.mimic.abx_prescriptions_list
17:06:16.645646 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.abx_prescriptions_list"
17:06:16.646230 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:16.646440 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: BEGIN
17:06:16.646742 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:16.652219 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:16.652457 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:16.652635 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */


  create  table "postgres"."public"."abx_prescriptions_list__dbt_tmp"
  as (
     
with t1 as
(
  select
    drug, drug_name_generic
    , route
    , case
      when lower(drug) like '%adoxa%' then 1
      when lower(drug) like '%ala-tet%' then 1
      when lower(drug) like '%alodox%' then 1
      when lower(drug) like '%amikacin%' then 1
      when lower(drug) like '%amikin%' then 1
      when lower(drug) like '%amoxicillin%' then 1
      when lower(drug) like '%amoxicillin%clavulanate%' then 1
      when lower(drug) like '%clavulanate%' then 1
      when lower(drug) like '%ampicillin%' then 1
      when lower(drug) like '%augmentin%' then 1
      when lower(drug) like '%avelox%' then 1
      when lower(drug) like '%avidoxy%' then 1
      when lower(drug) like '%azactam%' then 1
      when lower(drug) like '%azithromycin%' then 1
      when lower(drug) like '%aztreonam%' then 1
      when lower(drug) like '%axetil%' then 1
      when lower(drug) like '%bactocill%' then 1
      when lower(drug) like '%bactrim%' then 1
      when lower(drug) like '%bethkis%' then 1
      when lower(drug) like '%biaxin%' then 1
      when lower(drug) like '%bicillin l-a%' then 1
      when lower(drug) like '%cayston%' then 1
      when lower(drug) like '%cefazolin%' then 1
      when lower(drug) like '%cedax%' then 1
      when lower(drug) like '%cefoxitin%' then 1
      when lower(drug) like '%ceftazidime%' then 1
      when lower(drug) like '%cefaclor%' then 1
      when lower(drug) like '%cefadroxil%' then 1
      when lower(drug) like '%cefdinir%' then 1
      when lower(drug) like '%cefditoren%' then 1
      when lower(drug) like '%cefepime%' then 1
      when lower(drug) like '%cefotetan%' then 1
      when lower(drug) like '%cefotaxime%' then 1
      when lower(drug) like '%cefpodoxime%' then 1
      when lower(drug) like '%cefprozil%' then 1
      when lower(drug) like '%ceftibuten%' then 1
      when lower(drug) like '%ceftin%' then 1
      when lower(drug) like '%cefuroxime %' then 1
      when lower(drug) like '%cefuroxime%' then 1
      when lower(drug) like '%cephalexin%' then 1
      when lower(drug) like '%chloramphenicol%' then 1
      when lower(drug) like '%cipro%' then 1
      when lower(drug) like '%ciprofloxacin%' then 1
      when lower(drug) like '%claforan%' then 1
      when lower(drug) like '%clarithromycin%' then 1
      when lower(drug) like '%cleocin%' then 1
      when lower(drug) like '%clindamycin%' then 1
      when lower(drug) like '%cubicin%' then 1
      when lower(drug) like '%dicloxacillin%' then 1
      when lower(drug) like '%doryx%' then 1
      when lower(drug) like '%doxycycline%' then 1
      when lower(drug) like '%duricef%' then 1
      when lower(drug) like '%dynacin%' then 1
      when lower(drug) like '%ery-tab%' then 1
      when lower(drug) like '%eryped%' then 1
      when lower(drug) like '%eryc%' then 1
      when lower(drug) like '%erythrocin%' then 1
      when lower(drug) like '%erythromycin%' then 1
      when lower(drug) like '%factive%' then 1
      when lower(drug) like '%flagyl%' then 1
      when lower(drug) like '%fortaz%' then 1
      when lower(drug) like '%furadantin%' then 1
      when lower(drug) like '%garamycin%' then 1
      when lower(drug) like '%gentamicin%' then 1
      when lower(drug) like '%kanamycin%' then 1
      when lower(drug) like '%keflex%' then 1
      when lower(drug) like '%ketek%' then 1
      when lower(drug) like '%levaquin%' then 1
      when lower(drug) like '%levofloxacin%' then 1
      when lower(drug) like '%lincocin%' then 1
      when lower(drug) like '%macrobid%' then 1
      when lower(drug) like '%macrodantin%' then 1
      when lower(drug) like '%maxipime%' then 1
      when lower(drug) like '%mefoxin%' then 1
      when lower(drug) like '%metronidazole%' then 1
      when lower(drug) like '%minocin%' then 1
      when lower(drug) like '%minocycline%' then 1
      when lower(drug) like '%monodox%' then 1
      when lower(drug) like '%monurol%' then 1
      when lower(drug) like '%morgidox%' then 1
      when lower(drug) like '%moxatag%' then 1
      when lower(drug) like '%moxifloxacin%' then 1
      when lower(drug) like '%myrac%' then 1
      when lower(drug) like '%nafcillin sodium%' then 1
      when lower(drug) like '%nicazel doxy 30%' then 1
      when lower(drug) like '%nitrofurantoin%' then 1
      when lower(drug) like '%noroxin%' then 1
      when lower(drug) like '%ocudox%' then 1
      when lower(drug) like '%ofloxacin%' then 1
      when lower(drug) like '%omnicef%' then 1
      when lower(drug) like '%oracea%' then 1
      when lower(drug) like '%oraxyl%' then 1
      when lower(drug) like '%oxacillin%' then 1
      when lower(drug) like '%pc pen vk%' then 1
      when lower(drug) like '%pce dispertab%' then 1
      when lower(drug) like '%panixine%' then 1
      when lower(drug) like '%pediazole%' then 1
      when lower(drug) like '%penicillin%' then 1
      when lower(drug) like '%periostat%' then 1
      when lower(drug) like '%pfizerpen%' then 1
      when lower(drug) like '%piperacillin%' then 1
      when lower(drug) like '%tazobactam%' then 1
      when lower(drug) like '%primsol%' then 1
      when lower(drug) like '%proquin%' then 1
      when lower(drug) like '%raniclor%' then 1
      when lower(drug) like '%rifadin%' then 1
      when lower(drug) like '%rifampin%' then 1
      when lower(drug) like '%rocephin%' then 1
      when lower(drug) like '%smz-tmp%' then 1
      when lower(drug) like '%septra%' then 1
      when lower(drug) like '%septra ds%' then 1
      when lower(drug) like '%septra%' then 1
      when lower(drug) like '%solodyn%' then 1
      when lower(drug) like '%spectracef%' then 1
      when lower(drug) like '%streptomycin sulfate%' then 1
      when lower(drug) like '%sulfadiazine%' then 1
      when lower(drug) like '%sulfamethoxazole%' then 1
      when lower(drug) like '%trimethoprim%' then 1
      when lower(drug) like '%sulfatrim%' then 1
      when lower(drug) like '%sulfisoxazole%' then 1
      when lower(drug) like '%suprax%' then 1
      when lower(drug) like '%synercid%' then 1
      when lower(drug) like '%tazicef%' then 1
      when lower(drug) like '%tetracycline%' then 1
      when lower(drug) like '%timentin%' then 1
      when lower(drug) like '%tobi%' then 1
      when lower(drug) like '%tobramycin%' then 1
      when lower(drug) like '%trimethoprim%' then 1
      when lower(drug) like '%unasyn%' then 1
      when lower(drug) like '%vancocin%' then 1
      when lower(drug) like '%vancomycin%' then 1
      when lower(drug) like '%vantin%' then 1
      when lower(drug) like '%vibativ%' then 1
      when lower(drug) like '%vibra-tabs%' then 1
      when lower(drug) like '%vibramycin%' then 1
      when lower(drug) like '%zinacef%' then 1
      when lower(drug) like '%zithromax%' then 1
      when lower(drug) like '%zmax%' then 1
      when lower(drug) like '%zosyn%' then 1
      when lower(drug) like '%zyvox%' then 1
    else 0
    end as antibiotic
  from prescriptions
  where drug_type in ('MAIN','ADDITIVE')
  -- we exclude routes via the eye, ears, or topically
  and route not in ('OU','OS','OD','AU','AS','AD', 'TP')
  and lower(route) not like '%ear%'
  and lower(route) not like '%eye%'
  -- we exclude certain types of antibiotics: topical creams, gels, desens, etc
  and lower(drug) not like '%cream%'
  and lower(drug) not like '%desensitization%'
  and lower(drug) not like '%ophth oint%'
  and lower(drug) not like '%gel%'
  -- other routes not sure about...
  -- for sure keep: ('IV','PO','PO/NG','ORAL', 'IV DRIP', 'IV BOLUS')
  -- ? VT, PB, PR, PL, NS, NG, NEB, NAS, LOCK, J TUBE, IVT
  -- ? IT, IRR, IP, IO, INHALATION, IN, IM
  -- ? IJ, IH, G TUBE, DIALYS
  -- ?? enemas??
)
select
  drug --, drug_name_generic
  , count(*) as numobs
from t1
where antibiotic = 1
group by drug --, drug_name_generic
order by numobs desc
  );
17:06:50.761430 [debug] [Thread-1  ]: SQL status: SELECT 156 in 34.11 seconds
17:06:50.773443 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:50.773830 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
alter table "postgres"."public"."abx_prescriptions_list" rename to "abx_prescriptions_list__dbt_backup"
17:06:50.774831 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:50.778307 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:50.778602 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
alter table "postgres"."public"."abx_prescriptions_list__dbt_tmp" rename to "abx_prescriptions_list"
17:06:50.779378 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:50.790916 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: COMMIT
17:06:50.791160 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:50.791353 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: COMMIT
17:06:50.792802 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:50.796834 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:06:50.797038 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
drop table if exists "postgres"."public"."abx_prescriptions_list__dbt_backup" cascade
17:06:50.801073 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:50.804629 [debug] [Thread-1  ]: finished collecting timing info
17:06:50.804860 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: Close
17:06:50.805638 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edca73a0>]}
17:06:50.806030 [info ] [Thread-1  ]: 1 of 107 OK created table model public.abx_prescriptions_list .................. [[32mSELECT 156[0m in 34.20s]
17:06:50.806448 [debug] [Thread-1  ]: Finished running node model.mimic.abx_prescriptions_list
17:06:50.806940 [debug] [Thread-1  ]: Began running node model.mimic.adenosine_durations
17:06:50.807332 [info ] [Thread-1  ]: 2 of 107 START table model public.adenosine_durations .......................... [RUN]
17:06:50.808632 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.adenosine_durations"
17:06:50.808929 [debug] [Thread-1  ]: Began compiling node model.mimic.adenosine_durations
17:06:50.809418 [debug] [Thread-1  ]: Compiling model.mimic.adenosine_durations
17:06:50.811590 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.adenosine_durations"
17:06:50.812314 [debug] [Thread-1  ]: finished collecting timing info
17:06:50.812847 [debug] [Thread-1  ]: Began executing node model.mimic.adenosine_durations
17:06:50.822291 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.adenosine_durations"
17:06:50.823156 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.823587 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: BEGIN
17:06:50.823943 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:50.829910 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:50.830157 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.830256 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */


  create  table "postgres"."public"."adenosine_durations__dbt_tmp"
  as (
    -- This query extracts durations of adenosine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- *** COULD NOT FIND ADENOSINE IN THE INPUTEVENTS_MV TABLE ***
-- This drug is rarely used - it could just be that it was never used in MetaVision.
-- If using this code, ensure the durations make sense for carevue patients first

with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 4649 then 1 else 0 end) as vaso -- adenosine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , 0 as vaso_stopped
    , max(case when itemid = 4649 and valuenum is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 4649 then valuenum else null end) as vaso_rate
    , max(case when itemid = 4649 then valuenum else null end) as vaso_amount

  FROM chartevents
  where itemid = 4649 -- adenosine
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221282 -- adenosine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:06:50.873524 [debug] [Thread-1  ]: SQL status: SELECT 160 in 0.04 seconds
17:06:50.880230 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.880868 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations" rename to "adenosine_durations__dbt_backup"
17:06:50.882142 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:50.887639 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.887852 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations__dbt_tmp" rename to "adenosine_durations"
17:06:50.888546 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:50.891487 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:06:50.891722 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.891901 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:06:50.893553 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:50.896347 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:06:50.896540 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
drop table if exists "postgres"."public"."adenosine_durations__dbt_backup" cascade
17:06:50.898826 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:50.901488 [debug] [Thread-1  ]: finished collecting timing info
17:06:50.901693 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: Close
17:06:50.902404 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec4660a0>]}
17:06:50.903002 [info ] [Thread-1  ]: 2 of 107 OK created table model public.adenosine_durations ..................... [[32mSELECT 160[0m in 0.09s]
17:06:50.903496 [debug] [Thread-1  ]: Finished running node model.mimic.adenosine_durations
17:06:50.903774 [debug] [Thread-1  ]: Began running node model.mimic.age_histogram
17:06:50.904394 [info ] [Thread-1  ]: 3 of 107 START table model public.age_histogram ................................ [RUN]
17:06:50.905046 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.age_histogram"
17:06:50.905321 [debug] [Thread-1  ]: Began compiling node model.mimic.age_histogram
17:06:50.905513 [debug] [Thread-1  ]: Compiling model.mimic.age_histogram
17:06:50.907263 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.age_histogram"
17:06:50.907911 [debug] [Thread-1  ]: finished collecting timing info
17:06:50.908226 [debug] [Thread-1  ]: Began executing node model.mimic.age_histogram
17:06:50.919578 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.age_histogram"
17:06:50.920449 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:50.920698 [debug] [Thread-1  ]: On model.mimic.age_histogram: BEGIN
17:06:50.920867 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:50.925642 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:06:50.926195 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:50.926721 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */


  create  table "postgres"."public"."age_histogram__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of hospital admissions in equally sized bins of age
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- ------------------------------------------------------------------

WITH agetbl AS
(
    SELECT DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') AS age
      FROM admissions ad
      INNER JOIN patients p
      ON ad.subject_id = p.subject_id
)
, agebin AS
(
      SELECT age, width_bucket(age, 15, 100, 85) AS bucket
      FROM agetbl
)
SELECT bucket+15 as age, count(*)
FROM agebin
GROUP BY bucket
ORDER BY bucket
  );
17:06:51.090905 [debug] [Thread-1  ]: SQL status: SELECT 77 in 0.16 seconds
17:06:51.097472 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:51.097875 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
alter table "postgres"."public"."age_histogram" rename to "age_histogram__dbt_backup"
17:06:51.099274 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:51.106319 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:51.106607 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
alter table "postgres"."public"."age_histogram__dbt_tmp" rename to "age_histogram"
17:06:51.107474 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:51.112563 [debug] [Thread-1  ]: On model.mimic.age_histogram: COMMIT
17:06:51.112912 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:51.113218 [debug] [Thread-1  ]: On model.mimic.age_histogram: COMMIT
17:06:51.116149 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:51.118756 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:06:51.118976 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
drop table if exists "postgres"."public"."age_histogram__dbt_backup" cascade
17:06:51.120702 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:51.124032 [debug] [Thread-1  ]: finished collecting timing info
17:06:51.124259 [debug] [Thread-1  ]: On model.mimic.age_histogram: Close
17:06:51.125190 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc78df0>]}
17:06:51.126176 [info ] [Thread-1  ]: 3 of 107 OK created table model public.age_histogram ........................... [[32mSELECT 77[0m in 0.22s]
17:06:51.127048 [debug] [Thread-1  ]: Finished running node model.mimic.age_histogram
17:06:51.127435 [debug] [Thread-1  ]: Began running node model.mimic.angus
17:06:51.128128 [info ] [Thread-1  ]: 4 of 107 START table model public.angus ........................................ [RUN]
17:06:51.128828 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.angus"
17:06:51.129053 [debug] [Thread-1  ]: Began compiling node model.mimic.angus
17:06:51.129280 [debug] [Thread-1  ]: Compiling model.mimic.angus
17:06:51.131974 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.angus"
17:06:51.132747 [debug] [Thread-1  ]: finished collecting timing info
17:06:51.133039 [debug] [Thread-1  ]: Began executing node model.mimic.angus
17:06:51.142168 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.angus"
17:06:51.143223 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:51.143563 [debug] [Thread-1  ]: On model.mimic.angus: BEGIN
17:06:51.143957 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:51.149600 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:51.149829 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:51.149929 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */


  create  table "postgres"."public"."angus__dbt_tmp"
  as (
    -- ICD-9 codes for Angus criteria of sepsis

-- Angus et al, 2001. Epidemiology of severe sepsis in the United States
-- http://www.ncbi.nlm.nih.gov/pubmed/11445675

-- Case selection and definitions
-- To identify cases with severe sepsis, we selected all acute care
-- hospitalizations with ICD-9-CM codes for both:
-- (a) a bacterial or fungal infectious process AND
-- (b) a diagnosis of acute organ dysfunction (Appendix 2).

-- ICD-9 codes for infection - as sourced from Appendix 1 of above paper
 

WITH infection_group AS
(
	SELECT subject_id, hadm_id,
	CASE
		WHEN SUBSTR(icd9_code,1,3) IN ('001','002','003','004','005','008',
			   '009','010','011','012','013','014','015','016','017','018',
			   '020','021','022','023','024','025','026','027','030','031',
			   '032','033','034','035','036','037','038','039','040','041',
			   '090','091','092','093','094','095','096','097','098','100',
			   '101','102','103','104','110','111','112','114','115','116',
			   '117','118','320','322','324','325','420','421','451','461',
			   '462','463','464','465','481','482','485','486','494','510',
			   '513','540','541','542','566','567','590','597','601','614',
			   '615','616','681','682','683','686','730') THEN 1
		WHEN SUBSTR(icd9_code,1,4) IN ('5695','5720','5721','5750','5990','7110',
				'7907','9966','9985','9993') THEN 1
		WHEN SUBSTR(icd9_code,1,5) IN ('49121','56201','56203','56211','56213',
				'56983') THEN 1
		ELSE 0 END AS infection
	from diagnoses_icd
),
-- ICD-9 codes for organ dysfunction - as sourced from Appendix 2 of above paper
organ_diag_group as
(
	SELECT subject_id, hadm_id,
		CASE
		-- Acute Organ Dysfunction Diagnosis Codes
		WHEN SUBSTR(icd9_code,1,3) IN ('458','293','570','584') THEN 1
		WHEN SUBSTR(icd9_code,1,4) IN ('7855','3483','3481',
				'2874','2875','2869','2866','5734')  THEN 1
		ELSE 0 END AS organ_dysfunction,
		-- Explicit diagnosis of severe sepsis or septic shock
		CASE
		WHEN SUBSTR(icd9_code,1,5) IN ('99592','78552')  THEN 1
		ELSE 0 END AS explicit_sepsis
	from diagnoses_icd
),
-- Mechanical ventilation
organ_proc_group as
(
	SELECT subject_id, hadm_id,
		CASE
		WHEN icd9_code IN ('9670', '9671', '9672') THEN 1
		ELSE 0 END AS mech_vent
	FROM procedures_icd
),
-- Aggregate above views together
aggregate as
(
	SELECT subject_id, hadm_id,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM infection_group
					WHERE infection = 1)
				THEN 1
			ELSE 0 END AS infection,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM organ_diag_group
					WHERE explicit_sepsis = 1)
				THEN 1
			ELSE 0 END AS explicit_sepsis,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM organ_diag_group
					WHERE organ_dysfunction = 1)
				THEN 1
			ELSE 0 END AS organ_dysfunction,
		CASE
		WHEN hadm_id in
				(SELECT DISTINCT hadm_id
				FROM organ_proc_group
				WHERE mech_vent = 1)
			THEN 1
		ELSE 0 END AS mech_vent
	FROM admissions
)
-- Output component flags (explicit sepsis, organ dysfunction) and final flag (angus)
SELECT subject_id, hadm_id, infection,
   explicit_sepsis, organ_dysfunction, mech_vent,
CASE
	WHEN explicit_sepsis = 1 THEN 1
	WHEN infection = 1 AND organ_dysfunction = 1 THEN 1
	WHEN infection = 1 AND mech_vent = 1 THEN 1
	ELSE 0 END
AS angus
FROM aggregate
  );
17:06:53.643585 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 2.49 seconds
17:06:53.653127 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:53.653437 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
alter table "postgres"."public"."angus" rename to "angus__dbt_backup"
17:06:53.654202 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.657829 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:53.658027 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
alter table "postgres"."public"."angus__dbt_tmp" rename to "angus"
17:06:53.658922 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.662000 [debug] [Thread-1  ]: On model.mimic.angus: COMMIT
17:06:53.662188 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:53.662305 [debug] [Thread-1  ]: On model.mimic.angus: COMMIT
17:06:53.664817 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:53.667286 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:06:53.667491 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
drop table if exists "postgres"."public"."angus__dbt_backup" cascade
17:06:53.669519 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:53.672605 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.672931 [debug] [Thread-1  ]: On model.mimic.angus: Close
17:06:53.673752 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec3d1fa0>]}
17:06:53.674248 [info ] [Thread-1  ]: 4 of 107 OK created table model public.angus ................................... [[32mSELECT 58976[0m in 2.55s]
17:06:53.674951 [debug] [Thread-1  ]: Finished running node model.mimic.angus
17:06:53.675448 [debug] [Thread-1  ]: Began running node model.mimic.arterial_line_durations
17:06:53.676207 [info ] [Thread-1  ]: 5 of 107 START table model public.arterial_line_durations ...................... [RUN]
17:06:53.676955 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.arterial_line_durations"
17:06:53.677278 [debug] [Thread-1  ]: Began compiling node model.mimic.arterial_line_durations
17:06:53.677765 [debug] [Thread-1  ]: Compiling model.mimic.arterial_line_durations
17:06:53.680321 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.arterial_line_durations"
17:06:53.681225 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.681862 [debug] [Thread-1  ]: Began executing node model.mimic.arterial_line_durations
17:06:53.695503 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.arterial_line_durations"
17:06:53.696476 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.696782 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: BEGIN
17:06:53.696911 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:53.702372 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:53.702787 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.703030 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */


  create  table "postgres"."public"."arterial_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
  , case
      when itemid in (225752, 224272)
        then 1
      when pe.locationcategory = 'Invasive Arterial'
        then 1
      when itemid = 225789 and pe.locationcategory IS NULL
        then 1
      else 0
    end as arterial_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    -- , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    -- , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    -- , 225203 -- Pheresis Catheter | None | 12 | Processes
    -- , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 225789 -- Sheath
    , 224272 -- IABP Line
    -- , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('A-Line', 'IABP'))
     OR (inv2_type in ('A-Line', 'IABP'))
     OR (inv3_type in ('A-Line', 'IABP'))
     OR (inv4_type in ('A-Line', 'IABP'))
     OR (inv5_type in ('A-Line', 'IABP'))
     OR (inv6_type in ('A-Line', 'IABP'))
     OR (inv7_type in ('A-Line', 'IABP'))
     OR (inv8_type in ('A-Line', 'IABP'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as arterial_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as arterial_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( arterial_line_new )
    OVER ( partition by icustay_id order by charttime )
    as arterial_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , arterial_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, arterial_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , arterial_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as arterial_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where arterial_line = 1
order by icustay_id, starttime
  );
17:06:53.798434 [debug] [Thread-1  ]: SQL status: SELECT 13059 in 0.1 seconds
17:06:53.804621 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.804980 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations" rename to "arterial_line_durations__dbt_backup"
17:06:53.806606 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.811224 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.811434 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations__dbt_tmp" rename to "arterial_line_durations"
17:06:53.812268 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.816304 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:06:53.816518 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.816801 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:06:53.819573 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:53.821506 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:06:53.821696 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
drop table if exists "postgres"."public"."arterial_line_durations__dbt_backup" cascade
17:06:53.824827 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:53.828556 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.828821 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: Close
17:06:53.829527 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ee6cb250>]}
17:06:53.830053 [info ] [Thread-1  ]: 5 of 107 OK created table model public.arterial_line_durations ................. [[32mSELECT 13059[0m in 0.15s]
17:06:53.830651 [debug] [Thread-1  ]: Finished running node model.mimic.arterial_line_durations
17:06:53.830999 [debug] [Thread-1  ]: Began running node model.mimic.auroc
17:06:53.831641 [info ] [Thread-1  ]: 6 of 107 START table model public.auroc ........................................ [RUN]
17:06:53.832544 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.auroc"
17:06:53.833045 [debug] [Thread-1  ]: Began compiling node model.mimic.auroc
17:06:53.833343 [debug] [Thread-1  ]: Compiling model.mimic.auroc
17:06:53.834968 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.auroc"
17:06:53.835707 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.836109 [debug] [Thread-1  ]: Began executing node model.mimic.auroc
17:06:53.846938 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.auroc"
17:06:53.848619 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.848870 [debug] [Thread-1  ]: On model.mimic.auroc: BEGIN
17:06:53.848970 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:53.852954 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:06:53.853181 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.853281 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */


  create  table "postgres"."public"."auroc__dbt_tmp"
  as (
    -- Calculate the AUROC of age for predicting in-hospital mortality
-- You can easily calculate the AUROC of any model you'd like by:
--  Replacing "PRED" with your predictor
--  Replacing "TAR" with the target (*must* be a binary target)

with datatable as (
select
  -- name the predictor "PRED"
  cast(adm.admittime as date) - cast(pat.dob as date) as PRED -- age is our predictor
  -- name the target variable "TAR"
  , case when adm.deathtime is not null then 1 else 0 end as TAR -- in-hospital mortality
FROM admissions adm
inner join patients pat
  on adm.subject_id = pat.subject_id
)
, datacs as (
select
  TAR
  -- calculate the cumulative sum of negative targets, then multiply by positive targets
  -- this has the effect of returning 0 for negative targets, and the # of negative targets below each positive target
  , TAR * SUM(1-TAR) OVER (ORDER BY PRED ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS AUROC
from datatable
)
select
  -- Calculate the AUROC as:
  --    SUM( number of negative targets below each positive target )
  -- /  number of possible negative/positive target pairs
  round(sum(AUROC) / (sum(TAR)*sum(1-TAR)),4) as AUROC
from datacs
  );
17:06:53.926792 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.07 seconds
17:06:53.931081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.931288 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
alter table "postgres"."public"."auroc" rename to "auroc__dbt_backup"
17:06:53.932082 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.935679 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.935880 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
alter table "postgres"."public"."auroc__dbt_tmp" rename to "auroc"
17:06:53.936523 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:53.939579 [debug] [Thread-1  ]: On model.mimic.auroc: COMMIT
17:06:53.939955 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.940283 [debug] [Thread-1  ]: On model.mimic.auroc: COMMIT
17:06:53.942505 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:53.945130 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:06:53.945328 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
drop table if exists "postgres"."public"."auroc__dbt_backup" cascade
17:06:53.947330 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:53.950756 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.951010 [debug] [Thread-1  ]: On model.mimic.auroc: Close
17:06:53.951739 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc811c0>]}
17:06:53.952210 [info ] [Thread-1  ]: 6 of 107 OK created table model public.auroc ................................... [[32mSELECT 1[0m in 0.12s]
17:06:53.952765 [debug] [Thread-1  ]: Finished running node model.mimic.auroc
17:06:53.953279 [debug] [Thread-1  ]: Began running node model.mimic.basic_patient_info
17:06:53.954025 [info ] [Thread-1  ]: 7 of 107 START table model public.basic_patient_info ........................... [RUN]
17:06:53.954736 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.basic_patient_info"
17:06:53.955169 [debug] [Thread-1  ]: Began compiling node model.mimic.basic_patient_info
17:06:53.955613 [debug] [Thread-1  ]: Compiling model.mimic.basic_patient_info
17:06:53.957336 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.basic_patient_info"
17:06:53.958074 [debug] [Thread-1  ]: finished collecting timing info
17:06:53.958722 [debug] [Thread-1  ]: Began executing node model.mimic.basic_patient_info
17:06:53.969301 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.basic_patient_info"
17:06:53.970502 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:53.971032 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: BEGIN
17:06:53.971313 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:53.977869 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:53.978313 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:53.978903 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */


  create  table "postgres"."public"."basic_patient_info__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Retrieves basic patient information from the patients table
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- ------------------------------------------------------------------


SELECT subject_id, gender, dob
FROM patients
  );
17:06:54.000053 [debug] [Thread-1  ]: SQL status: SELECT 46520 in 0.02 seconds
17:06:54.005480 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:54.005775 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
alter table "postgres"."public"."basic_patient_info" rename to "basic_patient_info__dbt_backup"
17:06:54.007004 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.013320 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:54.013524 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
alter table "postgres"."public"."basic_patient_info__dbt_tmp" rename to "basic_patient_info"
17:06:54.014127 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.017506 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: COMMIT
17:06:54.017714 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:54.017913 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: COMMIT
17:06:54.022668 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:54.026875 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:06:54.027091 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
drop table if exists "postgres"."public"."basic_patient_info__dbt_backup" cascade
17:06:54.028948 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:54.031654 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.031886 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: Close
17:06:54.032679 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc811c0>]}
17:06:54.033131 [info ] [Thread-1  ]: 7 of 107 OK created table model public.basic_patient_info ...................... [[32mSELECT 46520[0m in 0.08s]
17:06:54.033630 [debug] [Thread-1  ]: Finished running node model.mimic.basic_patient_info
17:06:54.033814 [debug] [Thread-1  ]: Began running node model.mimic.blood_gas_first_day
17:06:54.034395 [info ] [Thread-1  ]: 8 of 107 START table model public.blood_gas_first_day .......................... [RUN]
17:06:54.035219 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.blood_gas_first_day"
17:06:54.035632 [debug] [Thread-1  ]: Began compiling node model.mimic.blood_gas_first_day
17:06:54.035893 [debug] [Thread-1  ]: Compiling model.mimic.blood_gas_first_day
17:06:54.037039 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.blood_gas_first_day"
17:06:54.037557 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.037791 [debug] [Thread-1  ]: Began executing node model.mimic.blood_gas_first_day
17:06:54.049834 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.blood_gas_first_day"
17:06:54.050419 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.051052 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: BEGIN
17:06:54.051468 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:54.057525 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:54.058314 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.058529 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */


  create  table "postgres"."public"."blood_gas_first_day__dbt_tmp"
  as (
    -- The aim of this query is to pivot entries related to blood gases and
-- chemistry values which were found in LABEVENTS

-- things to check:
--  when a mixed venous/arterial blood sample are taken at the same time, is the store time different?

with pvt as
( -- begin query that extracts the data
  select ie.subject_id, ie.hadm_id, ie.icustay_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
      , case
        when itemid = 50800 then 'SPECIMEN'
        when itemid = 50801 then 'AADO2'
        when itemid = 50802 then 'BASEEXCESS'
        when itemid = 50803 then 'BICARBONATE'
        when itemid = 50804 then 'TOTALCO2'
        when itemid = 50805 then 'CARBOXYHEMOGLOBIN'
        when itemid = 50806 then 'CHLORIDE'
        when itemid = 50808 then 'CALCIUM'
        when itemid = 50809 then 'GLUCOSE'
        when itemid = 50810 then 'HEMATOCRIT'
        when itemid = 50811 then 'HEMOGLOBIN'
        when itemid = 50812 then 'INTUBATED'
        when itemid = 50813 then 'LACTATE'
        when itemid = 50814 then 'METHEMOGLOBIN'
        when itemid = 50815 then 'O2FLOW'
        when itemid = 50816 then 'FIO2'
        when itemid = 50817 then 'SO2' -- OXYGENSATURATION
        when itemid = 50818 then 'PCO2'
        when itemid = 50819 then 'PEEP'
        when itemid = 50820 then 'PH'
        when itemid = 50821 then 'PO2'
        when itemid = 50822 then 'POTASSIUM'
        when itemid = 50823 then 'REQUIREDO2'
        when itemid = 50824 then 'SODIUM'
        when itemid = 50825 then 'TEMPERATURE'
        when itemid = 50826 then 'TIDALVOLUME'
        when itemid = 50827 then 'VENTILATIONRATE'
        when itemid = 50828 then 'VENTILATOR'
        else null
        end as label
        , charttime
        , value
        -- add in some sanity checks on the values
        , case
          when valuenum <= 0 and itemid != 50802 then null -- allow negative baseexcess
          when itemid = 50810 and valuenum > 100 then null -- hematocrit
          -- ensure FiO2 is a valid number between 21-100
          -- mistakes are rare (<100 obs out of ~100,000)
          -- there are 862 obs of valuenum == 20 - some people round down!
          -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
          when itemid = 50816 and valuenum < 20 then null
          when itemid = 50816 and valuenum > 100 then null
          when itemid = 50817 and valuenum > 100 then null -- O2 sat
          when itemid = 50815 and valuenum >  70 then null -- O2 flow
          when itemid = 50821 and valuenum > 800 then null -- PO2
           -- conservative upper limit
        else valuenum
        end as valuenum

    FROM icustays ie
    left join labevents le
      on le.subject_id = ie.subject_id and le.hadm_id = ie.hadm_id
      and le.charttime between (DATETIME_SUB(ie.intime, INTERVAL '6' HOUR)) and (DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
      and le.ITEMID in
      -- blood gases
      (
        50800, 50801, 50802, 50803, 50804, 50805, 50806, 50807, 50808, 50809
        , 50810, 50811, 50812, 50813, 50814, 50815, 50816, 50817, 50818, 50819
        , 50820, 50821, 50822, 50823, 50824, 50825, 50826, 50827, 50828
        , 51545
      )
)
select pvt.SUBJECT_ID, pvt.HADM_ID, pvt.ICUSTAY_ID, pvt.CHARTTIME
, max(case when label = 'SPECIMEN' then value else null end) as specimen
, max(case when label = 'AADO2' then valuenum else null end) as aado2
, max(case when label = 'BASEEXCESS' then valuenum else null end) as baseexcess
, max(case when label = 'BICARBONATE' then valuenum else null end) as bicarbonate
, max(case when label = 'TOTALCO2' then valuenum else null end) as totalco2
, max(case when label = 'CARBOXYHEMOGLOBIN' then valuenum else null end) as carboxyhemoglobin
, max(case when label = 'CHLORIDE' then valuenum else null end) as chloride
, max(case when label = 'CALCIUM' then valuenum else null end) as calcium
, max(case when label = 'GLUCOSE' then valuenum else null end) as glucose
, max(case when label = 'HEMATOCRIT' then valuenum else null end) as hematocrit
, max(case when label = 'HEMOGLOBIN' then valuenum else null end) as hemoglobin
, max(case when label = 'INTUBATED' then valuenum else null end) as intubated
, max(case when label = 'LACTATE' then valuenum else null end) as lactate
, max(case when label = 'METHEMOGLOBIN' then valuenum else null end) as methemoglobin
, max(case when label = 'O2FLOW' then valuenum else null end) as o2flow
, max(case when label = 'FIO2' then valuenum else null end) as fio2
, max(case when label = 'SO2' then valuenum else null end) as so2 -- OXYGENSATURATION
, max(case when label = 'PCO2' then valuenum else null end) as pco2
, max(case when label = 'PEEP' then valuenum else null end) as peep
, max(case when label = 'PH' then valuenum else null end) as ph
, max(case when label = 'PO2' then valuenum else null end) as po2
, max(case when label = 'POTASSIUM' then valuenum else null end) as potassium
, max(case when label = 'REQUIREDO2' then valuenum else null end) as requiredo2
, max(case when label = 'SODIUM' then valuenum else null end) as sodium
, max(case when label = 'TEMPERATURE' then valuenum else null end) as temperature
, max(case when label = 'TIDALVOLUME' then valuenum else null end) as tidalvolume
, max(case when label = 'VENTILATIONRATE' then valuenum else null end) as ventilationrate
, max(case when label = 'VENTILATOR' then valuenum else null end) as ventilator
from pvt
group by pvt.subject_id, pvt.hadm_id, pvt.icustay_id, pvt.CHARTTIME
order by pvt.subject_id, pvt.hadm_id, pvt.icustay_id, pvt.CHARTTIME
  );
17:06:54.195330 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.14 seconds
17:06:54.202231 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.202744 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
alter table "postgres"."public"."blood_gas_first_day" rename to "blood_gas_first_day__dbt_backup"
17:06:54.204087 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.207993 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.208194 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
alter table "postgres"."public"."blood_gas_first_day__dbt_tmp" rename to "blood_gas_first_day"
17:06:54.208915 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.212033 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: COMMIT
17:06:54.212231 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.212429 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: COMMIT
17:06:54.220062 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:06:54.222019 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:06:54.222278 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
drop table if exists "postgres"."public"."blood_gas_first_day__dbt_backup" cascade
17:06:54.225217 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:54.227969 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.228196 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: Close
17:06:54.228956 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81310>]}
17:06:54.229475 [info ] [Thread-1  ]: 8 of 107 OK created table model public.blood_gas_first_day ..................... [[32mSELECT 61532[0m in 0.19s]
17:06:54.230096 [debug] [Thread-1  ]: Finished running node model.mimic.blood_gas_first_day
17:06:54.230367 [debug] [Thread-1  ]: Began running node model.mimic.bun
17:06:54.231308 [info ] [Thread-1  ]: 9 of 107 START table model public.bun .......................................... [RUN]
17:06:54.232438 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.bun"
17:06:54.232877 [debug] [Thread-1  ]: Began compiling node model.mimic.bun
17:06:54.233204 [debug] [Thread-1  ]: Compiling model.mimic.bun
17:06:54.234277 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.bun"
17:06:54.234861 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.235129 [debug] [Thread-1  ]: Began executing node model.mimic.bun
17:06:54.246155 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.bun"
17:06:54.246903 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.247157 [debug] [Thread-1  ]: On model.mimic.bun: BEGIN
17:06:54.247752 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:54.252406 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:06:54.252654 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.252823 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */


  create  table "postgres"."public"."bun__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a distribution of BUN values for adult hospital admissions
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
    SELECT ad.subject_id
    FROM admissions ad
    INNER JOIN patients p
    ON ad.subject_id = p.subject_id
    WHERE
     -- filter to only adults
    DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
    -- group by subject_id to ensure there is only 1 subject_id per row
    group by ad.subject_id
)
, bun as
(
  SELECT width_bucket(valuenum, 0, 280, 280) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (51006)
)
SELECT bucket as blood_urea_nitrogen, count(*)
FROM bun
GROUP BY bucket
ORDER BY bucket
  );
17:06:54.395645 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:06:54.401309 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.401661 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
alter table "postgres"."public"."bun" rename to "bun__dbt_backup"
17:06:54.402982 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.408542 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.408737 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
alter table "postgres"."public"."bun__dbt_tmp" rename to "bun"
17:06:54.409458 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.412563 [debug] [Thread-1  ]: On model.mimic.bun: COMMIT
17:06:54.412761 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.412963 [debug] [Thread-1  ]: On model.mimic.bun: COMMIT
17:06:54.415300 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:54.417876 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:06:54.418067 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
drop table if exists "postgres"."public"."bun__dbt_backup" cascade
17:06:54.419866 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:54.422293 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.422606 [debug] [Thread-1  ]: On model.mimic.bun: Close
17:06:54.423396 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81460>]}
17:06:54.423869 [info ] [Thread-1  ]: 9 of 107 OK created table model public.bun ..................................... [[32mSELECT 0[0m in 0.19s]
17:06:54.424424 [debug] [Thread-1  ]: Finished running node model.mimic.bun
17:06:54.424910 [debug] [Thread-1  ]: Began running node model.mimic.central_line_durations
17:06:54.425840 [info ] [Thread-1  ]: 10 of 107 START table model public.central_line_durations ...................... [RUN]
17:06:54.426400 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.central_line_durations"
17:06:54.426798 [debug] [Thread-1  ]: Began compiling node model.mimic.central_line_durations
17:06:54.427197 [debug] [Thread-1  ]: Compiling model.mimic.central_line_durations
17:06:54.428384 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.central_line_durations"
17:06:54.428920 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.429175 [debug] [Thread-1  ]: Began executing node model.mimic.central_line_durations
17:06:54.438080 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.central_line_durations"
17:06:54.438601 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.438867 [debug] [Thread-1  ]: On model.mimic.central_line_durations: BEGIN
17:06:54.439098 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:54.445851 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:54.446111 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.446213 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */


  create  table "postgres"."public"."central_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
    , case
        when (locationcategory <> 'Invasive Arterial' or locationcategory is null)
          then 1
        else 0
      end as central_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    , 225203 -- Pheresis Catheter | None | 12 | Processes
    , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
    , 224270 -- Dialysis Catheter
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv2_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv3_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv4_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv5_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv6_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv7_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv8_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as central_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as central_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( central_line_new )
    OVER ( partition by icustay_id order by charttime )
    as central_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , central_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, central_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , central_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as central_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where central_line = 1
order by icustay_id, starttime
  );
17:06:54.531314 [debug] [Thread-1  ]: SQL status: SELECT 21211 in 0.08 seconds
17:06:54.536430 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.536634 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations" rename to "central_line_durations__dbt_backup"
17:06:54.537367 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.542024 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.542221 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations__dbt_tmp" rename to "central_line_durations"
17:06:54.544683 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.548468 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:06:54.548729 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.549030 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:06:54.552254 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:54.554912 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:06:54.555299 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
drop table if exists "postgres"."public"."central_line_durations__dbt_backup" cascade
17:06:54.558446 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:54.561427 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.561635 [debug] [Thread-1  ]: On model.mimic.central_line_durations: Close
17:06:54.562350 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc814f0>]}
17:06:54.562772 [info ] [Thread-1  ]: 10 of 107 OK created table model public.central_line_durations ................. [[32mSELECT 21211[0m in 0.14s]
17:06:54.563329 [debug] [Thread-1  ]: Finished running node model.mimic.central_line_durations
17:06:54.563777 [debug] [Thread-1  ]: Began running node model.mimic.code_status
17:06:54.564639 [info ] [Thread-1  ]: 11 of 107 START table model public.code_status ................................. [RUN]
17:06:54.565436 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.code_status"
17:06:54.565942 [debug] [Thread-1  ]: Began compiling node model.mimic.code_status
17:06:54.566195 [debug] [Thread-1  ]: Compiling model.mimic.code_status
17:06:54.568847 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.code_status"
17:06:54.570198 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.570439 [debug] [Thread-1  ]: Began executing node model.mimic.code_status
17:06:54.583376 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.code_status"
17:06:54.584176 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.584461 [debug] [Thread-1  ]: On model.mimic.code_status: BEGIN
17:06:54.584700 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:54.591376 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:54.591845 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.592240 [debug] [Thread-1  ]: On model.mimic.code_status: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.code_status"} */


  create  table "postgres"."public"."code_status__dbt_tmp"
  as (
    -- This query extracts:
--    i) a patient's first code status
--    ii) a patient's last code status
--    iii) the time of the first entry of DNR or CMO



with t1 as
(
  select icustay_id, charttime, value
  -- use row number to identify first and last code status
  , ROW_NUMBER() over (PARTITION BY icustay_id order by charttime) as rnfirst
  , ROW_NUMBER() over (PARTITION BY icustay_id order by charttime desc) as rnlast

  -- coalesce the values
  , case
      when value in ('Full Code','Full code') then 1
    else 0 end as fullcode
  , case
      when value in ('Comfort Measures','Comfort measures only') then 1
    else 0 end as cmo
  , case
      when value = 'CPR Not Indicate' then 1
    else 0 end as dncpr -- only in CareVue, i.e. only possible for ~60-70% of patients
  , case
      when value in ('Do Not Intubate','DNI (do not intubate)','DNR / DNI') then 1
    else 0 end as dni
  , case
      when value in ('Do Not Resuscita','DNR (do not resuscitate)','DNR / DNI') then 1
    else 0 end as dnr
  FROM chartevents
  where itemid in (128, 223758)
  and value is not null
  and value != 'Other/Remarks'
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
  -- first recorded code status
  , max(case when rnfirst = 1 then t1.fullcode else null end) as fullcode_first
  , max(case when rnfirst = 1 then t1.cmo else null end) as cmo_first
  , max(case when rnfirst = 1 then t1.dnr else null end) as dnr_first
  , max(case when rnfirst = 1 then t1.dni else null end) as dni_first
  , max(case when rnfirst = 1 then t1.dncpr else null end) as dncpr_first

  -- last recorded code status
  , max(case when  rnlast = 1 then t1.fullcode else null end) as fullcode_last
  , max(case when  rnlast = 1 then t1.cmo else null end) as cmo_last
  , max(case when  rnlast = 1 then t1.dnr else null end) as dnr_last
  , max(case when  rnlast = 1 then t1.dni else null end) as dni_last
  , max(case when  rnlast = 1 then t1.dncpr else null end) as DNCPR_last

  -- were they *at any time* given a certain code status
  , max(t1.fullcode) as fullcode
  , max(t1.cmo) as cmo
  , max(t1.dnr) as dnr
  , max(t1.dni) as dni
  , max(t1.dncpr) as dncpr

  -- time until their first DNR
  , min(case when t1.dnr = 1 then t1.charttime else null end)
        as dnr_first_charttime
  , min(case when t1.dni = 1 then t1.charttime else null end)
        as dni_first_charttime
  , min(case when t1.dncpr = 1 then t1.charttime else null end)
        as dncpr_first_charttime

  -- first code status of CMO
  , min(case when t1.cmo = 1 then t1.charttime else null end)
        as timecmo_chart

FROM icustays ie
left join t1
  on ie.icustay_id = t1.icustay_id
group by ie.subject_id, ie.hadm_id, ie.icustay_id, ie.intime
  );
17:06:54.698369 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.11 seconds
17:06:54.704737 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.705017 [debug] [Thread-1  ]: On model.mimic.code_status: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.code_status"} */
alter table "postgres"."public"."code_status" rename to "code_status__dbt_backup"
17:06:54.706253 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.711573 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.711781 [debug] [Thread-1  ]: On model.mimic.code_status: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.code_status"} */
alter table "postgres"."public"."code_status__dbt_tmp" rename to "code_status"
17:06:54.712566 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:54.715674 [debug] [Thread-1  ]: On model.mimic.code_status: COMMIT
17:06:54.715875 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.716055 [debug] [Thread-1  ]: On model.mimic.code_status: COMMIT
17:06:54.723096 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:06:54.725347 [debug] [Thread-1  ]: Using postgres connection "model.mimic.code_status"
17:06:54.725546 [debug] [Thread-1  ]: On model.mimic.code_status: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.code_status"} */
drop table if exists "postgres"."public"."code_status__dbt_backup" cascade
17:06:54.727596 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:54.730126 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.730355 [debug] [Thread-1  ]: On model.mimic.code_status: Close
17:06:54.731197 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec3c3940>]}
17:06:54.731661 [info ] [Thread-1  ]: 11 of 107 OK created table model public.code_status ............................ [[32mSELECT 61532[0m in 0.17s]
17:06:54.732207 [debug] [Thread-1  ]: Finished running node model.mimic.code_status
17:06:54.732584 [debug] [Thread-1  ]: Began running node model.mimic.colloid_bolus
17:06:54.733240 [info ] [Thread-1  ]: 12 of 107 START table model public.colloid_bolus ............................... [RUN]
17:06:54.734060 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.colloid_bolus"
17:06:54.734319 [debug] [Thread-1  ]: Began compiling node model.mimic.colloid_bolus
17:06:54.734685 [debug] [Thread-1  ]: Compiling model.mimic.colloid_bolus
17:06:54.736144 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.colloid_bolus"
17:06:54.736835 [debug] [Thread-1  ]: finished collecting timing info
17:06:54.737210 [debug] [Thread-1  ]: Began executing node model.mimic.colloid_bolus
17:06:54.749715 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.colloid_bolus"
17:06:54.750123 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:54.750228 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: BEGIN
17:06:54.750320 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:54.754319 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:06:54.754641 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:54.754837 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.colloid_bolus"} */


  create  table "postgres"."public"."colloid_bolus__dbt_tmp"
  as (
    -- received colloid before admission
-- 226365  --  OR Colloid Intake
-- 226376  --  PACU Colloid Intake

with t1 as
(
  select
    mv.icustay_id
  , mv.starttime as charttime
  -- standardize the units to millilitres
  -- also metavision has floating point precision.. but we only care down to the mL
  , round(case
      when mv.amountuom = 'L'
        then mv.amount * 1000.0
      when mv.amountuom = 'ml'
        then mv.amount
    else null end) as amount
  from inputevents_mv mv
  where mv.itemid in
  (
    220864, --	Albumin 5%	7466 132 7466
    220862, --	Albumin 25%	9851 174 9851
    225174, --	Hetastarch (Hespan) 6%	82 1 82
    225795, --	Dextran 40	38 3 38
    225796  --  Dextran 70
    -- below ITEMIDs not in use
   -- 220861 | Albumin (Human) 20%
   -- 220863 | Albumin (Human) 4%
  )
  and mv.statusdescription != 'Rewritten'
  and
  -- in MetaVision, these ITEMIDs never appear with a null rate
  -- so it is sufficient to check the rate is > 100
    (
      (mv.rateuom = 'mL/hour' and mv.rate > 100)
      OR (mv.rateuom = 'mL/min' and mv.rate > (100/60.0))
      OR (mv.rateuom = 'mL/kg/hour' and (mv.rate*mv.patientweight) > 100)
    )
)
, t2 as
(
  select
    cv.icustay_id
  , cv.charttime
  -- carevue always has units in millilitres (or null)
  , round(cv.amount) as amount
  from inputevents_cv cv
  where cv.itemid in
  (
   30008 --	Albumin 5%
  ,30009 --	Albumin 25%
  ,42832 --	albumin 12.5%
  ,40548 --	ALBUMIN
  ,45403 --	albumin
  ,44203 --	Albumin 12.5%
  ,30181 -- Serum Albumin 5%
  ,46564 -- Albumin
  ,43237 -- 25% Albumin
  ,43353 -- Albumin (human) 25%

  ,30012 --	Hespan
  ,46313 --	6% Hespan

  ,30011 -- Dextran 40
  ,30016 -- Dextrose 10%
  ,42975 --	DEXTRAN DRIP
  ,42944 --	dextran
  ,46336 --	10% Dextran 40/D5W
  ,46729 --	Dextran
  ,40033 --	DEXTRAN
  ,45410 --	10% Dextran 40
  ,42731 -- Dextran40 10%
  )
  and cv.amount > 100
  and cv.amount < 2000
)
-- some colloids are charted in chartevents
, t3 as
(
  select
    ce.icustay_id
  , ce.charttime
  -- carevue always has units in millilitres (or null)
  , round(ce.valuenum) as amount
  from chartevents ce
  where ce.itemid in
  (
      2510 --	DEXTRAN LML 10%
    , 3087 --	DEXTRAN 40  10%
    , 6937 --	Dextran
    , 3087 -- DEXTRAN 40  10%
    , 3088 --	DEXTRAN 40%
  )
  and ce.valuenum is not null
  and ce.valuenum > 100
  and ce.valuenum < 2000
)
select
    icustay_id
  , charttime
  , sum(amount) as colloid_bolus
from t1
-- just because the rate was high enough, does *not* mean the final amount was
where amount > 100
group by t1.icustay_id, t1.charttime
UNION ALL
select
    icustay_id
  , charttime
  , sum(amount) as colloid_bolus
from t2
group by t2.icustay_id, t2.charttime
UNION ALL 
select
    icustay_id
  , charttime
  , sum(amount) as colloid_bolus
from t3
group by t3.icustay_id, t3.charttime
order by icustay_id, charttime
  );
17:06:57.027431 [debug] [Thread-1  ]: SQL status: SELECT 12209 in 2.27 seconds
17:06:57.033960 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:57.034351 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.colloid_bolus"} */
alter table "postgres"."public"."colloid_bolus" rename to "colloid_bolus__dbt_backup"
17:06:57.035815 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:57.039743 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:57.039954 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.colloid_bolus"} */
alter table "postgres"."public"."colloid_bolus__dbt_tmp" rename to "colloid_bolus"
17:06:57.040609 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:57.043852 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: COMMIT
17:06:57.044054 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:57.044247 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: COMMIT
17:06:57.046167 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:57.048623 [debug] [Thread-1  ]: Using postgres connection "model.mimic.colloid_bolus"
17:06:57.048818 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.colloid_bolus"} */
drop table if exists "postgres"."public"."colloid_bolus__dbt_backup" cascade
17:06:57.051224 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:57.054937 [debug] [Thread-1  ]: finished collecting timing info
17:06:57.055185 [debug] [Thread-1  ]: On model.mimic.colloid_bolus: Close
17:06:57.056024 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81790>]}
17:06:57.056574 [info ] [Thread-1  ]: 12 of 107 OK created table model public.colloid_bolus .......................... [[32mSELECT 12209[0m in 2.32s]
17:06:57.057137 [debug] [Thread-1  ]: Finished running node model.mimic.colloid_bolus
17:06:57.057500 [debug] [Thread-1  ]: Began running node model.mimic.crrt_durations
17:06:57.058151 [info ] [Thread-1  ]: 13 of 107 START table model public.crrt_durations .............................. [RUN]
17:06:57.058934 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.crrt_durations"
17:06:57.059179 [debug] [Thread-1  ]: Began compiling node model.mimic.crrt_durations
17:06:57.059553 [debug] [Thread-1  ]: Compiling model.mimic.crrt_durations
17:06:57.060996 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.crrt_durations"
17:06:57.061700 [debug] [Thread-1  ]: finished collecting timing info
17:06:57.061942 [debug] [Thread-1  ]: Began executing node model.mimic.crrt_durations
17:06:57.073197 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.crrt_durations"
17:06:57.073981 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.074211 [debug] [Thread-1  ]: On model.mimic.crrt_durations: BEGIN
17:06:57.074315 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:57.081566 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:57.081838 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.081963 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */


  create  table "postgres"."public"."crrt_durations__dbt_tmp"
  as (
    with crrt_settings as
(
  select ce.icustay_id, ce.charttime
  , max(
      case
        when ce.itemid in
        (
          224149, -- Access Pressure
          224144, -- Blood Flow (ml/min)
          228004, -- Citrate (ACD-A)
          225183, -- Current Goal
          225977, -- Dialysate Fluid
          224154, -- Dialysate Rate
          224151, -- Effluent Pressure
          224150, -- Filter Pressure
          225958, -- Heparin Concentration (units/mL)
          224145, -- Heparin Dose (per hour)
          224191, -- Hourly Patient Fluid Removal
          228005, -- PBP (Prefilter) Replacement Rate
          228006, -- Post Filter Replacement Rate
          225976, -- Replacement Fluid
          224153, -- Replacement Rate
          224152, -- Return Pressure
          226457  -- Ultrafiltrate Output
        ) then 1
      when ce.itemid in
        (
        29,  -- Access mmHg
        173, -- Effluent Press mmHg
        192, -- Filter Pressure mmHg
        624, -- Return Pressure mmHg
        79, -- Blood Flow ml/min
        142, -- Current Goal
        146, -- Dialysate Flow ml/hr
        611, -- Replace Rate ml/hr
        5683 -- Hourly PFR
        ) then 1
      when ce.itemid = 665 and value in ('Active','Clot Increasing','Clots Present','No Clot Present')
         then 1
      when ce.itemid = 147 and value = 'Yes'
         then 1
      else 0 end)
      as RRT
  -- Below indicates that a new instance of CRRT has started
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('New Filter','Reinitiated')
        then 1
      when ce.itemid = 665 and value in ('Initiated')
        then 1
    else 0
   end ) as RRT_start
  -- Below indicates that the current instance of CRRT has ended
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('Discontinued','Recirculating')
        then 1
      -- the only value like DC is "DC'D", use like to avoid apostrophe
      when ce.itemid = 665 and (value = 'Clotted' OR value LIKE 'DC%')
        then 1
      -- Reason for CRRT filter change
      when ce.itemid = 225956
        then 1
    else 0
   end ) as RRT_end
  FROM chartevents ce
  where ce.itemid in
  (
    -- MetaVision ITEMIDs
    -- Below require special handling
    224146, -- System Integrity
    225956,  -- Reason for CRRT Filter Change
    -- Below are settings which indicate CRRT is started/continuing
    224149, -- Access Pressure
    224144, -- Blood Flow (ml/min)
    228004, -- Citrate (ACD-A)
    225183, -- Current Goal
    225977, -- Dialysate Fluid
    224154, -- Dialysate Rate
    224151, -- Effluent Pressure
    224150, -- Filter Pressure
    225958, -- Heparin Concentration (units/mL)
    224145, -- Heparin Dose (per hour)
    224191, -- Hourly Patient Fluid Removal
    228005, -- PBP (Prefilter) Replacement Rate
    228006, -- Post Filter Replacement Rate
    225976, -- Replacement Fluid
    224153, -- Replacement Rate
    224152, -- Return Pressure
    226457, -- Ultrafiltrate Output
    -- CareVue ITEMIDs
    -- Below require special handling
    665,  -- System integrity
    147, -- Dialysate Infusing
    612, -- Replace.Fluid Infuse
    -- Below are settings which indicate CRRT is started/continuing
    29,  -- Access mmHg
    173, -- Effluent Press mmHg
    192, -- Filter Pressure mmHg
    624, -- Return Pressure mmHg
    142, -- Current Goal
    79, -- Blood Flow ml/min
    146, -- Dialysate Flow ml/hr
    611, -- Replace Rate ml/hr
    5683 -- Hourly PFR
  )
  and ce.value is not null
  and coalesce(ce.valuenum,1) != 0 -- non-zero rates/values
  group by icustay_id, charttime
)
-- create various lagged variables for future query
, vd_lag AS
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER W AS charttime_prev_row
    , charttime
    , RRT
    , RRT_start
    , RRT_end
    , LAG(RRT_end, 1) OVER W AS rrt_ended_prev_row
  FROM crrt_settings
  WINDOW w AS 
  (
    partition by icustay_id, case when RRT=1 or RRT_end=1 then 1 else 0 end
    order by charttime
  )
)
, vd1 as
(
  select
      icustay_id
      , charttime
      , RRT
      , RRT_start
      , RRT_end

      -- now we determine if the current event is a new instantiation
      , case
          when RRT_start = 1
            then 1
        -- if there is an end flag, we mark any subsequent event as new
          when RRT_end = 1
            -- note the end is *not* a new event, the *subsequent* row is
            -- so here we output 0
            then 0
          when rrt_ended_prev_row = 1
            then 1
            -- if there is less than 2 hours between CRRT settings, we do not treat this as a new CRRT event
          when DATETIME_DIFF(charttime, charttime_prev_row, 'HOUR') <= 2
            then 0
        else 1
      end as NewCRRT
  -- use the temp table with only settings FROM chartevents
  FROM vd_lag
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new CRRT
  -- this results in a monotonically increasing integer assigned to each CRRT
  , case when RRT_start = 1 or RRT=1 or RRT_end = 1 then
      SUM( NewCRRT )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as num
  --- now we convert CHARTTIME of CRRT settings into durations
  from vd1
  -- now we can isolate to just rows with settings
  -- (before we had rows with start/end flags)
  -- this removes any null values for NewCRRT
  where
    RRT_start = 1 or RRT = 1 or RRT_end = 1
)
-- create the durations for each CRRT instance
, fin as
(
select icustay_id
  , num
  , min(charttime) as starttime
  , max(charttime) as endtime
 	, DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  -- add durations
from vd2
group by icustay_id, num
having min(charttime) != max(charttime)
)
select icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as num
  , starttime, endtime, duration_hours
from fin
order by icustay_id, num
  );
17:06:57.095064 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:06:57.100722 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.100924 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations" rename to "crrt_durations__dbt_backup"
17:06:57.101562 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:57.108691 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.108930 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations__dbt_tmp" rename to "crrt_durations"
17:06:57.109446 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:06:57.112513 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:06:57.112712 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.112903 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:06:57.113779 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:06:57.115604 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:06:57.115801 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
drop table if exists "postgres"."public"."crrt_durations__dbt_backup" cascade
17:06:57.117791 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:06:57.121349 [debug] [Thread-1  ]: finished collecting timing info
17:06:57.122222 [debug] [Thread-1  ]: On model.mimic.crrt_durations: Close
17:06:57.123991 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec3380d0>]}
17:06:57.124554 [info ] [Thread-1  ]: 13 of 107 OK created table model public.crrt_durations ......................... [[32mSELECT 0[0m in 0.07s]
17:06:57.125086 [debug] [Thread-1  ]: Finished running node model.mimic.crrt_durations
17:06:57.125341 [debug] [Thread-1  ]: Began running node model.mimic.crystalloid_bolus
17:06:57.126108 [info ] [Thread-1  ]: 14 of 107 START table model public.crystalloid_bolus ........................... [RUN]
17:06:57.126939 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.crystalloid_bolus"
17:06:57.127275 [debug] [Thread-1  ]: Began compiling node model.mimic.crystalloid_bolus
17:06:57.127493 [debug] [Thread-1  ]: Compiling model.mimic.crystalloid_bolus
17:06:57.128793 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.crystalloid_bolus"
17:06:57.129350 [debug] [Thread-1  ]: finished collecting timing info
17:06:57.129655 [debug] [Thread-1  ]: Began executing node model.mimic.crystalloid_bolus
17:06:57.138062 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.crystalloid_bolus"
17:06:57.138916 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:06:57.139172 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: BEGIN
17:06:57.139371 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:06:57.144715 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:06:57.145377 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:06:57.145786 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crystalloid_bolus"} */


  create  table "postgres"."public"."crystalloid_bolus__dbt_tmp"
  as (
    with t1 as
(
  select
    mv.icustay_id
  , mv.starttime as charttime
  -- standardize the units to millilitres
  -- also metavision has floating point precision.. but we only care down to the mL
  , round(case
      when mv.amountuom = 'L'
        then mv.amount * 1000.0
      when mv.amountuom = 'ml'
        then mv.amount
    else null end) as amount
  from inputevents_mv mv
  where mv.itemid in
  (
    -- 225943 Solution
    225158, -- NaCl 0.9%
    225828, -- LR
    225944, -- Sterile Water
    225797, -- Free Water
	  225159, -- NaCl 0.45%
	  -- 225161, -- NaCl 3% (Hypertonic Saline)
	  225823, -- D5 1/2NS
	  225825, -- D5NS
	  225827, -- D5LR
	  225941, -- D5 1/4NS
	  226089 -- Piggyback
  )
  and mv.statusdescription != 'Rewritten'
  and
  -- in MetaVision, these ITEMIDs appear with a null rate IFF endtime=starttime + 1 minute
  -- so it is sufficient to:
  --    (1) check the rate is > 240 if it exists or
  --    (2) ensure the rate is null and amount > 240 ml
    (
      (mv.rate is not null and mv.rateuom = 'mL/hour' and mv.rate > 248)
      OR (mv.rate is not null and mv.rateuom = 'mL/min' and mv.rate > (248/60.0))
      OR (mv.rate is null and mv.amountuom = 'L' and mv.amount > 0.248)
      OR (mv.rate is null and mv.amountuom = 'ml' and mv.amount > 248)
    )
)
, t2 as
(
  select
    cv.icustay_id
  , cv.charttime
  -- carevue always has units in millilitres
  , round(cv.amount) as amount
  from inputevents_cv cv
  where cv.itemid in
  (
    30015 -- "D5/.45NS" -- mixed colloids and crystalloids
  , 30018 --	.9% Normal Saline
  , 30020 -- .45% Normal Saline
  , 30021 --	Lactated Ringers
  , 30058 --	Free Water Bolus
  , 30060 -- D5NS
  , 30061 -- D5RL
  , 30063 --	IV Piggyback
  , 30065 --	Sterile Water
  -- , 30143 -- 3% Normal Saline
  , 30159 -- D5 Ringers Lact.
  , 30160 -- D5 Normal Saline
  , 30169 --	Sterile H20_GU
  , 30190 -- NS .9%
  , 40850 --	ns bolus
  , 41491 --	fluid bolus
  , 42639 --	bolus
  , 42187 --	free h20
  , 43819 --	1:1 NS Repletion.
  , 41430 --	free water boluses
  , 40712 --	free H20
  , 44160 --	BOLUS
  , 42383 --	cc for cc replace
  , 42297 --	Fluid bolus
  , 42453 --	Fluid Bolus
  , 40872 --	free water
  , 41915 --	FREE WATER
  , 41490 --	NS bolus
  , 46501 --	H2O Bolus
  , 45045 --	WaterBolus
  , 41984 --	FREE H20
  , 41371 --	ns fluid bolus
  , 41582 --	free h20 bolus
  , 41322 --	rl bolus
  , 40778 --	Free H2O
  , 41896 --	ivf boluses
  , 41428 --	ns .9% bolus
  , 43936 --	FREE WATER BOLUSES
  , 44200 --	FLUID BOLUS
  , 41619 --	frfee water boluses
  , 40424 --	free H2O
  , 41457 --	Free H20 intake
  , 41581 --	Water bolus
  , 42844 --	NS fluid bolus
  , 42429 --	Free water
  , 41356 --	IV Bolus
  , 40532 --	FREE H2O
  , 42548 --	NS Bolus
  , 44184 --	LR Bolus
  , 44521 --	LR bolus
  , 44741 --	NS FLUID BOLUS
  , 44126 --	fl bolus
  , 44110 --	RL BOLUS
  , 44633 --	ns boluses
  , 44983 --	Bolus NS
  , 44815 --	LR BOLUS
  , 43986 --	iv bolus
  , 45079 --	500 cc ns bolus
  , 46781 --	lr bolus
  , 45155 --	ns cc/cc replacement
  , 43909 --	H20 BOlus
  , 41467 --	NS IV bolus
  , 44367 --	LR
  , 41743 --	water bolus
  , 40423 --	Bolus
  , 44263 --	fluid bolus ns
  , 42749 --	fluid bolus NS
  , 45480 --	500cc ns bolus
  , 44491 --	.9NS bolus
  , 41695 --	NS fluid boluses
  , 46169 --	free water bolus.
  , 41580 --	free h2o bolus
  , 41392 --	ns b
  , 45989 --	NS Fluid Bolus
  , 45137 --	NS cc/cc
  , 45154 --	Free H20 bolus
  , 44053 --	normal saline bolus
  , 41416 --	free h2o boluses
  , 44761 --	Free H20
  , 41237 --	ns fluid boluses
  , 44426 --	bolus ns
  , 43975 --	FREE H20 BOLUSES
  , 44894 --	N/s 500 ml bolus
  , 41380 --	nsbolus
  , 42671 --	free h2o
  )
  and cv.amount > 248
  and cv.amount <= 2000
  and cv.amountuom = 'ml'
)
select
    icustay_id
  , charttime
  , sum(amount) as crystalloid_bolus
from t1
-- just because the rate was high enough, does *not* mean the final amount was
where amount > 248
group by t1.icustay_id, t1.charttime
UNION
select
    icustay_id
  , charttime
  , sum(amount) as crystalloid_bolus
from t2
group by t2.icustay_id, t2.charttime
order by icustay_id, charttime
  );
17:07:00.663244 [debug] [Thread-1  ]: SQL status: SELECT 155976 in 3.52 seconds
17:07:00.669118 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:07:00.669423 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crystalloid_bolus"} */
alter table "postgres"."public"."crystalloid_bolus" rename to "crystalloid_bolus__dbt_backup"
17:07:00.670216 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:00.674145 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:07:00.674348 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crystalloid_bolus"} */
alter table "postgres"."public"."crystalloid_bolus__dbt_tmp" rename to "crystalloid_bolus"
17:07:00.675150 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:00.678005 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: COMMIT
17:07:00.678260 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:07:00.678446 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: COMMIT
17:07:00.692451 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:00.694598 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crystalloid_bolus"
17:07:00.694879 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crystalloid_bolus"} */
drop table if exists "postgres"."public"."crystalloid_bolus__dbt_backup" cascade
17:07:00.697351 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:00.701703 [debug] [Thread-1  ]: finished collecting timing info
17:07:00.702078 [debug] [Thread-1  ]: On model.mimic.crystalloid_bolus: Close
17:07:00.703216 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec37d820>]}
17:07:00.703841 [info ] [Thread-1  ]: 14 of 107 OK created table model public.crystalloid_bolus ...................... [[32mSELECT 155976[0m in 3.58s]
17:07:00.704450 [debug] [Thread-1  ]: Finished running node model.mimic.crystalloid_bolus
17:07:00.704872 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_dose
17:07:00.705641 [info ] [Thread-1  ]: 15 of 107 START table model public.dobutamine_dose ............................. [RUN]
17:07:00.706420 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_dose"
17:07:00.706762 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_dose
17:07:00.707151 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_dose
17:07:00.708636 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_dose"
17:07:00.709429 [debug] [Thread-1  ]: finished collecting timing info
17:07:00.709819 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_dose
17:07:00.722715 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_dose"
17:07:00.723350 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:00.723554 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: BEGIN
17:07:00.723786 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:00.729592 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:00.729879 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:00.730076 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */


  create  table "postgres"."public"."dobutamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30042,30306) then 1 else 0 end) as vaso -- dobutamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30042,30306) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30042,30306) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30042,30306) then rate else null end) as vaso_rate
    , max(case when itemid in (30042,30306) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30042,30306) -- dobutamine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221653 -- dobutamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:07:05.924626 [debug] [Thread-1  ]: SQL status: SELECT 6548 in 5.19 seconds
17:07:05.929536 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:05.929793 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose" rename to "dobutamine_dose__dbt_backup"
17:07:05.930790 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:05.934469 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:05.934829 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose__dbt_tmp" rename to "dobutamine_dose"
17:07:05.935517 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:05.938510 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:07:05.938775 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:05.938961 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:07:05.941099 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:05.943512 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:07:05.943717 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
drop table if exists "postgres"."public"."dobutamine_dose__dbt_backup" cascade
17:07:05.945541 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:05.948864 [debug] [Thread-1  ]: finished collecting timing info
17:07:05.949092 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: Close
17:07:05.949856 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec41bd00>]}
17:07:05.950315 [info ] [Thread-1  ]: 15 of 107 OK created table model public.dobutamine_dose ........................ [[32mSELECT 6548[0m in 5.24s]
17:07:05.950958 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_dose
17:07:05.951437 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_durations
17:07:05.952138 [info ] [Thread-1  ]: 16 of 107 START table model public.dobutamine_durations ........................ [RUN]
17:07:05.952952 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_durations"
17:07:05.953218 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_durations
17:07:05.953596 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_durations
17:07:05.955543 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_durations"
17:07:05.956396 [debug] [Thread-1  ]: finished collecting timing info
17:07:05.956675 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_durations
17:07:05.969745 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_durations"
17:07:05.970223 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:05.970330 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: BEGIN
17:07:05.970421 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:05.976696 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:05.976981 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:05.977183 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */


  create  table "postgres"."public"."dobutamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dobutamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID
-- Get drug administration data from CareVue first
with vasocv1 as (
  select
    icustay_id,
    charttime -- case statement determining whether the ITEMID is an instance of vasopressor usage
,
    max(
      case
        when itemid in (30042, 30306) then 1
        else 0
      end
    ) as vaso -- dobutamine
    -- the 'stopped' column indicates if a vasopressor has been disconnected
,
    max(
      case
        when itemid in (30042, 30306)
        and (
          stopped = 'Stopped'
          OR stopped like 'D/C%'
        ) then 1
        else 0
      end
    ) as vaso_stopped,
    max(
      case
        when itemid in (30042, 30306)
        and rate is not null then 1
        else 0
      end
    ) as vaso_null,
    max(
      case
        when itemid in (30042, 30306) then rate
        else null
      end
    ) as vaso_rate,
    max(
      case
        when itemid in (30042, 30306) then amount
        else null
      end
    ) as vaso_amount
  FROM
    inputevents_cv
  where
    itemid in (30042, 30306) -- dobutamine
  group by
    icustay_id,
    charttime
),
vasocv2 as (
  select
    v.*,
    sum(vaso_null) over (
      partition by icustay_id
      order by
        charttime
    ) as vaso_partition
  from
    vasocv1 v
),
vasocv3 as (
  select
    v.*,
    first_value(vaso_rate) over (
      partition by icustay_id,
      vaso_partition
      order by
        charttime
    ) as vaso_prevrate_ifnull
  from
    vasocv2 v
),
vasocv4 as (
  select
    icustay_id,
    charttime -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta
,
    vaso,
    vaso_rate,
    vaso_amount,
    vaso_stopped,
    vaso_prevrate_ifnull -- We define start time here
,
    case
      when vaso = 0 then null -- if this is the first instance of the vasoactive drug
      when vaso_rate > 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso,
        vaso_null
        order by
          charttime
      ) is null then 1 -- you often get a string of 0s
      -- we decide not to set these as 1, just because it makes vasonum sequential
      when vaso_rate = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- sometimes you get a string of NULL, associated with 0 volumes
      -- same reason as before, we decide not to set these as 1
      -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
      when vaso_prevrate_ifnull = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- If the last recorded rate was 0, newvaso = 1
      when LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 1 -- If the last recorded vaso was D/C'd, newvaso = 1
      when LAG(vaso_stopped, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 1 then 1 -- ** not sure if the below is needed
      --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
    end as vaso_start
  FROM
    vasocv3
) -- propagate start/stop flags forward in time
,
vasocv5 as (
  select
    v.*,
    SUM(vaso_start) OVER (
      partition by icustay_id,
      vaso
      order by
        charttime
    ) as vaso_first
  FROM
    vasocv4 v
),
vasocv6 as (
  select
    v.* -- We define end time here
,
    case
      when vaso = 0 then null -- If the recorded vaso was D/C'd, this is an end time
      when vaso_stopped = 1 then vaso_first -- If the rate is zero, this is the end time
      when vaso_rate = 0 then vaso_first -- the last row in the table is always a potential end time
      -- this captures patients who die/are discharged while on vasopressors
      -- in principle, this could add an extra end time for the vasopressor
      -- however, since we later group on vaso_start, any extra end times are ignored
      when LEAD(CHARTTIME, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) is null then vaso_first
      else null
    end as vaso_stop
  from
    vasocv5 v
) -- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime
,
vasocv as (
  -- below groups together vasopressor administrations into groups
  select
    icustay_id -- the first non-null rate is considered the starttime
,
    min(
      case
        when vaso_rate is not null then charttime
        else null
      end
    ) as starttime -- the *first* time the first/last flags agree is the stop time for this duration
,
    min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    ) as endtime
  from
    vasocv6
  where
    vaso_first is not null -- bogus data
    and vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
    and icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
  group by
    icustay_id,
    vaso_first
  having
    -- ensure start time is not the same as end time
    min(charttime) != min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    )
    and max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
) -- now we extract the associated data for metavision patients
,
vasomv as (
  select
    icustay_id,
    linkorderid,
    min(starttime) as starttime,
    max(endtime) as endtime
  FROM
    inputevents_mv
  where
    itemid = 221653 -- dobutamine
    and statusdescription != 'Rewritten' -- only valid orders
  group by
    icustay_id,
    linkorderid
)
select
  icustay_id -- generate a sequential integer for convenience
,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasocv
UNION
ALL
select
  icustay_id,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasomv
order by
  icustay_id,
  vasonum
  );
17:07:06.353318 [debug] [Thread-1  ]: SQL status: SELECT 1792 in 0.38 seconds
17:07:06.359850 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:06.360260 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations" rename to "dobutamine_durations__dbt_backup"
17:07:06.361563 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:06.365895 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:06.366089 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations__dbt_tmp" rename to "dobutamine_durations"
17:07:06.366855 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:06.369620 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:07:06.369813 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:06.370024 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:07:06.371373 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:06.373234 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:07:06.373421 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
drop table if exists "postgres"."public"."dobutamine_durations__dbt_backup" cascade
17:07:06.375465 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:06.378215 [debug] [Thread-1  ]: finished collecting timing info
17:07:06.378443 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: Close
17:07:06.379391 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81cd0>]}
17:07:06.379875 [info ] [Thread-1  ]: 16 of 107 OK created table model public.dobutamine_durations ................... [[32mSELECT 1792[0m in 0.43s]
17:07:06.380425 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_durations
17:07:06.380799 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_dose
17:07:06.381470 [info ] [Thread-1  ]: 17 of 107 START table model public.dopamine_dose ............................... [RUN]
17:07:06.382297 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_dose"
17:07:06.382452 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_dose
17:07:06.382817 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_dose
17:07:06.384872 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_dose"
17:07:06.386101 [debug] [Thread-1  ]: finished collecting timing info
17:07:06.387221 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_dose
17:07:06.397220 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_dose"
17:07:06.397844 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:06.398225 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: BEGIN
17:07:06.399045 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:06.405164 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:06.405584 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:06.405861 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */


  create  table "postgres"."public"."dopamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:07:10.374594 [debug] [Thread-1  ]: SQL status: SELECT 38953 in 3.97 seconds
17:07:10.381897 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:10.382261 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose" rename to "dopamine_dose__dbt_backup"
17:07:10.383545 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:10.387721 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:10.387937 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose__dbt_tmp" rename to "dopamine_dose"
17:07:10.388494 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:10.391540 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:07:10.391743 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:10.391921 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:07:10.397540 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:10.399772 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:07:10.399981 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
drop table if exists "postgres"."public"."dopamine_dose__dbt_backup" cascade
17:07:10.401892 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:10.405106 [debug] [Thread-1  ]: finished collecting timing info
17:07:10.405338 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: Close
17:07:10.406078 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81ee0>]}
17:07:10.406426 [info ] [Thread-1  ]: 17 of 107 OK created table model public.dopamine_dose .......................... [[32mSELECT 38953[0m in 4.02s]
17:07:10.407118 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_dose
17:07:10.407633 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_durations
17:07:10.408243 [info ] [Thread-1  ]: 18 of 107 START table model public.dopamine_durations .......................... [RUN]
17:07:10.409018 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_durations"
17:07:10.409422 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_durations
17:07:10.409608 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_durations
17:07:10.413436 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_durations"
17:07:10.414202 [debug] [Thread-1  ]: finished collecting timing info
17:07:10.414343 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_durations
17:07:10.425349 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_durations"
17:07:10.426119 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:10.426344 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: BEGIN
17:07:10.426454 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:10.436630 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:10.436950 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:10.437322 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */


  create  table "postgres"."public"."dopamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dopamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:12.554967 [debug] [Thread-1  ]: SQL status: SELECT 6524 in 2.12 seconds
17:07:12.560722 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:12.560962 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations" rename to "dopamine_durations__dbt_backup"
17:07:12.561710 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:12.565820 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:12.566008 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations__dbt_tmp" rename to "dopamine_durations"
17:07:12.566754 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:12.569854 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:07:12.570048 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:12.570144 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:07:12.571960 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:12.573888 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:07:12.574059 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
drop table if exists "postgres"."public"."dopamine_durations__dbt_backup" cascade
17:07:12.576770 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:12.579718 [debug] [Thread-1  ]: finished collecting timing info
17:07:12.579950 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: Close
17:07:12.580719 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81b80>]}
17:07:12.581179 [info ] [Thread-1  ]: 18 of 107 OK created table model public.dopamine_durations ..................... [[32mSELECT 6524[0m in 2.17s]
17:07:12.581658 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_durations
17:07:12.581819 [debug] [Thread-1  ]: Began running node model.mimic.echo_data
17:07:12.582371 [info ] [Thread-1  ]: 19 of 107 START table model public.echo_data ................................... [RUN]
17:07:12.583297 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.echo_data"
17:07:12.583583 [debug] [Thread-1  ]: Began compiling node model.mimic.echo_data
17:07:12.583845 [debug] [Thread-1  ]: Compiling model.mimic.echo_data
17:07:12.586261 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.echo_data"
17:07:12.587600 [debug] [Thread-1  ]: finished collecting timing info
17:07:12.588145 [debug] [Thread-1  ]: Began executing node model.mimic.echo_data
17:07:12.602183 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.echo_data"
17:07:12.603442 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.603846 [debug] [Thread-1  ]: On model.mimic.echo_data: BEGIN
17:07:12.603974 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:12.610635 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:12.611193 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.611665 [debug] [Thread-1  ]: On model.mimic.echo_data: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.echo_data"} */


  create  table "postgres"."public"."echo_data__dbt_tmp"
  as (
    -- This code extracts structured data from echocardiographies
-- You can join it to the text notes using ROW_ID
-- Just note that ROW_ID will differ across versions of MIMIC-III.


select ROW_ID
  , subject_id, hadm_id
  , chartdate
  -- charttime is always null for echoes..
  -- however, the time is available in the echo text, e.g.:
  -- , substring(ne.text, 'Date/Time: [\[\]0-9*-]+ at ([0-9:]+)') as TIMESTAMP
  -- we can therefore impute it and re-create charttime
  , PARSE_DATETIME
  (
      '%Y-%m-%d%H:%M:%S',
      FORMAT_DATE('%Y-%m-%d', chartdate)
      || REGEXP_EXTRACT(ne.text, 'Date/Time: .+? at ([0-9]+:[0-9]{2})')
      || ':00'
   ) AS charttime

  -- explanation of below substring:
  --  'Indication: ' - matched verbatim
  --  (.*?) - match any character
  --  \n - the end of the line
  -- substring only returns the item in ()s
  -- note: the '?' makes it non-greedy. if you exclude it, it matches until it reaches the *last* \n

  , REGEXP_EXTRACT(ne.text, 'Indication: (.*?)\n') as Indication

  -- sometimes numeric values contain de-id text, e.g. [** Numeric Identifier **]
  -- this removes that text
  , cast(REGEXP_EXTRACT(ne.text, 'Height: \\x28in\\x29 ([0-9]+)') as numeric) as Height
  , cast(REGEXP_EXTRACT(ne.text, 'Weight \\x28lb\\x29: ([0-9]+)\n') as numeric) as Weight
  , cast(REGEXP_EXTRACT(ne.text, 'BSA \\x28m2\\x29: ([0-9]+) m2\n') as numeric) as BSA -- ends in 'm2'
  , REGEXP_EXTRACT(ne.text, 'BP \\x28mm Hg\\x29: (.+)\n') as BP -- Sys/Dias
  , cast(REGEXP_EXTRACT(ne.text, 'BP \\x28mm Hg\\x29: ([0-9]+)/[0-9]+?\n') as numeric) as BPSys -- first part of fraction
  , cast(REGEXP_EXTRACT(ne.text, 'BP \\x28mm Hg\\x29: [0-9]+/([0-9]+?)\n') as numeric) as BPDias -- second part of fraction
  , cast(REGEXP_EXTRACT(ne.text, 'HR \\x28bpm\\x29: ([0-9]+?)\n') as numeric) as HR

  , REGEXP_EXTRACT(ne.text, 'Status: (.*?)\n') as Status
  , REGEXP_EXTRACT(ne.text, 'Test: (.*?)\n') as Test
  , REGEXP_EXTRACT(ne.text, 'Doppler: (.*?)\n') as Doppler
  , REGEXP_EXTRACT(ne.text, 'Contrast: (.*?)\n') as Contrast
  , REGEXP_EXTRACT(ne.text, 'Technical Quality: (.*?)\n') as TechnicalQuality
FROM noteevents ne
where category = 'Echo'
  );
17:07:12.619593 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:07:12.623475 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.623689 [debug] [Thread-1  ]: On model.mimic.echo_data: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.echo_data"} */
alter table "postgres"."public"."echo_data" rename to "echo_data__dbt_backup"
17:07:12.624288 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:12.632340 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.632865 [debug] [Thread-1  ]: On model.mimic.echo_data: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.echo_data"} */
alter table "postgres"."public"."echo_data__dbt_tmp" rename to "echo_data"
17:07:12.633335 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:12.636590 [debug] [Thread-1  ]: On model.mimic.echo_data: COMMIT
17:07:12.636812 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.636928 [debug] [Thread-1  ]: On model.mimic.echo_data: COMMIT
17:07:12.637767 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:12.639706 [debug] [Thread-1  ]: Using postgres connection "model.mimic.echo_data"
17:07:12.639907 [debug] [Thread-1  ]: On model.mimic.echo_data: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.echo_data"} */
drop table if exists "postgres"."public"."echo_data__dbt_backup" cascade
17:07:12.642585 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:12.646176 [debug] [Thread-1  ]: finished collecting timing info
17:07:12.646396 [debug] [Thread-1  ]: On model.mimic.echo_data: Close
17:07:12.647214 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc81fd0>]}
17:07:12.647754 [info ] [Thread-1  ]: 19 of 107 OK created table model public.echo_data .............................. [[32mSELECT 0[0m in 0.06s]
17:07:12.648361 [debug] [Thread-1  ]: Finished running node model.mimic.echo_data
17:07:12.648702 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_ahrq_v37
17:07:12.649379 [info ] [Thread-1  ]: 20 of 107 START table model public.elixhauser_ahrq_v37 ......................... [RUN]
17:07:12.650150 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:12.650349 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_ahrq_v37
17:07:12.650491 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_ahrq_v37
17:07:12.656397 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_ahrq_v37"
17:07:12.657211 [debug] [Thread-1  ]: finished collecting timing info
17:07:12.657772 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_ahrq_v37
17:07:12.667407 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_ahrq_v37"
17:07:12.668054 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:12.668304 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: BEGIN
17:07:12.668416 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:12.673222 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:12.673462 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:12.673587 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */


  create  table "postgres"."public"."elixhauser_ahrq_v37__dbt_tmp"
  as (
    -- This code uses the latest version of Elixhauser provided by AHRQ
 

with eliflg as (
    select
        hadm_id,
        seq_num,
        icd9_code -- note that these codes will seem incomplete at first
        -- for example, CHF is missing a lot of codes referenced in the literature (402.11, 402.91, etc)
        -- these codes are captured by hypertension flags instead
        -- later there are some complicated rules which confirm/reject those codes as chf
,
        CASE
            when icd9_code = '39891' then 1
            when icd9_code between '4280'
            and '4289' then 1
        end as chf
        /* Congestive heart failure */
        -- cardiac arrhythmias is removed in up to date versions
,
        case
            when icd9_code = '42610' then 1
            when icd9_code = '42611' then 1
            when icd9_code = '42613' then 1
            when icd9_code between '4262'
            and '42653' then 1
            when icd9_code between '4266'
            and '42689' then 1
            when icd9_code = '4270' then 1
            when icd9_code = '4272' then 1
            when icd9_code = '42731' then 1
            when icd9_code = '42760' then 1
            when icd9_code = '4279' then 1
            when icd9_code = '7850' then 1
            when icd9_code between 'V450'
            and 'V4509' then 1
            when icd9_code between 'V533'
            and 'V5339' then 1
        end as arythm
        /* Cardiac arrhythmias */
,
        CASE
            when icd9_code between '09320'
            and '09324' then 1
            when icd9_code between '3940'
            and '3971' then 1
            when icd9_code = '3979' then 1
            when icd9_code between '4240'
            and '42499' then 1
            when icd9_code between '7463'
            and '7466' then 1
            when icd9_code = 'V422' then 1
            when icd9_code = 'V433' then 1
        end as valve
        /* Valvular disease */
,
        CASE
            when icd9_code between '41511'
            and '41519' then 1
            when icd9_code between '4160'
            and '4169' then 1
            when icd9_code = '4179' then 1
        end as pulmcirc
        /* Pulmonary circulation disorder */
,
        CASE
            when icd9_code between '4400'
            and '4409' then 1
            when icd9_code between '44100'
            and '4419' then 1
            when icd9_code between '4420'
            and '4429' then 1
            when icd9_code between '4431'
            and '4439' then 1
            when icd9_code between '44421'
            and '44422' then 1
            when icd9_code = '4471' then 1
            when icd9_code = '449' then 1
            when icd9_code = '5571' then 1
            when icd9_code = '5579' then 1
            when icd9_code = 'V434' then 1
        end as perivasc
        /* Peripheral vascular disorder */
,
        CASE
            when icd9_code = '4011' then 1
            when icd9_code = '4019' then 1
            when icd9_code between '64200'
            and '64204' then 1
        end as htn
        /* Hypertension, uncomplicated */
,
        CASE
            when icd9_code = '4010' then 1
            when icd9_code = '4372' then 1
        end as htncx
        /* Hypertension, complicated */
        /******************************************************************/
        /* The following are special, temporary formats used in the       */
        /* creation of the hypertension complicated comorbidity when      */
        /* overlapping with congestive heart failure or renal failure     */
        /* occurs. These temporary formats are referenced in the program  */
        /* called comoanaly2009.txt.                                      */
        /******************************************************************/
,
        CASE
            when icd9_code between '64220'
            and '64224' then 1
        end as htnpreg
        /* Pre-existing hypertension complicating pregnancy */
,
        CASE
            when icd9_code = '40200' then 1
            when icd9_code = '40210' then 1
            when icd9_code = '40290' then 1
            when icd9_code = '40509' then 1
            when icd9_code = '40519' then 1
            when icd9_code = '40599' then 1
        end as htnwochf
        /* Hypertensive heart disease without heart failure */
,
        CASE
            when icd9_code = '40201' then 1
            when icd9_code = '40211' then 1
            when icd9_code = '40291' then 1
        end as htnwchf
        /* Hypertensive heart disease with heart failure */
,
        CASE
            when icd9_code = '40300' then 1
            when icd9_code = '40310' then 1
            when icd9_code = '40390' then 1
            when icd9_code = '40501' then 1
            when icd9_code = '40511' then 1
            when icd9_code = '40591' then 1
            when icd9_code between '64210'
            and '64214' then 1
        end as hrenworf
        /* Hypertensive renal disease without renal failure */
,
        CASE
            when icd9_code = '40301' then 1
            when icd9_code = '40311' then 1
            when icd9_code = '40391' then 1
        end as hrenwrf
        /* Hypertensive renal disease with renal failure */
,
        CASE
            when icd9_code = '40400' then 1
            when icd9_code = '40410' then 1
            when icd9_code = '40490' then 1
        end as hhrwohrf
        /* Hypertensive heart and renal disease without heart or renal failure */
,
        CASE
            when icd9_code = '40401' then 1
            when icd9_code = '40411' then 1
            when icd9_code = '40491' then 1
        end as hhrwchf
        /* Hypertensive heart and renal disease with heart failure */
,
        CASE
            when icd9_code = '40402' then 1
            when icd9_code = '40412' then 1
            when icd9_code = '40492' then 1
        end as hhrwrf
        /* Hypertensive heart and renal disease with renal failure */
,
        CASE
            when icd9_code = '40403' then 1
            when icd9_code = '40413' then 1
            when icd9_code = '40493' then 1
        end as hhrwhrf
        /* Hypertensive heart and renal disease with heart and renal failure */
,
        CASE
            when icd9_code between '64270'
            and '64274' then 1
            when icd9_code between '64290'
            and '64294' then 1
        end as ohtnpreg
        /* Other hypertension in pregnancy */
        /******************** End Temporary Formats ***********************/
,
        CASE
            when icd9_code between '3420'
            and '3449' then 1
            when icd9_code between '43820'
            and '43853' then 1
            when icd9_code = '78072' then 1
        end as para
        /* Paralysis */
,
        CASE
            when icd9_code between '3300'
            and '3319' then 1
            when icd9_code = '3320' then 1
            when icd9_code = '3334' then 1
            when icd9_code = '3335' then 1
            when icd9_code = '3337' then 1
            when icd9_code in ('33371', '33372', '33379', '33385', '33394') then 1
            when icd9_code between '3340'
            and '3359' then 1
            when icd9_code = '3380' then 1
            when icd9_code = '340' then 1
            when icd9_code between '3411'
            and '3419' then 1
            when icd9_code between '34500'
            and '34511' then 1
            when icd9_code between '3452'
            and '3453' then 1
            when icd9_code between '34540'
            and '34591' then 1
            when icd9_code between '34700'
            and '34701' then 1
            when icd9_code between '34710'
            and '34711' then 1
            when icd9_code = '3483' then 1 -- discontinued icd-9
            when icd9_code between '64940'
            and '64944' then 1
            when icd9_code = '7687' then 1
            when icd9_code between '76870'
            and '76873' then 1
            when icd9_code = '7803' then 1
            when icd9_code = '78031' then 1
            when icd9_code = '78032' then 1
            when icd9_code = '78033' then 1
            when icd9_code = '78039' then 1
            when icd9_code = '78097' then 1
            when icd9_code = '7843' then 1
        end as neuro
        /* Other neurological */
,
        CASE
            when icd9_code between '490'
            and '4928' then 1
            when icd9_code between '49300'
            and '49392' then 1
            when icd9_code between '494'
            and '4941' then 1
            when icd9_code between '4950'
            and '505' then 1
            when icd9_code = '5064' then 1
        end as chrnlung
        /* Chronic pulmonary disease */
,
        CASE
            when icd9_code between '25000'
            and '25033' then 1
            when icd9_code between '64800'
            and '64804' then 1
            when icd9_code between '24900'
            and '24931' then 1
        end as dm
        /* Diabetes w/o chronic complications*/
,
        CASE
            when icd9_code between '25040'
            and '25093' then 1
            when icd9_code = '7751' then 1
            when icd9_code between '24940'
            and '24991' then 1
        end as dmcx
        /* Diabetes w/ chronic complications */
,
        CASE
            when icd9_code between '243'
            and '2442' then 1
            when icd9_code = '2448' then 1
            when icd9_code = '2449' then 1
        end as hypothy
        /* Hypothyroidism */
,
        CASE
            when icd9_code = '585' then 1 -- discontinued code
            when icd9_code = '5853' then 1
            when icd9_code = '5854' then 1
            when icd9_code = '5855' then 1
            when icd9_code = '5856' then 1
            when icd9_code = '5859' then 1
            when icd9_code = '586' then 1
            when icd9_code = 'V420' then 1
            when icd9_code = 'V451' then 1
            when icd9_code between 'V560'
            and 'V5632' then 1
            when icd9_code = 'V568' then 1
            when icd9_code between 'V4511'
            and 'V4512' then 1
        end as renlfail
        /* Renal failure */
,
        CASE
            when icd9_code = '07022' then 1
            when icd9_code = '07023' then 1
            when icd9_code = '07032' then 1
            when icd9_code = '07033' then 1
            when icd9_code = '07044' then 1
            when icd9_code = '07054' then 1
            when icd9_code = '4560' then 1
            when icd9_code = '4561' then 1
            when icd9_code = '45620' then 1
            when icd9_code = '45621' then 1
            when icd9_code = '5710' then 1
            when icd9_code = '5712' then 1
            when icd9_code = '5713' then 1
            when icd9_code between '57140'
            and '57149' then 1
            when icd9_code = '5715' then 1
            when icd9_code = '5716' then 1
            when icd9_code = '5718' then 1
            when icd9_code = '5719' then 1
            when icd9_code = '5723' then 1
            when icd9_code = '5728' then 1
            when icd9_code = '5735' then 1
            when icd9_code = 'V427' then 1
        end as liver
        /* Liver disease */
,
        CASE
            when icd9_code = '53141' then 1
            when icd9_code = '53151' then 1
            when icd9_code = '53161' then 1
            when icd9_code = '53170' then 1
            when icd9_code = '53171' then 1
            when icd9_code = '53191' then 1
            when icd9_code = '53241' then 1
            when icd9_code = '53251' then 1
            when icd9_code = '53261' then 1
            when icd9_code = '53270' then 1
            when icd9_code = '53271' then 1
            when icd9_code = '53291' then 1
            when icd9_code = '53341' then 1
            when icd9_code = '53351' then 1
            when icd9_code = '53361' then 1
            when icd9_code = '53370' then 1
            when icd9_code = '53371' then 1
            when icd9_code = '53391' then 1
            when icd9_code = '53441' then 1
            when icd9_code = '53451' then 1
            when icd9_code = '53461' then 1
            when icd9_code = '53470' then 1
            when icd9_code = '53471' then 1
            when icd9_code = '53491' then 1
        end as ulcer
        /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */
,
        CASE
            when icd9_code between '042'
            and '0449' then 1
        end as aids
        /* HIV and AIDS */
,
        CASE
            when icd9_code between '20000'
            and '20238' then 1
            when icd9_code between '20250'
            and '20301' then 1
            when icd9_code = '2386' then 1
            when icd9_code = '2733' then 1
            when icd9_code between '20302'
            and '20382' then 1
        end as lymph
        /* Lymphoma */
,
        CASE
            when icd9_code between '1960'
            and '1991' then 1
            when icd9_code between '20970'
            and '20975' then 1
            when icd9_code = '20979' then 1
            when icd9_code = '78951' then 1
        end as mets
        /* Metastatic cancer */
,
        CASE
            when icd9_code between '1400'
            and '1729' then 1
            when icd9_code between '1740'
            and '1759' then 1
            when icd9_code between '179'
            and '1958' then 1
            when icd9_code between '20900'
            and '20924' then 1
            when icd9_code between '20925'
            and '2093' then 1
            when icd9_code between '20930'
            and '20936' then 1
            when icd9_code between '25801'
            and '25803' then 1
        end as tumor
        /* Solid tumor without metastasis */
,
        CASE
            when icd9_code = '7010' then 1
            when icd9_code between '7100'
            and '7109' then 1
            when icd9_code between '7140'
            and '7149' then 1
            when icd9_code between '7200'
            and '7209' then 1
            when icd9_code = '725' then 1
        end as arth
        /* Rheumatoid arthritis/collagen vascular diseases */
,
        CASE
            when icd9_code between '2860'
            and '2869' then 1
            when icd9_code = '2871' then 1
            when icd9_code between '2873'
            and '2875' then 1
            when icd9_code between '64930'
            and '64934' then 1
            when icd9_code = '28984' then 1
        end as coag
        /* Coagulation deficiency */
,
        CASE
            when icd9_code = '2780' then 1
            when icd9_code = '27800' then 1
            when icd9_code = '27801' then 1
            when icd9_code = '27803' then 1
            when icd9_code between '64910'
            and '64914' then 1
            when icd9_code between 'V8530'
            and 'V8539' then 1
            when icd9_code = 'V854' then 1 -- hierarchy used for AHRQ v3.6 and earlier
            when icd9_code between 'V8541'
            and 'V8545' then 1
            when icd9_code = 'V8554' then 1
            when icd9_code = '79391' then 1
        end as obese
        /* Obesity      */
,
        CASE
            when icd9_code between '260'
            and '2639' then 1
            when icd9_code between '78321'
            and '78322' then 1
        end as wghtloss
        /* Weight loss */
,
        CASE
            when icd9_code between '2760'
            and '2769' then 1
        end as lytes
        /* Fluid and electrolyte disorders - note:
         this comorbidity should be dropped when
         used with the AHRQ Patient Safety Indicators*/
,
        CASE
            when icd9_code = '2800' then 1
            when icd9_code between '64820'
            and '64824' then 1
        end as bldloss
        /* Blood loss anemia */
,
        CASE
            when icd9_code between '2801'
            and '2819' then 1
            when icd9_code between '28521'
            and '28529' then 1
            when icd9_code = '2859' then 1
        end as anemdef
        /* Deficiency anemias */
,
        CASE
            when icd9_code between '2910'
            and '2913' then 1
            when icd9_code = '2915' then 1
            when icd9_code = '2918' then 1
            when icd9_code = '29181' then 1
            when icd9_code = '29182' then 1
            when icd9_code = '29189' then 1
            when icd9_code = '2919' then 1
            when icd9_code between '30300'
            and '30393' then 1
            when icd9_code between '30500'
            and '30503' then 1
        end as alcohol
        /* Alcohol abuse */
,
        CASE
            when icd9_code = '2920' then 1
            when icd9_code between '29282'
            and '29289' then 1
            when icd9_code = '2929' then 1
            when icd9_code between '30400'
            and '30493' then 1
            when icd9_code between '30520'
            and '30593' then 1
            when icd9_code between '64830'
            and '64834' then 1
        end as drug
        /* Drug abuse */
,
        CASE
            when icd9_code between '29500'
            and '2989' then 1
            when icd9_code = '29910' then 1
            when icd9_code = '29911' then 1
        end as psych
        /* Psychoses */
,
        CASE
            when icd9_code = '3004' then 1
            when icd9_code = '30112' then 1
            when icd9_code = '3090' then 1
            when icd9_code = '3091' then 1
            when icd9_code = '311' then 1
        end as depress
        /* Depression */
    from
        diagnoses_icd icd
    WHERE
        seq_num = 1
) -- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
,
eligrp as (
    select
        hadm_id,
        max(chf) as chf,
        max(arythm) as arythm,
        max(valve) as valve,
        max(pulmcirc) as pulmcirc,
        max(perivasc) as perivasc,
        max(htn) as htn,
        max(htncx) as htncx,
        max(htnpreg) as htnpreg,
        max(htnwochf) as htnwochf,
        max(htnwchf) as htnwchf,
        max(hrenworf) as hrenworf,
        max(hrenwrf) as hrenwrf,
        max(hhrwohrf) as hhrwohrf,
        max(hhrwchf) as hhrwchf,
        max(hhrwrf) as hhrwrf,
        max(hhrwhrf) as hhrwhrf,
        max(ohtnpreg) as ohtnpreg,
        max(para) as para,
        max(neuro) as neuro,
        max(chrnlung) as chrnlung,
        max(dm) as dm,
        max(dmcx) as dmcx,
        max(hypothy) as hypothy,
        max(renlfail) as renlfail,
        max(liver) as liver,
        max(ulcer) as ulcer,
        max(aids) as aids,
        max(lymph) as lymph,
        max(mets) as mets,
        max(tumor) as tumor,
        max(arth) as arth,
        max(coag) as coag,
        max(obese) as obese,
        max(wghtloss) as wghtloss,
        max(lytes) as lytes,
        max(bldloss) as bldloss,
        max(anemdef) as anemdef,
        max(alcohol) as alcohol,
        max(drug) as drug,
        max(psych) as psych,
        max(depress) as depress
    from
        eliflg
    group by
        hadm_id
) -- DRG FILTER --
,
msdrg as (
    select
        hadm_id
        /**** V29 MS-DRG Formats ****/
        /* Cardiac */
,
        case
            when d.drg_code between 001
            and 002 then 1
            when d.drg_code between 215
            and 238 then 1
            when d.drg_code between 242
            and 252 then 1
            when d.drg_code between 253
            and 254 then 1
            when d.drg_code between 258
            and 262 then 1
            when d.drg_code between 265
            and 267 then 1
            when d.drg_code between 280
            and 293 then 1
            when d.drg_code between 296
            and 298 then 1
            when d.drg_code between 302
            and 303 then 1
            when d.drg_code between 306
            and 313 then 1
            else 0
        end as carddrg
        /* Peripheral vascular */
,
        case
            when d.drg_code between 299
            and 301 then 1
            else 0
        end as peridrg
        /* Renal */
,
        case
            when d.drg_code = 652 then 1
            when d.drg_code between 656
            and 661 then 1
            when d.drg_code between 673
            and 675 then 1
            when d.drg_code between 682
            and 700 then 1
            else 0
        end as renaldrg
        /* Nervous system */
,
        case
            when d.drg_code between 020
            and 042 then 1
            when d.drg_code between 052
            and 103 then 1
            else 0
        end as nervdrg
        /* Cerebrovascular */
,
        case
            when d.drg_code between 020
            and 022 then 1
            when d.drg_code between 034
            and 039 then 1
            when d.drg_code between 064
            and 072 then 1
            else 0
        end as ceredrg
        /* COPD asthma */
,
        case
            when d.drg_code between 190
            and 192 then 1
            when d.drg_code between 202
            and 203 then 1
            else 0
        end as pulmdrg
        /* Diabetes */
,
        case
            when d.drg_code between 637
            and 639 then 1
            else 0
        end as DIABDRG
        /* Thyroid endocrine */
,
        case
            when d.drg_code between 625
            and 627 then 1
            when d.drg_code between 643
            and 645 then 1
            else 0
        end as hypodrg
        /* Kidney transp, renal fail/dialysis */
,
        case
            when d.drg_code = 652 then 1
            when d.drg_code between 682
            and 685 then 1
            else 0
        end as renfdrg
        /* Liver */
,
        case
            when d.drg_code between 420
            and 425 then 1
            when d.drg_code between 432
            and 434 then 1
            when d.drg_code between 441
            and 446 then 1
            else 0
        end as liverdrg
        /* GI hemorrhage or ulcer */
,
        case
            when d.drg_code between 377
            and 384 then 1
            else 0
        end as ulcedrg
        /* Human immunodeficiency virus */
,
        case
            when d.drg_code between 969
            and 970 then 1
            when d.drg_code between 974
            and 977 then 1
            else 0
        end as hivdrg
        /* Leukemia/lymphoma */
,
        case
            when d.drg_code between 820
            and 830 then 1
            when d.drg_code between 834
            and 849 then 1
            else 0
        end as leukdrg
        /* Cancer, lymphoma */
,
        case
            when d.drg_code = 054 then 1
            when d.drg_code = 055 then 1
            when d.drg_code between 146
            and 148 then 1
            when d.drg_code between 180
            and 182 then 1
            when d.drg_code between 374
            and 376 then 1
            when d.drg_code between 435
            and 437 then 1
            when d.drg_code between 542
            and 544 then 1
            when d.drg_code between 582
            and 585 then 1
            when d.drg_code between 597
            and 599 then 1
            when d.drg_code between 656
            and 658 then 1
            when d.drg_code between 686
            and 688 then 1
            when d.drg_code between 715
            and 716 then 1
            when d.drg_code between 722
            and 724 then 1
            when d.drg_code between 736
            and 741 then 1
            when d.drg_code between 754
            and 756 then 1
            when d.drg_code between 826
            and 830 then 1
            when d.drg_code between 843
            and 849 then 1
            else 0
        end as cancdrg
        /* Connective tissue */
,
        case
            when d.drg_code between 545
            and 547 then 1
            else 0
        end as arthdrg
        /* Nutrition/metabolic */
,
        case
            when d.drg_code between 640
            and 641 then 1
            else 0
        end as nutrdrg
        /* Anemia */
,
        case
            when d.drg_code between 808
            and 812 then 1
            else 0
        end as anemdrg
        /* Alcohol drug */
,
        case
            when d.drg_code between 894
            and 897 then 1
            else 0
        end as alcdrg
        /*Coagulation disorders*/
,
        case
            when d.drg_code = 813 then 1
            else 0
        end as coagdrg
        /*Hypertensive Complicated  */
,
        case
            when d.drg_code = 077 then 1
            when d.drg_code = 078 then 1
            when d.drg_code = 304 then 1
            else 0
        end as htncxdrg
        /*Hypertensive Uncomplicated  */
,
        case
            when d.drg_code = 079 then 1
            when d.drg_code = 305 then 1
            else 0
        end as htndrg
        /* Psychoses */
,
        case
            when d.drg_code = 885 then 1
            else 0
        end as psydrg
        /* Obesity */
,
        case
            when d.drg_code between 619
            and 621 then 1
            else 0
        end as obesedrg
        /* Depressive Neuroses */
,
        case
            when d.drg_code = 881 then 1
            else 0
        end as deprsdrg
    from
        (
            select
                hadm_id,
                drg_type,
                cast(drg_code as numeric) as drg_code
            from
                drgcodes
            where
                drg_type = 'MS'
        ) d
),
hcfadrg as (
    select
        hadm_id
        /** V24 DRG Formats  **/
        /* Cardiac */
,
        case
            when d.drg_code between 103
            and 112 then 1
            when d.drg_code between 115
            and 118 then 1
            when d.drg_code between 121
            and 127 then 1
            when d.drg_code = 129 then 1
            when d.drg_code = 132 then 1
            when d.drg_code = 133 then 1
            when d.drg_code between 135
            and 143 then 1
            when d.drg_code between 514
            and 518 then 1
            when d.drg_code between 525
            and 527 then 1
            when d.drg_code between 535
            and 536 then 1
            when d.drg_code between 547
            and 550 then 1
            when d.drg_code between 551
            and 558 then 1
            else 0
        end as carddrg
        /* Peripheral vascular */
,
        case
            when d.drg_code = 130 then 1
            when d.drg_code = 131 then 1
            else 0
        end as peridrg
        /* Renal */
,
        case
            when d.drg_code between 302
            and 305 then 1
            when d.drg_code between 315
            and 333 then 1
            else 0
        end as renaldrg
        /* Nervous system */
,
        case
            when d.drg_code between 1
            and 35 then 1
            when d.drg_code = 524 then 1
            when d.drg_code between 528
            and 534 then 1
            when d.drg_code = 543 then 1
            when d.drg_code between 559
            and 564 then 1
            when d.drg_code = 577 then 1
            else 0
        end as nervdrg
        /* Cerebrovascular */
,
        case
            when d.drg_code = 5 then 1
            when d.drg_code between 14
            and 17 then 1
            when d.drg_code = 524 then 1
            when d.drg_code = 528 then 1
            when d.drg_code between 533
            and 534 then 1
            when d.drg_code = 577 then 1
            else 0
        end as ceredrg
        /* COPD asthma */
,
        case
            when d.drg_code = 88 then 1
            when d.drg_code between 96
            and 98 then 1
            else 0
        end as pulmdrg
        /* Diabetes */
,
        case
            when d.drg_code = 294 then 1
            when d.drg_code = 295 then 1
            else 0
        end as diabdrg
        /* Thyroid endocrine */
,
        case
            when d.drg_code = 290 then 1
            when d.drg_code = 300 then 1
            when d.drg_code = 301 then 1
            else 0
        end as hypodrg
        /* Kidney transp, renal fail/dialysis */
,
        case
            when d.drg_code = 302 then 1
            when d.drg_code = 316 then 1
            when d.drg_code = 317 then 1
            else 0
        end as renfdrg
        /* Liver */
,
        case
            when d.drg_code between 199
            and 202 then 1
            when d.drg_code between 205
            and 208 then 1
            else 0
        end as liverdrg
        /* GI hemorrhage or ulcer */
,
        case
            when d.drg_code between 174
            and 178 then 1
            else 0
        end as ulcedrg
        /* Human immunodeficiency virus */
,
        case
            when d.drg_code = 488 then 1
            when d.drg_code = 489 then 1
            when d.drg_code = 490 then 1
            else 0
        end as hivdrg
        /* Leukemia/lymphoma */
,
        case
            when d.drg_code between 400
            and 414 then 1
            when d.drg_code = 473 then 1
            when d.drg_code = 492 then 1
            when d.drg_code between 539
            and 540 then 1
            else 0
        end as leukdrg
        /* Cancer, lymphoma */
,
        case
            when d.drg_code = 10 then 1
            when d.drg_code = 11 then 1
            when d.drg_code = 64 then 1
            when d.drg_code = 82 then 1
            when d.drg_code = 172 then 1
            when d.drg_code = 173 then 1
            when d.drg_code = 199 then 1
            when d.drg_code = 203 then 1
            when d.drg_code = 239 then 1
            when d.drg_code between 257
            and 260 then 1
            when d.drg_code = 274 then 1
            when d.drg_code = 275 then 1
            when d.drg_code = 303 then 1
            when d.drg_code = 318 then 1
            when d.drg_code = 319 then 1
            when d.drg_code = 338 then 1
            when d.drg_code = 344 then 1
            when d.drg_code = 346 then 1
            when d.drg_code = 347 then 1
            when d.drg_code = 354 then 1
            when d.drg_code = 355 then 1
            when d.drg_code = 357 then 1
            when d.drg_code = 363 then 1
            when d.drg_code = 366 then 1
            when d.drg_code = 367 then 1
            when d.drg_code between 406
            and 414 then 1
            else 0
        end as cancdrg
        /* Connective tissue */
,
        case
            when d.drg_code = 240 then 1
            when d.drg_code = 241 then 1
            else 0
        end as arthdrg
        /* Nutrition/metabolic */
,
        case
            when d.drg_code between 296
            and 298 then 1
            else 0
        end as nutrdrg
        /* Anemia */
,
        case
            when d.drg_code = 395 then 1
            when d.drg_code = 396 then 1
            when d.drg_code = 574 then 1
            else 0
        end as anemdrg
        /* Alcohol drug */
,
        case
            when d.drg_code between 433
            and 437 then 1
            when d.drg_code between 521
            and 523 then 1
            else 0
        end as alcdrg
        /* Coagulation disorders */
,
        case
            when d.drg_code = 397 then 1
            else 0
        end as coagdrg
        /* Hypertensive Complicated */
,
        case
            when d.drg_code = 22 then 1
            when d.drg_code = 134 then 1
            else 0
        end as htncxdrg
        /* Hypertensive Uncomplicated */
,
        case
            when d.drg_code = 134 then 1
            else 0
        end as htndrg
        /* Psychoses */
,
        case
            when d.drg_code = 430 then 1
            else 0
        end as psydrg
        /* Obesity */
,
        case
            when d.drg_code = 288 then 1
            else 0
        end as obesedrg
        /* Depressive Neuroses */
,
        case
            when d.drg_code = 426 then 1
            else 0
        end as deprsdrg
    from
        (
            select
                hadm_id,
                drg_type,
                cast(drg_code as numeric) as drg_code
            from
                drgcodes
            where
                drg_type = 'HCFA'
        ) d
) -- merge DRG groups together
,
drggrp as (
    select
        hadm_id,
        max(carddrg) as carddrg,
        max(peridrg) as peridrg,
        max(renaldrg) as renaldrg,
        max(nervdrg) as nervdrg,
        max(ceredrg) as ceredrg,
        max(pulmdrg) as pulmdrg,
        max(diabdrg) as diabdrg,
        max(hypodrg) as hypodrg,
        max(renfdrg) as renfdrg,
        max(liverdrg) as liverdrg,
        max(ulcedrg) as ulcedrg,
        max(hivdrg) as hivdrg,
        max(leukdrg) as leukdrg,
        max(cancdrg) as cancdrg,
        max(arthdrg) as arthdrg,
        max(nutrdrg) as nutrdrg,
        max(anemdrg) as anemdrg,
        max(alcdrg) as alcdrg,
        max(coagdrg) as coagdrg,
        max(htncxdrg) as htncxdrg,
        max(htndrg) as htndrg,
        max(psydrg) as psydrg,
        max(obesedrg) as obesedrg,
        max(deprsdrg) as deprsdrg
    from
        (
            select
                d1.*
            from
                msdrg d1
            UNION
            DISTINCT
            select
                d1.*
            from
                hcfadrg d1
        ) d
    group by
        d.hadm_id
) -- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select
    adm.subject_id,
    adm.hadm_id,
    case
        when carddrg = 1 then 0 -- DRG filter
        when chf = 1 then 1
        when htnwchf = 1 then 1
        when hhrwchf = 1 then 1
        when hhrwhrf = 1 then 1
        else 0
    end as congestive_heart_failure,
    case
        when carddrg = 1 then 0 -- DRG filter
        when arythm = 1 then 1
        else 0
    end as cardiac_arrhythmias,
    case
        when carddrg = 1 then 0
        when valve = 1 then 1
        else 0
    end as valvular_disease,
    case
        when carddrg = 1
        or pulmdrg = 1 then 0
        when pulmcirc = 1 then 1
        else 0
    end as pulmonary_circulation,
    case
        when peridrg = 1 then 0
        when perivasc = 1 then 1
        else 0
    end as peripheral_vascular -- we combine 'htn' and 'htncx' into 'HYPERTENSION'
    -- note 'htn' (hypertension) is only 1 if 'htncx' (complicated hypertension) is 0
    -- also if htncxdrg = 1, then htndrg = 1
    -- In the original Sas code, it appears that:
    --  HTN can be 1
    --  HTNCX is set to 0 by DRGs
    --  but HTN_C is still 1, because HTN is 1
    -- so we have to do this complex addition.
,
    case
        when (
            -- first hypertension
            case
                when htndrg = 0 then 0
                when htn = 1 then 1
                else 0
            end
        ) + (
            -- next complicated hypertension
            case
                when htncx = 1
                and htncxdrg = 1 then 0
                when htnpreg = 1
                and htncxdrg = 1 then 0
                when htnwochf = 1
                and (
                    htncxdrg = 1
                    OR carddrg = 1
                ) then 0
                when htnwchf = 1
                and htncxdrg = 1 then 0
                when htnwchf = 1
                and carddrg = 1 then 0
                when hrenworf = 1
                and (
                    htncxdrg = 1
                    or renaldrg = 1
                ) then 0
                when hrenwrf = 1
                and htncxdrg = 1 then 0
                when hrenwrf = 1
                and renaldrg = 1 then 0
                when hhrwohrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwchf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwhrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when ohtnpreg = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when htncx = 1 then 1
                when htnpreg = 1 then 1
                when htnwochf = 1 then 1
                when htnwchf = 1 then 1
                when hrenworf = 1 then 1
                when hrenwrf = 1 then 1
                when hhrwohrf = 1 then 1
                when hhrwchf = 1 then 1
                when hhrwrf = 1 then 1
                when hhrwhrf = 1 then 1
                when ohtnpreg = 1 then 1
                else 0
            end
        ) > 0 then 1
        else 0
    end as hypertension,
    case
        when ceredrg = 1 then 0
        when para = 1 then 1
        else 0
    end as paralysis,
    case
        when nervdrg = 1 then 0
        when neuro = 1 then 1
        else 0
    end as other_neurological,
    case
        when pulmdrg = 1 then 0
        when chrnlung = 1 then 1
        else 0
    end as chronic_pulmonary,
    case
        -- only the more severe comorbidity (complicated diabetes) is kept
        when diabdrg = 1 then 0
        when dmcx = 1 then 0
        when dm = 1 then 1
        else 0
    end as diabetes_uncomplicated,
    case
        when diabdrg = 1 then 0
        when dmcx = 1 then 1
        else 0
    end as diabetes_complicated,
    case
        when hypodrg = 1 then 0
        when hypothy = 1 then 1
        else 0
    end as hypothyroidism,
    case
        when renaldrg = 1 then 0
        when renlfail = 1 then 1
        when hrenwrf = 1 then 1
        when hhrwrf = 1 then 1
        when hhrwhrf = 1 then 1
        else 0
    end as renal_failure,
    case
        when liverdrg = 1 then 0
        when liver = 1 then 1
        else 0
    end as liver_disease,
    case
        when ulcedrg = 1 then 0
        when ulcer = 1 then 1
        else 0
    end as peptic_ulcer,
    case
        when hivdrg = 1 then 0
        when aids = 1 then 1
        else 0
    end as aids,
    case
        when leukdrg = 1 then 0
        when lymph = 1 then 1
        else 0
    end as lymphoma,
    case
        when cancdrg = 1 then 0
        when mets = 1 then 1
        else 0
    end as metastatic_cancer,
    case
        when cancdrg = 1 then 0 -- only the more severe comorbidity (metastatic cancer) is kept
        when mets = 1 then 0
        when tumor = 1 then 1
        else 0
    end as solid_tumor,
    case
        when arthdrg = 1 then 0
        when arth = 1 then 1
        else 0
    end as rheumatoid_arthritis,
    case
        when coagdrg = 1 then 0
        when coag = 1 then 1
        else 0
    end as coagulopathy,
    case
        when nutrdrg = 1
        OR obesedrg = 1 then 0
        when obese = 1 then 1
        else 0
    end as obesity,
    case
        when nutrdrg = 1 then 0
        when wghtloss = 1 then 1
        else 0
    end as weight_loss,
    case
        when nutrdrg = 1 then 0
        when lytes = 1 then 1
        else 0
    end as fluid_electrolyte,
    case
        when anemdrg = 1 then 0
        when bldloss = 1 then 1
        else 0
    end as blood_loss_anemia,
    case
        when anemdrg = 1 then 0
        when anemdef = 1 then 1
        else 0
    end as deficiency_anemias,
    case
        when alcdrg = 1 then 0
        when alcohol = 1 then 1
        else 0
    end as alcohol_abuse,
    case
        when alcdrg = 1 then 0
        when drug = 1 then 1
        else 0
    end as drug_abuse,
    case
        when psydrg = 1 then 0
        when psych = 1 then 1
        else 0
    end as psychoses,
    case
        when deprsdrg = 1 then 0
        when depress = 1 then 1
        else 0
    end as depression
FROM
    admissions adm
    left join eligrp eli on adm.hadm_id = eli.hadm_id
    left join drggrp d on adm.hadm_id = d.hadm_id
order by
    adm.hadm_id
  );
17:07:14.270820 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 1.6 seconds
17:07:14.277952 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:14.278371 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
alter table "postgres"."public"."elixhauser_ahrq_v37" rename to "elixhauser_ahrq_v37__dbt_backup"
17:07:14.280030 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:14.285003 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:14.285199 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
alter table "postgres"."public"."elixhauser_ahrq_v37__dbt_tmp" rename to "elixhauser_ahrq_v37"
17:07:14.286044 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:14.289285 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: COMMIT
17:07:14.289512 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:14.289798 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: COMMIT
17:07:14.293255 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:14.295953 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:07:14.296157 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
drop table if exists "postgres"."public"."elixhauser_ahrq_v37__dbt_backup" cascade
17:07:14.299049 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:14.303118 [debug] [Thread-1  ]: finished collecting timing info
17:07:14.303366 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: Close
17:07:14.304319 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc85250>]}
17:07:14.304868 [info ] [Thread-1  ]: 20 of 107 OK created table model public.elixhauser_ahrq_v37 .................... [[32mSELECT 58976[0m in 1.65s]
17:07:14.305556 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_ahrq_v37
17:07:14.305986 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_ahrq_v37_no_drg
17:07:14.306721 [info ] [Thread-1  ]: 21 of 107 START table model public.elixhauser_ahrq_v37_no_drg .................. [RUN]
17:07:14.307883 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.308232 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_ahrq_v37_no_drg
17:07:14.308603 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_ahrq_v37_no_drg
17:07:14.314198 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.315159 [debug] [Thread-1  ]: finished collecting timing info
17:07:14.315497 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_ahrq_v37_no_drg
17:07:14.324953 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.326170 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.326400 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: BEGIN
17:07:14.326859 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:14.333084 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:14.333343 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.333446 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */


  create  table "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_tmp"
  as (
    -- This code uses the latest version of Elixhauser provided by AHRQ
-- However, it does *not* filter based on diagnosis related groups (DRGs)
-- As such, "comorbidities" identified are more likely to be associated with the primary reason for their hospital stay

-- The code:
--  removes "primary" ICD9_CODE (seq_num != 1)
--  uses AHRQ published rules to define comorbidities
 

with
eliflg as
(
select hadm_id, seq_num, icd9_code
-- note that these codes will seem incomplete at first
-- for example, CHF is missing a lot of codes referenced in the literature (402.11, 402.91, etc)
-- these codes are captured by hypertension flags instead
-- later there are some complicated rules which confirm/reject those codes as chf
, CASE
  when icd9_code = '39891' then 1
  when icd9_code between '4280' and '4289' then 1
		end as chf       /* Congestive heart failure */

-- cardiac arrhythmias is removed in up to date versions
, case
    when icd9_code = '42610' then 1
    when icd9_code = '42611' then 1
    when icd9_code = '42613' then 1
    when icd9_code between '4262' and '42653' then 1
    when icd9_code between '4266' and '42689' then 1
    when icd9_code = '4270' then 1
    when icd9_code = '4272' then 1
    when icd9_code = '42731' then 1
    when icd9_code = '42760' then 1
    when icd9_code = '4279' then 1
    when icd9_code = '7850' then 1
    when icd9_code between 'V450' and 'V4509' then 1
    when icd9_code between 'V533' and 'V5339' then 1
  end as arythm /* Cardiac arrhythmias */

, CASE
  when icd9_code between '09320' and '09324' then 1
  when icd9_code between '3940' and '3971' then 1
  when icd9_code = '3979' then 1
  when icd9_code between '4240' and '42499' then 1
  when icd9_code between '7463' and '7466' then 1
  when icd9_code = 'V422' then 1
  when icd9_code = 'V433' then 1
		end as valve     /* Valvular disease */

, CASE
  when icd9_code between '41511' and '41519' then 1
  when icd9_code between '4160' and '4169' then 1
  when icd9_code = '4179' then 1
		end as pulmcirc  /* Pulmonary circulation disorder */

, CASE
  when icd9_code between '4400' and '4409' then 1
  when icd9_code between '44100' and '4419' then 1
  when icd9_code between '4420' and '4429' then 1
  when icd9_code between '4431' and '4439' then 1
  when icd9_code between '44421' and '44422' then 1
  when icd9_code = '4471' then 1
  when icd9_code = '449' then 1
  when icd9_code = '5571' then 1
  when icd9_code = '5579' then 1
  when icd9_code = 'V434' then 1
		end as perivasc  /* Peripheral vascular disorder */

, CASE
  when icd9_code = '4011' then 1
  when icd9_code = '4019' then 1
  when icd9_code between '64200' and '64204' then 1
		end as htn       /* Hypertension, uncomplicated */

, CASE
  when icd9_code = '4010' then 1
  when icd9_code = '4372' then 1
		end as htncx     /* Hypertension, complicated */


      /******************************************************************/
      /* The following are special, temporary formats used in the       */
      /* creation of the hypertension complicated comorbidity when      */
      /* overlapping with congestive heart failure or renal failure     */
      /* occurs. These temporary formats are referenced in the program  */
      /* called comoanaly2009.txt.                                      */
      /******************************************************************/
, CASE
  when icd9_code between '64220' and '64224' then 1
		end as htnpreg   /* Pre-existing hypertension complicating pregnancy */

, CASE
  when icd9_code = '40200' then 1
  when icd9_code = '40210' then 1
  when icd9_code = '40290' then 1
  when icd9_code = '40509' then 1
  when icd9_code = '40519' then 1
  when icd9_code = '40599'         then 1
		end as htnwochf  /* Hypertensive heart disease without heart failure */

, CASE
  when icd9_code = '40201' then 1
  when icd9_code = '40211' then 1
  when icd9_code = '40291'         then 1
		end as htnwchf   /* Hypertensive heart disease with heart failure */

, CASE
  when icd9_code = '40300' then 1
  when icd9_code = '40310' then 1
  when icd9_code = '40390' then 1
  when icd9_code = '40501' then 1
  when icd9_code = '40511' then 1
  when icd9_code = '40591' then 1
  when icd9_code between '64210' and '64214' then 1
		end as hrenworf  /* Hypertensive renal disease without renal failure */

, CASE
  when icd9_code = '40301' then 1
  when icd9_code = '40311' then 1
  when icd9_code = '40391'         then 1
		end as hrenwrf   /* Hypertensive renal disease with renal failure */

, CASE
  when icd9_code = '40400' then 1
  when icd9_code = '40410' then 1
  when icd9_code = '40490'         then 1
		end as hhrwohrf  /* Hypertensive heart and renal disease without heart or renal failure */

, CASE
  when icd9_code = '40401' then 1
  when icd9_code = '40411' then 1
  when icd9_code = '40491'         then 1
		end as hhrwchf   /* Hypertensive heart and renal disease with heart failure */

, CASE
  when icd9_code = '40402' then 1
  when icd9_code = '40412' then 1
  when icd9_code = '40492'         then 1
		end as hhrwrf    /* Hypertensive heart and renal disease with renal failure */

, CASE
  when icd9_code = '40403' then 1
  when icd9_code = '40413' then 1
  when icd9_code = '40493'         then 1
		end as hhrwhrf   /* Hypertensive heart and renal disease with heart and renal failure */

, CASE
  when icd9_code between '64270' and '64274' then 1
  when icd9_code between '64290' and '64294' then 1
		end as ohtnpreg  /* Other hypertension in pregnancy */

      /******************** End Temporary Formats ***********************/

, CASE
  when icd9_code between '3420' and '3449' then 1
  when icd9_code between '43820' and '43853' then 1
  when icd9_code = '78072'         then 1
		end as para      /* Paralysis */

, CASE
  when icd9_code between '3300' and '3319' then 1
  when icd9_code = '3320' then 1
  when icd9_code = '3334' then 1
  when icd9_code = '3335' then 1
  when icd9_code = '3337' then 1
  when icd9_code in ('33371','33372','33379','33385','33394') then 1
  when icd9_code between '3340' and '3359' then 1
  when icd9_code = '3380' then 1
  when icd9_code = '340' then 1
  when icd9_code between '3411' and '3419' then 1
  when icd9_code between '34500' and '34511' then 1
  when icd9_code between '3452' and '3453' then 1
  when icd9_code between '34540' and '34591' then 1
  when icd9_code between '34700' and '34701' then 1
  when icd9_code between '34710' and '34711' then 1
  when icd9_code = '3483' then 1 -- discontinued icd-9
  when icd9_code between '64940' and '64944' then 1
  when icd9_code = '7687' then 1
  when icd9_code between '76870' and '76873' then 1
  when icd9_code = '7803' then 1
  when icd9_code = '78031' then 1
  when icd9_code = '78032' then 1
  when icd9_code = '78033' then 1
  when icd9_code = '78039' then 1
  when icd9_code = '78097' then 1
  when icd9_code = '7843'         then 1
		end as neuro     /* Other neurological */

, CASE
  when icd9_code between '490' and '4928' then 1
  when icd9_code between '49300' and '49392' then 1
  when icd9_code between '494' and '4941' then 1
  when icd9_code between '4950' and '505' then 1
  when icd9_code = '5064'         then 1
		end as chrnlung  /* Chronic pulmonary disease */

, CASE
  when icd9_code between '25000' and '25033' then 1
  when icd9_code between '64800' and '64804' then 1
  when icd9_code between '24900' and '24931' then 1
		end as dm        /* Diabetes w/o chronic complications*/

, CASE
  when icd9_code between '25040' and '25093' then 1
  when icd9_code = '7751' then 1
  when icd9_code between '24940' and '24991' then 1
		end as dmcx      /* Diabetes w/ chronic complications */

, CASE
  when icd9_code between '243' and '2442' then 1
  when icd9_code = '2448' then 1
  when icd9_code = '2449'         then 1
		end as hypothy   /* Hypothyroidism */

, CASE
  when icd9_code = '585' then 1 -- discontinued code
  when icd9_code = '5853' then 1
  when icd9_code = '5854' then 1
  when icd9_code = '5855' then 1
  when icd9_code = '5856' then 1
  when icd9_code = '5859' then 1
  when icd9_code = '586' then 1
  when icd9_code = 'V420' then 1
  when icd9_code = 'V451' then 1
  when icd9_code between 'V560' and 'V5632' then 1
  when icd9_code = 'V568' then 1
  when icd9_code between 'V4511' and 'V4512' then 1
		end as renlfail  /* Renal failure */

, CASE
  when icd9_code = '07022' then 1
  when icd9_code = '07023' then 1
  when icd9_code = '07032' then 1
  when icd9_code = '07033' then 1
  when icd9_code = '07044' then 1
  when icd9_code = '07054' then 1
  when icd9_code = '4560' then 1
  when icd9_code = '4561' then 1
  when icd9_code = '45620' then 1
  when icd9_code = '45621' then 1
  when icd9_code = '5710' then 1
  when icd9_code = '5712' then 1
  when icd9_code = '5713' then 1
  when icd9_code between '57140' and '57149' then 1
  when icd9_code = '5715' then 1
  when icd9_code = '5716' then 1
  when icd9_code = '5718' then 1
  when icd9_code = '5719' then 1
  when icd9_code = '5723' then 1
  when icd9_code = '5728' then 1
  when icd9_code = '5735' then 1
  when icd9_code = 'V427'         then 1
		end as liver     /* Liver disease */

, CASE
  when icd9_code = '53141' then 1
  when icd9_code = '53151' then 1
  when icd9_code = '53161' then 1
  when icd9_code = '53170' then 1
  when icd9_code = '53171' then 1
  when icd9_code = '53191' then 1
  when icd9_code = '53241' then 1
  when icd9_code = '53251' then 1
  when icd9_code = '53261' then 1
  when icd9_code = '53270' then 1
  when icd9_code = '53271' then 1
  when icd9_code = '53291' then 1
  when icd9_code = '53341' then 1
  when icd9_code = '53351' then 1
  when icd9_code = '53361' then 1
  when icd9_code = '53370' then 1
  when icd9_code = '53371' then 1
  when icd9_code = '53391' then 1
  when icd9_code = '53441' then 1
  when icd9_code = '53451' then 1
  when icd9_code = '53461' then 1
  when icd9_code = '53470' then 1
  when icd9_code = '53471' then 1
  when icd9_code = '53491'         then 1
		end as ulcer     /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */

, CASE
  when icd9_code between '042' and '0449' then 1
		end as aids      /* HIV and AIDS */

, CASE
  when icd9_code between '20000' and '20238' then 1
  when icd9_code between '20250' and '20301' then 1
  when icd9_code = '2386' then 1
  when icd9_code = '2733' then 1
  when icd9_code between '20302' and '20382' then 1
		end as lymph     /* Lymphoma */

, CASE
  when icd9_code between '1960' and '1991' then 1
  when icd9_code between '20970' and '20975' then 1
  when icd9_code = '20979' then 1
  when icd9_code = '78951'         then 1
		end as mets      /* Metastatic cancer */

, CASE
  when icd9_code between '1400' and '1729' then 1
  when icd9_code between '1740' and '1759' then 1
  when icd9_code between '179' and '1958' then 1
  when icd9_code between '20900' and '20924' then 1
  when icd9_code between '20925' and '2093' then 1
  when icd9_code between '20930' and '20936' then 1
  when icd9_code between '25801' and '25803' then 1
		end as tumor     /* Solid tumor without metastasis */

, CASE
  when icd9_code = '7010' then 1
  when icd9_code between '7100' and '7109' then 1
  when icd9_code between '7140' and '7149' then 1
  when icd9_code between '7200' and '7209' then 1
  when icd9_code = '725' then 1
		end as arth              /* Rheumatoid arthritis/collagen vascular diseases */

, CASE
  when icd9_code between '2860' and '2869' then 1
  when icd9_code = '2871' then 1
  when icd9_code between '2873' and '2875' then 1
  when icd9_code between '64930' and '64934' then 1
  when icd9_code = '28984'         then 1
		end as coag      /* Coagulation deficiency */

, CASE
  when icd9_code = '2780' then 1
  when icd9_code = '27800' then 1
  when icd9_code = '27801' then 1
  when icd9_code = '27803' then 1
  when icd9_code between '64910' and '64914' then 1
  when icd9_code between 'V8530' and 'V8539' then 1
  when icd9_code = 'V854' then 1 -- hierarchy used for AHRQ v3.6 and earlier
  when icd9_code between 'V8541' and 'V8545' then 1
  when icd9_code = 'V8554' then 1
  when icd9_code = '79391'         then 1
		end as obese     /* Obesity      */

, CASE
  when icd9_code between '260' and '2639' then 1
  when icd9_code between '78321' and '78322' then 1
		end as wghtloss  /* Weight loss */

, CASE
  when icd9_code between '2760' and '2769' then 1
		end as lytes     /* Fluid and electrolyte disorders - note:
                                      this comorbidity should be dropped when
                                      used with the AHRQ Patient Safety Indicators*/
, CASE
  when icd9_code = '2800' then 1
  when icd9_code between '64820' and '64824' then 1
		end as bldloss   /* Blood loss anemia */

, CASE
  when icd9_code between '2801' and '2819' then 1
  when icd9_code between '28521' and '28529' then 1
  when icd9_code = '2859'         then 1
		end as anemdef  /* Deficiency anemias */

, CASE
  when icd9_code between '2910' and '2913' then 1
  when icd9_code = '2915' then 1
  when icd9_code = '2918' then 1
  when icd9_code = '29181' then 1
  when icd9_code = '29182' then 1
  when icd9_code = '29189' then 1
  when icd9_code = '2919' then 1
  when icd9_code between '30300' and '30393' then 1
  when icd9_code between '30500' and '30503' then 1
		end as alcohol   /* Alcohol abuse */

, CASE
  when icd9_code = '2920' then 1
  when icd9_code between '29282' and '29289' then 1
  when icd9_code = '2929' then 1
  when icd9_code between '30400' and '30493' then 1
  when icd9_code between '30520' and '30593' then 1
  when icd9_code between '64830' and '64834' then 1
		end as drug      /* Drug abuse */

, CASE
  when icd9_code between '29500' and '2989' then 1
  when icd9_code = '29910' then 1
  when icd9_code = '29911'         then 1
		end as psych    /* Psychoses */

, CASE
  when icd9_code = '3004' then 1
  when icd9_code = '30112' then 1
  when icd9_code = '3090' then 1
  when icd9_code = '3091' then 1
  when icd9_code = '311'         then 1
		end as depress  /* Depression */
from diagnoses_icd icd
WHERE seq_num = 1
)
-- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
, eligrp as
(
  select hadm_id
  , max(chf) as chf
  , max(arythm) as arythm
  , max(valve) as valve
  , max(pulmcirc) as pulmcirc
  , max(perivasc) as perivasc
  , max(htn) as htn
  , max(htncx) as htncx
  , max(htnpreg) as htnpreg
  , max(htnwochf) as htnwochf
  , max(htnwchf) as htnwchf
  , max(hrenworf) as hrenworf
  , max(hrenwrf) as hrenwrf
  , max(hhrwohrf) as hhrwohrf
  , max(hhrwchf) as hhrwchf
  , max(hhrwrf) as hhrwrf
  , max(hhrwhrf) as hhrwhrf
  , max(ohtnpreg) as ohtnpreg
  , max(para) as para
  , max(neuro) as neuro
  , max(chrnlung) as chrnlung
  , max(dm) as dm
  , max(dmcx) as dmcx
  , max(hypothy) as hypothy
  , max(renlfail) as renlfail
  , max(liver) as liver
  , max(ulcer) as ulcer
  , max(aids) as aids
  , max(lymph) as lymph
  , max(mets) as mets
  , max(tumor) as tumor
  , max(arth) as arth
  , max(coag) as coag
  , max(obese) as obese
  , max(wghtloss) as wghtloss
  , max(lytes) as lytes
  , max(bldloss) as bldloss
  , max(anemdef) as anemdef
  , max(alcohol) as alcohol
  , max(drug) as drug
  , max(psych) as psych
  , max(depress) as depress
from eliflg
group by hadm_id
)
-- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select adm.subject_id, adm.hadm_id
, case
    when chf     = 1 then 1
    when htnwchf = 1 then 1
    when hhrwchf = 1 then 1
    when hhrwhrf = 1 then 1
  else 0 end as congestive_heart_failure
, case
    when arythm = 1 then 1
  else 0 end as cardiac_arrhythmias
, case when    valve = 1 then 1 else 0 end as valvular_disease
, case when pulmcirc = 1 then 1 else 0 end as pulmonary_circulation
, case when perivasc = 1 then 1 else 0 end as peripheral_vascular

-- we combine "htn" and "htncx" into "HYPERTENSION"
-- note "htn" (hypertension) is only 1 if "htncx" (complicated hypertension) is 0
-- this matters if you filter on DRG but for this query we can just merge them immediately
, case
    when htn = 1 then 1
    when htncx = 1 then 1
    when htnpreg = 1 then 1
    when htnwochf = 1 then 1
    when htnwchf = 1 then 1
    when hrenworf = 1 then 1
    when hrenwrf = 1 then 1
    when hhrwohrf = 1 then 1
    when hhrwchf = 1 then 1
    when hhrwrf = 1 then 1
    when hhrwhrf = 1 then 1
    when ohtnpreg = 1 then 1
  else 0 end as hypertension

, case when para      = 1 then 1 else 0 end as paralysis
, case when neuro     = 1 then 1 else 0 end as other_neurological
, case when chrnlung  = 1 then 1 else 0 end as chronic_pulmonary
, case
    -- only the more severe comorbidity (complicated diabetes) is kept
    when dmcx = 1 then 0
    when dm = 1 then 1
  else 0 end as diabetes_uncomplicated
, case when dmcx    = 1 then 1 else 0 end as diabetes_complicated
, case when hypothy = 1 then 1 else 0 end as hypothyroidism
, case
    when renlfail = 1 then 1
    when hrenwrf  = 1 then 1
    when hhrwrf   = 1 then 1
    when hhrwhrf  = 1 then 1
  else 0 end as renal_failure

, case when liver = 1 then 1 else 0 end as liver_disease
, case when ulcer = 1 then 1 else 0 end as peptic_ulcer
, case when aids = 1 then 1 else 0 end as aids
, case when lymph = 1 then 1 else 0 end as lymphoma
, case when mets = 1 then 1 else 0 end as metastatic_cancer
, case
    -- only the more severe comorbidity (metastatic cancer) is kept
    when mets = 1 then 0
    when tumor = 1 then 1
  else 0 end as solid_tumor
, case when arth = 1 then 1 else 0 end as rheumatoid_arthritis
, case when coag = 1 then 1 else 0 end as coagulopathy
, case when obese = 1 then 1 else 0 end as obesity
, case when wghtloss = 1 then 1 else 0 end as weight_loss
, case when lytes = 1 then 1 else 0 end as fluid_electrolyte
, case when bldloss = 1 then 1 else 0 end as blood_loss_anemia
, case when anemdef = 1 then 1 else 0 end as deficiency_anemias
, case when alcohol = 1 then 1 else 0 end as alcohol_abuse
, case when drug = 1 then 1 else 0 end as drug_abuse
, case when psych = 1 then 1 else 0 end as psychoses
, case when depress = 1 then 1 else 0 end as depression

FROM admissions adm
left join eligrp eli
  on adm.hadm_id = eli.hadm_id
order by adm.hadm_id
  );
17:07:14.819982 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.49 seconds
17:07:14.827315 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.827520 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
alter table "postgres"."public"."elixhauser_ahrq_v37_no_drg" rename to "elixhauser_ahrq_v37_no_drg__dbt_backup"
17:07:14.828231 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:14.831689 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.832184 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
alter table "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_tmp" rename to "elixhauser_ahrq_v37_no_drg"
17:07:14.832878 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:14.836428 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: COMMIT
17:07:14.836630 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.836838 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: COMMIT
17:07:14.838157 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:14.839987 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:07:14.840183 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
drop table if exists "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_backup" cascade
17:07:14.842369 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:14.845776 [debug] [Thread-1  ]: finished collecting timing info
17:07:14.846006 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: Close
17:07:14.846879 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc85370>]}
17:07:14.847364 [info ] [Thread-1  ]: 21 of 107 OK created table model public.elixhauser_ahrq_v37_no_drg ............. [[32mSELECT 58976[0m in 0.54s]
17:07:14.847979 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_ahrq_v37_no_drg
17:07:14.848428 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_quan
17:07:14.849201 [info ] [Thread-1  ]: 22 of 107 START table model public.elixhauser_quan ............................. [RUN]
17:07:14.849879 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_quan"
17:07:14.850047 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_quan
17:07:14.850378 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_quan
17:07:14.855375 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_quan"
17:07:14.856384 [debug] [Thread-1  ]: finished collecting timing info
17:07:14.856906 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_quan
17:07:14.874452 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_quan"
17:07:14.876133 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:14.876460 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: BEGIN
17:07:14.876610 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:14.883321 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:14.883572 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:14.883750 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */


  create  table "postgres"."public"."elixhauser_quan__dbt_tmp"
  as (
    -- This code calculates the Elixhauser comorbidities as defined in Quan et. al 2009:
-- Quan, Hude, et al. "Coding algorithms for defining comorbidities in
-- ICD-9-CM and ICD-10 administrative data." Medical care (2005): 1130-1139.
--  https://www.ncbi.nlm.nih.gov/pubmed/16224307
-- Quan defined an "Enhanced ICD-9" coding scheme for deriving Elixhauser
-- comorbidities from ICD-9 billing codes. This script implements that calculation.
-- The logic of the code is roughly that, if the comorbidity lists a length 3
-- ICD-9 code (e.g. 585), then we only require a match on the first 3 characters.
-- This code derives each comorbidity as follows:
--  1) ICD9_CODE is directly compared to 5 character codes
--  2) The first 4 characters of ICD9_CODE are compared to 4 character codes
--  3) The first 3 characters of ICD9_CODE are compared to 3 character codes

 

with eliflg as (
    select
        hadm_id,
        seq_num,
        icd9_code,
        CASE
            when icd9_code in (
                '39891',
                '40201',
                '40211',
                '40291',
                '40401',
                '40403',
                '40411',
                '40413',
                '40491',
                '40493'
            ) then 1
            when SUBSTR(icd9_code, 1, 4) in ('4254', '4255', '4257', '4258', '4259') then 1
            when SUBSTR(icd9_code, 1, 3) in ('428') then 1
            else 0
        end as chf
        /* Congestive heart failure */
,
        CASE
            when icd9_code in ('42613', '42610', '42612', '99601', '99604') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '4260',
                '4267',
                '4269',
                '4270',
                '4271',
                '4272',
                '4273',
                '4274',
                '4276',
                '4278',
                '4279',
                '7850',
                'V450',
                'V533'
            ) then 1
            else 0
        end as arrhy,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('0932', '7463', '7464', '7465', '7466', 'V422', 'V433') then 1
            when SUBSTR(icd9_code, 1, 3) in ('394', '395', '396', '397', '424') then 1
            else 0
        end as valve
        /* Valvular disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('4150', '4151', '4170', '4178', '4179') then 1
            when SUBSTR(icd9_code, 1, 3) in ('416') then 1
            else 0
        end as pulmcirc
        /* Pulmonary circulation disorder */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '0930',
                '4373',
                '4431',
                '4432',
                '4438',
                '4439',
                '4471',
                '5571',
                '5579',
                'V434'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('440', '441') then 1
            else 0
        end as perivasc
        /* Peripheral vascular disorder */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('401') then 1
            else 0
        end as htn
        /* Hypertension, uncomplicated */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('402', '403', '404', '405') then 1
            else 0
        end as htncx
        /* Hypertension, complicated */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '3341',
                '3440',
                '3441',
                '3442',
                '3443',
                '3444',
                '3445',
                '3446',
                '3449'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('342', '343') then 1
            else 0
        end as para
        /* Paralysis */
,
        CASE
            when icd9_code in ('33392') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '3319',
                '3320',
                '3321',
                '3334',
                '3335',
                '3362',
                '3481',
                '3483',
                '7803',
                '7843'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('334', '335', '340', '341', '345') then 1
            else 0
        end as neuro
        /* Other neurological */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('4168', '4169', '5064', '5081', '5088') then 1
            when SUBSTR(icd9_code, 1, 3) in (
                '490',
                '491',
                '492',
                '493',
                '494',
                '495',
                '496',
                '500',
                '501',
                '502',
                '503',
                '504',
                '505'
            ) then 1
            else 0
        end as chrnlung
        /* Chronic pulmonary disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2500', '2501', '2502', '2503') then 1
            else 0
        end as dm
        /* Diabetes w/o chronic complications*/
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2504', '2505', '2506', '2507', '2508', '2509') then 1
            else 0
        end as dmcx
        /* Diabetes w/ chronic complications */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2409', '2461', '2468') then 1
            when SUBSTR(icd9_code, 1, 3) in ('243', '244') then 1
            else 0
        end as hypothy
        /* Hypothyroidism */
,
        CASE
            when icd9_code in (
                '40301',
                '40311',
                '40391',
                '40402',
                '40403',
                '40412',
                '40413',
                '40492',
                '40493'
            ) then 1
            when SUBSTR(icd9_code, 1, 4) in ('5880', 'V420', 'V451') then 1
            when SUBSTR(icd9_code, 1, 3) in ('585', '586', 'V56') then 1
            else 0
        end as renlfail
        /* Renal failure */
,
        CASE
            when icd9_code in ('07022', '07023', '07032', '07033', '07044', '07054') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '0706',
                '0709',
                '4560',
                '4561',
                '4562',
                '5722',
                '5723',
                '5724',
                '5728',
                '5733',
                '5734',
                '5738',
                '5739',
                'V427'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('570', '571') then 1
            else 0
        end as liver
        /* Liver disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '5317',
                '5319',
                '5327',
                '5329',
                '5337',
                '5339',
                '5347',
                '5349'
            ) then 1
            else 0
        end as ulcer
        /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('042', '043', '044') then 1
            else 0
        end as aids
        /* HIV and AIDS */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2030', '2386') then 1
            when SUBSTR(icd9_code, 1, 3) in ('200', '201', '202') then 1
            else 0
        end as lymph
        /* Lymphoma */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('196', '197', '198', '199') then 1
            else 0
        end as mets
        /* Metastatic cancer */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in (
                '140',
                '141',
                '142',
                '143',
                '144',
                '145',
                '146',
                '147',
                '148',
                '149',
                '150',
                '151',
                '152',
                '153',
                '154',
                '155',
                '156',
                '157',
                '158',
                '159',
                '160',
                '161',
                '162',
                '163',
                '164',
                '165',
                '166',
                '167',
                '168',
                '169',
                '170',
                '171',
                '172',
                '174',
                '175',
                '176',
                '177',
                '178',
                '179',
                '180',
                '181',
                '182',
                '183',
                '184',
                '185',
                '186',
                '187',
                '188',
                '189',
                '190',
                '191',
                '192',
                '193',
                '194',
                '195'
            ) then 1
            else 0
        end as tumor
        /* Solid tumor without metastasis */
,
        CASE
            when icd9_code in ('72889', '72930') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '7010',
                '7100',
                '7101',
                '7102',
                '7103',
                '7104',
                '7108',
                '7109',
                '7112',
                '7193',
                '7285'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('446', '714', '720', '725') then 1
            else 0
        end as arth
        /* Rheumatoid arthritis/collagen vascular diseases */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2871', '2873', '2874', '2875') then 1
            when SUBSTR(icd9_code, 1, 3) in ('286') then 1
            else 0
        end as coag
        /* Coagulation deficiency */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2780') then 1
            else 0
        end as obese
        /* Obesity      */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('7832', '7994') then 1
            when SUBSTR(icd9_code, 1, 3) in ('260', '261', '262', '263') then 1
            else 0
        end as wghtloss
        /* Weight loss */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2536') then 1
            when SUBSTR(icd9_code, 1, 3) in ('276') then 1
            else 0
        end as lytes
        /* Fluid and electrolyte disorders */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2800') then 1
            else 0
        end as bldloss
        /* Blood loss anemia */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2801', '2808', '2809') then 1
            when SUBSTR(icd9_code, 1, 3) in ('281') then 1
            else 0
        end as anemdef
        /* Deficiency anemias */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '2652',
                '2911',
                '2912',
                '2913',
                '2915',
                '2918',
                '2919',
                '3030',
                '3039',
                '3050',
                '3575',
                '4255',
                '5353',
                '5710',
                '5711',
                '5712',
                '5713',
                'V113'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('980') then 1
            else 0
        end as alcohol
        /* Alcohol abuse */
,
        CASE
            when icd9_code in ('V6542') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '3052',
                '3053',
                '3054',
                '3055',
                '3056',
                '3057',
                '3058',
                '3059'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('292', '304') then 1
            else 0
        end as drug
        /* Drug abuse */
,
        CASE
            when icd9_code in ('29604', '29614', '29644', '29654') then 1
            when SUBSTR(icd9_code, 1, 4) in ('2938') then 1
            when SUBSTR(icd9_code, 1, 3) in ('295', '297', '298') then 1
            else 0
        end as psych
        /* Psychoses */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2962', '2963', '2965', '3004') then 1
            when SUBSTR(icd9_code, 1, 3) in ('309', '311') then 1
            else 0
        end as depress
        /* Depression */
    from
        diagnoses_icd icd
    where
        seq_num != 1 -- we do not include the primary icd-9 code
) -- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
,
eligrp as (
    select
        hadm_id,
        max(chf) as chf,
        max(arrhy) as arrhy,
        max(valve) as valve,
        max(pulmcirc) as pulmcirc,
        max(perivasc) as perivasc,
        max(htn) as htn,
        max(htncx) as htncx,
        max(para) as para,
        max(neuro) as neuro,
        max(chrnlung) as chrnlung,
        max(dm) as dm,
        max(dmcx) as dmcx,
        max(hypothy) as hypothy,
        max(renlfail) as renlfail,
        max(liver) as liver,
        max(ulcer) as ulcer,
        max(aids) as aids,
        max(lymph) as lymph,
        max(mets) as mets,
        max(tumor) as tumor,
        max(arth) as arth,
        max(coag) as coag,
        max(obese) as obese,
        max(wghtloss) as wghtloss,
        max(lytes) as lytes,
        max(bldloss) as bldloss,
        max(anemdef) as anemdef,
        max(alcohol) as alcohol,
        max(drug) as drug,
        max(psych) as psych,
        max(depress) as depress
    from
        eliflg
    group by
        hadm_id
) -- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select
    adm.hadm_id,
    chf as congestive_heart_failure,
    arrhy as cardiac_arrhythmias,
    valve as valvular_disease,
    pulmcirc as pulmonary_circulation,
    perivasc as peripheral_vascular -- we combine "htn" and "htncx" into "HYPERTENSION"
,
    case
        when htn = 1 then 1
        when htncx = 1 then 1
        else 0
    end as hypertension,
    para as paralysis,
    neuro as other_neurological,
    chrnlung as chronic_pulmonary -- only the more severe comorbidity (complicated diabetes) is kept
,
    case
        when dmcx = 1 then 0
        when dm = 1 then 1
        else 0
    end as diabetes_uncomplicated,
    dmcx as diabetes_complicated,
    hypothy as hypothyroidism,
    renlfail as renal_failure,
    liver as liver_disease,
    ulcer as peptic_ulcer,
    aids as aids,
    lymph as lymphoma,
    mets as metastatic_cancer -- only the more severe comorbidity (metastatic cancer) is kept
,
    case
        when mets = 1 then 0
        when tumor = 1 then 1
        else 0
    end as solid_tumor,
    arth as rheumatoid_arthritis,
    coag as coagulopathy,
    obese as obesity,
    wghtloss as weight_loss,
    lytes as fluid_electrolyte,
    bldloss as blood_loss_anemia,
    anemdef as deficiency_anemias,
    alcohol as alcohol_abuse,
    drug as drug_abuse,
    psych as psychoses,
    depress as depression
FROM
    admissions adm
    left join eligrp eli on adm.hadm_id = eli.hadm_id
order by
    adm.hadm_id
  );
17:07:17.015697 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 2.13 seconds
17:07:17.019832 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:17.020052 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
alter table "postgres"."public"."elixhauser_quan" rename to "elixhauser_quan__dbt_backup"
17:07:17.020714 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:17.026095 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:17.026331 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
alter table "postgres"."public"."elixhauser_quan__dbt_tmp" rename to "elixhauser_quan"
17:07:17.026974 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:17.029907 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: COMMIT
17:07:17.030111 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:17.030210 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: COMMIT
17:07:17.032348 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:17.034630 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:07:17.034921 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
drop table if exists "postgres"."public"."elixhauser_quan__dbt_backup" cascade
17:07:17.037502 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:17.041652 [debug] [Thread-1  ]: finished collecting timing info
17:07:17.041903 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: Close
17:07:17.042778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc854f0>]}
17:07:17.043271 [info ] [Thread-1  ]: 22 of 107 OK created table model public.elixhauser_quan ........................ [[32mSELECT 58976[0m in 2.19s]
17:07:17.043792 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_quan
17:07:17.044015 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_durations
17:07:17.044579 [info ] [Thread-1  ]: 23 of 107 START table model public.epinephrine_durations ....................... [RUN]
17:07:17.045348 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_durations"
17:07:17.045488 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_durations
17:07:17.045773 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_durations
17:07:17.047398 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_durations"
17:07:17.047954 [debug] [Thread-1  ]: finished collecting timing info
17:07:17.048242 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_durations
17:07:17.060751 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_durations"
17:07:17.062080 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:17.062336 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: BEGIN
17:07:17.062592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:17.067491 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:17.067734 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:17.067941 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */


  create  table "postgres"."public"."epinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of epinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30044,30119,30309) then rate else null end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:18.865408 [debug] [Thread-1  ]: SQL status: SELECT 3126 in 1.8 seconds
17:07:18.871018 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:18.871321 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations" rename to "epinephrine_durations__dbt_backup"
17:07:18.872289 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:18.876434 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:18.876630 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations__dbt_tmp" rename to "epinephrine_durations"
17:07:18.877323 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:18.880360 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:07:18.880555 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:18.880755 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:07:18.882111 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:18.884085 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:07:18.884283 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
drop table if exists "postgres"."public"."epinephrine_durations__dbt_backup" cascade
17:07:18.886787 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:18.890982 [debug] [Thread-1  ]: finished collecting timing info
17:07:18.891386 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: Close
17:07:18.892269 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc85640>]}
17:07:18.892786 [info ] [Thread-1  ]: 23 of 107 OK created table model public.epinephrine_durations .................. [[32mSELECT 3126[0m in 1.85s]
17:07:18.893304 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_durations
17:07:18.893553 [debug] [Thread-1  ]: Began running node model.mimic.explicit
17:07:18.894212 [info ] [Thread-1  ]: 24 of 107 START table model public.explicit .................................... [RUN]
17:07:18.895179 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.explicit"
17:07:18.895568 [debug] [Thread-1  ]: Began compiling node model.mimic.explicit
17:07:18.895904 [debug] [Thread-1  ]: Compiling model.mimic.explicit
17:07:18.898320 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.explicit"
17:07:18.899927 [debug] [Thread-1  ]: finished collecting timing info
17:07:18.900421 [debug] [Thread-1  ]: Began executing node model.mimic.explicit
17:07:18.912061 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.explicit"
17:07:18.912667 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:18.912875 [debug] [Thread-1  ]: On model.mimic.explicit: BEGIN
17:07:18.913046 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:18.917514 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:18.917761 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:18.917862 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */


  create  table "postgres"."public"."explicit__dbt_tmp"
  as (
    -- This code extracts explicit sepsis using ICD-9 diagnosis codes
-- That is, the two codes 995.92 (severe sepsis) or 785.52 (septic shock)
-- These codes are extremely specific to sepsis, but have very low sensitivity
-- From Iwashyna et al. (vs. chart reviews): 100% PPV, 9.3% sens, 100% specificity
 

WITH co_dx AS
(
	SELECT hadm_id
	-- sepsis codes
	, MAX(
    	CASE
    		WHEN icd9_code = '99592' THEN 1
      ELSE 0 END
    ) AS severe_sepsis
	, MAX(
    	CASE
    		WHEN icd9_code = '78552' THEN 1
      ELSE 0 END
    ) AS septic_shock
  from diagnoses_icd
  GROUP BY hadm_id
)
select
  adm.subject_id
  , adm.hadm_id
	, co_dx.severe_sepsis
  , co_dx.septic_shock
	, case when co_dx.severe_sepsis = 1 or co_dx.septic_shock = 1
			then 1
		else 0 end as sepsis
FROM admissions adm
left join co_dx
  on adm.hadm_id = co_dx.hadm_id
order by adm.subject_id, adm.hadm_id
  );
17:07:19.130302 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.21 seconds
17:07:19.139763 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:19.140200 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
alter table "postgres"."public"."explicit" rename to "explicit__dbt_backup"
17:07:19.141113 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:19.147452 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:19.147798 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
alter table "postgres"."public"."explicit__dbt_tmp" rename to "explicit"
17:07:19.149017 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:19.156856 [debug] [Thread-1  ]: On model.mimic.explicit: COMMIT
17:07:19.157419 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:19.157641 [debug] [Thread-1  ]: On model.mimic.explicit: COMMIT
17:07:19.164856 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:19.167795 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:07:19.168102 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
drop table if exists "postgres"."public"."explicit__dbt_backup" cascade
17:07:19.170740 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:19.173124 [debug] [Thread-1  ]: finished collecting timing info
17:07:19.173301 [debug] [Thread-1  ]: On model.mimic.explicit: Close
17:07:19.173729 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48edc85790>]}
17:07:19.173994 [info ] [Thread-1  ]: 24 of 107 OK created table model public.explicit ............................... [[32mSELECT 58976[0m in 0.28s]
17:07:19.174312 [debug] [Thread-1  ]: Finished running node model.mimic.explicit
17:07:19.174454 [debug] [Thread-1  ]: Began running node model.mimic.ffp_transfusion
17:07:19.175424 [info ] [Thread-1  ]: 25 of 107 START table model public.ffp_transfusion ............................. [RUN]
17:07:19.175963 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ffp_transfusion"
17:07:19.176102 [debug] [Thread-1  ]: Began compiling node model.mimic.ffp_transfusion
17:07:19.176210 [debug] [Thread-1  ]: Compiling model.mimic.ffp_transfusion
17:07:19.177099 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ffp_transfusion"
17:07:19.177382 [debug] [Thread-1  ]: finished collecting timing info
17:07:19.177493 [debug] [Thread-1  ]: Began executing node model.mimic.ffp_transfusion
17:07:19.189622 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ffp_transfusion"
17:07:19.190113 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:19.190233 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: BEGIN
17:07:19.190341 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:19.195755 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:19.196052 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:19.196182 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ffp_transfusion"} */


  create  table "postgres"."public"."ffp_transfusion__dbt_tmp"
  as (
    -- Retrieves instances of fresh frozen plasma transfusions
WITH raw_ffp AS (
  SELECT
      CASE
        WHEN amount IS NOT NULL THEN amount
        WHEN stopped IS NOT NULL THEN 0
        -- impute 200 mL when unit is not documented
        -- this is an approximation which holds ~90% of the time
        ELSE 200
      END AS amount
    , amountuom
    , icustay_id
    , charttime
  FROM inputevents_cv
  WHERE itemid IN
  (
    30005,  -- Fresh Frozen Plasma
    30180   -- Fresh Froz Plasma
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
  UNION ALL
  SELECT amount
    , amountuom
    , icustay_id
    , endtime AS charttime
  FROM inputevents_mv
  WHERE itemid in
  (
    220970   -- Fresh Frozen Plasma
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
),
pre_icu_ffp as (
  SELECT
    sum(amount) as amount, icustay_id
  FROM inputevents_cv
  WHERE itemid IN (
    44172,  -- FFP GTT         
    44236,  -- E.R. FFP        
    46410,  -- angio FFP
    46418,  -- ER ffp
    46684,  -- ER FFP
    44819,  -- FFP ON FARR 2
    46530,  -- Floor FFP       
    44044,  -- FFP Drip
    46122,  -- ER in FFP
    45669,  -- ED FFP
    42323   -- er ffp
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
  GROUP BY icustay_id
  UNION ALL
  SELECT
    sum(amount) as amount, icustay_id
  FROM inputevents_mv
  WHERE itemid IN (
    227072  -- PACU FFP Intake
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
  GROUP BY icustay_id
),
cumulative AS (
  SELECT
    sum(amount) over (PARTITION BY icustay_id ORDER BY charttime DESC) AS amount
    , amountuom
    , icustay_id
    , charttime
    , DATETIME_DIFF(lag(charttime) over (PARTITION BY icustay_id ORDER BY charttime ASC), charttime, 'HOUR') AS delta
  FROM raw_ffp
)
-- We consider any transfusions started within 1 hr of the last one
-- to be part of the same event
SELECT
    cm.icustay_id
  , cm.charttime
  , ROUND(CAST(cm.amount AS numeric) - CASE
      WHEN ROW_NUMBER() OVER w = 1 THEN CAST(0 AS numeric)
      ELSE cast(lag(cm.amount) OVER w AS numeric)
    END, 2) AS amount
  , ROUND(CAST(cm.amount AS numeric) + CASE
      WHEN pre.amount IS NULL THEN CAST(0 AS numeric)
      ELSE CAST(pre.amount AS numeric)
    END, 2) AS totalamount
  , cm.amountuom
FROM cumulative AS cm
LEFT JOIN pre_icu_ffp AS pre
  USING (icustay_id)
WHERE delta IS NULL OR delta < -1
WINDOW w AS (PARTITION BY cm.icustay_id ORDER BY cm.charttime DESC)
ORDER BY icustay_id, charttime
  );
17:07:20.065401 [debug] [Thread-1  ]: SQL status: SELECT 13583 in 0.87 seconds
17:07:20.073226 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:20.073518 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ffp_transfusion"} */
alter table "postgres"."public"."ffp_transfusion" rename to "ffp_transfusion__dbt_backup"
17:07:20.074407 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.078896 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:20.079084 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ffp_transfusion"} */
alter table "postgres"."public"."ffp_transfusion__dbt_tmp" rename to "ffp_transfusion"
17:07:20.079507 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.081868 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: COMMIT
17:07:20.081982 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:20.082085 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: COMMIT
17:07:20.090895 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:20.093241 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ffp_transfusion"
17:07:20.093427 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ffp_transfusion"} */
drop table if exists "postgres"."public"."ffp_transfusion__dbt_backup" cascade
17:07:20.095643 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:20.098357 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.098980 [debug] [Thread-1  ]: On model.mimic.ffp_transfusion: Close
17:07:20.099773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d826656-3a4e-42bd-ba48-1049a0e46e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ec36f040>]}
17:07:20.105794 [warn ] [Thread-1  ]: Error sending message, disabling tracking
17:07:20.106432 [info ] [Thread-1  ]: 25 of 107 OK created table model public.ffp_transfusion ........................ [[32mSELECT 13583[0m in 0.92s]
17:07:20.107659 [debug] [Thread-1  ]: Finished running node model.mimic.ffp_transfusion
17:07:20.107863 [debug] [Thread-1  ]: Began running node model.mimic.gcs
17:07:20.108314 [info ] [Thread-1  ]: 26 of 107 START table model public.gcs ......................................... [RUN]
17:07:20.109497 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.gcs"
17:07:20.109726 [debug] [Thread-1  ]: Began compiling node model.mimic.gcs
17:07:20.109884 [debug] [Thread-1  ]: Compiling model.mimic.gcs
17:07:20.112323 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.gcs"
17:07:20.113062 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.113310 [debug] [Thread-1  ]: Began executing node model.mimic.gcs
17:07:20.126075 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.gcs"
17:07:20.127351 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.127651 [debug] [Thread-1  ]: On model.mimic.gcs: BEGIN
17:07:20.127790 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:20.133378 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:20.133709 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.133822 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */


  create  table "postgres"."public"."gcs__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Find the glasgow coma *MOTOR* score for each adult patient
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
    SELECT ad.subject_id
    FROM admissions ad
    INNER JOIN patients p
    ON ad.subject_id = p.subject_id
    WHERE
     -- filter to only adults
    DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
    -- group by subject_id to ensure there is only 1 subject_id per row
    group by ad.subject_id
)
, gcs as
(
    SELECT width_bucket(valuenum, 1, 30, 30) AS bucket
    FROM chartevents ce
    INNER JOIN agetbl
    ON ce.subject_id = agetbl.subject_id
    WHERE itemid IN
    (
        454 -- "Motor Response"
      , 223900 -- "GCS - Motor Response"
    )
)
SELECT bucket as GCS_Motor_Response, count(*)
FROM gcs
GROUP BY bucket
ORDER BY bucket
  );
17:07:20.321868 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.19 seconds
17:07:20.327110 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.327343 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
alter table "postgres"."public"."gcs" rename to "gcs__dbt_backup"
17:07:20.327981 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.331970 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.332171 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
alter table "postgres"."public"."gcs__dbt_tmp" rename to "gcs"
17:07:20.332894 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.337923 [debug] [Thread-1  ]: On model.mimic.gcs: COMMIT
17:07:20.338135 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.338235 [debug] [Thread-1  ]: On model.mimic.gcs: COMMIT
17:07:20.340763 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:20.343530 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:07:20.343998 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
drop table if exists "postgres"."public"."gcs__dbt_backup" cascade
17:07:20.347067 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:20.350859 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.351229 [debug] [Thread-1  ]: On model.mimic.gcs: Close
17:07:20.353005 [info ] [Thread-1  ]: 26 of 107 OK created table model public.gcs .................................... [[32mSELECT 0[0m in 0.24s]
17:07:20.354148 [debug] [Thread-1  ]: Finished running node model.mimic.gcs
17:07:20.354305 [debug] [Thread-1  ]: Began running node model.mimic.gcs_first_day
17:07:20.354958 [info ] [Thread-1  ]: 27 of 107 START table model public.gcs_first_day ............................... [RUN]
17:07:20.355783 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.gcs_first_day"
17:07:20.356035 [debug] [Thread-1  ]: Began compiling node model.mimic.gcs_first_day
17:07:20.356305 [debug] [Thread-1  ]: Compiling model.mimic.gcs_first_day
17:07:20.357563 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.gcs_first_day"
17:07:20.357984 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.358108 [debug] [Thread-1  ]: Began executing node model.mimic.gcs_first_day
17:07:20.365800 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.gcs_first_day"
17:07:20.366378 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.366723 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: BEGIN
17:07:20.366924 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:20.373876 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:20.374142 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.374405 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */


  create  table "postgres"."public"."gcs_first_day__dbt_tmp"
  as (
    -- ITEMIDs used:

-- CAREVUE
--    723 as GCSVerbal
--    454 as GCSMotor
--    184 as GCSEyes

-- METAVISION
--    223900 GCS - Verbal Response
--    223901 GCS - Motor Response
--    220739 GCS - Eye Opening

-- The code combines the ITEMIDs into the carevue itemids, then pivots those
-- So 223900 is changed to 723, then the ITEMID 723 is pivoted to form GCSVerbal

-- Note:
--  The GCS for sedated patients is defaulted to 15 in this code.
--  This is in line with how the data is meant to be collected.
--  e.g., from the SAPS II publication:
--    For sedated patients, the Glasgow Coma Score before sedation was used.
--    This was ascertained either from interviewing the physician who ordered the sedation,
--    or by reviewing the patient's medical record.

with base as
(
  SELECT pvt.ICUSTAY_ID
  , pvt.charttime

  -- Easier names - note we coalesced Metavision and CareVue IDs below
  , max(case when pvt.itemid = 454 then pvt.valuenum else null end) as GCSMotor
  , max(case when pvt.itemid = 723 then pvt.valuenum else null end) as GCSVerbal
  , max(case when pvt.itemid = 184 then pvt.valuenum else null end) as GCSEyes

  -- If verbal was set to 0 in the below select, then this is an intubated patient
  , case
      when max(case when pvt.itemid = 723 then pvt.valuenum else null end) = 0
    then 1
    else 0
    end as EndoTrachFlag

  , ROW_NUMBER ()
          OVER (PARTITION BY pvt.ICUSTAY_ID ORDER BY pvt.charttime ASC) as rn

  FROM  (
  select l.ICUSTAY_ID
  -- merge the ITEMIDs so that the pivot applies to both metavision/carevue data
  , case
      when l.ITEMID in (723,223900) then 723
      when l.ITEMID in (454,223901) then 454
      when l.ITEMID in (184,220739) then 184
      else l.ITEMID end
    as ITEMID

  -- convert the data into a number, reserving a value of 0 for ET/Trach
  , case
      -- endotrach/vent is assigned a value of 0, later parsed specially
      when l.ITEMID = 723 and l.VALUE = '1.0 ET/Trach' then 0 -- carevue
      when l.ITEMID = 223900 and l.VALUE = 'No Response-ETT' then 0 -- metavision

      else VALUENUM
      end
    as VALUENUM
  , l.CHARTTIME
  FROM chartevents l

  -- get intime for charttime subselection
  inner join icustays b
    on l.icustay_id = b.icustay_id

  -- Isolate the desired GCS variables
  where l.ITEMID in
  (
    -- 198 -- GCS
    -- GCS components, CareVue
    184, 454, 723
    -- GCS components, Metavision
    , 223900, 223901, 220739
  )
  -- Only get data for the first 24 hours
  and l.charttime between b.intime and DATETIME_ADD(b.intime, INTERVAL '1' DAY)
  -- exclude rows marked as error
  AND (l.error IS NULL OR l.error = 0)
  ) pvt
  group by pvt.ICUSTAY_ID, pvt.charttime
)
, gcs as (
  select b.*
  , b2.GCSVerbal as GCSVerbalPrev
  , b2.GCSMotor as GCSMotorPrev
  , b2.GCSEyes as GCSEyesPrev
  -- Calculate GCS, factoring in special case when they are intubated and prev vals
  -- note that the coalesce are used to implement the following if:
  --  if current value exists, use it
  --  if previous value exists, use it
  --  otherwise, default to normal
  , case
      -- replace GCS during sedation with 15
      when b.GCSVerbal = 0
        then 15
      when b.GCSVerbal is null and b2.GCSVerbal = 0
        then 15
      -- if previously they were intub, but they aren't now, do not use previous GCS values
      when b2.GCSVerbal = 0
        then
            coalesce(b.GCSMotor,6)
          + coalesce(b.GCSVerbal,5)
          + coalesce(b.GCSEyes,4)
      -- otherwise, add up score normally, imputing previous value if none available at current time
      else
            coalesce(b.GCSMotor,coalesce(b2.GCSMotor,6))
          + coalesce(b.GCSVerbal,coalesce(b2.GCSVerbal,5))
          + coalesce(b.GCSEyes,coalesce(b2.GCSEyes,4))
      end as GCS

  from base b
  -- join to itself within 6 hours to get previous value
  left join base b2
    on b.ICUSTAY_ID = b2.ICUSTAY_ID and b.rn = b2.rn+1 and b2.charttime > DATETIME_SUB(b.charttime, INTERVAL '6' HOUR)
)
, gcs_final as (
  select gcs.*
  -- This sorts the data by GCS, so rn=1 is the the lowest GCS values to keep
  , ROW_NUMBER ()
          OVER (PARTITION BY gcs.ICUSTAY_ID
                ORDER BY gcs.GCS
               ) as IsMinGCS
  from gcs
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- The minimum GCS is determined by the above row partition, we only join if IsMinGCS=1
, GCS as mingcs
, coalesce(GCSMotor,GCSMotorPrev) as gcsmotor
, coalesce(GCSVerbal,GCSVerbalPrev) as gcsverbal
, coalesce(GCSEyes,GCSEyesPrev) as gcseyes
, EndoTrachFlag as endotrachflag

-- subselect down to the cohort of eligible patients
FROM icustays ie
left join gcs_final gs
  on ie.icustay_id = gs.icustay_id and gs.IsMinGCS = 1
ORDER BY ie.icustay_id
  );
17:07:20.518308 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.14 seconds
17:07:20.526097 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.526618 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
alter table "postgres"."public"."gcs_first_day" rename to "gcs_first_day__dbt_backup"
17:07:20.527675 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.531931 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.532145 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
alter table "postgres"."public"."gcs_first_day__dbt_tmp" rename to "gcs_first_day"
17:07:20.532893 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.536156 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: COMMIT
17:07:20.536352 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.536582 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: COMMIT
17:07:20.542104 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:20.545502 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:07:20.545687 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
drop table if exists "postgres"."public"."gcs_first_day__dbt_backup" cascade
17:07:20.547941 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:20.550393 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.550770 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: Close
17:07:20.551626 [info ] [Thread-1  ]: 27 of 107 OK created table model public.gcs_first_day .......................... [[32mSELECT 61532[0m in 0.20s]
17:07:20.552203 [debug] [Thread-1  ]: Finished running node model.mimic.gcs_first_day
17:07:20.552558 [debug] [Thread-1  ]: Began running node model.mimic.glucose
17:07:20.553356 [info ] [Thread-1  ]: 28 of 107 START table model public.glucose ..................................... [RUN]
17:07:20.554024 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.glucose"
17:07:20.554361 [debug] [Thread-1  ]: Began compiling node model.mimic.glucose
17:07:20.554532 [debug] [Thread-1  ]: Compiling model.mimic.glucose
17:07:20.555755 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.glucose"
17:07:20.556250 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.556552 [debug] [Thread-1  ]: Began executing node model.mimic.glucose
17:07:20.565648 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.glucose"
17:07:20.566059 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.566166 [debug] [Thread-1  ]: On model.mimic.glucose: BEGIN
17:07:20.566260 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:20.572583 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:20.572877 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.573108 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */


  create  table "postgres"."public"."glucose__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves a glucose histogram of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, glc as
(
  SELECT width_bucket(valuenum, 0.5, 1000, 1000) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50809,50931)
  AND valuenum IS NOT NULL
)
SELECT bucket as glucose, count(*)
FROM glc
GROUP BY bucket
ORDER BY bucket
  );
17:07:20.719799 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:07:20.726423 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.726731 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
alter table "postgres"."public"."glucose" rename to "glucose__dbt_backup"
17:07:20.727962 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.732060 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.732263 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
alter table "postgres"."public"."glucose__dbt_tmp" rename to "glucose"
17:07:20.733050 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.738139 [debug] [Thread-1  ]: On model.mimic.glucose: COMMIT
17:07:20.738395 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.738606 [debug] [Thread-1  ]: On model.mimic.glucose: COMMIT
17:07:20.739746 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:20.741748 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:07:20.741951 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
drop table if exists "postgres"."public"."glucose__dbt_backup" cascade
17:07:20.744028 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:20.747206 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.747449 [debug] [Thread-1  ]: On model.mimic.glucose: Close
17:07:20.748427 [info ] [Thread-1  ]: 28 of 107 OK created table model public.glucose ................................ [[32mSELECT 0[0m in 0.19s]
17:07:20.749152 [debug] [Thread-1  ]: Finished running node model.mimic.glucose
17:07:20.749514 [debug] [Thread-1  ]: Began running node model.mimic.hco
17:07:20.750128 [info ] [Thread-1  ]: 29 of 107 START table model public.hco ......................................... [RUN]
17:07:20.750946 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.hco"
17:07:20.751360 [debug] [Thread-1  ]: Began compiling node model.mimic.hco
17:07:20.752063 [debug] [Thread-1  ]: Compiling model.mimic.hco
17:07:20.754407 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.hco"
17:07:20.755259 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.755580 [debug] [Thread-1  ]: Began executing node model.mimic.hco
17:07:20.766128 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.hco"
17:07:20.766736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.767009 [debug] [Thread-1  ]: On model.mimic.hco: BEGIN
17:07:20.767275 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:20.773680 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:20.773920 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.774036 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */


  create  table "postgres"."public"."hco__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram bicarbonate levels for all patients (adults and neonates)
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, hco as
(
  SELECT width_bucket(valuenum, 0, 231, 231) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50803, 50804, 50882)
  AND valuenum IS NOT NULL
)
SELECT bucket as bicarbonate, count(*)
FROM hco
GROUP BY bucket
ORDER BY bucket
  );
17:07:20.925838 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:07:20.931972 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.932179 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
alter table "postgres"."public"."hco" rename to "hco__dbt_backup"
17:07:20.932967 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.939742 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.939971 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
alter table "postgres"."public"."hco__dbt_tmp" rename to "hco"
17:07:20.940757 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:20.943963 [debug] [Thread-1  ]: On model.mimic.hco: COMMIT
17:07:20.944169 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.944475 [debug] [Thread-1  ]: On model.mimic.hco: COMMIT
17:07:20.945662 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:20.947720 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:07:20.947926 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
drop table if exists "postgres"."public"."hco__dbt_backup" cascade
17:07:20.949801 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:20.954901 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.955464 [debug] [Thread-1  ]: On model.mimic.hco: Close
17:07:20.956374 [info ] [Thread-1  ]: 29 of 107 OK created table model public.hco .................................... [[32mSELECT 0[0m in 0.21s]
17:07:20.957054 [debug] [Thread-1  ]: Finished running node model.mimic.hco
17:07:20.957405 [debug] [Thread-1  ]: Began running node model.mimic.heart_rate
17:07:20.957865 [info ] [Thread-1  ]: 30 of 107 START table model public.heart_rate .................................. [RUN]
17:07:20.958442 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.heart_rate"
17:07:20.958825 [debug] [Thread-1  ]: Began compiling node model.mimic.heart_rate
17:07:20.959044 [debug] [Thread-1  ]: Compiling model.mimic.heart_rate
17:07:20.960227 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.heart_rate"
17:07:20.960629 [debug] [Thread-1  ]: finished collecting timing info
17:07:20.960875 [debug] [Thread-1  ]: Began executing node model.mimic.heart_rate
17:07:20.969596 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.heart_rate"
17:07:20.970315 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:20.970423 [debug] [Thread-1  ]: On model.mimic.heart_rate: BEGIN
17:07:20.970721 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:20.977109 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:20.977358 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:20.977577 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */


  create  table "postgres"."public"."heart_rate__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram of heart rates for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, hr as
(
  SELECT width_bucket(valuenum, 0, 300, 301) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid in (211,220045)
)
SELECT bucket as heart_rate, count(*)
FROM hr
GROUP BY bucket
ORDER BY bucket
  );
17:07:21.146640 [debug] [Thread-1  ]: SQL status: SELECT 75 in 0.17 seconds
17:07:21.150124 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:21.150298 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
alter table "postgres"."public"."heart_rate" rename to "heart_rate__dbt_backup"
17:07:21.151679 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.158020 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:21.158213 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
alter table "postgres"."public"."heart_rate__dbt_tmp" rename to "heart_rate"
17:07:21.158849 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.161613 [debug] [Thread-1  ]: On model.mimic.heart_rate: COMMIT
17:07:21.161783 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:21.161881 [debug] [Thread-1  ]: On model.mimic.heart_rate: COMMIT
17:07:21.163188 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:21.166081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:07:21.166253 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
drop table if exists "postgres"."public"."heart_rate__dbt_backup" cascade
17:07:21.169593 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:21.173322 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.173552 [debug] [Thread-1  ]: On model.mimic.heart_rate: Close
17:07:21.174299 [info ] [Thread-1  ]: 30 of 107 OK created table model public.heart_rate ............................. [[32mSELECT 75[0m in 0.22s]
17:07:21.174852 [debug] [Thread-1  ]: Finished running node model.mimic.heart_rate
17:07:21.175276 [debug] [Thread-1  ]: Began running node model.mimic.height
17:07:21.175923 [info ] [Thread-1  ]: 31 of 107 START table model public.height ...................................... [RUN]
17:07:21.176787 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.height"
17:07:21.177148 [debug] [Thread-1  ]: Began compiling node model.mimic.height
17:07:21.177289 [debug] [Thread-1  ]: Compiling model.mimic.height
17:07:21.178234 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.height"
17:07:21.178734 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.179003 [debug] [Thread-1  ]: Began executing node model.mimic.height
17:07:21.187989 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.height"
17:07:21.188771 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.188985 [debug] [Thread-1  ]: On model.mimic.height: BEGIN
17:07:21.189201 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:21.194936 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:21.195265 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.195560 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */


  create  table "postgres"."public"."height__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram of heights for all patients
--  note: some height ITEMIDs were not included, which may implicitly exclude
--  some neonates from this calculation
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH ht AS
(
  SELECT valuenum, width_bucket(valuenum, 1, 200, 200) AS bucket
  FROM chartevents
  WHERE itemid in (920,226730)
  AND valuenum IS NOT NULL
  AND valuenum > 0
  AND valuenum < 500
)
SELECT bucket as height, count(*)
FROM ht
GROUP BY bucket
ORDER BY bucket
  );
17:07:21.200717 [debug] [Thread-1  ]: SQL status: SELECT 6 in 0.0 seconds
17:07:21.208044 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.208327 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
alter table "postgres"."public"."height" rename to "height__dbt_backup"
17:07:21.209462 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.214061 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.214255 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
alter table "postgres"."public"."height__dbt_tmp" rename to "height"
17:07:21.214908 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.218871 [debug] [Thread-1  ]: On model.mimic.height: COMMIT
17:07:21.219548 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.219844 [debug] [Thread-1  ]: On model.mimic.height: COMMIT
17:07:21.221207 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:21.226116 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:07:21.226813 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
drop table if exists "postgres"."public"."height__dbt_backup" cascade
17:07:21.228629 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:21.231593 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.231885 [debug] [Thread-1  ]: On model.mimic.height: Close
17:07:21.232789 [info ] [Thread-1  ]: 31 of 107 OK created table model public.height ................................. [[32mSELECT 6[0m in 0.06s]
17:07:21.233349 [debug] [Thread-1  ]: Finished running node model.mimic.height
17:07:21.233572 [debug] [Thread-1  ]: Began running node model.mimic.icd9agelimited
17:07:21.234085 [info ] [Thread-1  ]: 32 of 107 START table model public.icd9agelimited .............................. [RUN]
17:07:21.235726 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9agelimited"
17:07:21.236794 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9agelimited
17:07:21.237082 [debug] [Thread-1  ]: Compiling model.mimic.icd9agelimited
17:07:21.238459 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9agelimited"
17:07:21.239100 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.239326 [debug] [Thread-1  ]: Began executing node model.mimic.icd9agelimited
17:07:21.247182 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9agelimited"
17:07:21.247728 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.247938 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: BEGIN
17:07:21.248099 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:21.254294 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:21.254887 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.255211 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */


  create  table "postgres"."public"."icd9agelimited__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code above a certain age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Reference: tompollard, alistairewj, erinhong for code taken
-- from sodium.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH agetbl AS 
	(
	SELECT ad.subject_id 
	FROM admissions ad 
	INNER JOIN patients p 
	ON ad.subject_id = p.subject_id 
	WHERE 
	-- filter to only adults above 30
	DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 30
	-- group by subject_id to ensure there is only 1 subject_id per row
	GROUP BY ad.subject_id
	) 
SELECT COUNT(DISTINCT dia.subject_id) 
AS "Hypertension Age 30+" 
from diagnoses_icd dia 
INNER JOIN agetbl 
ON dia.subject_id = agetbl.subject_id 
WHERE dia.icd9_code 
-- 401% relates to Hypertension
LIKE '401%'
  );
17:07:21.465953 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
17:07:21.472540 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.472750 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
alter table "postgres"."public"."icd9agelimited" rename to "icd9agelimited__dbt_backup"
17:07:21.473500 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.477795 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.477993 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
alter table "postgres"."public"."icd9agelimited__dbt_tmp" rename to "icd9agelimited"
17:07:21.478736 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.481766 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: COMMIT
17:07:21.481966 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.482074 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: COMMIT
17:07:21.483174 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:21.486952 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:07:21.487224 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
drop table if exists "postgres"."public"."icd9agelimited__dbt_backup" cascade
17:07:21.489227 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:21.492161 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.492494 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: Close
17:07:21.493193 [info ] [Thread-1  ]: 32 of 107 OK created table model public.icd9agelimited ......................... [[32mSELECT 1[0m in 0.26s]
17:07:21.493510 [debug] [Thread-1  ]: Finished running node model.mimic.icd9agelimited
17:07:21.493642 [debug] [Thread-1  ]: Began running node model.mimic.icd9count
17:07:21.493781 [info ] [Thread-1  ]: 33 of 107 START table model public.icd9count ................................... [RUN]
17:07:21.494840 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9count"
17:07:21.495193 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9count
17:07:21.495391 [debug] [Thread-1  ]: Compiling model.mimic.icd9count
17:07:21.496604 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9count"
17:07:21.496959 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.497086 [debug] [Thread-1  ]: Began executing node model.mimic.icd9count
17:07:21.505163 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9count"
17:07:21.506001 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.506189 [debug] [Thread-1  ]: On model.mimic.icd9count: BEGIN
17:07:21.506282 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:21.512882 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:21.513233 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.513427 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */


  create  table "postgres"."public"."icd9count__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgement: Credit goes to Kris Kindle
-- ------------------------------------------------------------------

SELECT COUNT(DISTINCT subject_id) 
AS "Hypertension" 
from diagnoses_icd 
WHERE icd9_code 
-- 401% will search for all icd9 codes relating to hypertension
LIKE '401%'
  );
17:07:21.545009 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.03 seconds
17:07:21.549202 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.549396 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
alter table "postgres"."public"."icd9count" rename to "icd9count__dbt_backup"
17:07:21.550048 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.556202 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.556407 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
alter table "postgres"."public"."icd9count__dbt_tmp" rename to "icd9count"
17:07:21.557014 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.560111 [debug] [Thread-1  ]: On model.mimic.icd9count: COMMIT
17:07:21.560310 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.560511 [debug] [Thread-1  ]: On model.mimic.icd9count: COMMIT
17:07:21.561427 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:21.564581 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:07:21.564786 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
drop table if exists "postgres"."public"."icd9count__dbt_backup" cascade
17:07:21.566612 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:21.570304 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.570679 [debug] [Thread-1  ]: On model.mimic.icd9count: Close
17:07:21.571494 [info ] [Thread-1  ]: 33 of 107 OK created table model public.icd9count .............................. [[32mSELECT 1[0m in 0.08s]
17:07:21.572053 [debug] [Thread-1  ]: Finished running node model.mimic.icd9count
17:07:21.572417 [debug] [Thread-1  ]: Began running node model.mimic.icd9vagehistogram
17:07:21.573000 [info ] [Thread-1  ]: 34 of 107 START table model public.icd9vagehistogram ........................... [RUN]
17:07:21.573664 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vagehistogram"
17:07:21.573877 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vagehistogram
17:07:21.574073 [debug] [Thread-1  ]: Compiling model.mimic.icd9vagehistogram
17:07:21.575466 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vagehistogram"
17:07:21.576022 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.576346 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vagehistogram
17:07:21.587016 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vagehistogram"
17:07:21.588399 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.589136 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: BEGIN
17:07:21.589336 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:21.594437 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:21.594835 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.595052 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */


  create  table "postgres"."public"."icd9vagehistogram__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code and shows the output as a histogram with groups of age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgements: Made with help from Kris Kindle
-- Reference: tompollard, alistairewj for code taken
-- from age_hist.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH diatbl AS
	(
	SELECT DISTINCT ON (dia.subject_id) dia.subject_id, ad.admittime
	from diagnoses_icd dia
	INNER JOIN admissions ad
	ON dia.subject_id = ad.subject_id
	WHERE dia.icd9_code
	-- 401% relates to hypertension
	LIKE '401%'
	),
agetbl AS
	(
	SELECT dt.subject_id, DATETIME_DIFF(dt.admittime, p.dob, 'YEAR') AS age
	FROM diatbl dt
	INNER JOIN patients p
	ON dt.subject_id = p.subject_id
	)
SELECT
        COUNT(*) AS TOTAL,
        COUNT(CASE WHEN age >= 0 AND age < 16 THEN  '0 - 15' END) AS "0-15",
        COUNT(CASE WHEN age >= 16 AND age < 21 THEN '16 - 20' END) AS "16-20",
        COUNT(CASE WHEN age >= 21 AND age < 26 THEN '21 - 25' END) AS "21-25",
        COUNT(CASE WHEN age >= 26 AND age < 31 THEN '26 - 30' END) AS "26-30",
        COUNT(CASE WHEN age >= 31 AND age < 36 THEN '31 - 35' END) AS "31-35",
        COUNT(CASE WHEN age >= 36 AND age < 41 THEN '36 - 40' END) AS "36-40",
        COUNT(CASE WHEN age >= 41 AND age < 46 THEN '41 - 45' END) AS "41-45",
        COUNT(CASE WHEN age >= 46 AND age < 51 THEN '46 - 50' END) AS "46-50",
        COUNT(CASE WHEN age >= 51 AND age < 56 THEN '51 - 55' END) AS "51-55",
        COUNT(CASE WHEN age >= 56 AND age < 61 THEN '56 - 60' END) AS "56-60",
        COUNT(CASE WHEN age >= 61 AND age < 66 THEN '61 - 65' END) AS "61-65",
        COUNT(CASE WHEN age >= 66 AND age < 71 THEN '66 - 70' END) AS "66-70",
        COUNT(CASE WHEN age >= 71 AND age < 76 THEN '71 - 75' END) AS "71-75",
        COUNT(CASE WHEN age >= 76 AND age < 81 THEN '76 - 80' END) AS "76-80",
        COUNT(CASE WHEN age >= 81 AND age < 86 THEN '81 - 85' END) AS "81-85",
        COUNT(CASE WHEN age >= 86 AND age < 91 THEN '86 - 90' END) AS "86-91",
        COUNT(CASE WHEN age >= 91 THEN 'Over 91' END) AS ">91"
FROM agetbl
  );
17:07:21.730695 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.14 seconds
17:07:21.736846 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.737057 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
alter table "postgres"."public"."icd9vagehistogram" rename to "icd9vagehistogram__dbt_backup"
17:07:21.737812 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.741685 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.741888 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
alter table "postgres"."public"."icd9vagehistogram__dbt_tmp" rename to "icd9vagehistogram"
17:07:21.742625 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:21.745441 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: COMMIT
17:07:21.745623 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.745731 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: COMMIT
17:07:21.747119 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:21.749480 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:07:21.749674 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
drop table if exists "postgres"."public"."icd9vagehistogram__dbt_backup" cascade
17:07:21.751757 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:21.755082 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.755327 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: Close
17:07:21.756173 [info ] [Thread-1  ]: 34 of 107 OK created table model public.icd9vagehistogram ...................... [[32mSELECT 1[0m in 0.18s]
17:07:21.756913 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vagehistogram
17:07:21.757343 [debug] [Thread-1  ]: Began running node model.mimic.icd9vicd9agelimited
17:07:21.758055 [info ] [Thread-1  ]: 35 of 107 START table model public.icd9vicd9agelimited ......................... [RUN]
17:07:21.758827 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vicd9agelimited"
17:07:21.759224 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vicd9agelimited
17:07:21.759498 [debug] [Thread-1  ]: Compiling model.mimic.icd9vicd9agelimited
17:07:21.760640 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vicd9agelimited"
17:07:21.761249 [debug] [Thread-1  ]: finished collecting timing info
17:07:21.761506 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vicd9agelimited
17:07:21.772442 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vicd9agelimited"
17:07:21.773084 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:21.773290 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: BEGIN
17:07:21.773450 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:21.779546 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:21.779839 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:21.780026 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */


  create  table "postgres"."public"."icd9vicd9agelimited__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with two specific icd9 codes above a certain age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Reference: tompollard, alistairewj, erinhong for code taken
-- from sodium.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH agetbl AS 
	(
	SELECT ad.subject_id 
	FROM admissions ad 
	INNER JOIN patients p 
	ON ad.subject_id = p.subject_id 
	WHERE 
	DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 40 
	GROUP BY ad.subject_id
	) 
SELECT COUNT(DISTINCT dia.subject_id) 
AS "Obesity vs Hypertension Age 40+" 
from diagnoses_icd dia 
INNER JOIN agetbl 
ON dia.subject_id = agetbl.subject_id 
INNER JOIN diagnoses_icd dib 
ON dia.subject_id = dib.subject_id 
WHERE dia.icd9_code 
-- 278% relates to obesity
LIKE '278%' 
AND dib.icd9_code 
-- 401% relates to hypertension
LIKE '401%'
  );
17:07:22.103890 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.32 seconds
17:07:22.110244 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:22.110798 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
alter table "postgres"."public"."icd9vicd9agelimited" rename to "icd9vicd9agelimited__dbt_backup"
17:07:22.111951 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.116699 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:22.116893 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
alter table "postgres"."public"."icd9vicd9agelimited__dbt_tmp" rename to "icd9vicd9agelimited"
17:07:22.117558 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.120870 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: COMMIT
17:07:22.121069 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:22.121163 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: COMMIT
17:07:22.122188 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:22.124105 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:07:22.124297 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
drop table if exists "postgres"."public"."icd9vicd9agelimited__dbt_backup" cascade
17:07:22.126088 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:22.128612 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.128838 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: Close
17:07:22.129567 [info ] [Thread-1  ]: 35 of 107 OK created table model public.icd9vicd9agelimited .................... [[32mSELECT 1[0m in 0.37s]
17:07:22.130129 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vicd9agelimited
17:07:22.130441 [debug] [Thread-1  ]: Began running node model.mimic.icd9vicd9count
17:07:22.131253 [info ] [Thread-1  ]: 36 of 107 START table model public.icd9vicd9count .............................. [RUN]
17:07:22.132178 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vicd9count"
17:07:22.132433 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vicd9count
17:07:22.132851 [debug] [Thread-1  ]: Compiling model.mimic.icd9vicd9count
17:07:22.134694 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vicd9count"
17:07:22.135479 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.135910 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vicd9count
17:07:22.148525 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vicd9count"
17:07:22.149069 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.149274 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: BEGIN
17:07:22.149445 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:22.155992 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:22.156299 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.156522 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */


  create  table "postgres"."public"."icd9vicd9count__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with two specific icd9 codes
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgement: Credit goes to Kris Kindle
-- ------------------------------------------------------------------

SELECT COUNT(DISTINCT a.subject_id) 
AS "Obesity and Dyslipidemia" 
from diagnoses_icd a 
INNER JOIN diagnoses_icd b 
ON a.subject_id = b.subject_id 
WHERE a.icd9_code
-- 278% relates to obesity 
LIKE '278%' 
AND b.icd9_code 
-- 272 relates to Dyslipidemia
LIKE '272%'
  );
17:07:22.193309 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.04 seconds
17:07:22.197463 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.197649 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
alter table "postgres"."public"."icd9vicd9count" rename to "icd9vicd9count__dbt_backup"
17:07:22.198336 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.203917 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.204129 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
alter table "postgres"."public"."icd9vicd9count__dbt_tmp" rename to "icd9vicd9count"
17:07:22.204795 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.207864 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: COMMIT
17:07:22.208126 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.208390 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: COMMIT
17:07:22.209445 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:22.212609 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:07:22.212806 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
drop table if exists "postgres"."public"."icd9vicd9count__dbt_backup" cascade
17:07:22.214451 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:22.218132 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.218376 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: Close
17:07:22.219173 [info ] [Thread-1  ]: 36 of 107 OK created table model public.icd9vicd9count ......................... [[32mSELECT 1[0m in 0.09s]
17:07:22.219733 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vicd9count
17:07:22.220153 [debug] [Thread-1  ]: Began running node model.mimic.icustay_days
17:07:22.220875 [info ] [Thread-1  ]: 37 of 107 START table model public.icustay_days ................................ [RUN]
17:07:22.221437 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icustay_days"
17:07:22.221692 [debug] [Thread-1  ]: Began compiling node model.mimic.icustay_days
17:07:22.221809 [debug] [Thread-1  ]: Compiling model.mimic.icustay_days
17:07:22.223053 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icustay_days"
17:07:22.223451 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.223569 [debug] [Thread-1  ]: Began executing node model.mimic.icustay_days
17:07:22.286674 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icustay_days"
17:07:22.287279 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_days"
17:07:22.287501 [debug] [Thread-1  ]: On model.mimic.icustay_days: BEGIN
17:07:22.287664 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:22.292380 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:22.292627 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_days"
17:07:22.292799 [debug] [Thread-1  ]: On model.mimic.icustay_days: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_days"} */


  create  table "postgres"."public"."icustay_days__dbt_tmp"
  as (
    -- ----------------------------------------------------------
-- Create a table that counts each day spent in the ICU    --
-- and assign a timestamp to the start and end of each day --
-- ----------------------------------------------------------

-- ----------
-- Columns:
-- ----------
-- icustay_id
-- intime
-- outime
-- icudayseq_asc:  Counting days since arrival in the ICU
-- 				         0 = day of arrival in the ICU
--                 1 = day 1 after arrival
--                 2 = day 2 after arrival etc
-- icudayseq_desc: Counting down to the day of discharge from the ICU
--                 2 = day 2 before discharge etc
--                 1 = day 1 before discharge
-- 				         0 = day of discharge from the ICU
-- startday: if day of arrival then intime, else midnight at start of day
-- endday: if day of discharge then outtime, else midnight at end of day
-- ----------

DROP MATERIALIZED VIEW icustay_days;
CREATE VIEW icustay_days AS
WITH dayseq AS (
	SELECT icustay_id, intime, outtime,
       GENERATE_SERIES(0,CEIL(los)::INT-1,1) AS icudayseq_asc,
       GENERATE_SERIES(CEIL(los)::INT-1,0,-1) AS icudayseq_desc
	FROM icustays)
SELECT icustay_id, intime, outtime,
    icudayseq_asc, icudayseq_desc,
    CASE WHEN icudayseq_asc = 0 THEN intime
        ELSE DATETIME_ADD(date_trunc('day', intime), INTERVAL icudayseq_asc DAY)
        END AS startday,
    CASE WHEN icudayseq_desc = 0 THEN OUTTIME
        ELSE DATETIME_ADD(date_trunc('day', intime), INTERVAL icudayseq_asc+1 DAY)
				END AS endday
FROM dayseq
  );
17:07:22.293175 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "DROP"
LINE 29: DROP MATERIALIZED VIEW icustay_days;
         ^

17:07:22.293370 [debug] [Thread-1  ]: On model.mimic.icustay_days: ROLLBACK
17:07:22.293769 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.293966 [debug] [Thread-1  ]: On model.mimic.icustay_days: Close
17:07:22.294379 [debug] [Thread-1  ]: Database Error in model icustay_days (models/cookbook/icustay_days.sql)
  syntax error at or near "DROP"
  LINE 29: DROP MATERIALIZED VIEW icustay_days;
           ^
  compiled SQL at target/run/mimic/models/cookbook/icustay_days.sql
17:07:22.294889 [error] [Thread-1  ]: 37 of 107 ERROR creating table model public.icustay_days ....................... [[31mERROR[0m in 0.07s]
17:07:22.295428 [debug] [Thread-1  ]: Finished running node model.mimic.icustay_days
17:07:22.295669 [debug] [Thread-1  ]: Began running node model.mimic.icustay_detail
17:07:22.296217 [info ] [Thread-1  ]: 38 of 107 START table model public.icustay_detail .............................. [RUN]
17:07:22.296726 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icustay_detail"
17:07:22.296832 [debug] [Thread-1  ]: Began compiling node model.mimic.icustay_detail
17:07:22.296938 [debug] [Thread-1  ]: Compiling model.mimic.icustay_detail
17:07:22.298124 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icustay_detail"
17:07:22.298382 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.298626 [debug] [Thread-1  ]: Began executing node model.mimic.icustay_detail
17:07:22.309947 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icustay_detail"
17:07:22.310366 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.310469 [debug] [Thread-1  ]: On model.mimic.icustay_detail: BEGIN
17:07:22.311197 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:22.316266 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:22.316752 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.317737 [debug] [Thread-1  ]: On model.mimic.icustay_detail: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_detail"} */


  create  table "postgres"."public"."icustay_detail__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Detailed information on ICUSTAY_ID
-- Description: This query provides a useful set of information regarding patient
--              ICU stays. The information is combined from the admissions, patients, and
--              icustays tables. It includes age, length of stay, sequence, and expiry flags.
-- MIMIC version: MIMIC-III v1.3
-- ------------------------------------------------------------------

-- This query extracts useful demographic/administrative information for patient ICU stays

SELECT ie.subject_id, ie.hadm_id, ie.icustay_id

-- patient level factors
, pat.gender, pat.dod

-- hospital level factors
, adm.admittime, adm.dischtime
, DATETIME_DIFF(adm.dischtime, adm.admittime, 'DAY') as los_hospital
, DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') as admission_age
, adm.ethnicity
, case when ethnicity in
  (
       'WHITE' --  40996
     , 'WHITE - RUSSIAN' --    164
     , 'WHITE - OTHER EUROPEAN' --     81
     , 'WHITE - BRAZILIAN' --     59
     , 'WHITE - EASTERN EUROPEAN' --     25
  ) then 'white'
  when ethnicity in
  (
      'BLACK/AFRICAN AMERICAN' --   5440
    , 'BLACK/CAPE VERDEAN' --    200
    , 'BLACK/HAITIAN' --    101
    , 'BLACK/AFRICAN' --     44
    , 'CARIBBEAN ISLAND' --      9
  ) then 'black'
  when ethnicity in
    (
      'HISPANIC OR LATINO' --   1696
    , 'HISPANIC/LATINO - PUERTO RICAN' --    232
    , 'HISPANIC/LATINO - DOMINICAN' --     78
    , 'HISPANIC/LATINO - GUATEMALAN' --     40
    , 'HISPANIC/LATINO - CUBAN' --     24
    , 'HISPANIC/LATINO - SALVADORAN' --     19
    , 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)' --     13
    , 'HISPANIC/LATINO - MEXICAN' --     13
    , 'HISPANIC/LATINO - COLOMBIAN' --      9
    , 'HISPANIC/LATINO - HONDURAN' --      4
  ) then 'hispanic'
  when ethnicity in
  (
      'ASIAN' --   1509
    , 'ASIAN - CHINESE' --    277
    , 'ASIAN - ASIAN INDIAN' --     85
    , 'ASIAN - VIETNAMESE' --     53
    , 'ASIAN - FILIPINO' --     25
    , 'ASIAN - CAMBODIAN' --     17
    , 'ASIAN - OTHER' --     17
    , 'ASIAN - KOREAN' --     13
    , 'ASIAN - JAPANESE' --      7
    , 'ASIAN - THAI' --      4
  ) then 'asian'
  when ethnicity in
  (
       'AMERICAN INDIAN/ALASKA NATIVE' --     51
     , 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE' --      3
  ) then 'native'
  when ethnicity in
  (
      'UNKNOWN/NOT SPECIFIED' --   4523
    , 'UNABLE TO OBTAIN' --    814
    , 'PATIENT DECLINED TO ANSWER' --    559
  ) then 'unknown'
  else 'other' end as ethnicity_grouped
  -- , 'OTHER' --   1512
  -- , 'MULTI RACE ETHNICITY' --    130
  -- , 'PORTUGUESE' --     61
  -- , 'MIDDLE EASTERN' --     43
  -- , 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' --     18
  -- , 'SOUTH AMERICAN' --      8
, adm.hospital_expire_flag
, DENSE_RANK() OVER (PARTITION BY adm.subject_id ORDER BY adm.admittime) AS hospstay_seq
, CASE
    WHEN DENSE_RANK() OVER (PARTITION BY adm.subject_id ORDER BY adm.admittime) = 1 THEN True
    ELSE False END AS first_hosp_stay

-- icu level factors
, ie.intime, ie.outtime
, DATETIME_DIFF(ie.outtime, ie.intime, 'DAY') as los_icu
, DENSE_RANK() OVER (PARTITION BY ie.hadm_id ORDER BY ie.intime) AS icustay_seq

-- first ICU stay *for the current hospitalization*
, CASE
    WHEN DENSE_RANK() OVER (PARTITION BY ie.hadm_id ORDER BY ie.intime) = 1 THEN True
    ELSE False END AS first_icu_stay

FROM icustays ie
INNER JOIN admissions adm
    ON ie.hadm_id = adm.hadm_id
INNER JOIN patients pat
    ON ie.subject_id = pat.subject_id
WHERE adm.has_chartevents_data = 1
ORDER BY ie.subject_id, adm.admittime, ie.intime
  );
17:07:22.838953 [debug] [Thread-1  ]: SQL status: SELECT 61051 in 0.52 seconds
17:07:22.844677 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.844869 [debug] [Thread-1  ]: On model.mimic.icustay_detail: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_detail"} */
alter table "postgres"."public"."icustay_detail" rename to "icustay_detail__dbt_backup"
17:07:22.845677 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.849380 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.849609 [debug] [Thread-1  ]: On model.mimic.icustay_detail: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_detail"} */
alter table "postgres"."public"."icustay_detail__dbt_tmp" rename to "icustay_detail"
17:07:22.850261 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:22.853310 [debug] [Thread-1  ]: On model.mimic.icustay_detail: COMMIT
17:07:22.853495 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.853721 [debug] [Thread-1  ]: On model.mimic.icustay_detail: COMMIT
17:07:22.861791 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:22.863947 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_detail"
17:07:22.864268 [debug] [Thread-1  ]: On model.mimic.icustay_detail: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_detail"} */
drop table if exists "postgres"."public"."icustay_detail__dbt_backup" cascade
17:07:22.867104 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:22.871381 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.871623 [debug] [Thread-1  ]: On model.mimic.icustay_detail: Close
17:07:22.872479 [info ] [Thread-1  ]: 38 of 107 OK created table model public.icustay_detail ......................... [[32mSELECT 61051[0m in 0.58s]
17:07:22.873066 [debug] [Thread-1  ]: Finished running node model.mimic.icustay_detail
17:07:22.873416 [debug] [Thread-1  ]: Began running node model.mimic.icustay_times
17:07:22.874083 [info ] [Thread-1  ]: 39 of 107 START table model public.icustay_times ............................... [RUN]
17:07:22.874903 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icustay_times"
17:07:22.875149 [debug] [Thread-1  ]: Began compiling node model.mimic.icustay_times
17:07:22.875485 [debug] [Thread-1  ]: Compiling model.mimic.icustay_times
17:07:22.876641 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icustay_times"
17:07:22.877181 [debug] [Thread-1  ]: finished collecting timing info
17:07:22.877456 [debug] [Thread-1  ]: Began executing node model.mimic.icustay_times
17:07:22.889271 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icustay_times"
17:07:22.889851 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:22.890053 [debug] [Thread-1  ]: On model.mimic.icustay_times: BEGIN
17:07:22.890148 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:22.895658 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:22.895907 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:22.896085 [debug] [Thread-1  ]: On model.mimic.icustay_times: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_times"} */


  create  table "postgres"."public"."icustay_times__dbt_tmp"
  as (
    -- create a table which has fuzzy boundaries on hospital admission
-- involves first creating a lag/lead version of disch/admit time
with h as
(
  select
    subject_id, hadm_id, admittime, dischtime
    , lag (dischtime) over (partition by subject_id order by admittime) as dischtime_lag
    , lead (admittime) over (partition by subject_id order by admittime) as admittime_lead
  FROM admissions
)
, adm as
(
  select
    h.subject_id, h.hadm_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when h.dischtime_lag is not null
        and h.dischtime_lag > (DATETIME_SUB(h.admittime, INTERVAL '24 HOUR'))
          then DATETIME_SUB(h.admittime, (DATETIME_DIFF(h.admittime, h.dischtime_lag, 'SECOND')/2  || ' SECOND')::interval)
      else DATETIME_SUB(h.admittime, INTERVAL '12 HOUR')
      end as data_start
    , case
        when h.admittime_lead is not null
        and h.admittime_lead < (DATETIME_ADD(h.dischtime, INTERVAL '24 HOUR'))
          then DATETIME_ADD(h.dischtime, (DATETIME_DIFF(h.admittime_lead, h.dischtime, 'SECOND')/2 || ' SECOND')::interval)
      else (DATETIME_ADD(h.dischtime, INTERVAL '12 HOUR'))
      end as data_end
    from h
)
-- get first/last heart rate measurement during hospitalization for each ICUSTAY_ID
, t1 as
(
select ce.icustay_id
, min(charttime) as intime_hr
, max(charttime) as outtime_hr
FROM chartevents ce
-- very loose join to admissions to ensure charttime is near patient admission
inner join adm
  on ce.hadm_id = adm.hadm_id
  and ce.charttime >= adm.data_start
  and ce.charttime <  adm.data_end
-- only look at heart rate
where ce.itemid in (211,220045)
group by ce.icustay_id
)
-- add in subject_id/hadm_id
select
  ie.subject_id, ie.hadm_id, ie.icustay_id
  , t1.intime_hr
  , t1.outtime_hr
FROM icustays ie
left join t1
  on ie.icustay_id = t1.icustay_id
order by ie.subject_id, ie.hadm_id, ie.icustay_id
  );
17:07:23.119947 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.22 seconds
17:07:23.126299 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:23.126670 [debug] [Thread-1  ]: On model.mimic.icustay_times: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_times"} */
alter table "postgres"."public"."icustay_times" rename to "icustay_times__dbt_backup"
17:07:23.127999 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.133428 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:23.133638 [debug] [Thread-1  ]: On model.mimic.icustay_times: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_times"} */
alter table "postgres"."public"."icustay_times__dbt_tmp" rename to "icustay_times"
17:07:23.134382 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.137205 [debug] [Thread-1  ]: On model.mimic.icustay_times: COMMIT
17:07:23.137388 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:23.137601 [debug] [Thread-1  ]: On model.mimic.icustay_times: COMMIT
17:07:23.143230 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:23.145567 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_times"
17:07:23.145822 [debug] [Thread-1  ]: On model.mimic.icustay_times: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_times"} */
drop table if exists "postgres"."public"."icustay_times__dbt_backup" cascade
17:07:23.148315 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:23.152731 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.152973 [debug] [Thread-1  ]: On model.mimic.icustay_times: Close
17:07:23.153851 [info ] [Thread-1  ]: 39 of 107 OK created table model public.icustay_times .......................... [[32mSELECT 61532[0m in 0.28s]
17:07:23.154277 [debug] [Thread-1  ]: Finished running node model.mimic.icustay_times
17:07:23.154678 [debug] [Thread-1  ]: Began running node model.mimic.isuprel_durations
17:07:23.155368 [info ] [Thread-1  ]: 40 of 107 START table model public.isuprel_durations ........................... [RUN]
17:07:23.156426 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.isuprel_durations"
17:07:23.156706 [debug] [Thread-1  ]: Began compiling node model.mimic.isuprel_durations
17:07:23.157268 [debug] [Thread-1  ]: Compiling model.mimic.isuprel_durations
17:07:23.159194 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.isuprel_durations"
17:07:23.159760 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.159935 [debug] [Thread-1  ]: Began executing node model.mimic.isuprel_durations
17:07:23.172364 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.isuprel_durations"
17:07:23.173053 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.173265 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: BEGIN
17:07:23.173369 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:23.179168 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:23.179423 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.179540 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */


  create  table "postgres"."public"."isuprel_durations__dbt_tmp"
  as (
    -- This query extracts durations of isuprel administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30046 then 1 else 0 end) as vaso -- Isuprel

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30046 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30046 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30046 then rate else null end) as vaso_rate
    , max(case when itemid = 30046 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30046 -- Isuprel
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 227692 -- Isuprel
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:23.194838 [debug] [Thread-1  ]: SQL status: SELECT 26 in 0.02 seconds
17:07:23.202096 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.202408 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations" rename to "isuprel_durations__dbt_backup"
17:07:23.203978 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.208349 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.208581 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations__dbt_tmp" rename to "isuprel_durations"
17:07:23.209199 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.212202 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:07:23.212403 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.212674 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:07:23.213649 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:23.216053 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:07:23.216589 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
drop table if exists "postgres"."public"."isuprel_durations__dbt_backup" cascade
17:07:23.219820 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:23.222995 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.223260 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: Close
17:07:23.224272 [info ] [Thread-1  ]: 40 of 107 OK created table model public.isuprel_durations ...................... [[32mSELECT 26[0m in 0.07s]
17:07:23.224702 [debug] [Thread-1  ]: Finished running node model.mimic.isuprel_durations
17:07:23.224898 [debug] [Thread-1  ]: Began running node model.mimic.kdigo_creatinine
17:07:23.225425 [info ] [Thread-1  ]: 41 of 107 START table model public.kdigo_creatinine ............................ [RUN]
17:07:23.225891 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.kdigo_creatinine"
17:07:23.226019 [debug] [Thread-1  ]: Began compiling node model.mimic.kdigo_creatinine
17:07:23.226285 [debug] [Thread-1  ]: Compiling model.mimic.kdigo_creatinine
17:07:23.227568 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.kdigo_creatinine"
17:07:23.228074 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.228317 [debug] [Thread-1  ]: Began executing node model.mimic.kdigo_creatinine
17:07:23.236897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.kdigo_creatinine"
17:07:23.238302 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.238817 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: BEGIN
17:07:23.239027 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:23.245575 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:23.245820 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.245921 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_creatinine"} */


  create  table "postgres"."public"."kdigo_creatinine__dbt_tmp"
  as (
    -- Extract all creatinine values FROM labevents around patient's ICU stay
with cr as
(
select
    ie.icustay_id
  , ie.intime, ie.outtime
  , le.valuenum as creat
  , le.charttime
  FROM icustays ie
  left join labevents le
    on ie.subject_id = le.subject_id
    and le.ITEMID = 50912
    and le.VALUENUM is not null
    and DATETIME_DIFF(le.charttime, ie.intime, 'HOUR') <= (7*24-6)
    and le.CHARTTIME >= DATETIME_SUB(ie.intime, INTERVAL '6 HOUR')
    and le.CHARTTIME <= DATETIME_ADD(ie.intime, INTERVAL '7 DAY')
)
-- add in the lowest value in the previous 48 hours/7 days
SELECT
  cr.icustay_id
  , cr.charttime
  , cr.creat
  , MIN(cr48.creat) AS creat_low_past_48hr
  , MIN(cr7.creat) AS creat_low_past_7day
FROM cr
-- add in all creatinine values in the last 48 hours
LEFT JOIN cr cr48
  ON cr.icustay_id = cr48.icustay_id
  AND cr48.charttime <  cr.charttime
  AND DATETIME_DIFF(cr.charttime, cr48.charttime, 'HOUR') <= 48
-- add in all creatinine values in the last 7 days
LEFT JOIN cr cr7
  ON cr.icustay_id = cr7.icustay_id
  AND cr7.charttime <  cr.charttime
  AND DATETIME_DIFF(cr.charttime, cr7.charttime, 'DAY') <= 7
GROUP BY cr.icustay_id, cr.charttime, cr.creat
ORDER BY cr.icustay_id, cr.charttime, cr.creat
  );
17:07:23.817046 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.57 seconds
17:07:23.823270 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.823632 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_creatinine"} */
alter table "postgres"."public"."kdigo_creatinine" rename to "kdigo_creatinine__dbt_backup"
17:07:23.824833 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.829322 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.829516 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_creatinine"} */
alter table "postgres"."public"."kdigo_creatinine__dbt_tmp" rename to "kdigo_creatinine"
17:07:23.830204 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:23.833503 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: COMMIT
17:07:23.833715 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.833907 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: COMMIT
17:07:23.839914 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:23.843295 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_creatinine"
17:07:23.843505 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_creatinine"} */
drop table if exists "postgres"."public"."kdigo_creatinine__dbt_backup" cascade
17:07:23.845730 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:23.848775 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.849011 [debug] [Thread-1  ]: On model.mimic.kdigo_creatinine: Close
17:07:23.849912 [info ] [Thread-1  ]: 41 of 107 OK created table model public.kdigo_creatinine ....................... [[32mSELECT 61532[0m in 0.62s]
17:07:23.850556 [debug] [Thread-1  ]: Finished running node model.mimic.kdigo_creatinine
17:07:23.851061 [debug] [Thread-1  ]: Began running node model.mimic.labs_first_day
17:07:23.851796 [info ] [Thread-1  ]: 42 of 107 START table model public.labs_first_day .............................. [RUN]
17:07:23.852497 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.labs_first_day"
17:07:23.852731 [debug] [Thread-1  ]: Began compiling node model.mimic.labs_first_day
17:07:23.853027 [debug] [Thread-1  ]: Compiling model.mimic.labs_first_day
17:07:23.854336 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.labs_first_day"
17:07:23.855078 [debug] [Thread-1  ]: finished collecting timing info
17:07:23.855392 [debug] [Thread-1  ]: Began executing node model.mimic.labs_first_day
17:07:23.866447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.labs_first_day"
17:07:23.867736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:23.868146 [debug] [Thread-1  ]: On model.mimic.labs_first_day: BEGIN
17:07:23.868343 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:23.875150 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:23.875501 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:23.875736 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */


  create  table "postgres"."public"."labs_first_day__dbt_tmp"
  as (
    -- This query pivots lab values taken in the first 24 hours of a patient's stay

-- Have already confirmed that the unit of measurement is always the same: null or the correct unit

SELECT
  pvt.subject_id, pvt.hadm_id, pvt.icustay_id

  , min(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE NULL END) AS aniongap_min
  , max(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE NULL END) AS aniongap_max
  , min(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE NULL END) AS albumin_min
  , max(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE NULL END) AS albumin_max
  , min(CASE WHEN label = 'BANDS' THEN valuenum ELSE NULL END) AS bands_min
  , max(CASE WHEN label = 'BANDS' THEN valuenum ELSE NULL END) AS bands_max
  , min(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE NULL END) AS bicarbonate_min
  , max(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE NULL END) AS bicarbonate_max
  , min(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE NULL END) AS bilirubin_min
  , max(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE NULL END) AS bilirubin_max
  , min(CASE WHEN label = 'CREATININE' THEN valuenum ELSE NULL END) AS creatinine_min
  , max(CASE WHEN label = 'CREATININE' THEN valuenum ELSE NULL END) AS creatinine_max
  , min(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE NULL END) AS chloride_min
  , max(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE NULL END) AS chloride_max
  , min(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE NULL END) AS glucose_min
  , max(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE NULL END) AS glucose_max
  , min(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE NULL END) AS hematocrit_min
  , max(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE NULL END) AS hematocrit_max
  , min(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE NULL END) AS hemoglobin_min
  , max(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE NULL END) AS hemoglobin_max
  , min(CASE WHEN label = 'LACTATE' THEN valuenum ELSE NULL END) AS lactate_min
  , max(CASE WHEN label = 'LACTATE' THEN valuenum ELSE NULL END) AS lactate_max
  , min(CASE WHEN label = 'PLATELET' THEN valuenum ELSE NULL END) AS platelet_min
  , max(CASE WHEN label = 'PLATELET' THEN valuenum ELSE NULL END) AS platelet_max
  , min(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE NULL END) AS potassium_min
  , max(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE NULL END) AS potassium_max
  , min(CASE WHEN label = 'PTT' THEN valuenum ELSE NULL END) AS ptt_min
  , max(CASE WHEN label = 'PTT' THEN valuenum ELSE NULL END) AS ptt_max
  , min(CASE WHEN label = 'INR' THEN valuenum ELSE NULL END) AS inr_min
  , max(CASE WHEN label = 'INR' THEN valuenum ELSE NULL END) AS inr_max
  , min(CASE WHEN label = 'PT' THEN valuenum ELSE NULL END) AS pt_min
  , max(CASE WHEN label = 'PT' THEN valuenum ELSE NULL END) AS pt_max
  , min(CASE WHEN label = 'SODIUM' THEN valuenum ELSE NULL END) AS sodium_min
  , max(CASE WHEN label = 'SODIUM' THEN valuenum ELSE NULL END) AS sodium_max
  , min(CASE WHEN label = 'BUN' THEN valuenum ELSE NULL END) AS bun_min
  , max(CASE WHEN label = 'BUN' THEN valuenum ELSE NULL END) AS bun_max
  , min(CASE WHEN label = 'WBC' THEN valuenum ELSE NULL END) AS wbc_min
  , max(CASE WHEN label = 'WBC' THEN valuenum ELSE NULL END) AS wbc_max


FROM
( -- begin query that extracts the data
  SELECT ie.subject_id, ie.hadm_id, ie.icustay_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
  , CASE
        WHEN itemid = 50868 THEN 'ANION GAP'
        WHEN itemid = 50862 THEN 'ALBUMIN'
        WHEN itemid = 51144 THEN 'BANDS'
        WHEN itemid = 50882 THEN 'BICARBONATE'
        WHEN itemid = 50885 THEN 'BILIRUBIN'
        WHEN itemid = 50912 THEN 'CREATININE'
        WHEN itemid = 50806 THEN 'CHLORIDE'
        WHEN itemid = 50902 THEN 'CHLORIDE'
        WHEN itemid = 50809 THEN 'GLUCOSE'
        WHEN itemid = 50931 THEN 'GLUCOSE'
        WHEN itemid = 50810 THEN 'HEMATOCRIT'
        WHEN itemid = 51221 THEN 'HEMATOCRIT'
        WHEN itemid = 50811 THEN 'HEMOGLOBIN'
        WHEN itemid = 51222 THEN 'HEMOGLOBIN'
        WHEN itemid = 50813 THEN 'LACTATE'
        WHEN itemid = 51265 THEN 'PLATELET'
        WHEN itemid = 50822 THEN 'POTASSIUM'
        WHEN itemid = 50971 THEN 'POTASSIUM'
        WHEN itemid = 51275 THEN 'PTT'
        WHEN itemid = 51237 THEN 'INR'
        WHEN itemid = 51274 THEN 'PT'
        WHEN itemid = 50824 THEN 'SODIUM'
        WHEN itemid = 50983 THEN 'SODIUM'
        WHEN itemid = 51006 THEN 'BUN'
        WHEN itemid = 51300 THEN 'WBC'
        WHEN itemid = 51301 THEN 'WBC'
      ELSE null
    END as label
  , -- add in some sanity checks on the values
  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks
    CASE
      WHEN itemid = 50862 and valuenum >    10 THEN null -- g/dL 'ALBUMIN'
      WHEN itemid = 50868 and valuenum > 10000 THEN null -- mEq/L 'ANION GAP'
      WHEN itemid = 51144 and valuenum <     0 THEN null -- immature band forms, %
      WHEN itemid = 51144 and valuenum >   100 THEN null -- immature band forms, %
      WHEN itemid = 50882 and valuenum > 10000 THEN null -- mEq/L 'BICARBONATE'
      WHEN itemid = 50885 and valuenum >   150 THEN null -- mg/dL 'BILIRUBIN'
      WHEN itemid = 50806 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50902 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50912 and valuenum >   150 THEN null -- mg/dL 'CREATININE'
      WHEN itemid = 50809 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50931 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50810 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 51221 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 50811 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 51222 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 50813 and valuenum >    50 THEN null -- mmol/L 'LACTATE'
      WHEN itemid = 51265 and valuenum > 10000 THEN null -- K/uL 'PLATELET'
      WHEN itemid = 50822 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 50971 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 51275 and valuenum >   150 THEN null -- sec 'PTT'
      WHEN itemid = 51237 and valuenum >    50 THEN null -- 'INR'
      WHEN itemid = 51274 and valuenum >   150 THEN null -- sec 'PT'
      WHEN itemid = 50824 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 50983 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 51006 and valuenum >   300 THEN null -- 'BUN'
      WHEN itemid = 51300 and valuenum >  1000 THEN null -- 'WBC'
      WHEN itemid = 51301 and valuenum >  1000 THEN null -- 'WBC'
    ELSE le.valuenum
    END as valuenum

  FROM icustays ie

  LEFT JOIN labevents le
    ON le.subject_id = ie.subject_id AND le.hadm_id = ie.hadm_id
    AND le.charttime BETWEEN (DATETIME_SUB(ie.intime, INTERVAL '6' HOUR)) AND (DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
    AND le.ITEMID in
    (
      -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS
      50868, -- ANION GAP | CHEMISTRY | BLOOD | 769895
      50862, -- ALBUMIN | CHEMISTRY | BLOOD | 146697
      51144, -- BANDS - hematology
      50882, -- BICARBONATE | CHEMISTRY | BLOOD | 780733
      50885, -- BILIRUBIN, TOTAL | CHEMISTRY | BLOOD | 238277
      50912, -- CREATININE | CHEMISTRY | BLOOD | 797476
      50902, -- CHLORIDE | CHEMISTRY | BLOOD | 795568
      50806, -- CHLORIDE, WHOLE BLOOD | BLOOD GAS | BLOOD | 48187
      50931, -- GLUCOSE | CHEMISTRY | BLOOD | 748981
      50809, -- GLUCOSE | BLOOD GAS | BLOOD | 196734
      51221, -- HEMATOCRIT | HEMATOLOGY | BLOOD | 881846
      50810, -- HEMATOCRIT, CALCULATED | BLOOD GAS | BLOOD | 89715
      51222, -- HEMOGLOBIN | HEMATOLOGY | BLOOD | 752523
      50811, -- HEMOGLOBIN | BLOOD GAS | BLOOD | 89712
      50813, -- LACTATE | BLOOD GAS | BLOOD | 187124
      51265, -- PLATELET COUNT | HEMATOLOGY | BLOOD | 778444
      50971, -- POTASSIUM | CHEMISTRY | BLOOD | 845825
      50822, -- POTASSIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 192946
      51275, -- PTT | HEMATOLOGY | BLOOD | 474937
      51237, -- INR(PT) | HEMATOLOGY | BLOOD | 471183
      51274, -- PT | HEMATOLOGY | BLOOD | 469090
      50983, -- SODIUM | CHEMISTRY | BLOOD | 808489
      50824, -- SODIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 71503
      51006, -- UREA NITROGEN | CHEMISTRY | BLOOD | 791925
      51301, -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301
      51300  -- WBC COUNT | HEMATOLOGY | BLOOD | 2371
    )
    AND valuenum IS NOT null AND valuenum > 0 -- lab values cannot be 0 and cannot be negative
) pvt
GROUP BY pvt.subject_id, pvt.hadm_id, pvt.icustay_id
ORDER BY pvt.subject_id, pvt.hadm_id, pvt.icustay_id
  );
17:07:24.971059 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.1 seconds
17:07:24.976273 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:24.976478 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
alter table "postgres"."public"."labs_first_day" rename to "labs_first_day__dbt_backup"
17:07:24.977285 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:24.981413 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:24.981624 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
alter table "postgres"."public"."labs_first_day__dbt_tmp" rename to "labs_first_day"
17:07:24.982272 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:24.985714 [debug] [Thread-1  ]: On model.mimic.labs_first_day: COMMIT
17:07:24.985913 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:24.986097 [debug] [Thread-1  ]: On model.mimic.labs_first_day: COMMIT
17:07:24.989629 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:24.992107 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:07:24.992310 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
drop table if exists "postgres"."public"."labs_first_day__dbt_backup" cascade
17:07:24.994918 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:24.997760 [debug] [Thread-1  ]: finished collecting timing info
17:07:24.997999 [debug] [Thread-1  ]: On model.mimic.labs_first_day: Close
17:07:24.998964 [info ] [Thread-1  ]: 42 of 107 OK created table model public.labs_first_day ......................... [[32mSELECT 61532[0m in 1.15s]
17:07:24.999612 [debug] [Thread-1  ]: Finished running node model.mimic.labs_first_day
17:07:25.000006 [debug] [Thread-1  ]: Began running node model.mimic.martin
17:07:25.000762 [info ] [Thread-1  ]: 43 of 107 START table model public.martin ...................................... [RUN]
17:07:25.001764 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.martin"
17:07:25.002038 [debug] [Thread-1  ]: Began compiling node model.mimic.martin
17:07:25.002325 [debug] [Thread-1  ]: Compiling model.mimic.martin
17:07:25.005559 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.martin"
17:07:25.007403 [debug] [Thread-1  ]: finished collecting timing info
17:07:25.008121 [debug] [Thread-1  ]: Began executing node model.mimic.martin
17:07:25.021883 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.martin"
17:07:25.022688 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.023026 [debug] [Thread-1  ]: On model.mimic.martin: BEGIN
17:07:25.023218 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:25.027727 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:25.027980 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.028155 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */


  create  table "postgres"."public"."martin__dbt_tmp"
  as (
    -- ICD-9 codes for sepsis as validated by Martin et al.

-- Greg S. Martin, David M. Mannino, Stephanie Eaton, and Marc Moss. The epidemiology of
-- sepsis in the united states from 1979 through 2000. N Engl J Med, 348(16):1546–1554, Apr
-- 2003. doi: 10.1056/NEJMoa022139. URL http://dx.doi.org/10.1056/NEJMoa022139.
 
WITH co_dx AS
(
	SELECT subject_id, hadm_id
  , MAX(
    	CASE
        -- septicemia
    		WHEN SUBSTR(icd9_code,1,3) = '038' THEN 1
        -- septicemic, bacteremia, disseminated fungal infection, disseminated candida infection
				-- NOTE: the paper specifies 020.0 ... but this is bubonic plague
				-- presumably, they meant 020.2, which is septicemic plague
        WHEN SUBSTR(icd9_code,1,4) in ('0202','7907','1179','1125') THEN 1
        -- disseminated fungal endocarditis
        WHEN SUBSTR(icd9_code,1,5) = '11281' THEN 1
      ELSE 0 END
    ) AS sepsis
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('7991') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('51881','51882','51885','78609') THEN 1
      ELSE 0 END
    ) AS respiratory
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('4580','7855','4580','4588','4589','7963') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('785.51','785.59') THEN 1
      ELSE 0 END
    ) AS cardiovascular
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('584','580','585') THEN 1
      ELSE 0 END
    ) AS renal
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('570') THEN 1
        WHEN SUBSTR(icd9_code,1,4) in ('5722','5733') THEN 1
      ELSE 0 END
    ) AS hepatic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('2862','2866','2869','2873','2874','2875') THEN 1
      ELSE 0 END
    ) AS hematologic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('2762') THEN 1
      ELSE 0 END
    ) AS metabolic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('293') THEN 1
        WHEN SUBSTR(icd9_code,1,4) in ('3481','3483') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('78001','78009') THEN 1
      ELSE 0 END
    ) AS neurologic
  from diagnoses_icd
  GROUP BY subject_id, hadm_id
)
-- procedure codes:
-- "96.7 - Ventilator management"
-- translated:
--    9670	Continuous invasive mechanical ventilation of unspecified duration
--    9671	Continuous invasive mechanical ventilation for less than 96 consecutive hours
--    9672	Continuous invasive mechanical ventilation for 96 consecutive hours or more
-- "39.95 - Hemodialysis"
--    3995	Hemodialysis
-- "89.14 - Electroencephalography"
--    8914	Electroencephalogram
, co_proc as
(
  SELECT subject_id, hadm_id
  , MAX(CASE WHEN icd9_code = '967' then 1 ELSE 0 END) as respiratory
  , MAX(CASE WHEN icd9_code = '3995' then 1 ELSE 0 END) as renal
  , MAX(CASE WHEN icd9_code = '8914' then 1 ELSE 0 END) as neurologic
  FROM procedures_icd
  GROUP BY subject_id, hadm_id
)
select adm.subject_id, adm.hadm_id
, co_dx.sepsis
, CASE
    WHEN co_dx.respiratory = 1 OR co_proc.respiratory = 1
      OR co_dx.cardiovascular = 1
      OR co_dx.renal = 1 OR co_proc.renal = 1
      OR co_dx.hepatic = 1
      OR co_dx.hematologic = 1
      OR co_dx.metabolic = 1
      OR co_dx.neurologic = 1 OR co_proc.neurologic = 1
    THEN 1
  ELSE 0 END as organ_failure
, case when co_dx.respiratory = 1 or co_proc.respiratory = 1 then 1 else 0 end as respiratory
, co_dx.cardiovascular
, case when co_dx.renal = 1 or co_proc.renal = 1 then 1 else 0 end as renal
, co_dx.hepatic
, co_dx.hematologic
, co_dx.metabolic
, case when co_dx.neurologic = 1 or co_proc.neurologic = 1 then 1 else 0 end as neurologic
FROM admissions adm
left join co_dx
  on adm.hadm_id = co_dx.hadm_id
left join co_proc
  on adm.hadm_id = co_proc.hadm_id
  );
17:07:25.921351 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.89 seconds
17:07:25.925103 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.925296 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
alter table "postgres"."public"."martin" rename to "martin__dbt_backup"
17:07:25.925773 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:25.929735 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.929932 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
alter table "postgres"."public"."martin__dbt_tmp" rename to "martin"
17:07:25.930926 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:25.935719 [debug] [Thread-1  ]: On model.mimic.martin: COMMIT
17:07:25.935980 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.936159 [debug] [Thread-1  ]: On model.mimic.martin: COMMIT
17:07:25.937430 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:25.939620 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:07:25.939818 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
drop table if exists "postgres"."public"."martin__dbt_backup" cascade
17:07:25.941469 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:25.944181 [debug] [Thread-1  ]: finished collecting timing info
17:07:25.944405 [debug] [Thread-1  ]: On model.mimic.martin: Close
17:07:25.945374 [info ] [Thread-1  ]: 43 of 107 OK created table model public.martin ................................. [[32mSELECT 58976[0m in 0.94s]
17:07:25.946032 [debug] [Thread-1  ]: Finished running node model.mimic.martin
17:07:25.946238 [debug] [Thread-1  ]: Began running node model.mimic.milrinone_durations
17:07:25.946929 [info ] [Thread-1  ]: 44 of 107 START table model public.milrinone_durations ......................... [RUN]
17:07:25.948930 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.milrinone_durations"
17:07:25.949713 [debug] [Thread-1  ]: Began compiling node model.mimic.milrinone_durations
17:07:25.950101 [debug] [Thread-1  ]: Compiling model.mimic.milrinone_durations
17:07:25.953105 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.milrinone_durations"
17:07:25.953687 [debug] [Thread-1  ]: finished collecting timing info
17:07:25.953885 [debug] [Thread-1  ]: Began executing node model.mimic.milrinone_durations
17:07:25.963338 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.milrinone_durations"
17:07:25.964853 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:25.965273 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: BEGIN
17:07:25.965394 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:25.971639 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:25.971871 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:25.972088 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */


  create  table "postgres"."public"."milrinone_durations__dbt_tmp"
  as (
    -- This query extracts durations of milrinone administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30125 then 1 else 0 end) as vaso -- milrinone

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30125 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30125 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30125 then rate else null end) as vaso_rate
    , max(case when itemid = 30125 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30125 -- milrinone
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221986 -- milrinone
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:27.580478 [debug] [Thread-1  ]: SQL status: SELECT 3600 in 1.61 seconds
17:07:27.587308 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:27.587589 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations" rename to "milrinone_durations__dbt_backup"
17:07:27.588330 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:27.592169 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:27.592370 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations__dbt_tmp" rename to "milrinone_durations"
17:07:27.593122 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:27.596294 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:07:27.596557 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:27.596757 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:07:27.598224 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:27.600919 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:07:27.601119 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
drop table if exists "postgres"."public"."milrinone_durations__dbt_backup" cascade
17:07:27.603212 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:27.605967 [debug] [Thread-1  ]: finished collecting timing info
17:07:27.606196 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: Close
17:07:27.607106 [info ] [Thread-1  ]: 44 of 107 OK created table model public.milrinone_durations .................... [[32mSELECT 3600[0m in 1.66s]
17:07:27.607674 [debug] [Thread-1  ]: Finished running node model.mimic.milrinone_durations
17:07:27.608018 [debug] [Thread-1  ]: Began running node model.mimic.min_surviving_bp
17:07:27.608740 [info ] [Thread-1  ]: 45 of 107 START table model public.min_surviving_bp ............................ [RUN]
17:07:27.609504 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.min_surviving_bp"
17:07:27.609734 [debug] [Thread-1  ]: Began compiling node model.mimic.min_surviving_bp
17:07:27.609977 [debug] [Thread-1  ]: Compiling model.mimic.min_surviving_bp
17:07:27.611801 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.min_surviving_bp"
17:07:27.612585 [debug] [Thread-1  ]: finished collecting timing info
17:07:27.612852 [debug] [Thread-1  ]: Began executing node model.mimic.min_surviving_bp
17:07:27.625531 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.min_surviving_bp"
17:07:27.626214 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.626413 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: BEGIN
17:07:27.626703 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:27.634381 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:27.635269 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.635479 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */


  create  table "postgres"."public"."min_surviving_bp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the systolic blood pressure of hospital survivors
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, min_surviving_bp as
(
  SELECT p.subject_id, ce.icustay_id, min(valuenum) AS min_sbp
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  -- here we filter down to only survivors
  INNER JOIN patients p
  ON ce.subject_id = p.subject_id and p.expire_flag = 0
  WHERE itemid IN (6, 51, 455, 6701, 220179, 220050)
  GROUP BY p.subject_id, ce.icustay_id
)
, min_surviving_bp_counted as
(
  SELECT width_bucket(min_sbp, 0, 300, 300) AS bucket
  FROM min_surviving_bp
)
SELECT bucket as systolic_blood_pressure, count(*)
FROM min_surviving_bp_counted
GROUP BY bucket
ORDER BY bucket
  );
17:07:27.806446 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.17 seconds
17:07:27.809957 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.810135 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
alter table "postgres"."public"."min_surviving_bp" rename to "min_surviving_bp__dbt_backup"
17:07:27.811026 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:27.815452 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.815673 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
alter table "postgres"."public"."min_surviving_bp__dbt_tmp" rename to "min_surviving_bp"
17:07:27.816468 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:27.819478 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: COMMIT
17:07:27.819682 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.819872 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: COMMIT
17:07:27.822322 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:27.824938 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:07:27.825159 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
drop table if exists "postgres"."public"."min_surviving_bp__dbt_backup" cascade
17:07:27.827229 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:27.830116 [debug] [Thread-1  ]: finished collecting timing info
17:07:27.830346 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: Close
17:07:27.831329 [info ] [Thread-1  ]: 45 of 107 OK created table model public.min_surviving_bp ....................... [[32mSELECT 4[0m in 0.22s]
17:07:27.831891 [debug] [Thread-1  ]: Finished running node model.mimic.min_surviving_bp
17:07:27.832307 [debug] [Thread-1  ]: Began running node model.mimic.mortality
17:07:27.833070 [info ] [Thread-1  ]: 46 of 107 START table model public.mortality ................................... [RUN]
17:07:27.833911 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.mortality"
17:07:27.834224 [debug] [Thread-1  ]: Began compiling node model.mimic.mortality
17:07:27.834683 [debug] [Thread-1  ]: Compiling model.mimic.mortality
17:07:27.836131 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.mortality"
17:07:27.836799 [debug] [Thread-1  ]: finished collecting timing info
17:07:27.837076 [debug] [Thread-1  ]: Began executing node model.mimic.mortality
17:07:27.849736 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.mortality"
17:07:27.850138 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:27.850242 [debug] [Thread-1  ]: On model.mimic.mortality: BEGIN
17:07:27.850335 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:27.856878 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:27.857213 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:27.857496 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */


  create  table "postgres"."public"."mortality__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Calculate in-hospital, 30-day, and 1 year mortality (from hospital admission)
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Inclusion criteria: Adult (>15 year old) patients, *MOST RECENT* hospital admission
-- ------------------------------------------------------------------

WITH tmp as
(
    SELECT adm.hadm_id, admittime, dischtime, adm.deathtime, pat.dod
    FROM admissions adm
    INNER JOIN patients pat
    ON adm.subject_id = pat.subject_id
    -- filter out organ donor accounts
    WHERE lower(diagnosis) NOT LIKE '%organ donor%'
    -- at least 15 years old
    AND DATETIME_DIFF(admittime, dob, 'YEAR') > 15
    -- filter that removes hospital admissions with no corresponding ICU data
    AND HAS_CHARTEVENTS_DATA = 1
)
SELECT COUNT(hadm_id) AS NumPat -- total number of patients
, round( cast(COUNT(deathtime) AS NUMERIC)/COUNT(hadm_id)*100 , 4) AS HospMort -- % hospital mortality
, round( cast(SUM(CASE WHEN dod < DATETIME_ADD(admittime, INTERVAL '30' DAY) THEN 1 ELSE 0 END) AS NUMERIC)/COUNT(hadm_id)*100.0 , 4) AS HospMort30day -- % 30 day mortality
, round( cast(SUM(CASE WHEN dod < DATETIME_ADD(admittime, INTERVAL '1' YEAR) THEN 1 ELSE 0 END) AS NUMERIC)/COUNT(hadm_id)*100 , 4) AS HospMort1yr -- % 1 year mortality
FROM tmp
  );
17:07:28.084237 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.23 seconds
17:07:28.089997 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:28.090354 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
alter table "postgres"."public"."mortality" rename to "mortality__dbt_backup"
17:07:28.091706 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:28.097621 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:28.097819 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
alter table "postgres"."public"."mortality__dbt_tmp" rename to "mortality"
17:07:28.098522 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:28.101338 [debug] [Thread-1  ]: On model.mimic.mortality: COMMIT
17:07:28.101517 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:28.101737 [debug] [Thread-1  ]: On model.mimic.mortality: COMMIT
17:07:28.104030 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:28.106082 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:07:28.106274 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
drop table if exists "postgres"."public"."mortality__dbt_backup" cascade
17:07:28.108443 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:28.111226 [debug] [Thread-1  ]: finished collecting timing info
17:07:28.111526 [debug] [Thread-1  ]: On model.mimic.mortality: Close
17:07:28.112503 [info ] [Thread-1  ]: 46 of 107 OK created table model public.mortality .............................. [[32mSELECT 1[0m in 0.28s]
17:07:28.113078 [debug] [Thread-1  ]: Finished running node model.mimic.mortality
17:07:28.113470 [debug] [Thread-1  ]: Began running node model.mimic.neuroblock_dose
17:07:28.114107 [info ] [Thread-1  ]: 47 of 107 START table model public.neuroblock_dose ............................. [RUN]
17:07:28.114875 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.neuroblock_dose"
17:07:28.115258 [debug] [Thread-1  ]: Began compiling node model.mimic.neuroblock_dose
17:07:28.115537 [debug] [Thread-1  ]: Compiling model.mimic.neuroblock_dose
17:07:28.117050 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.neuroblock_dose"
17:07:28.117441 [debug] [Thread-1  ]: finished collecting timing info
17:07:28.117895 [debug] [Thread-1  ]: Began executing node model.mimic.neuroblock_dose
17:07:28.126435 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.neuroblock_dose"
17:07:28.127045 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:28.127255 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: BEGIN
17:07:28.127349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:28.133930 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:28.134156 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:28.134254 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */


  create  table "postgres"."public"."neuroblock_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of neuromuscular blocking agents
-- Note: we assume that injections will be filtered for carevue as they will have starttime = stopttime.

-- Get drug administration data from CareVue and MetaVision
-- metavision is simple and only requires one temporary table

with drugmv as
(
  select
      icustay_id, orderid
    , rate as drug_rate
    , amount as drug_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid in
  (
      222062 -- Vecuronium (664 rows, 154 infusion rows)
    , 221555 -- Cisatracurium (9334 rows, 8970 infusion rows)
  )
  and statusdescription != 'Rewritten' -- only valid orders
  and rate is not null -- only continuous infusions
)
, drugcv1 as
(
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped

    -- we only include continuous infusions, therefore expect a rate
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 and amount is not null then 1
            when itemid <  40000 and rate is not null then 1
          else 0 end) as drug_null
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 then coalesce(rate, amount)
          else rate end) as drug_rate
    , max(amount) as drug_amount
  from inputevents_cv
  where itemid in
  (
      30114 -- Cisatracurium (63994 rows)
    , 30138	-- Vecuronium	 (5160 rows)
    , 30113 -- Atracurium  (1163 rows)
    -- Below rows are less frequent ad-hoc documentation, but worth including!
    , 42174	-- nimbex cc/hr (207 rows)
    , 42385	-- Cisatracurium gtt (156 rows)
    , 41916	-- NIMBEX	inputevents_cv (136 rows)
    , 42100	-- cistatracurium	(132 rows)
    , 42045	-- nimbex mcg/kg/min (78 rows)
    , 42246 -- CISATRICARIUM CC/HR (70 rows)
    , 42291	-- NIMBEX CC/HR (48 rows)
    , 42590	-- nimbex	inputevents_cv (38 rows)
    , 42284	-- CISATRACURIUM DRIP (9 rows)
    , 45096	-- Vecuronium drip (2 rows)
  )
  group by icustay_id, charttime
  UNION
  -- add data from chartevents
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped
    , max(case when valuenum <= 10 then 0 else 1 end) as drug_null

    -- educated guess!
    , max(case when valuenum <= 10 then valuenum else null end) as drug_rate
    , max(case when valuenum  > 10 then valuenum else null end) as drug_amount
  from chartevents
  where itemid in
  (
      1856 -- Vecuronium mcg/min  (8 rows)
    , 2164 -- NIMBEX MG/KG/HR  (243 rows)
    , 2548 -- nimbex mg/kg/hr  (103 rows)
    , 2285 -- nimbex mcg/kg/min  (85 rows)
    , 2290 -- nimbex mcg/kg/m  (32 rows)
    , 2670 -- nimbex  (38 rows)
    , 2546 -- CISATRACURIUMMG/KG/H  (7 rows)
    , 1098 -- cisatracurium mg/kg  (36 rows)
    , 2390 -- cisatracurium mg/hr  (15 rows)
    , 2511 -- CISATRACURIUM GTT  (4 rows)
    , 1028 -- Cisatracurium  (208 rows)
    , 1858 -- cisatracurium  (351 rows)
  )
  group by icustay_id, charttime

)
, drugcv2 as
(
  select v.*
    , sum(drug_null) over (partition by icustay_id order by charttime) as drug_partition
  from
    drugcv1 v
)
, drugcv3 as
(
  select v.*
    , first_value(drug_rate) over (partition by icustay_id, drug_partition order by charttime) as drug_prevrate_ifnull
  from
    drugcv2 v
)
, drugcv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) AS delta

    , drug
    , drug_rate
    , drug_amount
    , drug_stopped
    , drug_prevrate_ifnull

    -- We define start time here
    , case
        when drug = 0 then null

        -- if this is the first instance of the drug
        when drug_rate > 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug, drug_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes drugnum sequential
        when drug_rate = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- drug_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when drug_prevrate_ifnull = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newdrug = 1
        when LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) = 0
          then 1

        -- If the last recorded drug was D/C'd, newdrug = 1
        when
          LAG(drug_stopped,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 1 then 1

        when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) > (interval '8 hours') then 1
      else null
      end as drug_start

FROM
  drugcv3
)
-- propagate start/stop flags forward in time
, drugcv5 as
(
  select v.*
    , SUM(drug_start) OVER (partition by icustay_id, drug order by charttime) as drug_first
FROM
  drugcv4 v
)
, drugcv6 as
(
  select v.*
    -- We define end time here
    , case
        when drug = 0
          then null

        -- If the recorded drug was D/C'd, this is an end time
        when drug_stopped = 1
          then drug_first

        -- If the rate is zero, this is the end time
        when drug_rate = 0
          then drug_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on drug
        -- in principle, this could add an extra end time for the drug
        -- however, since we later group on drug_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) is null
          then drug_first

        else null
        end as drug_stop
    from drugcv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, drug, drug_rate, drug_amount
--     , drug_stopped
--     , drug_start
--     , drug_first
--     , drug_stop
-- from drugcv6 order by icustay_id, charttime

, drugcv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, drug_first order by charttime) as endtime
  , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
from drugcv6
where
  drug_first is not null -- bogus data
and
  drug_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, drugcv8 as
(
  select
    icustay_id
    , starttime, endtime
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv7
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, drugcv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(drug_rate) OVER (partition by icustay_id order by starttime, endtime) = drug_rate
        THEN 0
      else 1
    end as drug_groups
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv8
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
, drugcv10 as
(
  select
    icustay_id
    , starttime, endtime
    , drug_groups
    , SUM(drug_groups) OVER (partition by icustay_id order by starttime, endtime) as drug_groups_sum
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv9
)
, drugcv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , drug_groups_sum
  , drug_rate
  , sum(drug_amount) as drug_amount
  from drugcv10
  group by icustay_id, drug_groups_sum, drug_rate
)
-- now assign this data to every hour of the patient's stay
-- drug_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugcv
UNION
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugmv
order by icustay_id, starttime
  );
17:07:29.614759 [debug] [Thread-1  ]: SQL status: SELECT 9704 in 1.48 seconds
17:07:29.621461 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:29.621702 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose" rename to "neuroblock_dose__dbt_backup"
17:07:29.622650 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:29.631454 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:29.631667 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose__dbt_tmp" rename to "neuroblock_dose"
17:07:29.632369 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:29.635472 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:07:29.635680 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:29.635870 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:07:29.637846 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:29.640582 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:07:29.640803 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
drop table if exists "postgres"."public"."neuroblock_dose__dbt_backup" cascade
17:07:29.642494 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:29.645243 [debug] [Thread-1  ]: finished collecting timing info
17:07:29.645470 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: Close
17:07:29.646305 [info ] [Thread-1  ]: 47 of 107 OK created table model public.neuroblock_dose ........................ [[32mSELECT 9704[0m in 1.53s]
17:07:29.646931 [debug] [Thread-1  ]: Finished running node model.mimic.neuroblock_dose
17:07:29.647358 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_durations
17:07:29.648122 [info ] [Thread-1  ]: 48 of 107 START table model public.norepinephrine_durations .................... [RUN]
17:07:29.648935 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_durations"
17:07:29.649198 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_durations
17:07:29.649528 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_durations
17:07:29.651502 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_durations"
17:07:29.652324 [debug] [Thread-1  ]: finished collecting timing info
17:07:29.652767 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_durations
17:07:29.665014 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_durations"
17:07:29.666138 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:29.666333 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: BEGIN
17:07:29.666881 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:29.672705 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:29.673080 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:29.673201 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */


  create  table "postgres"."public"."norepinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of norepinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30047,30120) then rate else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30047,30120) -- norepinephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the carevue data before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime

, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:37.253739 [debug] [Thread-1  ]: SQL status: SELECT 23188 in 7.58 seconds
17:07:37.259396 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:37.259632 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations" rename to "norepinephrine_durations__dbt_backup"
17:07:37.260766 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:37.265659 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:37.265855 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations__dbt_tmp" rename to "norepinephrine_durations"
17:07:37.266784 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:37.269538 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:07:37.269718 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:37.269823 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:07:37.274454 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:37.276629 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:07:37.276809 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
drop table if exists "postgres"."public"."norepinephrine_durations__dbt_backup" cascade
17:07:37.279058 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:37.281610 [debug] [Thread-1  ]: finished collecting timing info
17:07:37.281820 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: Close
17:07:37.282333 [info ] [Thread-1  ]: 48 of 107 OK created table model public.norepinephrine_durations ............... [[32mSELECT 23188[0m in 7.63s]
17:07:37.282974 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_durations
17:07:37.283326 [debug] [Thread-1  ]: Began running node model.mimic.number_of_patients
17:07:37.284064 [info ] [Thread-1  ]: 49 of 107 START table model public.number_of_patients .......................... [RUN]
17:07:37.284863 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.number_of_patients"
17:07:37.285114 [debug] [Thread-1  ]: Began compiling node model.mimic.number_of_patients
17:07:37.285363 [debug] [Thread-1  ]: Compiling model.mimic.number_of_patients
17:07:37.287403 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.number_of_patients"
17:07:37.288235 [debug] [Thread-1  ]: finished collecting timing info
17:07:37.288638 [debug] [Thread-1  ]: Began executing node model.mimic.number_of_patients
17:07:37.303092 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.number_of_patients"
17:07:37.303553 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.303661 [debug] [Thread-1  ]: On model.mimic.number_of_patients: BEGIN
17:07:37.303809 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:37.311360 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:37.311604 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.311706 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */


  create  table "postgres"."public"."number_of_patients__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Counts the total number of patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

SELECT count(*)
FROM patients
  );
17:07:37.317832 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.01 seconds
17:07:37.321585 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.321901 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
alter table "postgres"."public"."number_of_patients" rename to "number_of_patients__dbt_backup"
17:07:37.323791 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:37.329221 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.329408 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
alter table "postgres"."public"."number_of_patients__dbt_tmp" rename to "number_of_patients"
17:07:37.329846 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:37.332912 [debug] [Thread-1  ]: On model.mimic.number_of_patients: COMMIT
17:07:37.333108 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.333203 [debug] [Thread-1  ]: On model.mimic.number_of_patients: COMMIT
17:07:37.334013 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:37.336115 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:07:37.336313 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
drop table if exists "postgres"."public"."number_of_patients__dbt_backup" cascade
17:07:37.338829 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:37.343880 [debug] [Thread-1  ]: finished collecting timing info
17:07:37.344140 [debug] [Thread-1  ]: On model.mimic.number_of_patients: Close
17:07:37.344927 [info ] [Thread-1  ]: 49 of 107 OK created table model public.number_of_patients ..................... [[32mSELECT 1[0m in 0.06s]
17:07:37.345449 [debug] [Thread-1  ]: Finished running node model.mimic.number_of_patients
17:07:37.345617 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_dose
17:07:37.345924 [info ] [Thread-1  ]: 50 of 107 START table model public.phenylephrine_dose .......................... [RUN]
17:07:37.346349 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_dose"
17:07:37.346459 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_dose
17:07:37.346808 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_dose
17:07:37.348600 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_dose"
17:07:37.349088 [debug] [Thread-1  ]: finished collecting timing info
17:07:37.349325 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_dose
17:07:37.357937 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_dose"
17:07:37.359144 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:37.359523 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: BEGIN
17:07:37.360032 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:37.366129 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:37.366359 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:37.366462 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */


  create  table "postgres"."public"."phenylephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of phenylephrine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30127,30128) -- phenylephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:07:41.630133 [debug] [Thread-1  ]: SQL status: SELECT 186281 in 4.26 seconds
17:07:41.637816 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:41.638265 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose" rename to "phenylephrine_dose__dbt_backup"
17:07:41.639774 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:41.643417 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:41.643624 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose__dbt_tmp" rename to "phenylephrine_dose"
17:07:41.644289 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:41.647302 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:07:41.647563 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:41.647767 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:07:41.667008 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
17:07:41.669257 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:07:41.669443 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
drop table if exists "postgres"."public"."phenylephrine_dose__dbt_backup" cascade
17:07:41.671424 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:41.674416 [debug] [Thread-1  ]: finished collecting timing info
17:07:41.674783 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: Close
17:07:41.675667 [info ] [Thread-1  ]: 50 of 107 OK created table model public.phenylephrine_dose ..................... [[32mSELECT 186281[0m in 4.33s]
17:07:41.676246 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_dose
17:07:41.676593 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_durations
17:07:41.676978 [info ] [Thread-1  ]: 51 of 107 START table model public.phenylephrine_durations ..................... [RUN]
17:07:41.677901 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_durations"
17:07:41.678216 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_durations
17:07:41.678526 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_durations
17:07:41.680719 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_durations"
17:07:41.681620 [debug] [Thread-1  ]: finished collecting timing info
17:07:41.682060 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_durations
17:07:41.695687 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_durations"
17:07:41.696632 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:41.696934 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: BEGIN
17:07:41.697069 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:41.704128 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:41.704438 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:41.704592 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */


  create  table "postgres"."public"."phenylephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of phenylephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30127,30128 -- phenylephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:07:45.387772 [debug] [Thread-1  ]: SQL status: SELECT 33141 in 3.68 seconds
17:07:45.394020 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:45.394382 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations" rename to "phenylephrine_durations__dbt_backup"
17:07:45.397858 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.401784 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:45.401993 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations__dbt_tmp" rename to "phenylephrine_durations"
17:07:45.402682 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.405834 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:07:45.406014 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:45.406116 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:07:45.410764 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.412974 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:07:45.413171 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
drop table if exists "postgres"."public"."phenylephrine_durations__dbt_backup" cascade
17:07:45.417532 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.420321 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.420548 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: Close
17:07:45.421457 [info ] [Thread-1  ]: 51 of 107 OK created table model public.phenylephrine_durations ................ [[32mSELECT 33141[0m in 3.74s]
17:07:45.422033 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_durations
17:07:45.422368 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg
17:07:45.423041 [info ] [Thread-1  ]: 52 of 107 START table model public.pivoted_bg .................................. [RUN]
17:07:45.423724 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg"
17:07:45.423969 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg
17:07:45.424349 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg
17:07:45.426395 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg"
17:07:45.427357 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.427956 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg
17:07:45.444862 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg"
17:07:45.445777 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.445997 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: BEGIN
17:07:45.446092 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.455491 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.455869 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.456141 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */


  create  table "postgres"."public"."pivoted_bg__dbt_tmp"
  as (
    -- The aim of this query is to pivot entries related to blood gases and
-- chemistry values which were found in LABEVENTS

-- create a table which has fuzzy boundaries on ICU admission
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  FROM icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (cast(round((DATETIME_DIFF(i.intime, i.outtime_lag, 'hour')/2)) as integer) || 'HOUR')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (cast(round((DATETIME_DIFF(i.intime_lead, i.outtime, 'minute')/2)) as integer) || 'MINUTE')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
, pvt as
( -- begin query that extracts the data
  select le.hadm_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
      , case
        when itemid = 50800 then 'SPECIMEN'
        when itemid = 50801 then 'AADO2'
        when itemid = 50802 then 'BASEEXCESS'
        when itemid = 50803 then 'BICARBONATE'
        when itemid = 50804 then 'TOTALCO2'
        when itemid = 50805 then 'CARBOXYHEMOGLOBIN'
        when itemid = 50806 then 'CHLORIDE'
        when itemid = 50808 then 'CALCIUM'
        when itemid = 50809 then 'GLUCOSE'
        when itemid = 50810 then 'HEMATOCRIT'
        when itemid = 50811 then 'HEMOGLOBIN'
        when itemid = 50812 then 'INTUBATED'
        when itemid = 50813 then 'LACTATE'
        when itemid = 50814 then 'METHEMOGLOBIN'
        when itemid = 50815 then 'O2FLOW'
        when itemid = 50816 then 'FIO2'
        when itemid = 50817 then 'SO2' -- OXYGENSATURATION
        when itemid = 50818 then 'PCO2'
        when itemid = 50819 then 'PEEP'
        when itemid = 50820 then 'PH'
        when itemid = 50821 then 'PO2'
        when itemid = 50822 then 'POTASSIUM'
        when itemid = 50823 then 'REQUIREDO2'
        when itemid = 50824 then 'SODIUM'
        when itemid = 50825 then 'TEMPERATURE'
        when itemid = 50826 then 'TIDALVOLUME'
        when itemid = 50827 then 'VENTILATIONRATE'
        when itemid = 50828 then 'VENTILATOR'
        else null
        end as label
        , charttime
        , value
        -- add in some sanity checks on the values
        , case
          when valuenum <= 0 then null
          when itemid = 50810 and valuenum > 100 then null -- hematocrit
          -- ensure FiO2 is a valid number between 21-100
          -- mistakes are rare (<100 obs out of ~100,000)
          -- there are 862 obs of valuenum == 20 - some people round down!
          -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
          when itemid = 50816 and valuenum < 20 then null
          when itemid = 50816 and valuenum > 100 then null
          when itemid = 50817 and valuenum > 100 then null -- O2 sat
          when itemid = 50815 and valuenum >  70 then null -- O2 flow
          when itemid = 50821 and valuenum > 800 then null -- PO2
           -- conservative upper limit
        else valuenum
        end as valuenum
    FROM labevents le
    where le.ITEMID in
    -- blood gases
    (
      50800, 50801, 50802, 50803, 50804, 50805, 50806, 50807, 50808, 50809
      , 50810, 50811, 50812, 50813, 50814, 50815, 50816, 50817, 50818, 50819
      , 50820, 50821, 50822, 50823, 50824, 50825, 50826, 50827, 50828
      , 51545
    )
)
, grp as
(
  select pvt.hadm_id, pvt.charttime
  , max(case when label = 'SPECIMEN' then value else null end) as specimen
  , avg(case when label = 'AADO2' then valuenum else null end) as aado2
  , avg(case when label = 'BASEEXCESS' then valuenum else null end) as baseexcess
  , avg(case when label = 'BICARBONATE' then valuenum else null end) as bicarbonate
  , avg(case when label = 'TOTALCO2' then valuenum else null end) as totalco2
  , avg(case when label = 'CARBOXYHEMOGLOBIN' then valuenum else null end) as carboxyhemoglobin
  , avg(case when label = 'CHLORIDE' then valuenum else null end) as chloride
  , avg(case when label = 'CALCIUM' then valuenum else null end) as calcium
  , avg(case when label = 'GLUCOSE' then valuenum else null end) as glucose
  , avg(case when label = 'HEMATOCRIT' then valuenum else null end) as hematocrit
  , avg(case when label = 'HEMOGLOBIN' then valuenum else null end) as hemoglobin
  , avg(case when label = 'INTUBATED' then valuenum else null end) as intubated
  , avg(case when label = 'LACTATE' then valuenum else null end) as lactate
  , avg(case when label = 'METHEMOGLOBIN' then valuenum else null end) as methemoglobin
  , avg(case when label = 'O2FLOW' then valuenum else null end) as o2flow
  , avg(case when label = 'FIO2' then valuenum else null end) as fio2
  , avg(case when label = 'SO2' then valuenum else null end) as so2 -- OXYGENSATURATION
  , avg(case when label = 'PCO2' then valuenum else null end) as pco2
  , avg(case when label = 'PEEP' then valuenum else null end) as peep
  , avg(case when label = 'PH' then valuenum else null end) as ph
  , avg(case when label = 'PO2' then valuenum else null end) as po2
  , avg(case when label = 'POTASSIUM' then valuenum else null end) as potassium
  , avg(case when label = 'REQUIREDO2' then valuenum else null end) as requiredo2
  , avg(case when label = 'SODIUM' then valuenum else null end) as sodium
  , avg(case when label = 'TEMPERATURE' then valuenum else null end) as temperature
  , avg(case when label = 'TIDALVOLUME' then valuenum else null end) as tidalvolume
  , max(case when label = 'VENTILATIONRATE' then valuenum else null end) as ventilationrate
  , max(case when label = 'VENTILATOR' then valuenum else null end) as ventilator
  from pvt
  group by pvt.hadm_id, pvt.charttime
  -- remove observations if there is more than one specimen listed
  -- we do not know whether these are arterial or mixed venous, etc...
  -- happily this is a small fraction of the total number of observations
  having sum(case when label = 'SPECIMEN' then 1 else 0 end)<2
)
select
  iid.icustay_id, grp.*
from grp
inner join admissions adm
  on grp.hadm_id = adm.hadm_id
left join iid_assign iid
  on adm.subject_id = iid.subject_id
  and grp.charttime >= iid.data_start
  and grp.charttime < iid.data_end
order by grp.hadm_id, grp.charttime
  );
17:07:45.538060 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.08 seconds
17:07:45.542991 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.543222 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg" rename to "pivoted_bg__dbt_backup"
17:07:45.545477 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.549396 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.549598 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg__dbt_tmp" rename to "pivoted_bg"
17:07:45.550182 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.553893 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:07:45.554112 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.554365 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:07:45.555419 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.557014 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:07:45.557197 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
drop table if exists "postgres"."public"."pivoted_bg__dbt_backup" cascade
17:07:45.559457 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.562198 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.562400 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: Close
17:07:45.563372 [info ] [Thread-1  ]: 52 of 107 OK created table model public.pivoted_bg ............................. [[32mSELECT 0[0m in 0.14s]
17:07:45.563947 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg
17:07:45.564303 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_fio2
17:07:45.564978 [info ] [Thread-1  ]: 53 of 107 START table model public.pivoted_fio2 ................................ [RUN]
17:07:45.566070 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_fio2"
17:07:45.566426 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_fio2
17:07:45.566940 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_fio2
17:07:45.569257 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_fio2"
17:07:45.570022 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.570338 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_fio2
17:07:45.582694 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_fio2"
17:07:45.583512 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.583805 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: BEGIN
17:07:45.584110 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.590627 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.591037 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.591265 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */


  create  table "postgres"."public"."pivoted_fio2__dbt_tmp"
  as (
    with pvt as
( -- begin query that extracts the data
  select le.hadm_id
  , le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
    -- add in some sanity checks on the values
    , ROUND(MAX((case
        when valuenum <= 0 then null
        -- ensure FiO2 is a valid number between 21-100
        -- mistakes are rare (<100 obs out of ~100,000)
        -- there are 862 obs of valuenum == 20 - some people round down!
        -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
        when itemid = 50816 and valuenum < 20 then null
        when itemid = 50816 and valuenum > 100 then null
    ELSE valuenum END))::numeric, 2) AS valuenum
    FROM labevents le
    where le.ITEMID = 50816
    GROUP BY le.hadm_id, le.charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , ROUND((MAX(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ))::numeric, 2) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
select
  ie.icustay_id
  , COALESCE(pvt.charttime, fi.charttime) AS charttime
  , COALESCE(pvt.valuenum, fi.fio2_chartevents) AS fio2
from 
(
    -- one row per icustay_id/charttime
    SELECT hadm_id, charttime
    from pvt
    UNION DISTINCT
    SELECT hadm_id, charttime
    from stg_fio2
) base
INNER JOIN icustays ie
  on base.hadm_id = ie.hadm_id
  AND base.charttime >= DATETIME_SUB(ie.intime, INTERVAL '12' HOUR)
  AND base.charttime <= DATETIME_ADD(ie.outtime, INTERVAL '12' HOUR)
LEFT JOIN pvt
  ON base.hadm_id = pvt.hadm_id
  AND base.charttime = pvt.charttime
LEFT JOIN stg_fio2 fi
  ON base.hadm_id = fi.hadm_id
  AND base.charttime = fi.charttime
ORDER BY icustay_id, charttime
  );
17:07:45.601333 [debug] [Thread-1  ]: SQL status: SELECT 28 in 0.01 seconds
17:07:45.607069 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.607280 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2" rename to "pivoted_fio2__dbt_backup"
17:07:45.607944 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.611433 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.611639 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2__dbt_tmp" rename to "pivoted_fio2"
17:07:45.612232 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.617493 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:07:45.618102 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.618781 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:07:45.620299 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.622409 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:07:45.622865 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
drop table if exists "postgres"."public"."pivoted_fio2__dbt_backup" cascade
17:07:45.624993 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.627969 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.628195 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: Close
17:07:45.629115 [info ] [Thread-1  ]: 53 of 107 OK created table model public.pivoted_fio2 ........................... [[32mSELECT 28[0m in 0.06s]
17:07:45.629666 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_fio2
17:07:45.629959 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_gcs
17:07:45.630567 [info ] [Thread-1  ]: 54 of 107 START table model public.pivoted_gcs ................................. [RUN]
17:07:45.631680 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_gcs"
17:07:45.632319 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_gcs
17:07:45.632817 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_gcs
17:07:45.635324 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_gcs"
17:07:45.636035 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.636351 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_gcs
17:07:45.646032 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_gcs"
17:07:45.646994 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.647309 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: BEGIN
17:07:45.647500 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.653844 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.654115 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.654295 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */


  create  table "postgres"."public"."pivoted_gcs__dbt_tmp"
  as (
    -- This query extracts the Glasgow Coma Scale, a measure of neurological function.
-- The query has a few special rules:
--    (1) The verbal component can be set to 0 if the patient is ventilated.
--    This is corrected to 5 - the overall GCS is set to 15 in these cases.
--    (2) Often only one of three components is documented. The other components
--    are carried forward.

-- ITEMIDs used:

-- CAREVUE
--    723 as gcsverbal
--    454 as gcsmotor
--    184 as gcseyes

-- METAVISION
--    223900 GCS - Verbal Response
--    223901 GCS - Motor Response
--    220739 GCS - Eye Opening

-- The code combines the ITEMIDs into the carevue itemids, then pivots those
-- So 223900 is changed to 723, then the ITEMID 723 is pivoted to form gcsverbal

-- Note:
--  The GCS for sedated patients is defaulted to 15 in this code.
--  This is in line with how the data is meant to be collected.
--  e.g., from the SAPS II publication:
--    For sedated patients, the Glasgow Coma Score before sedation was used.
--    This was ascertained either from interviewing the physician who ordered the sedation,
--    or by reviewing the patient's medical record.

with base as
(
  select ce.icustay_id, ce.charttime
  -- pivot each value into its own column
  , max(case when ce.ITEMID in (454,223901) then ce.valuenum else null end) as gcsmotor
  , max(case
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 0
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 0
      when ce.ITEMID in (723,223900) then ce.valuenum
      else null 
    end) as gcsverbal
  , max(case when ce.ITEMID in (184,220739) then ce.valuenum else null end) as gcseyes
  -- convert the data into a number, reserving a value of 0 for ET/Trach
  , max(case
      -- endotrach/vent is assigned a value of 0, later parsed specially
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 1 -- carevue
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 1 -- metavision
    else 0 end)
    as endotrachflag
  , ROW_NUMBER ()
          OVER (PARTITION BY ce.icustay_id ORDER BY ce.charttime ASC) as rn
  FROM chartevents ce
  -- Isolate the desired GCS variables
  where ce.ITEMID in
  (
    -- 198 -- GCS
    -- GCS components, CareVue
    184, 454, 723
    -- GCS components, Metavision
    , 223900, 223901, 220739
  )
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error != 1)
  group by ce.icustay_id, ce.charttime
)
, gcs_stg0 as (
  select b.*
  , b2.gcsverbal as gcsverbalprev
  , b2.gcsmotor as gcsmotorprev
  , b2.gcseyes as gcseyesprev
  -- Calculate GCS, factoring in special case when they are intubated and prev vals
  -- note that the coalesce are used to implement the following if:
  --  if current value exists, use it
  --  if previous value exists, use it
  --  otherwise, default to normal
  , case
      -- replace GCS during sedation with 15
      when b.gcsverbal = 0
        then 15
      when b.gcsverbal is null and b2.gcsverbal = 0
        then 15
      -- if previously they were intub, but they aren't now, do not use previous GCS values
      when b2.gcsverbal = 0
        then
            coalesce(b.gcsmotor,6)
          + coalesce(b.gcsverbal,5)
          + coalesce(b.gcseyes,4)
      -- otherwise, add up score normally, imputing previous value if none available at current time
      else
            coalesce(b.gcsmotor,coalesce(b2.gcsmotor,6))
          + coalesce(b.gcsverbal,coalesce(b2.gcsverbal,5))
          + coalesce(b.gcseyes,coalesce(b2.gcseyes,4))
      end as gcs

  from base b
  -- join to itself within 6 hours to get previous value
  left join base b2
    on b.icustay_id = b2.icustay_id
    and b.rn = b2.rn+1
    and b2.charttime > DATETIME_SUB(b.charttime, INTERVAL '6' HOUR)
)
-- combine components with previous within 6 hours
-- filter down to cohort which is not excluded
-- truncate charttime to the hour
, gcs_stg1 as
(
  select gs.icustay_id, gs.charttime
  , gs.gcs
  , coalesce(gcsmotor,gcsmotorprev) as gcsmotor
  , coalesce(gcsverbal,gcsverbalprev) as gcsverbal
  , coalesce(gcseyes,gcseyesprev) as gcseyes
  , case when coalesce(gcsmotor,gcsmotorprev) is null then 0 else 1 end
  + case when coalesce(gcsverbal,gcsverbalprev) is null then 0 else 1 end
  + case when coalesce(gcseyes,gcseyesprev) is null then 0 else 1 end
    as components_measured
  , endotrachflag
  from gcs_stg0 gs
)
-- priority is:
--  (i) complete data, (ii) non-sedated GCS, (iii) lowest GCS, (iv) charttime
, gcs_priority as
(
  select icustay_id
    , charttime
    , gcs
    , gcsmotor
    , gcsverbal
    , gcseyes
    , endotrachflag
    , ROW_NUMBER() over
      (
        PARTITION BY icustay_id, charttime
        ORDER BY components_measured DESC, endotrachflag, gcs, charttime DESC
      ) as rn
  from gcs_stg1
)
select icustay_id
  , charttime
  , gcs
  , gcsmotor
  , gcsverbal
  , gcseyes
  , endotrachflag
from gcs_priority gs
where rn = 1
ORDER BY icustay_id, charttime
  );
17:07:45.661047 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:07:45.666998 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.667459 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs" rename to "pivoted_gcs__dbt_backup"
17:07:45.669216 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.674616 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.674910 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs__dbt_tmp" rename to "pivoted_gcs"
17:07:45.675687 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.678749 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:07:45.678969 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.679149 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:07:45.680242 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.683471 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:07:45.683688 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
drop table if exists "postgres"."public"."pivoted_gcs__dbt_backup" cascade
17:07:45.685892 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.690634 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.690905 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: Close
17:07:45.691775 [info ] [Thread-1  ]: 54 of 107 OK created table model public.pivoted_gcs ............................ [[32mSELECT 0[0m in 0.06s]
17:07:45.692343 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_gcs
17:07:45.692599 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_height
17:07:45.693052 [info ] [Thread-1  ]: 55 of 107 START table model public.pivoted_height .............................. [RUN]
17:07:45.693641 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_height"
17:07:45.693860 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_height
17:07:45.694064 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_height
17:07:45.695213 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_height"
17:07:45.695689 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.695932 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_height
17:07:45.711621 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_height"
17:07:45.712208 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.712353 [debug] [Thread-1  ]: On model.mimic.pivoted_height: BEGIN
17:07:45.712486 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.718194 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.718517 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.718914 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */


  create  table "postgres"."public"."pivoted_height__dbt_tmp"
  as (
    -- prep height
WITH ht_in AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN ROUND((c.valuenum * 2.54)::numeric, 2)
        -- ROUND(value::numeric, 2)
      ELSE c.valuenum
    END)::numeric, 2) AS height
    , c.valuenum as height_orig
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height (measured in inches)
  AND c.itemid IN
  (
    -- CareVue
    920, 1394, 4187, 3486
    -- Metavision
    , 226707
  )
)
, ht_cm AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN c.valuenum * 2.54
      ELSE c.valuenum
    END)::numeric, 2) AS height
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height cm
  AND c.itemid IN
  (
    -- CareVue
    3485, 4188
    -- MetaVision
    , 226730
  )
)
-- merge cm/height, only take 1 value per charted row
, ht_stg0 AS
(
  SELECT
  COALESCE(h1.subject_id, h1.subject_id) as subject_id
  , COALESCE(h1.charttime, h1.charttime) AS charttime
  , COALESCE(h1.height, h2.height) as height
  FROM ht_cm h1
  FULL OUTER JOIN ht_in h2
    ON h1.subject_id = h2.subject_id
    AND h1.charttime = h2.charttime
)
-- filter out bad heights
, ht_stg1 AS
(
  SELECT
    h.subject_id
    , charttime
    , CASE
        -- rule for neonates
        -- [charrtime don't have year coloum?]
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) <= 1 AND height < 80 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) <= 1 AND height < 80 THEN height
        
        -- rule for adults
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) > 1 AND height > 120 AND height < 230 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) > 1 AND height > 120 AND height < 230 THEN height
      ELSE NULL END as height
  FROM ht_stg0 h
  INNER JOIN patients pt
    ON h.subject_id = pt.subject_id
)
-- heights from echo-cardiography notes
, echo_note AS
(
  SELECT
    subject_id
    -- extract the time of the note from the text itself
    -- add this to the structured date in the chartdate column
    , PARSE_DATETIME('%b-%d-%Y%H:%M',
      CONCAT(
        FORMAT_DATE('%b-%d-%Y', chartdate),
        REGEXP_EXTRACT(ne.text, 'Date/Time: [\\[\\]0-9*-]+ at ([0-9:]+)')
       )
    ) AS charttime
    -- sometimes numeric values contain de-id numbers, e.g. [** Numeric Identifier **]
    -- this case is used to ignore that text
    , case
        when REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') like '%*%'
            then null
        else cast(REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') as numeric)
        end * 2.54 as height
  FROM noteevents ne
  WHERE ne.category = 'Echo'
)
-- use documented ideal body weights to back-calculate height
, ibw_note AS
(
    SELECT subject_id
    , ne.category
    , charttime
    , CAST(REGEXP_EXTRACT(text, 'Ideal body weight: ([0-9]+\\.?[0-9]*)') AS NUMERIC) as ibw
    FROM noteevents ne
    WHERE text like '%Ideal body weight:%'
    AND ne.category != 'Echo'
)
, ht_from_ibw AS
(
    -- IBW formulas
    -- inches
    -- F:  IBW = 45.5 kg + 2.3 kg * (height in inches - 60)
    -- M:  IBW = 50 kg + 2.3 kg * (height in inches - 60)
    
    -- cm
    -- F: 45.5 + (0.91 × [height in centimeters − 152.4])
    -- M: 50 + (0.91 × [height in centimeters − 152.4])
    
    SELECT ne.subject_id
    , charttime
    , CASE
        WHEN gender = 'F' THEN (ibw - 45.5)/0.91 + 152.4
        ELSE (ibw - 50)/0.91 + 152.4 END AS height
    FROM ibw_note ne
    INNER JOIN patients pt
      ON ne.subject_id = pt.subject_id
    WHERE ibw IS NOT NULL AND ibw != 0
)
, ht_nutrition AS
(
    -- nutrition notes usually only document height
    -- but the original note formatting has been lost, so we can't do a clever regex
    -- instead, we just look for the unit of measure (cm)
    SELECT subject_id
    , charttime
    , CAST(REGEXP_EXTRACT(ne.text, '([0-9]+) cm') AS NUMERIC) as height
    FROM noteevents ne
    WHERE category = 'Nutrition'
    AND lower(text) like '%height%'
)
SELECT subject_id, charttime, 'chartevents' as source, height
FROM ht_stg1
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - echo' as source, height
FROM echo_note
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - ibw' as source, height
FROM ht_from_ibw
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - nutrition' as source
-- convert the heights
    , CASE 
        WHEN height < 80 THEN height*2.54
        ELSE height
    END AS height
FROM ht_nutrition
WHERE height IS NOT NULL AND height > 0
ORDER BY subject_id, charttime, source, height
  );
17:07:45.730157 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:07:45.737386 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.737714 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height" rename to "pivoted_height__dbt_backup"
17:07:45.739005 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.744440 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.744638 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height__dbt_tmp" rename to "pivoted_height"
17:07:45.745276 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.750182 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:07:45.750427 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.750730 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:07:45.751883 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.753788 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:07:45.753973 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
drop table if exists "postgres"."public"."pivoted_height__dbt_backup" cascade
17:07:45.756106 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.759140 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.759391 [debug] [Thread-1  ]: On model.mimic.pivoted_height: Close
17:07:45.760369 [info ] [Thread-1  ]: 55 of 107 OK created table model public.pivoted_height ......................... [[32mSELECT 0[0m in 0.07s]
17:07:45.760998 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_height
17:07:45.761426 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_icp
17:07:45.761981 [info ] [Thread-1  ]: 56 of 107 START table model public.pivoted_icp ................................. [RUN]
17:07:45.762703 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_icp"
17:07:45.763064 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_icp
17:07:45.763306 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_icp
17:07:45.764807 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_icp"
17:07:45.765493 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.765619 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_icp
17:07:45.778816 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_icp"
17:07:45.779383 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.779592 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: BEGIN
17:07:45.779772 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.786007 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.786321 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.786653 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */


  create  table "postgres"."public"."pivoted_icp__dbt_tmp"
  as (
    with ce as
(
  select ce.icustay_id
    , ce.charttime
    -- TODO: handle high ICPs when monitoring two ICPs
    , case when valuenum > 0 and valuenum < 100 then valuenum else null end as icp
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error = 0)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
   226 -- ICP -- 99159
  ,1374 -- ICP Right -- 100
  ,2045 -- icp left -- 70
  ,2635 -- VENT ICP -- 195
  ,2660 -- ICP Camino -- 40
  ,2733 -- RIGHT VENT ICP -- 203
  ,2745 -- ICP LEFT -- 232
  ,2870 -- ICP-ventriculostomuy -- 114
  ,2956 -- ventriculostomy icp -- 64
  ,2985 -- ICP ventricle -- 85
  ,5856 -- icp -- 7
  ,7116 -- Rt ICP -- 80
  ,8218 -- left icp -- 6
  ,8298 -- L ICP -- 47
  ,8299 -- R ICP -- 16
  ,8305 -- ICP  Right -- 49
  ,220765 -- Intra Cranial Pressure -- 92306
  ,227989 -- Intra Cranial Pressure #2 -- 1052
  )
)
select
    ce.icustay_id
  , ce.charttime
  , MAX(icp) as icp
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:07:45.790427 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.0 seconds
17:07:45.794190 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.794354 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp" rename to "pivoted_icp__dbt_backup"
17:07:45.795621 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.801953 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.802185 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp__dbt_tmp" rename to "pivoted_icp"
17:07:45.803265 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.806072 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:07:45.806246 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.806338 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:07:45.807339 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.809168 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:07:45.809344 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
drop table if exists "postgres"."public"."pivoted_icp__dbt_backup" cascade
17:07:45.811105 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.813645 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.813917 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: Close
17:07:45.816221 [info ] [Thread-1  ]: 56 of 107 OK created table model public.pivoted_icp ............................ [[32mSELECT 0[0m in 0.05s]
17:07:45.817249 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_icp
17:07:45.817637 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_invasive_lines
17:07:45.818192 [info ] [Thread-1  ]: 57 of 107 START table model public.pivoted_invasive_lines ...................... [RUN]
17:07:45.818822 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.819051 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_invasive_lines
17:07:45.819286 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_invasive_lines
17:07:45.820464 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_invasive_lines"
17:07:45.820819 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.820935 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_invasive_lines
17:07:45.833121 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_invasive_lines"
17:07:45.833728 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.833851 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: BEGIN
17:07:45.833960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:45.840445 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:45.840710 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.840819 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */


  create  table "postgres"."public"."pivoted_invasive_lines__dbt_tmp"
  as (
    WITH stg0 AS
(
    SELECT 
        icustay_id
        , charttime
        , storetime
        , itemid
        -- create partition which separates the lines
        , CASE
            WHEN itemid IN (229, 8392) THEN 1
            WHEN itemid IN (235, 8393) THEN 2
            WHEN itemid IN (241, 8394) THEN 3
            WHEN itemid IN (247, 8395) THEN 4
            WHEN itemid IN (253, 8396) THEN 5
            WHEN itemid IN (259, 8397) THEN 6
            WHEN itemid IN (265, 8398) THEN 7
            WHEN itemid IN (271, 8399) THEN 8
          ELSE NULL END AS line_number
        , CASE WHEN itemid < 8000 THEN value ELSE NULL END AS line_type
        , CASE WHEN itemid > 8000 THEN value ELSE NULL END AS line_site
        -- the stopped column is always present for invasive lines
        , CASE 
            --   WHEN ce.stopped = 'D/C\'d' THEN 1
              WHEN ce.stopped = 'D/C''d' THEN 1
              WHEN ce.stopped = 'NotStopd' THEN 0
          ELSE NULL END AS line_dc
    FROM chartevents ce
    WHERE ce.itemid IN 
    (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
    )
    AND icustay_id IS NOT NULL
    AND COALESCE(ce.error, 0) = 0
)
, stg0_rn AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site, line_dc
        -- only keep the last documented value
        , ROW_NUMBER() OVER (PARTITION BY icustay_id, charttime, itemid ORDER BY storetime DESC) as rn_last_stored
    FROM stg0
)
, stg1 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        -- collapse line type/site into a single row
        -- MAX() always collapses a single value, due to where rn_last_stored = 1
        , MAX(line_type) as line_type
        , MAX(line_site) as line_site
        -- any disconnection at this charttime turns off the line
        , MAX(line_dc) AS line_dc
    FROM stg0_rn
    WHERE rn_last_stored = 1
    GROUP BY icustay_id, charttime, line_number
)
, stg2 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site
        , line_dc
        -- carry forward the line type
        , CASE
            -- if the previous line was D/C'd then it's a new line
            WHEN LAG(line_dc) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = 1 THEN 1
            -- if it's the same line as before, within 16 hours, continue the event
            WHEN LAG(line_type) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = line_type
            AND DATETIME_DIFF(
                charttime,
                LAG(charttime) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime),
                'HOUR'
                ) < 16 THEN 0
            -- otherwise, it's been more than 16 hours since the line was last documented
            -- (or it's the first documentation of this line)
            -- so we consider this a new event
            ELSE 1
        END AS rn_part
    FROM stg1
)
-- rn_part is 1 if it's a new event, and 0 if it's a continuation of the previous
-- so cumulatively summing it will result in a sequential integer which partitions
-- distinct line events. we can later group on this integer.
, stg3 AS
(
    SELECT
        icustay_id, charttime, line_number
        , line_type, line_site
        , line_dc
        , SUM(rn_part) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) as line_event
    FROM stg2
)
-- group by line_event to determine line start/stop times
, stg4 AS
(
    SELECT
        icustay_id, line_number
        , line_event
        , line_type, line_site
        , MIN(charttime) as starttime
        , MAX(charttime) as endtime
    FROM stg3
    -- filter out the D/C'd rows so they don't impact the starttime of future events
    WHERE line_dc = 0 
    GROUP BY icustay_id, line_number, line_event, line_type, line_site
)
-- metavision
, mv AS
(
    SELECT 
        icustay_id
        -- since metavision separates lines using itemid, we can use it as the line number
        , mv.itemid AS line_number
        , di.label AS line_type
        , mv.location AS line_site
        , starttime, endtime
    FROM procedureevents_mv mv
    INNER JOIN d_items di
      ON mv.itemid = di.itemid
    WHERE mv.itemid IN
    (
      227719 -- AVA Line
    , 225752 -- Arterial Line
    , 224269 -- CCO PAC
    , 224267 -- Cordis/Introducer
    , 224270 -- Dialysis Catheter
    , 224272 -- IABP line
    , 226124 -- ICP Catheter
    , 228169 -- Impella Line
    , 225202 -- Indwelling Port (PortaCath)
    , 228286 -- Intraosseous Device
    , 225204 -- Midline
    , 224263 -- Multi Lumen
    , 224560 -- PA Catheter
    , 224264 -- PICC Line
    , 225203 -- Pheresis Catheter
    , 224273 -- Presep Catheter
    , 225789 -- Sheath
    , 225761 -- Sheath Insertion
    , 228201 -- Tandem Heart Access Line
    , 228202 -- Tandem Heart Return Line
    , 224268 -- Trauma line
    , 225199 -- Triple Introducer
    , 225315 -- Tunneled (Hickman) Line
    , 225205 -- RIC
    )
    AND icustay_id IS NOT NULL
    AND statusdescription != 'Rewritten'
),
combined AS
(
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM stg4
    UNION DISTINCT
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM mv
)
-- as a final step, combine any similar terms together
-- this was comprehensive as of MIMIC-III v1.4
select 
    icustay_id
    , CASE
        WHEN line_type IN ('Arterial Line', 'A-Line') THEN 'Arterial'
        WHEN line_type IN ('CCO PA Line', 'CCO PAC') THEN 'Continuous Cardiac Output PA'
        WHEN line_type IN ('Dialysis Catheter', 'Dialysis Line') THEN 'Dialysis'
        WHEN line_type IN ('Hickman', 'Tunneled (Hickman) Line') THEN 'Hickman'
        WHEN line_type IN ('IABP', 'IABP line') THEN 'IABP'
        WHEN line_type IN ('Multi Lumen', 'Multi-lumen') THEN 'Multi Lumen'
        WHEN line_type IN ('PA Catheter', 'PA line') THEN 'PA'
        WHEN line_type IN ('PICC Line', 'PICC line') THEN 'PICC'
        WHEN line_type IN ('Pre-Sep Catheter', 'Presep Catheter') THEN 'Pre-Sep'
        WHEN line_type IN ('Trauma Line', 'Trauma line') THEN 'Trauma'
        WHEN line_type IN ('Triple Introducer', 'TripleIntroducer') THEN 'Triple Introducer'
        WHEN line_type IN ('Portacath', 'Indwelling Port (PortaCath)') THEN 'Portacath'
        -- AVA Line
        -- Camino Bolt
        -- Cordis/Introducer
        -- ICP Catheter
        -- Impella Line
        -- Intraosseous Device
        -- Introducer
        -- Lumbar Drain
        -- Midline
        -- Other/Remarks
        -- PacerIntroducer
        -- PermaCath
        -- Pheresis Catheter
        -- RIC
        -- Sheath
        -- Tandem Heart Access Line
        -- Tandem Heart Return Line
        -- Venous Access
        -- Ventriculostomy
    ELSE line_type END AS line_type
    , CASE
        WHEN line_site IN ('Left Antecub', 'Left Antecube') THEN 'Left Antecube'
        WHEN line_site IN ('Left Axilla', 'Left Axilla.') THEN 'Left Axilla'
        WHEN line_site IN ('Left Brachial', 'Left Brachial.') THEN 'Left Brachial'
        WHEN line_site IN ('Left Femoral', 'Left Femoral.') THEN 'Left Femoral'
        WHEN line_site IN ('Right Antecub', 'Right Antecube') THEN 'Right Antecube' 
        WHEN line_site IN ('Right Axilla', 'Right Axilla.') THEN 'Right Axilla' 
        WHEN line_site IN ('Right Brachial', 'Right Brachial.') THEN 'Right Brachial' 
        WHEN line_site IN ('Right Femoral', 'Right Femoral.') THEN 'Right Femoral' 
        -- 'Left Foot'
        -- 'Left IJ'
        -- 'Left Radial'
        -- 'Left Subclavian'
        -- 'Left Ulnar'
        -- 'Left Upper Arm'
        -- 'Right Foot'
        -- 'Right IJ'
        -- 'Right Radial'
        -- 'Right Side Head'
        -- 'Right Subclavian'
        -- 'Right Ulnar'
        -- 'Right Upper Arm'
        -- 'Transthoracic'
        -- 'Other/Remarks'
    ELSE line_site END AS line_site
    , starttime
    , endtime
FROM combined
ORDER BY icustay_id, starttime, line_type, line_site
  );
17:07:45.954067 [debug] [Thread-1  ]: SQL status: SELECT 34483 in 0.11 seconds
17:07:45.961547 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.961944 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines" rename to "pivoted_invasive_lines__dbt_backup"
17:07:45.963281 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.968984 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.969183 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines__dbt_tmp" rename to "pivoted_invasive_lines"
17:07:45.969890 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:45.972783 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:07:45.972972 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.973197 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:07:45.976489 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:45.979163 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:07:45.979365 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
drop table if exists "postgres"."public"."pivoted_invasive_lines__dbt_backup" cascade
17:07:45.981422 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:45.984429 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.984656 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: Close
17:07:45.985543 [info ] [Thread-1  ]: 57 of 107 OK created table model public.pivoted_invasive_lines ................. [[32mSELECT 34483[0m in 0.17s]
17:07:45.985979 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_invasive_lines
17:07:45.986120 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_lab
17:07:45.986933 [info ] [Thread-1  ]: 58 of 107 START table model public.pivoted_lab ................................. [RUN]
17:07:45.987694 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_lab"
17:07:45.987955 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_lab
17:07:45.988264 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_lab
17:07:45.989562 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_lab"
17:07:45.990049 [debug] [Thread-1  ]: finished collecting timing info
17:07:45.990281 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_lab
17:07:46.004953 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_lab"
17:07:46.005374 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.005480 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: BEGIN
17:07:46.005650 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:46.009924 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:46.010150 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.010250 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */


  create  table "postgres"."public"."pivoted_lab__dbt_tmp"
  as (
    -- create a table which has fuzzy boundaries on ICU admission (+- 12 hours from documented time)
-- this is used to assign icustay_id to lab data, which can be collected outside ICU
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  from icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two ICU stays within 24 hours, set the start/stop
    --  time as half way between the two ICU stays
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (CAST(DATETIME_DIFF(i.intime, i.outtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (CAST(DATETIME_DIFF(i.intime_lead, i.outtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
-- also create fuzzy boundaries on hospitalization
, h as
(
  select
    subject_id, hadm_id, admittime, dischtime
    , lag (dischtime) over (partition by subject_id order by admittime) as dischtime_lag
    , lead (admittime) over (partition by subject_id order by admittime) as admittime_lead
  from admissions
)
, adm as
(
  select
    h.subject_id, h.hadm_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when h.dischtime_lag is not null
        and h.dischtime_lag > (DATETIME_SUB(h.admittime, INTERVAL '24' HOUR))
          then DATETIME_SUB(h.admittime, (CAST(DATETIME_DIFF(h.admittime, h.dischtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(h.admittime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when h.admittime_lead is not null
        and h.admittime_lead < (DATETIME_ADD(h.dischtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(h.dischtime, (CAST(DATETIME_DIFF(h.admittime_lead, h.dischtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(h.dischtime, INTERVAL '12' HOUR))
      end as data_end
    from h
)
, le_avg as
(
SELECT
    pvt.subject_id, pvt.charttime
  , avg(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE null END) as ANIONGAP
  , avg(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE null END) as ALBUMIN
  , avg(CASE WHEN label = 'BANDS' THEN valuenum ELSE null END) as BANDS
  , avg(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE null END) as BICARBONATE
  , avg(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE null END) as BILIRUBIN
  , avg(CASE WHEN label = 'CREATININE' THEN valuenum ELSE null END) as CREATININE
  , avg(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE null END) as CHLORIDE
  , avg(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE null END) as GLUCOSE
  , avg(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE null END) as HEMATOCRIT
  , avg(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE null END) as HEMOGLOBIN
  , avg(CASE WHEN label = 'LACTATE' THEN valuenum ELSE null END) as LACTATE
  , avg(CASE WHEN label = 'PLATELET' THEN valuenum ELSE null END) as PLATELET
  , avg(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE null END) as POTASSIUM
  , avg(CASE WHEN label = 'PTT' THEN valuenum ELSE null END) as PTT
  , avg(CASE WHEN label = 'INR' THEN valuenum ELSE null END) as INR
  , avg(CASE WHEN label = 'PT' THEN valuenum ELSE null END) as PT
  , avg(CASE WHEN label = 'SODIUM' THEN valuenum ELSE null end) as SODIUM
  , avg(CASE WHEN label = 'BUN' THEN valuenum ELSE null end) as BUN
  , avg(CASE WHEN label = 'WBC' THEN valuenum ELSE null end) as WBC
FROM
( -- begin query that extracts the data
  SELECT le.subject_id, le.hadm_id, le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
  , CASE
        WHEN itemid = 50868 THEN 'ANION GAP'
        WHEN itemid = 50862 THEN 'ALBUMIN'
        WHEN itemid = 51144 THEN 'BANDS'
        WHEN itemid = 50882 THEN 'BICARBONATE'
        WHEN itemid = 50885 THEN 'BILIRUBIN'
        WHEN itemid = 50912 THEN 'CREATININE'
        -- exclude blood gas
        -- WHEN itemid = 50806 THEN 'CHLORIDE'
        WHEN itemid = 50902 THEN 'CHLORIDE'
        -- exclude blood gas
        -- WHEN itemid = 50809 THEN 'GLUCOSE'
        WHEN itemid = 50931 THEN 'GLUCOSE'
        -- exclude blood gas
        --WHEN itemid = 50810 THEN 'HEMATOCRIT'
        WHEN itemid = 51221 THEN 'HEMATOCRIT'
        -- exclude blood gas
        --WHEN itemid = 50811 THEN 'HEMOGLOBIN'
        WHEN itemid = 51222 THEN 'HEMOGLOBIN'
        WHEN itemid = 50813 THEN 'LACTATE'
        WHEN itemid = 51265 THEN 'PLATELET'
        -- exclude blood gas
        -- WHEN itemid = 50822 THEN 'POTASSIUM'
        WHEN itemid = 50971 THEN 'POTASSIUM'
        WHEN itemid = 51275 THEN 'PTT'
        WHEN itemid = 51237 THEN 'INR'
        WHEN itemid = 51274 THEN 'PT'
        -- exclude blood gas
        -- WHEN itemid = 50824 THEN 'SODIUM'
        WHEN itemid = 50983 THEN 'SODIUM'
        WHEN itemid = 51006 THEN 'BUN'
        WHEN itemid = 51300 THEN 'WBC'
        WHEN itemid = 51301 THEN 'WBC'
      ELSE null
    END AS label
  , -- add in some sanity checks on the values
  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks
    CASE
      WHEN itemid = 50862 and valuenum >    10 THEN null -- g/dL 'ALBUMIN'
      WHEN itemid = 50868 and valuenum > 10000 THEN null -- mEq/L 'ANION GAP'
      WHEN itemid = 51144 and valuenum <     0 THEN null -- immature band forms, %
      WHEN itemid = 51144 and valuenum >   100 THEN null -- immature band forms, %
      WHEN itemid = 50882 and valuenum > 10000 THEN null -- mEq/L 'BICARBONATE'
      WHEN itemid = 50885 and valuenum >   150 THEN null -- mg/dL 'BILIRUBIN'
      WHEN itemid = 50806 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50902 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50912 and valuenum >   150 THEN null -- mg/dL 'CREATININE'
      WHEN itemid = 50809 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50931 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50810 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 51221 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 50811 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 51222 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 50813 and valuenum >    50 THEN null -- mmol/L 'LACTATE'
      WHEN itemid = 51265 and valuenum > 10000 THEN null -- K/uL 'PLATELET'
      WHEN itemid = 50822 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 50971 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 51275 and valuenum >   150 THEN null -- sec 'PTT'
      WHEN itemid = 51237 and valuenum >    50 THEN null -- 'INR'
      WHEN itemid = 51274 and valuenum >   150 THEN null -- sec 'PT'
      WHEN itemid = 50824 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 50983 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 51006 and valuenum >   300 THEN null -- 'BUN'
      WHEN itemid = 51300 and valuenum >  1000 THEN null -- 'WBC'
      WHEN itemid = 51301 and valuenum >  1000 THEN null -- 'WBC'
    ELSE valuenum
    END AS valuenum
  FROM labevents le
  WHERE le.ITEMID in
  (
    -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS
    50868, -- ANION GAP | CHEMISTRY | BLOOD | 769895
    50862, -- ALBUMIN | CHEMISTRY | BLOOD | 146697
    51144, -- BANDS - hematology
    50882, -- BICARBONATE | CHEMISTRY | BLOOD | 780733
    50885, -- BILIRUBIN, TOTAL | CHEMISTRY | BLOOD | 238277
    50912, -- CREATININE | CHEMISTRY | BLOOD | 797476
    50902, -- CHLORIDE | CHEMISTRY | BLOOD | 795568
    -- 50806, -- CHLORIDE, WHOLE BLOOD | BLOOD GAS | BLOOD | 48187
    50931, -- GLUCOSE | CHEMISTRY | BLOOD | 748981
    -- 50809, -- GLUCOSE | BLOOD GAS | BLOOD | 196734
    51221, -- HEMATOCRIT | HEMATOLOGY | BLOOD | 881846
    -- 50810, -- HEMATOCRIT, CALCULATED | BLOOD GAS | BLOOD | 89715
    51222, -- HEMOGLOBIN | HEMATOLOGY | BLOOD | 752523
    -- 50811, -- HEMOGLOBIN | BLOOD GAS | BLOOD | 89712
    50813, -- LACTATE | BLOOD GAS | BLOOD | 187124
    51265, -- PLATELET COUNT | HEMATOLOGY | BLOOD | 778444
    50971, -- POTASSIUM | CHEMISTRY | BLOOD | 845825
    -- 50822, -- POTASSIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 192946
    51275, -- PTT | HEMATOLOGY | BLOOD | 474937
    51237, -- INR(PT) | HEMATOLOGY | BLOOD | 471183
    51274, -- PT | HEMATOLOGY | BLOOD | 469090
    50983, -- SODIUM | CHEMISTRY | BLOOD | 808489
    -- 50824, -- SODIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 71503
    51006, -- UREA NITROGEN | CHEMISTRY | BLOOD | 791925
    51301, -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301
    51300  -- WBC COUNT | HEMATOLOGY | BLOOD | 2371
  )
  AND valuenum IS NOT NULL AND valuenum > 0 -- lab values cannot be 0 and cannot be negative
) pvt
GROUP BY pvt.subject_id, pvt.charttime
)
select
  iid.icustay_id, adm.hadm_id, le_avg.*
from le_avg
left join adm
  on le_avg.subject_id  = adm.subject_id
  and le_avg.charttime >= adm.data_start
  and le_avg.charttime  < adm.data_end
left join iid_assign iid
  on  le_avg.subject_id = iid.subject_id
  and le_avg.charttime >= iid.data_start
  and le_avg.charttime  < iid.data_end
order by le_avg.subject_id, le_avg.charttime
  );
17:07:46.072176 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.06 seconds
17:07:46.076873 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.077195 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab" rename to "pivoted_lab__dbt_backup"
17:07:46.079446 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:46.083598 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.083805 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab__dbt_tmp" rename to "pivoted_lab"
17:07:46.084549 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:46.087560 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:07:46.087763 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.087964 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:07:46.090456 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:46.092660 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:07:46.092858 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
drop table if exists "postgres"."public"."pivoted_lab__dbt_backup" cascade
17:07:46.094945 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:46.097929 [debug] [Thread-1  ]: finished collecting timing info
17:07:46.098168 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: Close
17:07:46.098900 [info ] [Thread-1  ]: 58 of 107 OK created table model public.pivoted_lab ............................ [[32mSELECT 0[0m in 0.11s]
17:07:46.099494 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_lab
17:07:46.099849 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_rrt
17:07:46.100506 [info ] [Thread-1  ]: 59 of 107 START table model public.pivoted_rrt ................................. [RUN]
17:07:46.101316 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_rrt"
17:07:46.101636 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_rrt
17:07:46.101837 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_rrt
17:07:46.103559 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_rrt"
17:07:46.104749 [debug] [Thread-1  ]: finished collecting timing info
17:07:46.105192 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_rrt
17:07:46.115201 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_rrt"
17:07:46.116002 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:46.116413 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: BEGIN
17:07:46.116585 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:46.123858 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:46.124098 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:46.124290 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */


  create  table "postgres"."public"."pivoted_rrt__dbt_tmp"
  as (
    -- Creates a table with icustay_id / time / dialysis type (if present)

with ce as
(
  select ce.icustay_id
    , ce.charttime
          -- when ce.itemid in (152,148,149,146,147,151,150) and value is not null then 1
          -- when ce.itemid in (229,235,241,247,253,259,265,271) and value = 'Dialysis Line' then 1
          -- when ce.itemid = 466 and value = 'Dialysis RN' then 1
          -- when ce.itemid = 927 and value = 'Dialysis Solutions' then 1
          -- when ce.itemid = 6250 and value = 'dialys' then 1
          -- when ce.
          -- when ce.itemid = 582 and value in ('CAVH Start','CAVH D/C','CVVHD Start','CVVHD D/C','Hemodialysis st','Hemodialysis end') then 1
    , CASE
        WHEN ce.itemid IN
        (
          146 -- "Dialysate Flow ml/hr"
          , 147 -- "Dialysate Infusing";56605
          , 148 -- "Dialysis Access Site";60335
          , 149 -- "Dialysis Access Type";60030
          , 150 -- "Dialysis Machine";27472 (baxter or gambro)
          , 151 -- "Dialysis Site Appear";37345
          , 152 -- "Dialysis Type";61449
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid IN (229, 235, 241, 247, 253, 259, 265, 271) AND value = 'Dialysis Line' 
          THEN 1
        -- WHEN ce.itemid = 917 AND value IN
        -- (
        --   '+ INITIATE DIALYSIS', 'BLEEDING FROM DIALYSIS CATHETER',
        --   -- 'FAILED DIALYSIS CATH.',
        --   'FEBRILE SYNDROME;DIALYSIS', 'HYPOTENSION WITH HEMODIALYSIS',
        --   'HYPOTENSION.GLOGGED DIALYSIS',
        --   'INFECTED DIALYSIS CATHETER'
        -- )
        -- metavision itemids

        -- checkboxes
        WHEN ce.itemid IN
        (
            226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
          , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
          , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox
        ) THEN 1
        -- numeric data
        WHEN ce.itemid IN
        (
            226499 -- | Hemodialysis Output                               | Dialysis
          , 224154 -- | Dialysate Rate                                    | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224149 -- | Access Pressure                  | Dialysis
          , 224150 -- | Filter Pressure                  | Dialysis
          , 224151 -- | Effluent Pressure                | Dialysis
          , 224152 -- | Return Pressure                  | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 224404 -- | ART Lumen Volume                 | Dialysis
          , 224406 -- | VEN Lumen Volume                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1

        -- text fields
        WHEN ce.itemid IN
        (
            224135 -- | Dialysis Access Site | Dialysis
          , 224139 -- | Dialysis Site Appearance | Dialysis
          , 224146 -- | System Integrity | Dialysis
          , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive
          , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive
          , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225954 -- | Dialysis Access Type | Dialysis
          , 225956 -- | Reason for CRRT Filter Change | Dialysis
          , 225958 -- | Heparin Concentration (units/mL) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 225976 -- | Replacement Fluid | Dialysis
          , 225977 -- | Dialysate Fluid | Dialysis
          , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive
          , 227290 -- | CRRT mode | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
          , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive
        ) THEN 1
      ELSE 0 END
      AS dialysis_present
    , CASE
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end'
        ) THEN 0
        WHEN ce.itemid = 147 AND value = 'Yes' THEN 1 -- "Dialysate Infusing";56605
        WHEN ce.itemid = 225965 -- Peritoneal Dialysis Catheter Status
          AND value = 'In use' THEN 1
        WHEN ce.itemid IN
        (
            146    -- Dialysate Flow ml/hr
          , 226499 -- | Hemodialysis Output              | Dialysis
          , 224154 -- | Dialysate Rate                   | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1
      ELSE 0 END
      AS dialysis_active
    , CASE
        -- dialysis mode
        WHEN ce.itemid in (152, 227290) THEN
          CASE
            WHEN value = 'CVVH' THEN 'CVVH'
            WHEN value = 'CVVHD' THEN 'CVVHD'
            WHEN value = 'CVVHDF' THEN 'CVVHDF'
            WHEN value = 'SCUF' THEN 'SCUF'
            WHEN value = 'Peritoneal' THEN 'Peritoneal'
          END
        -- itemids which imply a certain dialysis mode

        -- peritoneal dialysis
        WHEN ce.itemid IN 
        (
            225810 -- | Dwell Time (Peritoneal Dialysis) | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
        )
          THEN 'Peritoneal'
        WHEN ce.itemid IN (226499)
          THEN 'IHD'
        WHEN ce.itemid = 582 THEN
          CASE
            WHEN value IN ('CAVH Start','CAVH D/C')
              THEN 'CAVH'
            WHEN value IN ('CVVHD Start','CVVHD D/C')
              THEN 'CVVHD'
            WHEN value IN ('Hemodialysis st', 'Hemodialysis end')
              -- null is ambiguous
              THEN NULL
          ELSE NULL
          END
      ELSE NULL END as dialysis_type
  from chartevents ce
  WHERE ce.itemid in
  (
     152 -- "Dialysis Type";61449
    ,146 -- "Dialysate Flow ml/hr";57445
    ,147 -- "Dialysate Infusing";56605
    ,148 -- "Dialysis Access Site";60335
    ,149 -- "Dialysis Access Type";60030
    ,150 -- "Dialysis Machine";27472 (baxter or gambro)
    ,151 -- "Dialysis Site Appear";37345
    ,582 -- Procedures
    -- below indicate existence of a dialysis line
    ,229 -- INV Line#1 [Type]
    ,235 -- INV Line#2 [Type]
    ,241 -- INV Line#3 [Type]
    ,247 -- INV Line#4 [Type]
    ,253 -- INV Line#5 [Type]
    ,259 -- INV Line#6 [Type]
    ,265 -- INV Line#7 [Type]
    ,271 -- INV Line#8 [Type]
    
    -- dialysis consults can't be 100% guaranteed to be active
    -- ,466 -- Nursing Consultation
    -- diagnosis has 6 or 7 dx related to dialysis, probably not worth including
    -- as the chart time isn't going to match the start time of dialysis
    -- , 917 -- Diagnosis/op
    -- ,7949 -- "Calcium for CVVH" - only has 2 null values
    
    -- === MetaVision itemids === --
  
    -- Checkboxes
    , 226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
    , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
    , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox

    -- Numeric values
    , 226499 -- | Hemodialysis Output                               | Dialysis                | chartevents        | Numeric
    , 224154 -- | Dialysate Rate                                    | Dialysis                | chartevents        | Numeric
    , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis                | chartevents        | Numeric
    , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis                | chartevents        | Numeric
    , 225183 -- | Current Goal                     | Dialysis | chartevents        | Numeric
    , 227438 -- | Volume not removed               | Dialysis | chartevents        | Numeric
    , 224191 -- | Hourly Patient Fluid Removal     | Dialysis | chartevents        | Numeric
    , 225806 -- | Volume In (PD)                   | Dialysis | chartevents        | Numeric
    , 225807 -- | Volume Out (PD)                  | Dialysis | chartevents        | Numeric
    , 228004 -- | Citrate (ACD-A)                  | Dialysis | chartevents        | Numeric
    , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis | chartevents        | Numeric
    , 228006 -- | Post Filter Replacement Rate     | Dialysis | chartevents        | Numeric
    , 224144 -- | Blood Flow (ml/min)              | Dialysis | chartevents        | Numeric
    , 224145 -- | Heparin Dose (per hour)          | Dialysis | chartevents        | Numeric
    , 224149 -- | Access Pressure                  | Dialysis | chartevents        | Numeric
    , 224150 -- | Filter Pressure                  | Dialysis | chartevents        | Numeric
    , 224151 -- | Effluent Pressure                | Dialysis | chartevents        | Numeric
    , 224152 -- | Return Pressure                  | Dialysis | chartevents        | Numeric
    , 224153 -- | Replacement Rate                 | Dialysis | chartevents        | Numeric
    , 224404 -- | ART Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 224406 -- | VEN Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 226457 -- | Ultrafiltrate Output             | Dialysis | chartevents        | Numeric
    , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis | chartevents | Numeric
    -- Text values
    , 224135 -- | Dialysis Access Site | Dialysis | chartevents | Text
    , 224139 -- | Dialysis Site Appearance | Dialysis | chartevents | Text
    , 224146 -- | System Integrity | Dialysis | chartevents | Text
    , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive | chartevents | Text
    , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive | chartevents | Text
    , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive | chartevents | Text
    , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis | chartevents | Text
    , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225954 -- | Dialysis Access Type | Dialysis | chartevents | Text
    , 225956 -- | Reason for CRRT Filter Change | Dialysis | chartevents | Text
    , 225958 -- | Heparin Concentration (units/mL) | Dialysis | chartevents | Text
    , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis | chartevents | Text
    , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis | chartevents | Text
    , 225976 -- | Replacement Fluid | Dialysis | chartevents | Text
    , 225977 -- | Dialysate Fluid | Dialysis | chartevents | Text
    , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive | chartevents | Text
    , 227290 -- | CRRT mode | Dialysis | chartevents | Text
    , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive | chartevents | Text
  )
  AND ce.value IS NOT NULL
  AND ce.icustay_id IS NOT NULL
  -- exclude rows marked as error
  and COALESCE(ce.error, 0) = 0
)

-- TODO:
--   charttime + dialysis_present + dialysis_active
--  for inputevents_cv, outputevents
--  for procedures_mv, left join and set the dialysis_type
, cv_ie as
(
  select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          44954 -- OR CVVHDF |  | inputevents_cv
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
            40788 -- PD dialysate in | Free Form Intake | inputevents_cv
          , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
          , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
          , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
          , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
          , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
        ) THEN 'Peritoneal'
        WHEN itemid IN
        (
            45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
          , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
        ) THEN 'CVVH'
        WHEN itemid IN
        (
            45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
          , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
          , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
        ) THEN 'CVVHD'
        WHEN itemid IN
        (
            46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
          , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
          , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
          , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
        ) THEN 'CVVHDF'
      ELSE NULL END AS dialysis_type
  from inputevents_cv
  where itemid in
  (
        40788 -- PD dialysate in | Free Form Intake | inputevents_cv
      , 40907 -- dialysate | Free Form Intake | inputevents_cv
      , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
      , 41147 -- Dialysate instilled | Free Form Intake | inputevents_cv
      , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
      , 41460 -- capd dialysate | Free Form Intake | inputevents_cv
      , 41620 -- dialysate in | Free Form Intake | inputevents_cv
      , 41711 -- CAPD dialysate dwell | Free Form Intake | inputevents_cv
      , 41791 -- 2.5% dialysate in | Free Form Intake | inputevents_cv
      , 41792 -- 1.5% dialysate | Free Form Intake | inputevents_cv
      , 42562 -- pos. dialysate intak | Free Form Intake | inputevents_cv
      , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
      , 44037 -- Dialysate Instilled | Free Form Intake | inputevents_cv
      , 44188 -- rep.+dialysate | Free Form Intake | inputevents_cv
      , 44526 -- dialysate 1.5% dex | Free Form Intake | inputevents_cv
      , 44527 -- dialysate 2.5% | Free Form Intake | inputevents_cv
      , 44584 -- Dialysate IN | Free Form Intake | inputevents_cv
      , 44591 -- dialysate 4.25% | Free Form Intake | inputevents_cv
      , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
      , 44927 -- CRRT HEPARIN | Free Form Intake | inputevents_cv
      , 44954 -- OR CVVHDF |  | inputevents_cv
      , 45157 -- ca+ gtt for cvvh | Free Form Intake | inputevents_cv
      , 45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
      , 45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
      , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
      , 46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
      , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
      , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
      , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
      , 46250 -- EBL  CVVH |  | inputevents_cv
      , 46262 -- dialysate 2.5% in | Free Form Intake | inputevents_cv
      , 46292 -- CRRT Irrigation | Free Form Intake | inputevents_cv
      , 46293 -- CRRT Citrate | Free Form Intake | inputevents_cv
      , 46311 -- crrt irrigation | Free Form Intake | inputevents_cv
      , 46389 -- CRRT FLUSH | Free Form Intake | inputevents_cv
      , 46574 -- CRRT rescue line NS | Free Form Intake | inputevents_cv
      , 46681 -- CRRT Rescue Flush | Free Form Intake | inputevents_cv
      , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
      , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
      , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
  )
  and amount > 0 -- also ensures it's not null
)
, oe as
(
 select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          41897 -- CVVH OUTPUT FROM OR
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
          40789 -- PD dialysate out
        , 40910 -- PERITONEAL DIALYSIS
        , 41069 -- PD Dialysate Output
        , 44843 -- peritoneal dialysis
        , 46394 -- Peritoneal dialysis
        ) THEN 'Peritoneal'
      ELSE NULL END AS dialysis_type
 from outputevents
 where itemid in
 (
       40386 -- hemodialysis
     , 40425 -- dialysis output
     , 40426 -- dialysis out
     , 40507 -- Dialysis out
     , 40613 -- DIALYSIS OUT
     , 40624 -- dialysis
     , 40690 -- DIALYSIS
     , 40745 -- Dialysis
     , 40789 -- PD dialysate out
     , 40881 -- Hemodialysis
     , 40910 -- PERITONEAL DIALYSIS
     , 41016 -- hemodialysis out
     , 41034 -- dialysis in
     , 41069 -- PD Dialysate Output
     , 41112 -- Dialysys out
     , 41250 -- HEMODIALYSIS OUT
     , 41374 -- Dialysis Out
     , 41417 -- Hemodialysis Out
     , 41500 -- hemodialysis output
     , 41527 -- HEMODIALYSIS
     , 41623 -- dialysate out
     , 41635 -- Hemodialysis removal
     , 41713 -- dialyslate out
     , 41750 -- dialysis  out
     , 41829 -- HEMODIALYSIS OUTPUT
     , 41842 -- Dialysis Output.
     , 41897 -- CVVH OUTPUT FROM OR
     , 42289 -- dialysis off
     , 42388 -- DIALYSIS OUTPUT
     , 42464 -- hemodialysis ultrafe
     , 42524 -- HemoDialysis
     , 42536 -- Dialysis output
     , 42868 -- hemodialysis off
     , 42928 -- HEMODIALYSIS.
     , 42972 -- HEMODIALYSIS OFF
     , 43016 -- DIALYSIS TOTAL OUT
     , 43052 -- DIALYSIS REMOVED
     , 43098 -- hemodialysis crystal
     , 43115 -- dialysis net
     , 43687 -- crystalloid/dialysis
     , 43941 -- dialysis/intake
     , 44027 -- dialysis fluid off
     , 44085 -- DIALYSIS OFF
     , 44193 -- Dialysis.
     , 44199 -- HEMODIALYSIS O/P
     , 44216 -- Hemodialysis out
     , 44286 -- Dialysis indwelling
     , 44567 -- Hemodialysis.
     , 44843 -- peritoneal dialysis
     , 44845 -- Dialysis fluids
     , 44857 -- dialysis- fluid off
     , 44901 -- Dialysis Removed
     , 44943 -- fluid removed dialys
     , 45479 -- Dialysis In
     , 45828 -- Hemo dialysis out
     , 46230 -- Dialysis 1.5% IN
     , 46232 -- dialysis flush
     , 46394 -- Peritoneal dialysis
     , 46464 -- Hemodialysis OUT
     , 46712 -- CALCIUM-DIALYSIS
     , 46713 -- KCL-10 MEQ-DIALYSIS
     , 46715 -- Citrate - dialysis
     , 46741 -- dialysis removed
 )
 and value > 0 -- also ensures it's not null
)
, mv_ranges as
(
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , 1 AS dialysis_active
    , 'CRRT' as dialysis_type
  from inputevents_mv
  where itemid in
  (
      227536 --	KCl (CRRT)	Medications	inputevents_mv	Solution
    , 227525 --	Calcium Gluconate (CRRT)	Medications	inputevents_mv	Solution
  )
  and amount > 0 -- also ensures it's not null
  UNION DISTINCT
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , CASE WHEN itemid NOT IN (224270, 225436) THEN 1 ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid = 225441 THEN 'IHD'
        WHEN itemid = 225802 THEN 'CRRT'  -- CVVH (Continuous venovenous hemofiltration)
        WHEN itemid = 225803 THEN 'CVVHD' -- CVVHD (Continuous venovenous hemodialysis)
        WHEN itemid = 225805 THEN 'Peritoneal'
        WHEN itemid = 225809 THEN 'CVVHDF' -- CVVHDF (Continuous venovenous hemodiafiltration)
        WHEN itemid = 225955 THEN 'SCUF' -- SCUF (Slow continuous ultra filtration)
      ELSE NULL END as dialysis_type
  from procedureevents_mv
  where itemid in
  (
      225441 -- | Hemodialysis          | 4-Procedures              | procedureevents_mv | Process
    , 225802 -- | Dialysis - CRRT       | Dialysis                  | procedureevents_mv | Process
    , 225803 -- | Dialysis - CVVHD      | Dialysis                  | procedureevents_mv | Process
    , 225805 -- | Peritoneal Dialysis   | Dialysis                  | procedureevents_mv | Process
    , 224270 -- | Dialysis Catheter     | Access Lines - Invasive   | procedureevents_mv | Process
    , 225809 -- | Dialysis - CVVHDF     | Dialysis                  | procedureevents_mv | Process
    , 225955 -- | Dialysis - SCUF       | Dialysis                  | procedureevents_mv | Process
    , 225436 -- | CRRT Filter Change    | Dialysis                  | procedureevents_mv | Process
  )
  AND value IS NOT NULL
)
-- union together the charttime tables; append times from mv_ranges to guarantee they exist
, stg0 AS
(
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM ce
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM cv_ie
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM oe
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, starttime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
  UNION DISTINCT
  SELECT
    icustay_id, endtime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
)
SELECT
    stg0.icustay_id
    , charttime
    , COALESCE(mv.dialysis_present, stg0.dialysis_present) AS dialysis_present
    , COALESCE(mv.dialysis_active, stg0.dialysis_active) AS dialysis_active
    , COALESCE(mv.dialysis_type, stg0.dialysis_type) AS dialysis_type
FROM stg0
LEFT JOIN mv_ranges mv
  ON stg0.icustay_id = mv.icustay_id
  AND stg0.charttime >= mv.starttime
  AND stg0.charttime <= mv.endtime
WHERE stg0.icustay_id IS NOT NULL
ORDER BY 1,2
  );
17:07:49.007727 [debug] [Thread-1  ]: SQL status: SELECT 301513 in 2.88 seconds
17:07:49.011904 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:49.012110 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt" rename to "pivoted_rrt__dbt_backup"
17:07:49.012875 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:49.016789 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:49.016990 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt__dbt_tmp" rename to "pivoted_rrt"
17:07:49.017671 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:49.020870 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:07:49.021081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:49.021278 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:07:49.023835 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:49.027182 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:07:49.027634 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
drop table if exists "postgres"."public"."pivoted_rrt__dbt_backup" cascade
17:07:49.029879 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:49.032983 [debug] [Thread-1  ]: finished collecting timing info
17:07:49.033214 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: Close
17:07:49.034098 [info ] [Thread-1  ]: 59 of 107 OK created table model public.pivoted_rrt ............................ [[32mSELECT 301513[0m in 2.93s]
17:07:49.034763 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_rrt
17:07:49.035111 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_sofa
17:07:49.035791 [info ] [Thread-1  ]: 60 of 107 START table model public.pivoted_sofa ................................ [RUN]
17:07:49.036574 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_sofa"
17:07:49.036812 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_sofa
17:07:49.037100 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_sofa
17:07:49.038510 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_sofa"
17:07:49.039252 [debug] [Thread-1  ]: finished collecting timing info
17:07:49.039507 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_sofa
17:07:49.052333 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_sofa"
17:07:49.052955 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:07:49.053144 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: BEGIN
17:07:49.053237 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:49.059207 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:49.059456 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:07:49.059557 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_sofa"} */


  create  table "postgres"."public"."pivoted_sofa__dbt_tmp"
  as (
    ﻿with co as
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
-- get minimum blood pressure FROM chartevents
, bp as
(
  select ce.icustay_id
    , ce.charttime
    , min(valuenum) as meanbp_min
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.itemid in
  (
  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312  --"ART BP mean"
  )
  and valuenum > 0 and valuenum < 300
  group by ce.icustay_id, ce.charttime
)
, pafi as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select ie.icustay_id
  , bg.charttime
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , case when vd.icustay_id is null then pao2fio2ratio else null end pao2fio2ratio_novent
  , case when vd.icustay_id is not null then pao2fio2ratio else null end pao2fio2ratio_vent
  FROM icustays ie
  inner join pivoted_bg_art bg
    on ie.icustay_id = bg.icustay_id
  left join ventilation_durations vd
    on ie.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(bp.meanbp_min) as meanbp_min
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- labs
  , max(labs.bilirubin) as bilirubin_max
  , max(labs.creatinine) as creatinine_max
  , min(labs.platelet) as platelet_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , min(case when vd.icustay_id is null then pao2fio2ratio else null end) AS pao2fio2ratio_novent
  , min(case when vd.icustay_id is not null then pao2fio2ratio else null end) AS pao2fio2ratio_vent
  from co
  left join bp
    on co.icustay_id = bp.icustay_id
    and co.starttime < bp.charttime
    and co.endtime >= bp.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  left join pivoted_lab labs
    on co.hadm_id = labs.hadm_id
    and co.starttime < labs.charttime
    and co.endtime >= labs.charttime
  -- bring in blood gases that occurred during this hour
  left join pivoted_bg_art bg
    on co.icustay_id = bg.icustay_id
    and co.starttime < bg.charttime
    and co.endtime >= bg.charttime
  -- at the time of the blood gas, determine if patient was ventilated
  left join ventilation_durations vd
    on co.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.pao2fio2ratio_novent
    , ma.pao2fio2ratio_vent
    , epi.vaso_rate as rate_epinephrine
    , nor.vaso_rate as rate_norepinephrine
    , dop.vaso_rate as rate_dopamine
    , dob.vaso_rate as rate_dobutamine
    , ma.meanbp_min
    , ma.GCS_min
    -- uo
    , uo.urineoutput
    -- labs
    , ma.bilirubin_max
    , ma.creatinine_max
    , ma.platelet_min
  from co
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
  left join pafi
    on co.icustay_id = pafi.icustay_id
    and co.starttime < pafi.charttime
    and co.endtime  >= pafi.charttime
  left join epinephrine_dose epi
    on co.icustay_id = epi.icustay_id
    and co.endtime > epi.starttime
    and co.endtime <= epi.endtime
  left join norepinephrine_dose nor
    on co.icustay_id = nor.icustay_id
    and co.endtime > nor.starttime
    and co.endtime <= nor.endtime
  left join dopamine_dose dop
    on co.icustay_id = dop.icustay_id
    and co.endtime > dop.starttime
    and co.endtime <= dop.endtime
  left join dobutamine_dose dob
    on co.icustay_id = dob.icustay_id
    and co.endtime > dob.starttime
    and co.endtime <= dob.endtime
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
  -- Respiration
  , cast(case
      when pao2fio2ratio_vent   < 100 then 4
      when pao2fio2ratio_vent   < 200 then 3
      when pao2fio2ratio_novent < 300 then 2
      when pao2fio2ratio_novent < 400 then 1
      when coalesce(pao2fio2ratio_vent, pao2fio2ratio_novent) is null then null
      else 0
    end as SMALLINT) as respiration

  -- Coagulation
  , cast(case
      when platelet_min < 20  then 4
      when platelet_min < 50  then 3
      when platelet_min < 100 then 2
      when platelet_min < 150 then 1
      when platelet_min is null then null
      else 0
    end as SMALLINT) as coagulation

  -- Liver
  , cast(case
      -- Bilirubin checks in mg/dL
        when Bilirubin_Max >= 12.0 then 4
        when Bilirubin_Max >= 6.0  then 3
        when Bilirubin_Max >= 2.0  then 2
        when Bilirubin_Max >= 1.2  then 1
        when Bilirubin_Max is null then null
        else 0
      end as SMALLINT) as liver

  -- Cardiovascular
  , cast(case
      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4
      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3
      when rate_dopamine >  0 or rate_dobutamine > 0 then 2
      when meanbp_min < 70 then 1
      when coalesce(meanbp_min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null
      else 0
    end as SMALLINT) as cardiovascular

  -- Neurological failure (GCS)
  , cast(case
      when (GCS_min >= 13 and GCS_min <= 14) then 1
      when (GCS_min >= 10 and GCS_min <= 12) then 2
      when (GCS_min >=  6 and GCS_min <=  9) then 3
      when  GCS_min <   6 then 4
      when  GCS_min is null then null
  else 0 end as SMALLINT)
    as cns

  -- Renal failure - high creatinine or low urine output
  , cast(case
    when (Creatinine_Max >= 5.0) then 4
    when
      SUM(urineoutput) OVER W < 200
        then 4
    when (Creatinine_Max >= 3.5 and Creatinine_Max < 5.0) then 3
    when
      SUM(urineoutput) OVER W < 500
        then 3
    when (Creatinine_Max >= 2.0 and Creatinine_Max < 3.5) then 2
    when (Creatinine_Max >= 1.2 and Creatinine_Max < 2.0) then 1
    when coalesce
      (
        SUM(urineoutput) OVER W
        , Creatinine_Max
      ) is null then null
  else 0 end as SMALLINT)
    as renal
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Combine all the scores to get SOFA
    -- Impute 0 if the score is missing
   -- the window function takes the max over the last 24 hours
    , cast(coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as respiration_24hours
     , cast(coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
        ,0) as SMALLINT) as coagulation_24hours
    , cast(coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as liver_24hours
    , cast(coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cardiovascular_24hours
    , cast(coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cns_24hours
    , cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as renal_24hours

    -- sum together data for final SOFA
    , coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT)
    as sofa_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:07:49.059998 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "﻿with"
LINE 6:     ﻿with co as
            ^

17:07:49.060234 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: ROLLBACK
17:07:49.060491 [debug] [Thread-1  ]: finished collecting timing info
17:07:49.060611 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: Close
17:07:49.061076 [debug] [Thread-1  ]: Database Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)
  syntax error at or near "﻿with"
  LINE 6:     ﻿with co as
              ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:07:49.061562 [error] [Thread-1  ]: 60 of 107 ERROR creating table model public.pivoted_sofa ....................... [[31mERROR[0m in 0.03s]
17:07:49.062637 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_sofa
17:07:49.063352 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_uo
17:07:49.064248 [info ] [Thread-1  ]: 61 of 107 START table model public.pivoted_uo .................................. [RUN]
17:07:49.065103 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_uo"
17:07:49.065496 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_uo
17:07:49.065696 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_uo
17:07:49.068020 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_uo"
17:07:49.068650 [debug] [Thread-1  ]: finished collecting timing info
17:07:49.068938 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_uo
17:07:49.076114 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_uo"
17:07:49.076609 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:49.076820 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: BEGIN
17:07:49.076912 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:49.083225 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:49.083615 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:49.083857 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */


  create  table "postgres"."public"."pivoted_uo__dbt_tmp"
  as (
    select
  icustay_id
  , charttime
  , sum(urineoutput) as urineoutput
from
(
  select
  -- patient identifiers
    oe.icustay_id
  , oe.charttime 
  -- volumes associated with urine output ITEMIDs
  -- note we consider input of GU irrigant as a negative volume
  , case
      when oe.itemid = 227488 and oe.value > 0 then -1*oe.value
      else oe.value
    end as urineoutput
  from outputevents oe
-- exclude rows marked as error
where (oe.iserror IS NULL OR oe.iserror != 1)
  and itemid in
  (
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in CareVue
  226559, -- "Foley"
  226560, -- "Void"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- R Ureteral Stent
  226558, -- L Ureteral Stent
  227488, -- GU Irrigant Volume In
  227489  -- GU Irrigant/Urine Volume Out
  )
) as foo
group by icustay_id, charttime
order by icustay_id, charttime
  );
17:07:52.388960 [debug] [Thread-1  ]: SQL status: SELECT 3381677 in 3.3 seconds
17:07:52.393778 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:52.393977 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo" rename to "pivoted_uo__dbt_backup"
17:07:52.394877 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.400551 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:52.400766 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo__dbt_tmp" rename to "pivoted_uo"
17:07:52.401499 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.404551 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:07:52.404748 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:52.404840 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:07:52.415956 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:07:52.418449 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:07:52.418937 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
drop table if exists "postgres"."public"."pivoted_uo__dbt_backup" cascade
17:07:52.423417 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:52.428000 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.428236 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: Close
17:07:52.429103 [info ] [Thread-1  ]: 61 of 107 OK created table model public.pivoted_uo ............................. [[32mSELECT 3381677[0m in 3.36s]
17:07:52.429599 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_uo
17:07:52.430002 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_vital
17:07:52.430819 [info ] [Thread-1  ]: 62 of 107 START table model public.pivoted_vital ............................... [RUN]
17:07:52.431602 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_vital"
17:07:52.431918 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_vital
17:07:52.432446 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_vital
17:07:52.433773 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_vital"
17:07:52.434324 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.434782 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_vital
17:07:52.448513 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_vital"
17:07:52.449075 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.449376 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: BEGIN
17:07:52.449557 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:52.455837 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:52.456093 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.456267 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */


  create  table "postgres"."public"."pivoted_vital__dbt_tmp"
  as (
    -- This query pivots the vital signs for the first 24 hours of a patient's stay
-- Vital signs include heart rate, blood pressure, respiration rate, and temperature

with ce as
(
  select ce.icustay_id
    , ce.charttime
    , (case when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then valuenum else null end) as heartrate
    , (case when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then valuenum else null end) as sysbp
    , (case when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then valuenum else null end) as diasbp
    , (case when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then valuenum else null end) as meanbp
    , (case when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then valuenum else null end) as resprate
    , (case when itemid in (223761,678) and valuenum > 70 and valuenum < 120 then (valuenum-32)/1.8 -- converted to degC in valuenum call
               when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then valuenum else null end) as tempc
    , (case when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then valuenum else null end) as spo2
    , (case when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then valuenum else null end) as glucose
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
  -- HEART RATE
  211, --"Heart Rate"
  220045, --"Heart Rate"

  -- Systolic/diastolic

  51, --	Arterial BP [Systolic]
  442, --	Manual BP [Systolic]
  455, --	NBP [Systolic]
  6701, --	Arterial BP #2 [Systolic]
  220179, --	Non Invasive Blood Pressure systolic
  220050, --	Arterial Blood Pressure systolic

  8368, --	Arterial BP [Diastolic]
  8440, --	Manual BP [Diastolic]
  8441, --	NBP [Diastolic]
  8555, --	Arterial BP #2 [Diastolic]
  220180, --	Non Invasive Blood Pressure diastolic
  220051, --	Arterial Blood Pressure diastolic


  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312, --"ART BP mean"

  -- RESPIRATORY RATE
  618,--	Respiratory Rate
  615,--	Resp Rate (Total)
  220210,--	Respiratory Rate
  224690, --	Respiratory Rate (Total)


  -- spo2, peripheral
  646, 220277,

  -- glucose, both lab and fingerstick
  807,--	Fingerstick glucose
  811,--	glucose (70-105)
  1529,--	glucose
  3745,--	Bloodglucose
  3744,--	Blood glucose
  225664,--	glucose finger stick
  220621,--	glucose (serum)
  226537,--	glucose (whole blood)

  -- TEMPERATURE
  223762, -- "Temperature Celsius"
  676,	-- "Temperature C"
  223761, -- "Temperature Fahrenheit"
  678 --	"Temperature F"

  )
)
select
    ce.icustay_id
  , ce.charttime
  , avg(heartrate) as heartrate
  , avg(sysbp) as sysbp
  , avg(diasbp) as diasbp
  , avg(meanbp) as meanbp
  , avg(resprate) as resprate
  , avg(tempc) as tempc
  , avg(spo2) as spo2
  , avg(glucose) as glucose
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:07:52.474774 [debug] [Thread-1  ]: SQL status: SELECT 1045 in 0.02 seconds
17:07:52.483428 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.483639 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital" rename to "pivoted_vital__dbt_backup"
17:07:52.484287 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.488064 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.488270 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital__dbt_tmp" rename to "pivoted_vital"
17:07:52.488893 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.492359 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:07:52.493021 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.493592 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:07:52.495338 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:52.497537 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:07:52.497729 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
drop table if exists "postgres"."public"."pivoted_vital__dbt_backup" cascade
17:07:52.499803 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:52.502406 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.502791 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: Close
17:07:52.503718 [info ] [Thread-1  ]: 62 of 107 OK created table model public.pivoted_vital .......................... [[32mSELECT 1045[0m in 0.07s]
17:07:52.504324 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_vital
17:07:52.504787 [debug] [Thread-1  ]: Began running node model.mimic.potassium
17:07:52.505416 [info ] [Thread-1  ]: 63 of 107 START table model public.potassium ................................... [RUN]
17:07:52.506228 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.potassium"
17:07:52.506649 [debug] [Thread-1  ]: Began compiling node model.mimic.potassium
17:07:52.506876 [debug] [Thread-1  ]: Compiling model.mimic.potassium
17:07:52.507998 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.potassium"
17:07:52.508536 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.508815 [debug] [Thread-1  ]: Began executing node model.mimic.potassium
17:07:52.519069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.potassium"
17:07:52.519680 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.519947 [debug] [Thread-1  ]: On model.mimic.potassium: BEGIN
17:07:52.520149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:52.524371 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:52.524595 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.524816 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */


  create  table "postgres"."public"."potassium__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Creates a histogram of serum potassium for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, k as
(
  SELECT width_bucket(valuenum, 0, 10, 100) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50822, 50971)
)
SELECT round(cast(bucket as numeric) / 10,2) as potassium_value, count(*)
FROM k
GROUP BY bucket
ORDER BY bucket
  );
17:07:52.675878 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:07:52.682885 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.683301 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
alter table "postgres"."public"."potassium" rename to "potassium__dbt_backup"
17:07:52.684278 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.689364 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.689600 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
alter table "postgres"."public"."potassium__dbt_tmp" rename to "potassium"
17:07:52.690376 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:52.693247 [debug] [Thread-1  ]: On model.mimic.potassium: COMMIT
17:07:52.693424 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.693643 [debug] [Thread-1  ]: On model.mimic.potassium: COMMIT
17:07:52.694858 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:52.696733 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:07:52.696919 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
drop table if exists "postgres"."public"."potassium__dbt_backup" cascade
17:07:52.698966 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:52.701508 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.701723 [debug] [Thread-1  ]: On model.mimic.potassium: Close
17:07:52.702660 [info ] [Thread-1  ]: 63 of 107 OK created table model public.potassium .............................. [[32mSELECT 0[0m in 0.20s]
17:07:52.703242 [debug] [Thread-1  ]: Finished running node model.mimic.potassium
17:07:52.703695 [debug] [Thread-1  ]: Began running node model.mimic.rbc_transfusion
17:07:52.704446 [info ] [Thread-1  ]: 64 of 107 START table model public.rbc_transfusion ............................. [RUN]
17:07:52.705304 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rbc_transfusion"
17:07:52.705760 [debug] [Thread-1  ]: Began compiling node model.mimic.rbc_transfusion
17:07:52.706037 [debug] [Thread-1  ]: Compiling model.mimic.rbc_transfusion
17:07:52.707380 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rbc_transfusion"
17:07:52.708199 [debug] [Thread-1  ]: finished collecting timing info
17:07:52.708603 [debug] [Thread-1  ]: Began executing node model.mimic.rbc_transfusion
17:07:52.719499 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rbc_transfusion"
17:07:52.721063 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:52.721294 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: BEGIN
17:07:52.721474 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:52.726325 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:07:52.726682 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:52.727067 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rbc_transfusion"} */


  create  table "postgres"."public"."rbc_transfusion__dbt_tmp"
  as (
    -- Retrieves instances of red blood cell transfusions
with raw_rbc as (
  SELECT
      CASE
        WHEN amount IS NOT NULL THEN amount
        WHEN stopped IS NOT NULL THEN 0
        -- impute 375 mL when unit is not documented
        ELSE 375
      END AS amount
    , amountuom
    , icustay_id
    , charttime
  FROM inputevents_cv
  WHERE itemid IN
  (
    30179,  -- PRBC's
    30001,  -- Packed RBC's
    30004   -- Washed PRBC's
  )
  AND icustay_id IS NOT NULL
  UNION ALL
  SELECT amount
    , amountuom
    , icustay_id
    , endtime AS charttime
  FROM inputevents_mv
  WHERE itemid in
  (
    225168   -- Packed Red Blood Cells
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
),
pre_icu_rbc as (
  SELECT
    sum(amount) as amount, icustay_id
  FROM inputevents_cv
  WHERE itemid IN (
    42324,  -- er prbc
    42588,  -- VICU PRBC
    42239,  -- CC7 PRBC
    46407,  -- ED PRBC
    46612,  -- E.R. prbc
    46124,  -- er in prbc
    42740   -- prbc in er
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
  GROUP BY icustay_id
  UNION ALL
  SELECT
    sum(amount) as amount, icustay_id
  FROM inputevents_mv
  WHERE itemid IN (
    227070  -- PACU Packed RBC Intake
  )
  AND amount > 0
  AND icustay_id IS NOT NULL
  GROUP BY icustay_id
),
cumulative AS (
  SELECT
    sum(amount) over (PARTITION BY icustay_id ORDER BY charttime DESC) AS amount
    , amountuom
    , icustay_id
    , charttime
    , DATETIME_DIFF(lag(charttime) over (PARTITION BY icustay_id ORDER BY charttime ASC), charttime, 'HOUR') AS delta
  FROM raw_rbc
)
-- We consider any transfusions started within 1 hr of the last one
-- to be part of the same event
SELECT
    cm.icustay_id
  , cm.charttime
  , ROUND(CAST(cm.amount AS numeric) - CASE
      WHEN ROW_NUMBER() OVER w = 1 THEN CAST(0 AS numeric)
      ELSE CAST(lag(cm.amount) OVER w AS numeric)
    END, 2) AS amount
  , ROUND(CAST(cm.amount AS numeric) + CASE
      WHEN CAST(pre.amount AS numeric) IS NULL THEN CAST(0 AS numeric)
      ELSE CAST(pre.amount AS numeric)
    END, 2) AS totalamount
  , cm.amountuom
FROM cumulative AS cm
LEFT JOIN pre_icu_rbc AS pre
  USING (icustay_id)
WHERE delta IS NULL OR delta < -1
WINDOW w AS (PARTITION BY cm.icustay_id ORDER BY cm.charttime DESC)
ORDER BY icustay_id, charttime
  );
17:07:53.966977 [debug] [Thread-1  ]: SQL status: SELECT 62851 in 1.24 seconds
17:07:53.974322 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:53.974722 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rbc_transfusion"} */
alter table "postgres"."public"."rbc_transfusion" rename to "rbc_transfusion__dbt_backup"
17:07:53.976165 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:53.981242 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:53.981440 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rbc_transfusion"} */
alter table "postgres"."public"."rbc_transfusion__dbt_tmp" rename to "rbc_transfusion"
17:07:53.982212 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:53.985238 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: COMMIT
17:07:53.985433 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:53.985651 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: COMMIT
17:07:53.989239 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:53.991850 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rbc_transfusion"
17:07:53.992049 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rbc_transfusion"} */
drop table if exists "postgres"."public"."rbc_transfusion__dbt_backup" cascade
17:07:53.994340 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:53.997402 [debug] [Thread-1  ]: finished collecting timing info
17:07:53.997626 [debug] [Thread-1  ]: On model.mimic.rbc_transfusion: Close
17:07:53.998454 [info ] [Thread-1  ]: 64 of 107 OK created table model public.rbc_transfusion ........................ [[32mSELECT 62851[0m in 1.29s]
17:07:53.999258 [debug] [Thread-1  ]: Finished running node model.mimic.rbc_transfusion
17:07:53.999658 [debug] [Thread-1  ]: Began running node model.mimic.rr
17:07:54.000490 [info ] [Thread-1  ]: 65 of 107 START table model public.rr .......................................... [RUN]
17:07:54.001343 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rr"
17:07:54.001766 [debug] [Thread-1  ]: Began compiling node model.mimic.rr
17:07:54.002161 [debug] [Thread-1  ]: Compiling model.mimic.rr
17:07:54.003439 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rr"
17:07:54.004044 [debug] [Thread-1  ]: finished collecting timing info
17:07:54.004278 [debug] [Thread-1  ]: Began executing node model.mimic.rr
17:07:54.018129 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rr"
17:07:54.018905 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.019270 [debug] [Thread-1  ]: On model.mimic.rr: BEGIN
17:07:54.019575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:54.024822 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:54.025305 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.025642 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */


  create  table "postgres"."public"."rr__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the respiration rate of adult patients
--        only for patients recorded with carevue
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, rr as
(
  SELECT valuenum, width_bucket(valuenum, 0, 130, 1400) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid in (219, 615, 618)
)
SELECT round(cast(bucket as numeric) / 10,2) as respiration_rate, count(*)
FROM rr
GROUP BY bucket
ORDER BY bucket
  );
17:07:54.173500 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:07:54.180460 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.180888 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr" rename to "rr__dbt_backup"
17:07:54.182746 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:54.188394 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.188597 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr__dbt_tmp" rename to "rr"
17:07:54.189316 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:54.192735 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:07:54.192934 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.193121 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:07:54.194326 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:54.196262 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:07:54.196450 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
drop table if exists "postgres"."public"."rr__dbt_backup" cascade
17:07:54.198460 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:54.201800 [debug] [Thread-1  ]: finished collecting timing info
17:07:54.202026 [debug] [Thread-1  ]: On model.mimic.rr: Close
17:07:54.202806 [info ] [Thread-1  ]: 65 of 107 OK created table model public.rr ..................................... [[32mSELECT 0[0m in 0.20s]
17:07:54.203388 [debug] [Thread-1  ]: Finished running node model.mimic.rr
17:07:54.203754 [debug] [Thread-1  ]: Began running node model.mimic.rrt_first_day
17:07:54.204484 [info ] [Thread-1  ]: 66 of 107 START table model public.rrt_first_day ............................... [RUN]
17:07:54.205297 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rrt_first_day"
17:07:54.205549 [debug] [Thread-1  ]: Began compiling node model.mimic.rrt_first_day
17:07:54.205809 [debug] [Thread-1  ]: Compiling model.mimic.rrt_first_day
17:07:54.207472 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rrt_first_day"
17:07:54.208133 [debug] [Thread-1  ]: finished collecting timing info
17:07:54.208427 [debug] [Thread-1  ]: Began executing node model.mimic.rrt_first_day
17:07:54.219407 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rrt_first_day"
17:07:54.220235 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:54.220930 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: BEGIN
17:07:54.221199 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:54.227376 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:54.227978 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:54.228197 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */


  create  table "postgres"."public"."rrt_first_day__dbt_tmp"
  as (
    -- determines if patients received any dialysis during their stay

-- Some example aggregate queries which summarize the data here..
-- This query estimates 6.7% of ICU patients received RRT.
    -- select count(rrt.icustay_id) as numobs
    -- , sum(rrt) as numrrt
    -- , sum(case when rrt=1 then 1 else 0 end)*100.0 / count(rrt.icustay_id)
    -- as percent_rrt
    -- from rrt
    -- inner join icustays ie on rrt.icustay_id = ie.icustay_id
    -- inner join patients p
    -- on rrt.subject_id = p.subject_id
    -- and p.dob < ie.intime - interval '1' year
    -- inner join admissions adm
    -- on rrt.hadm_id = adm.hadm_id

-- This query estimates that 4.6% of first ICU stays received RRT.
    -- select
    --   count(rrt.icustay_id) as numobs
    --   , sum(rrt) as numrrt
    --   , sum(case when rrt=1 then 1 else 0 end)*100.0 / count(rrt.icustay_id)
    -- as percent_rrt
    -- from
    -- (
    -- select ie.icustay_id, rrt.rrt
    --   , ROW_NUMBER() over (partition by ie.subject_id order by ie.intime) rn
    -- from rrt
    -- inner join icustays ie
    --   on rrt.icustay_id = ie.icustay_id
    -- inner join patients p
    --   on rrt.subject_id = p.subject_id
    -- and p.dob < ie.intime - interval '1' year
    -- inner join admissions adm
    --   on rrt.hadm_id = adm.hadm_id
    -- ) rrt
    -- where rn = 1

with cv as
(
  select ie.icustay_id
    , max(
        case
          when ce.itemid in (152,148,149,146,147,151,150) and value is not null then 1
          when ce.itemid in (229,235,241,247,253,259,265,271) and value = 'Dialysis Line' then 1
          when ce.itemid = 582 and value in ('CAVH Start','CAVH D/C','CVVHD Start','CVVHD D/C','Hemodialysis st','Hemodialysis end') then 1
        else 0 end
        ) as RRT
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.itemid in
    (
       152 -- "Dialysis Type"61449
      ,148 -- "Dialysis Access Site"60335
      ,149 -- "Dialysis Access Type"60030
      ,146 -- "Dialysate Flow ml/hr"57445
      ,147 -- "Dialysate Infusing"56605
      ,151 -- "Dialysis Site Appear"37345
      ,150 -- "Dialysis Machine"27472
      ,229 -- INV Line#1 [Type]
      ,235 -- INV Line#2 [Type]
      ,241 -- INV Line#3 [Type]
      ,247 -- INV Line#4 [Type]
      ,253 -- INV Line#5 [Type]
      ,259 -- INV Line#6 [Type]
      ,265 -- INV Line#7 [Type]
      ,271 -- INV Line#8 [Type]
      ,582 -- Procedures
    )
    and ce.value is not null
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where ie.dbsource = 'carevue'
  group by ie.icustay_id
)
, mv_ce as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
      -- Checkboxes
        226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
      , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
      , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox
      -- Numeric values
      , 226499 -- | Hemodialysis Output                               | Dialysis                | chartevents        | Numeric
      , 224154 -- | Dialysate Rate                                    | Dialysis                | chartevents        | Numeric
      , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis                | chartevents        | Numeric
      , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis                | chartevents        | Numeric
      , 225183 -- | Current Goal                     | Dialysis | chartevents        | Numeric
      , 227438 -- | Volume not removed               | Dialysis | chartevents        | Numeric
      , 224191 -- | Hourly Patient Fluid Removal     | Dialysis | chartevents        | Numeric
      , 225806 -- | Volume In (PD)                   | Dialysis | chartevents        | Numeric
      , 225807 -- | Volume Out (PD)                  | Dialysis | chartevents        | Numeric
      , 228004 -- | Citrate (ACD-A)                  | Dialysis | chartevents        | Numeric
      , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis | chartevents        | Numeric
      , 228006 -- | Post Filter Replacement Rate     | Dialysis | chartevents        | Numeric
      , 224144 -- | Blood Flow (ml/min)              | Dialysis | chartevents        | Numeric
      , 224145 -- | Heparin Dose (per hour)          | Dialysis | chartevents        | Numeric
      , 224149 -- | Access Pressure                  | Dialysis | chartevents        | Numeric
      , 224150 -- | Filter Pressure                  | Dialysis | chartevents        | Numeric
      , 224151 -- | Effluent Pressure                | Dialysis | chartevents        | Numeric
      , 224152 -- | Return Pressure                  | Dialysis | chartevents        | Numeric
      , 224153 -- | Replacement Rate                 | Dialysis | chartevents        | Numeric
      , 224404 -- | ART Lumen Volume                 | Dialysis | chartevents        | Numeric
      , 224406 -- | VEN Lumen Volume                 | Dialysis | chartevents        | Numeric
      , 226457 -- | Ultrafiltrate Output             | Dialysis | chartevents        | Numeric
    )
    and valuenum > 0 -- also ensures it's not null
  group by ie.icustay_id
)
, mv_ie as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join inputevents_mv tt
    on ie.icustay_id = tt.icustay_id
    and tt.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
        227536 --	KCl (CRRT)	Medications	inputevents_mv	Solution
      , 227525 --	Calcium Gluconate (CRRT)	Medications	inputevents_mv	Solution
    )
    and amount > 0 -- also ensures it's not null
  group by ie.icustay_id
)
, mv_de as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join datetimeevents tt
    on ie.icustay_id = tt.icustay_id
    and tt.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
      -- TODO: unsure how to handle "Last dialysis"
      --  225128 -- | Last dialysis                                     | Adm History/FHPA        | datetimeevents     | Date time
        225318 -- | Dialysis Catheter Cap Change                      | Access Lines - Invasive | datetimeevents     | Date time
      , 225319 -- | Dialysis Catheter Change over Wire Date           | Access Lines - Invasive | datetimeevents     | Date time
      , 225321 -- | Dialysis Catheter Dressing Change                 | Access Lines - Invasive | datetimeevents     | Date time
      , 225322 -- | Dialysis Catheter Insertion Date                  | Access Lines - Invasive | datetimeevents     | Date time
      , 225324 -- | Dialysis CatheterTubing Change                    | Access Lines - Invasive | datetimeevents     | Date time
    )
  group by ie.icustay_id
)
, mv_pe as
(
    select ie.icustay_id
      , 1 as RRT
    FROM icustays ie
    inner join procedureevents_mv tt
      on ie.icustay_id = tt.icustay_id
      and tt.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
      and itemid in
      (
          225441 -- | Hemodialysis                                      | 4-Procedures            | procedureevents_mv | Process
        , 225802 -- | Dialysis - CRRT                                   | Dialysis                | procedureevents_mv | Process
        , 225803 -- | Dialysis - CVVHD                                  | Dialysis                | procedureevents_mv | Process
        , 225805 -- | Peritoneal Dialysis                               | Dialysis                | procedureevents_mv | Process
        , 224270 -- | Dialysis Catheter                                 | Access Lines - Invasive | procedureevents_mv | Process
        , 225809 -- | Dialysis - CVVHDF                                 | Dialysis                | procedureevents_mv | Process
        , 225955 -- | Dialysis - SCUF                                   | Dialysis                | procedureevents_mv | Process
        , 225436 -- | CRRT Filter Change               | Dialysis | procedureevents_mv | Process
      )
    group by ie.icustay_id
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
  , case
      when cv.RRT = 1 then 1
      when mv_ce.RRT = 1 then 1
      when mv_ie.RRT = 1 then 1
      when mv_de.RRT = 1 then 1
      when mv_pe.RRT = 1 then 1
      else 0
    end as rrt
FROM icustays ie
left join cv
  on ie.icustay_id = cv.icustay_id
left join mv_ce
  on ie.icustay_id = mv_ce.icustay_id
left join mv_ie
  on ie.icustay_id = mv_ie.icustay_id
left join mv_de
  on ie.icustay_id = mv_de.icustay_id
left join mv_pe
  on ie.icustay_id = mv_pe.icustay_id
order by ie.icustay_id
  );
17:07:55.960808 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.73 seconds
17:07:55.967539 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:55.967983 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
alter table "postgres"."public"."rrt_first_day" rename to "rrt_first_day__dbt_backup"
17:07:55.968929 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:55.973733 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:55.973935 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
alter table "postgres"."public"."rrt_first_day__dbt_tmp" rename to "rrt_first_day"
17:07:55.974717 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:55.977517 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: COMMIT
17:07:55.977697 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:55.977915 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: COMMIT
17:07:55.983070 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:55.985169 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:07:55.985437 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
drop table if exists "postgres"."public"."rrt_first_day__dbt_backup" cascade
17:07:55.987227 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:55.990248 [debug] [Thread-1  ]: finished collecting timing info
17:07:55.990507 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: Close
17:07:55.991418 [info ] [Thread-1  ]: 66 of 107 OK created table model public.rrt_first_day .......................... [[32mSELECT 61532[0m in 1.79s]
17:07:55.992003 [debug] [Thread-1  ]: Finished running node model.mimic.rrt_first_day
17:07:55.992360 [debug] [Thread-1  ]: Began running node model.mimic.sbp
17:07:55.993122 [info ] [Thread-1  ]: 67 of 107 START table model public.sbp ......................................... [RUN]
17:07:55.994045 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sbp"
17:07:55.994342 [debug] [Thread-1  ]: Began compiling node model.mimic.sbp
17:07:55.994887 [debug] [Thread-1  ]: Compiling model.mimic.sbp
17:07:55.996448 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sbp"
17:07:55.997461 [debug] [Thread-1  ]: finished collecting timing info
17:07:55.997906 [debug] [Thread-1  ]: Began executing node model.mimic.sbp
17:07:56.008653 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sbp"
17:07:56.009351 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.009638 [debug] [Thread-1  ]: On model.mimic.sbp: BEGIN
17:07:56.009889 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:56.016453 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:56.016752 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.016961 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */


  create  table "postgres"."public"."sbp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the systolic blood pressure for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, sysbp as
(
  SELECT width_bucket(valuenum, 0, 300, 300) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid IN
  (
      6 -- ABP [Systolic]
    , 51 -- Arterial BP [Systolic]
    , 455 -- NBP [Systolic]
    , 6701 -- Arterial BP #2 [Systolic]
    , 220050 -- Arterial Blood Pressure systolic
    , 220179 -- Non Invasive Blood Pressure systolic
  )
)
SELECT bucket as systolic_blood_pressure, count(*)
FROM sysbp
GROUP BY bucket
ORDER BY bucket
  );
17:07:56.170933 [debug] [Thread-1  ]: SQL status: SELECT 155 in 0.15 seconds
17:07:56.178018 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.178378 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
alter table "postgres"."public"."sbp" rename to "sbp__dbt_backup"
17:07:56.179697 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.185030 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.185356 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
alter table "postgres"."public"."sbp__dbt_tmp" rename to "sbp"
17:07:56.186149 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.189509 [debug] [Thread-1  ]: On model.mimic.sbp: COMMIT
17:07:56.189714 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.189923 [debug] [Thread-1  ]: On model.mimic.sbp: COMMIT
17:07:56.191138 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:56.193174 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:07:56.193376 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
drop table if exists "postgres"."public"."sbp__dbt_backup" cascade
17:07:56.195357 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:56.198091 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.198317 [debug] [Thread-1  ]: On model.mimic.sbp: Close
17:07:56.199230 [info ] [Thread-1  ]: 67 of 107 OK created table model public.sbp .................................... [[32mSELECT 155[0m in 0.21s]
17:07:56.199805 [debug] [Thread-1  ]: Finished running node model.mimic.sbp
17:07:56.200172 [debug] [Thread-1  ]: Began running node model.mimic.sodium
17:07:56.200792 [info ] [Thread-1  ]: 68 of 107 START table model public.sodium ...................................... [RUN]
17:07:56.201524 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sodium"
17:07:56.201838 [debug] [Thread-1  ]: Began compiling node model.mimic.sodium
17:07:56.202097 [debug] [Thread-1  ]: Compiling model.mimic.sodium
17:07:56.203265 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sodium"
17:07:56.203819 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.204113 [debug] [Thread-1  ]: Began executing node model.mimic.sodium
17:07:56.215144 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sodium"
17:07:56.215826 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.216036 [debug] [Thread-1  ]: On model.mimic.sodium: BEGIN
17:07:56.216132 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:56.224652 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:56.224918 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.225034 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */


  create  table "postgres"."public"."sodium__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the blood serum sodium levels for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, sodium as
(
  SELECT width_bucket(valuenum, 0, 180, 180) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50824, 50983)
)
SELECT bucket as sodium, count(*)
FROM sodium
GROUP BY bucket
ORDER BY bucket
  );
17:07:56.363140 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:07:56.370374 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.370941 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
alter table "postgres"."public"."sodium" rename to "sodium__dbt_backup"
17:07:56.371957 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.375693 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.375897 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
alter table "postgres"."public"."sodium__dbt_tmp" rename to "sodium"
17:07:56.376604 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.380236 [debug] [Thread-1  ]: On model.mimic.sodium: COMMIT
17:07:56.380443 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.380637 [debug] [Thread-1  ]: On model.mimic.sodium: COMMIT
17:07:56.381688 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:56.383757 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:07:56.383958 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
drop table if exists "postgres"."public"."sodium__dbt_backup" cascade
17:07:56.385702 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:56.389265 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.389571 [debug] [Thread-1  ]: On model.mimic.sodium: Close
17:07:56.390371 [info ] [Thread-1  ]: 68 of 107 OK created table model public.sodium ................................. [[32mSELECT 0[0m in 0.19s]
17:07:56.391013 [debug] [Thread-1  ]: Finished running node model.mimic.sodium
17:07:56.391434 [debug] [Thread-1  ]: Began running node model.mimic.temp
17:07:56.392229 [info ] [Thread-1  ]: 69 of 107 START table model public.temp ........................................ [RUN]
17:07:56.393031 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.temp"
17:07:56.393336 [debug] [Thread-1  ]: Began compiling node model.mimic.temp
17:07:56.393711 [debug] [Thread-1  ]: Compiling model.mimic.temp
17:07:56.395139 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.temp"
17:07:56.395743 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.395989 [debug] [Thread-1  ]: Began executing node model.mimic.temp
17:07:56.406139 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.temp"
17:07:56.407004 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.407408 [debug] [Thread-1  ]: On model.mimic.temp: BEGIN
17:07:56.407873 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:56.416627 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:56.416977 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.417152 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */


  create  table "postgres"."public"."temp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the temperature of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, temp as
(
  SELECT width_bucket(
      CASE
        WHEN itemid IN (223762, 676, 677) THEN valuenum -- celsius
        WHEN itemid IN (223761, 678, 679) THEN (valuenum - 32) * 5 / 9 --fahrenheit
      END
    , 30, 45, 160) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid IN
  (
      676 -- Temperature C
    , 677 -- Temperature C (calc)
    , 678 -- Temperature F
    , 679 -- Temperature F (calc)
    , 223761 -- Temperature Fahrenheit
    , 223762 -- Temperature Celsius
  )
)
SELECT round((cast(bucket as numeric)/10) + 30,2) as temperature, count(*)
FROM temp
GROUP BY bucket
ORDER BY bucket
  );
17:07:56.570250 [debug] [Thread-1  ]: SQL status: SELECT 30 in 0.15 seconds
17:07:56.577966 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.578378 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
alter table "postgres"."public"."temp" rename to "temp__dbt_backup"
17:07:56.579703 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.583883 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.584095 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
alter table "postgres"."public"."temp__dbt_tmp" rename to "temp"
17:07:56.584853 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:56.588292 [debug] [Thread-1  ]: On model.mimic.temp: COMMIT
17:07:56.588545 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.588747 [debug] [Thread-1  ]: On model.mimic.temp: COMMIT
17:07:56.589883 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:56.592003 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:07:56.592199 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
drop table if exists "postgres"."public"."temp__dbt_backup" cascade
17:07:56.594197 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:56.597282 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.597632 [debug] [Thread-1  ]: On model.mimic.temp: Close
17:07:56.598414 [info ] [Thread-1  ]: 69 of 107 OK created table model public.temp ................................... [[32mSELECT 30[0m in 0.21s]
17:07:56.599110 [debug] [Thread-1  ]: Finished running node model.mimic.temp
17:07:56.599473 [debug] [Thread-1  ]: Began running node model.mimic.uo
17:07:56.600267 [info ] [Thread-1  ]: 70 of 107 START table model public.uo .......................................... [RUN]
17:07:56.601055 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.uo"
17:07:56.601304 [debug] [Thread-1  ]: Began compiling node model.mimic.uo
17:07:56.601528 [debug] [Thread-1  ]: Compiling model.mimic.uo
17:07:56.602834 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.uo"
17:07:56.603364 [debug] [Thread-1  ]: finished collecting timing info
17:07:56.603656 [debug] [Thread-1  ]: Began executing node model.mimic.uo
17:07:56.614032 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.uo"
17:07:56.614408 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:56.614782 [debug] [Thread-1  ]: On model.mimic.uo: BEGIN
17:07:56.614997 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:56.621639 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:56.621906 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:56.622008 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */


  create  table "postgres"."public"."uo__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the urine output of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ie.icustay_id, ie.intime
  FROM icustays ie
  INNER JOIN patients p
  ON ie.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ie.intime, p.dob, 'YEAR') > 15
)
-- Urine output is measured hourly, but the individual values are not of interest
-- Usually, you want an overall picture of patient output
-- This query sums the data over the first 24 hours
, uo_sum as
(
  select oe.icustay_id, sum(oe.VALUE) as urineoutput
  FROM outputevents oe
  INNER JOIN agetbl
  ON oe.icustay_id = agetbl.icustay_id
  -- and ensure the data occurs during the first day
  and oe.charttime between agetbl.intime and (DATETIME_ADD(agetbl.intime, INTERVAL '1' DAY)) -- first ICU day
  WHERE itemid IN
  (
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in Metavision
  226559, -- "Foley"
  226560, -- "Void"
  227510, -- "TF Residual"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- "R Ureteral Stent"
  226558  -- "L Ureteral Stent"
  )
  group by oe.icustay_id
)
, uo as
(
  SELECT width_bucket(urineoutput, 0, 5000, 50) AS bucket
  FROM uo_sum
)
SELECT bucket*100 as UrineOutput, COUNT(*)
FROM uo
GROUP BY bucket
ORDER BY bucket
  );
17:07:59.709808 [debug] [Thread-1  ]: SQL status: SELECT 53 in 3.09 seconds
17:07:59.717984 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:59.718407 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
alter table "postgres"."public"."uo" rename to "uo__dbt_backup"
17:07:59.719712 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:59.725047 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:59.725367 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
alter table "postgres"."public"."uo__dbt_tmp" rename to "uo"
17:07:59.726085 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:07:59.729246 [debug] [Thread-1  ]: On model.mimic.uo: COMMIT
17:07:59.729450 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:59.729653 [debug] [Thread-1  ]: On model.mimic.uo: COMMIT
17:07:59.730860 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:07:59.733820 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:07:59.734220 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
drop table if exists "postgres"."public"."uo__dbt_backup" cascade
17:07:59.736780 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:07:59.739924 [debug] [Thread-1  ]: finished collecting timing info
17:07:59.740149 [debug] [Thread-1  ]: On model.mimic.uo: Close
17:07:59.741187 [info ] [Thread-1  ]: 70 of 107 OK created table model public.uo ..................................... [[32mSELECT 53[0m in 3.14s]
17:07:59.741874 [debug] [Thread-1  ]: Finished running node model.mimic.uo
17:07:59.742135 [debug] [Thread-1  ]: Began running node model.mimic.urine_output
17:07:59.742899 [info ] [Thread-1  ]: 71 of 107 START table model public.urine_output ................................ [RUN]
17:07:59.743941 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.urine_output"
17:07:59.744523 [debug] [Thread-1  ]: Began compiling node model.mimic.urine_output
17:07:59.744806 [debug] [Thread-1  ]: Compiling model.mimic.urine_output
17:07:59.746061 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.urine_output"
17:07:59.746469 [debug] [Thread-1  ]: finished collecting timing info
17:07:59.747107 [debug] [Thread-1  ]: Began executing node model.mimic.urine_output
17:07:59.760677 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.urine_output"
17:07:59.761096 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:07:59.761202 [debug] [Thread-1  ]: On model.mimic.urine_output: BEGIN
17:07:59.761294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:07:59.767222 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:07:59.767465 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:07:59.767566 [debug] [Thread-1  ]: On model.mimic.urine_output: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output"} */


  create  table "postgres"."public"."urine_output__dbt_tmp"
  as (
    -- First we drop the table if it exists
select oe.icustay_id, oe.charttime
, SUM(
    -- we consider input of GU irrigant as a negative volume
    case when oe.itemid = 227488 then -1*value
    else value end
  ) as value
from outputevents oe
where oe.itemid in
(
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in MetaVision
  226559, -- "Foley"
  226560, -- "Void"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- R Ureteral Stent
  226558, -- L Ureteral Stent
  227488, -- GU Irrigant Volume In
  227489  -- GU Irrigant/Urine Volume Out
)
and oe.value < 5000 -- sanity check on urine value
and oe.icustay_id is not null
group by icustay_id, charttime
  );
17:08:02.557870 [debug] [Thread-1  ]: SQL status: SELECT 3361794 in 2.79 seconds
17:08:02.562098 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:08:02.562300 [debug] [Thread-1  ]: On model.mimic.urine_output: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output"} */
alter table "postgres"."public"."urine_output" rename to "urine_output__dbt_backup"
17:08:02.563231 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:02.567278 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:08:02.567529 [debug] [Thread-1  ]: On model.mimic.urine_output: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output"} */
alter table "postgres"."public"."urine_output__dbt_tmp" rename to "urine_output"
17:08:02.568260 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:02.571614 [debug] [Thread-1  ]: On model.mimic.urine_output: COMMIT
17:08:02.571816 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:08:02.572020 [debug] [Thread-1  ]: On model.mimic.urine_output: COMMIT
17:08:02.597878 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
17:08:02.600283 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output"
17:08:02.600583 [debug] [Thread-1  ]: On model.mimic.urine_output: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output"} */
drop table if exists "postgres"."public"."urine_output__dbt_backup" cascade
17:08:02.604780 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:02.607722 [debug] [Thread-1  ]: finished collecting timing info
17:08:02.607967 [debug] [Thread-1  ]: On model.mimic.urine_output: Close
17:08:02.608978 [info ] [Thread-1  ]: 71 of 107 OK created table model public.urine_output ........................... [[32mSELECT 3361794[0m in 2.87s]
17:08:02.609774 [debug] [Thread-1  ]: Finished running node model.mimic.urine_output
17:08:02.610155 [debug] [Thread-1  ]: Began running node model.mimic.urine_output_first_day
17:08:02.610790 [info ] [Thread-1  ]: 72 of 107 START table model public.urine_output_first_day ...................... [RUN]
17:08:02.611742 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.urine_output_first_day"
17:08:02.612206 [debug] [Thread-1  ]: Began compiling node model.mimic.urine_output_first_day
17:08:02.612552 [debug] [Thread-1  ]: Compiling model.mimic.urine_output_first_day
17:08:02.614075 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.urine_output_first_day"
17:08:02.614864 [debug] [Thread-1  ]: finished collecting timing info
17:08:02.615349 [debug] [Thread-1  ]: Began executing node model.mimic.urine_output_first_day
17:08:02.629203 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.urine_output_first_day"
17:08:02.629588 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:02.629693 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: BEGIN
17:08:02.629789 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:02.635097 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:02.635435 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:02.635609 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */


  create  table "postgres"."public"."urine_output_first_day__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Purpose: Create a view of the urine output for each ICUSTAY_ID over the first 24 hours.
-- ------------------------------------------------------------------

select
  -- patient identifiers
  ie.subject_id, ie.hadm_id, ie.icustay_id

  -- volumes associated with urine output ITEMIDs
  , sum(
      -- we consider input of GU irrigant as a negative volume
      case
        when oe.itemid = 227488 and oe.value > 0 then -1*oe.value
        else oe.value
    end) as urineoutput
FROM icustays ie
-- Join to the outputevents table to get urine output
left join outputevents oe
-- join on all patient identifiers
on ie.subject_id = oe.subject_id and ie.hadm_id = oe.hadm_id and ie.icustay_id = oe.icustay_id
-- and ensure the data occurs during the first day
and oe.charttime between ie.intime and (DATETIME_ADD(ie.intime, INTERVAL '1' DAY)) -- first ICU day
where itemid in
(
-- these are the most frequently occurring urine output observations in CareVue
40055, -- "Urine Out Foley"
43175, -- "Urine ."
40069, -- "Urine Out Void"
40094, -- "Urine Out Condom Cath"
40715, -- "Urine Out Suprapubic"
40473, -- "Urine Out IleoConduit"
40085, -- "Urine Out Incontinent"
40057, -- "Urine Out Rt Nephrostomy"
40056, -- "Urine Out Lt Nephrostomy"
40405, -- "Urine Out Other"
40428, -- "Urine Out Straight Cath"
40086,--	Urine Out Incontinent
40096, -- "Urine Out Ureteral Stent #1"
40651, -- "Urine Out Ureteral Stent #2"

-- these are the most frequently occurring urine output observations in MetaVision
226559, -- "Foley"
226560, -- "Void"
226561, -- "Condom Cath"
226584, -- "Ileoconduit"
226563, -- "Suprapubic"
226564, -- "R Nephrostomy"
226565, -- "L Nephrostomy"
226567, --	Straight Cath
226557, -- R Ureteral Stent
226558, -- L Ureteral Stent
227488, -- GU Irrigant Volume In
227489  -- GU Irrigant/Urine Volume Out
)
group by ie.subject_id, ie.hadm_id, ie.icustay_id
order by ie.subject_id, ie.hadm_id, ie.icustay_id
  );
17:08:05.784998 [debug] [Thread-1  ]: SQL status: SELECT 53359 in 3.15 seconds
17:08:05.789384 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:05.789591 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
alter table "postgres"."public"."urine_output_first_day" rename to "urine_output_first_day__dbt_backup"
17:08:05.790365 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:05.794306 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:05.794674 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
alter table "postgres"."public"."urine_output_first_day__dbt_tmp" rename to "urine_output_first_day"
17:08:05.795426 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:05.798586 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: COMMIT
17:08:05.798828 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:05.799023 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: COMMIT
17:08:05.805217 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:05.807510 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:08:05.807713 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
drop table if exists "postgres"."public"."urine_output_first_day__dbt_backup" cascade
17:08:05.809507 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:05.812535 [debug] [Thread-1  ]: finished collecting timing info
17:08:05.812763 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: Close
17:08:05.813860 [info ] [Thread-1  ]: 72 of 107 OK created table model public.urine_output_first_day ................. [[32mSELECT 53359[0m in 3.20s]
17:08:05.814784 [debug] [Thread-1  ]: Finished running node model.mimic.urine_output_first_day
17:08:05.815242 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_dose
17:08:05.816119 [info ] [Thread-1  ]: 73 of 107 START table model public.vasopressin_dose ............................ [RUN]
17:08:05.817026 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_dose"
17:08:05.817477 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_dose
17:08:05.817772 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_dose
17:08:05.819481 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_dose"
17:08:05.820422 [debug] [Thread-1  ]: finished collecting timing info
17:08:05.820800 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_dose
17:08:05.833977 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_dose"
17:08:05.834384 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:05.834994 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: BEGIN
17:08:05.835203 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:05.840813 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:05.841149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:05.841369 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */


  create  table "postgres"."public"."vasopressin_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of vasopressin administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    -- , CASE WHEN valueuom = 'units/min' THEN rate*60.0 ELSE rate END as vaso_rate
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:08:07.631969 [debug] [Thread-1  ]: SQL status: SELECT 10537 in 1.79 seconds
17:08:07.636064 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:07.636269 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose" rename to "vasopressin_dose__dbt_backup"
17:08:07.637086 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:07.642832 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:07.643063 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose__dbt_tmp" rename to "vasopressin_dose"
17:08:07.643982 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:07.647396 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:08:07.647608 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:07.647833 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:08:07.649838 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:07.652134 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:08:07.652369 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
drop table if exists "postgres"."public"."vasopressin_dose__dbt_backup" cascade
17:08:07.654368 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:07.657309 [debug] [Thread-1  ]: finished collecting timing info
17:08:07.657606 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: Close
17:08:07.658713 [info ] [Thread-1  ]: 73 of 107 OK created table model public.vasopressin_dose ....................... [[32mSELECT 10537[0m in 1.84s]
17:08:07.659499 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_dose
17:08:07.659952 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_durations
17:08:07.660802 [info ] [Thread-1  ]: 74 of 107 START table model public.vasopressin_durations ....................... [RUN]
17:08:07.661740 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_durations"
17:08:07.662151 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_durations
17:08:07.662315 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_durations
17:08:07.664166 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_durations"
17:08:07.664898 [debug] [Thread-1  ]: finished collecting timing info
17:08:07.665190 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_durations
17:08:07.674074 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_durations"
17:08:07.674850 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:07.675074 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: BEGIN
17:08:07.675262 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:07.683368 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:07.683847 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:07.684267 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */


  create  table "postgres"."public"."vasopressin_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressin administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:08:09.496295 [debug] [Thread-1  ]: SQL status: SELECT 4190 in 1.81 seconds
17:08:09.503551 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:09.503785 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations" rename to "vasopressin_durations__dbt_backup"
17:08:09.505084 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:09.509133 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:09.509325 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations__dbt_tmp" rename to "vasopressin_durations"
17:08:09.510191 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:09.513279 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:08:09.513476 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:09.513819 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:08:09.515669 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:09.517656 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:08:09.517857 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
drop table if exists "postgres"."public"."vasopressin_durations__dbt_backup" cascade
17:08:09.520214 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:09.523571 [debug] [Thread-1  ]: finished collecting timing info
17:08:09.523811 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: Close
17:08:09.524803 [info ] [Thread-1  ]: 74 of 107 OK created table model public.vasopressin_durations .................. [[32mSELECT 4190[0m in 1.86s]
17:08:09.525499 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_durations
17:08:09.525945 [debug] [Thread-1  ]: Began running node model.mimic.vasopressor_durations
17:08:09.526633 [info ] [Thread-1  ]: 75 of 107 START table model public.vasopressor_durations ....................... [RUN]
17:08:09.527516 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressor_durations"
17:08:09.527989 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressor_durations
17:08:09.528332 [debug] [Thread-1  ]: Compiling model.mimic.vasopressor_durations
17:08:09.529628 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressor_durations"
17:08:09.530341 [debug] [Thread-1  ]: finished collecting timing info
17:08:09.530828 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressor_durations
17:08:09.544173 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressor_durations"
17:08:09.545010 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:09.545314 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: BEGIN
17:08:09.545426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:09.551587 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:09.551844 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:09.551965 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */


  create  table "postgres"."public"."vasopressor_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressor administration
-- It groups together any administration of the below list of drugs:
--  norepinephrine - 30047,30120,221906
--  epinephrine - 30044,30119,30309,221289
--  phenylephrine - 30127,30128,221749
--  vasopressin - 30051,222315 (42273, 42802 also for 2 patients)
--  dopamine - 30043,30307,221662
--  dobutamine - 30042,30306,221653
--  milrinone - 30125,221986

-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table
-- by grouping using ICUSTAY_ID

-- select only the ITEMIDs from the inputevents_cv table related to vasopressors
with io_cv as
(
  select
    icustay_id, charttime, itemid, stopped
    -- ITEMIDs (42273, 42802) accidentally store rate in amount column
    , case
        when itemid in (42273, 42802)
          then amount
        else rate
      end as rate
    , case
        when itemid in (42273, 42802)
          then rate
        else amount
      end as amount
  FROM inputevents_cv
  where itemid in
  (
    30047,30120,30044,30119,30309,30127
  , 30128,30051,30043,30307,30042,30306,30125
  , 42273, 42802
  )
)
-- select only the ITEMIDs from the inputevents_mv table related to vasopressors
, io_mv as
(
  select
    icustay_id, linkorderid, starttime, endtime
  FROM inputevents_mv io
  -- Subselect the vasopressor ITEMIDs
  where itemid in
  (
  221906,221289,221749,222315,221662,221653,221986
  )
  and statusdescription != 'Rewritten' -- only valid orders
)
, vasocv1 as
(
  select
    icustay_id, charttime, itemid
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , 1 as vaso

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when rate is not null then 1 else 0 end) as vaso_null
    , max(rate) as vaso_rate
    , max(amount) as vaso_amount

  from io_cv
  group by icustay_id, charttime, itemid
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id, itemid order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, itemid, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    , itemid
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, itemid, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  , itemid
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, itemid, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)
-- we do not group by ITEMID in below query
-- this is because we want to collapse all vasopressors together
, vasocv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasocv s1
INNER JOIN vasocv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasocv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasocv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
-- now we extract the associated data for metavision patients
-- do not need to group by itemid because we group by linkorderid
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  from io_mv
  group by icustay_id, linkorderid
)
, vasomv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasomv s1
INNER JOIN vasomv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasomv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasomv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv_grp

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv_grp

order by icustay_id, vasonum
  );
17:08:18.294816 [debug] [Thread-1  ]: SQL status: SELECT 38832 in 8.74 seconds
17:08:18.300783 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:18.301023 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations" rename to "vasopressor_durations__dbt_backup"
17:08:18.301988 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.309166 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:18.309434 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations__dbt_tmp" rename to "vasopressor_durations"
17:08:18.310143 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.313647 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:08:18.313849 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:18.313943 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:08:18.314949 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:18.316797 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:08:18.316972 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
drop table if exists "postgres"."public"."vasopressor_durations__dbt_backup" cascade
17:08:18.319398 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:18.324099 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.324347 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: Close
17:08:18.325296 [info ] [Thread-1  ]: 75 of 107 OK created table model public.vasopressor_durations .................. [[32mSELECT 38832[0m in 8.80s]
17:08:18.326052 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressor_durations
17:08:18.326388 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_classification
17:08:18.327225 [info ] [Thread-1  ]: 76 of 107 START table model public.ventilation_classification .................. [RUN]
17:08:18.327986 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_classification"
17:08:18.328275 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_classification
17:08:18.328721 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_classification
17:08:18.330272 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_classification"
17:08:18.331217 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.331790 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_classification
17:08:18.344574 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_classification"
17:08:18.345299 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.345478 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: BEGIN
17:08:18.345616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:18.351407 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:18.351679 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.351792 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */


  create  table "postgres"."public"."ventilation_classification__dbt_tmp"
  as (
    -- Identify The presence of a mechanical ventilation using settings
select
  icustay_id, charttime
  -- case statement determining whether it is an instance of mech vent
  , max(
    case
      when itemid is null or value is null then 0 -- can't have null values
      when itemid = 720 and value != 'Other/Remarks' THEN 1  -- VentTypeRecorded
      when itemid = 223848 and value != 'Other' THEN 1
      when itemid = 223849 then 1 -- ventilator mode
      when itemid = 467 and value = 'Ventilator' THEN 1 -- O2 delivery device == ventilator
      when itemid in
        (
        445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
        , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
        , 218,436,535,444,459,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean/Neg insp force ("RespPressure")
        , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
        , 543 -- PlateauPressure
        , 5865,5866,224707,224709,224705,224706 -- APRV pressure
        , 60,437,505,506,686,220339,224700 -- PEEP
        , 3459 -- high pressure relief
        , 501,502,503,224702 -- PCV
        , 223,667,668,669,670,671,672 -- TCPCV
        , 224701 -- PSVlevel
        )
        THEN 1
      else 0
    end
    ) as MechVent
    , max(
      case
        -- initiation of oxygen therapy indicates the ventilation has ended
        when itemid = 226732 and value in
        (
          'Nasal cannula', -- 153714 observations
          'Face tent', -- 24601 observations
          'Aerosol-cool', -- 24560 observations
          'Trach mask ', -- 16435 observations
          'High flow neb', -- 10785 observations
          'Non-rebreather', -- 5182 observations
          'Venti mask ', -- 1947 observations
          'Medium conc mask ', -- 1888 observations
          'T-piece', -- 1135 observations
          'High flow nasal cannula', -- 925 observations
          'Ultrasonic neb', -- 9 observations
          'Vapomist' -- 3 observations
        ) then 1
        when itemid = 467 and value in
        (
          'Cannula', -- 278252 observations
          'Nasal Cannula', -- 248299 observations
          -- 'None', -- 95498 observations
          'Face Tent', -- 35766 observations
          'Aerosol-Cool', -- 33919 observations
          'Trach Mask', -- 32655 observations
          'Hi Flow Neb', -- 14070 observations
          'Non-Rebreather', -- 10856 observations
          'Venti Mask', -- 4279 observations
          'Medium Conc Mask', -- 2114 observations
          'Vapotherm', -- 1655 observations
          'T-Piece', -- 779 observations
          'Hood', -- 670 observations
          'Hut', -- 150 observations
          'TranstrachealCat', -- 78 observations
          'Heated Neb', -- 37 observations
          'Ultrasonic Neb' -- 2 observations
        ) then 1
      else 0
      end
    ) as OxygenTherapy
    , max(
      case when itemid is null or value is null then 0
        -- extubated indicates ventilation event has ended
        when itemid = 640 and value = 'Extubated' then 1
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as Extubated
    , max(
      case when itemid is null or value is null then 0
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as SelfExtubated
from chartevents ce
where ce.value is not null
-- exclude rows marked as error
and (ce.error != 1 or ce.error IS NULL)
and itemid in
(
    -- the below are settings used to indicate ventilation
      720, 223849 -- vent mode
    , 223848 -- vent type
    , 445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
    , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
    , 218,436,535,444,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean ("RespPressure")
    , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
    , 543 -- PlateauPressure
    , 5865,5866,224707,224709,224705,224706 -- APRV pressure
    , 60,437,505,506,686,220339,224700 -- PEEP
    , 3459 -- high pressure relief
    , 501,502,503,224702 -- PCV
    , 223,667,668,669,670,671,672 -- TCPCV
    , 224701 -- PSVlevel

    -- the below are settings used to indicate extubation
    , 640 -- extubated

    -- the below indicate oxygen/NIV, i.e. the end of a mechanical vent event
    , 468 -- O2 Delivery Device#2
    , 469 -- O2 Delivery Mode
    , 470 -- O2 Flow (lpm)
    , 471 -- O2 Flow (lpm) #2
    , 227287 -- O2 Flow (additional cannula)
    , 226732 -- O2 Delivery Device(s)
    , 223834 -- O2 Flow

    -- used in both oxygen + vent calculation
    , 467 -- O2 Delivery Device
)
group by icustay_id, charttime
UNION DISTINCT
-- add in the extubation flags from procedureevents_mv
-- note that we only need the start time for the extubation
-- (extubation is always charted as ending 1 minute after it started)
select
  icustay_id, starttime as charttime
  , 0 as MechVent
  , 0 as OxygenTherapy
  , 1 as Extubated
  , case when itemid = 225468 then 1 else 0 end as SelfExtubated
from procedureevents_mv
where itemid in
(
  227194 -- "Extubation"
, 225468 -- "Unplanned Extubation (patient-initiated)"
, 225477 -- "Unplanned Extubation (non-patient initiated)"
)
  );
17:08:18.411731 [debug] [Thread-1  ]: SQL status: SELECT 8642 in 0.06 seconds
17:08:18.417463 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.417788 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification" rename to "ventilation_classification__dbt_backup"
17:08:18.418415 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.427291 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.427505 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification__dbt_tmp" rename to "ventilation_classification"
17:08:18.428117 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.431190 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:08:18.431401 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.431576 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:08:18.433800 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:18.436079 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:08:18.436399 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
drop table if exists "postgres"."public"."ventilation_classification__dbt_backup" cascade
17:08:18.439247 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:18.443491 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.443763 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: Close
17:08:18.444658 [info ] [Thread-1  ]: 76 of 107 OK created table model public.ventilation_classification ............. [[32mSELECT 8642[0m in 0.12s]
17:08:18.445189 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_classification
17:08:18.445531 [debug] [Thread-1  ]: Began running node model.mimic.vitals_first_day
17:08:18.446103 [info ] [Thread-1  ]: 77 of 107 START table model public.vitals_first_day ............................ [RUN]
17:08:18.446897 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vitals_first_day"
17:08:18.447230 [debug] [Thread-1  ]: Began compiling node model.mimic.vitals_first_day
17:08:18.447440 [debug] [Thread-1  ]: Compiling model.mimic.vitals_first_day
17:08:18.448680 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vitals_first_day"
17:08:18.449186 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.449459 [debug] [Thread-1  ]: Began executing node model.mimic.vitals_first_day
17:08:18.461207 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vitals_first_day"
17:08:18.461807 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.461920 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: BEGIN
17:08:18.462014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:18.467085 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:18.467358 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.467528 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */


  create  table "postgres"."public"."vitals_first_day__dbt_tmp"
  as (
    -- This query pivots the vital signs for the first 24 hours of a patient's stay
-- Vital signs include heart rate, blood pressure, respiration rate, and temperature

SELECT pvt.subject_id, pvt.hadm_id, pvt.icustay_id

-- Easier names
, min(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_min
, max(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_max
, avg(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_mean
, min(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_min
, max(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_max
, avg(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_mean
, min(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_min
, max(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_max
, avg(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_mean
, min(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_min
, max(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_max
, avg(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_mean
, min(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_min
, max(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_max
, avg(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_mean
, min(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_min
, max(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_max
, avg(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_mean
, min(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_min
, max(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_max
, avg(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_mean
, min(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_min
, max(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_max
, avg(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_mean

FROM  (
  select ie.subject_id, ie.hadm_id, ie.icustay_id
  , case
    when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then 1 -- HeartRate
    when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then 2 -- SysBP
    when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then 3 -- DiasBP
    when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then 4 -- MeanBP
    when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then 5 -- RespRate
    when itemid in (223761,678) and valuenum > 70 and valuenum < 120  then 6 -- TempF, converted to degC in valuenum call
    when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then 6 -- TempC
    when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then 7 -- SpO2
    when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then 8 -- Glucose

    else null end as vitalid
      -- convert F to C
  , case when itemid in (223761,678) then (valuenum-32)/1.8 else valuenum end as valuenum

  from icustays ie
  left join chartevents ce
  on ie.icustay_id = ce.icustay_id
  and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1 DAY')
  and DATETIME_DIFF(ce.charttime, ie.intime, 'SECOND') > 0
  and DATETIME_DIFF(ce.charttime, ie.intime, 'HOUR') <= 24
  -- exclude rows marked as error
  and (ce.error IS NULL or ce.error = 0)
  where ce.itemid in
  (
  -- HEART RATE
  211, --"Heart Rate"
  220045, --"Heart Rate"

  -- Systolic/diastolic

  51, --	Arterial BP [Systolic]
  442, --	Manual BP [Systolic]
  455, --	NBP [Systolic]
  6701, --	Arterial BP #2 [Systolic]
  220179, --	Non Invasive Blood Pressure systolic
  220050, --	Arterial Blood Pressure systolic

  8368, --	Arterial BP [Diastolic]
  8440, --	Manual BP [Diastolic]
  8441, --	NBP [Diastolic]
  8555, --	Arterial BP #2 [Diastolic]
  220180, --	Non Invasive Blood Pressure diastolic
  220051, --	Arterial Blood Pressure diastolic


  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312, --"ART BP mean"

  -- RESPIRATORY RATE
  618,--	Respiratory Rate
  615,--	Resp Rate (Total)
  220210,--	Respiratory Rate
  224690, --	Respiratory Rate (Total)


  -- SPO2, peripheral
  646, 220277,

  -- GLUCOSE, both lab and fingerstick
  807,--	Fingerstick Glucose
  811,--	Glucose (70-105)
  1529,--	Glucose
  3745,--	BloodGlucose
  3744,--	Blood Glucose
  225664,--	Glucose finger stick
  220621,--	Glucose (serum)
  226537,--	Glucose (whole blood)

  -- TEMPERATURE
  223762, -- "Temperature Celsius"
  676,	-- "Temperature C"
  223761, -- "Temperature Fahrenheit"
  678 --	"Temperature F"

  )
) pvt
group by pvt.subject_id, pvt.hadm_id, pvt.icustay_id
order by pvt.subject_id, pvt.hadm_id, pvt.icustay_id
  );
17:08:18.516197 [debug] [Thread-1  ]: SQL status: SELECT 13 in 0.05 seconds
17:08:18.522584 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.522826 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
alter table "postgres"."public"."vitals_first_day" rename to "vitals_first_day__dbt_backup"
17:08:18.523541 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.527194 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.527405 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
alter table "postgres"."public"."vitals_first_day__dbt_tmp" rename to "vitals_first_day"
17:08:18.528074 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.531087 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: COMMIT
17:08:18.531313 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.531505 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: COMMIT
17:08:18.532668 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:18.534773 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:08:18.535026 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
drop table if exists "postgres"."public"."vitals_first_day__dbt_backup" cascade
17:08:18.536823 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:18.539741 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.539975 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: Close
17:08:18.540819 [info ] [Thread-1  ]: 77 of 107 OK created table model public.vitals_first_day ....................... [[32mSELECT 13[0m in 0.09s]
17:08:18.541386 [debug] [Thread-1  ]: Finished running node model.mimic.vitals_first_day
17:08:18.541725 [debug] [Thread-1  ]: Began running node model.mimic.wbc
17:08:18.542373 [info ] [Thread-1  ]: 78 of 107 START table model public.wbc ......................................... [RUN]
17:08:18.543558 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.wbc"
17:08:18.543916 [debug] [Thread-1  ]: Began compiling node model.mimic.wbc
17:08:18.544145 [debug] [Thread-1  ]: Compiling model.mimic.wbc
17:08:18.545347 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.wbc"
17:08:18.545927 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.546153 [debug] [Thread-1  ]: Began executing node model.mimic.wbc
17:08:18.559014 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.wbc"
17:08:18.559740 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.559965 [debug] [Thread-1  ]: On model.mimic.wbc: BEGIN
17:08:18.560273 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:18.565945 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:18.566188 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.566302 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */


  create  table "postgres"."public"."wbc__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the white blood cell count for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, wbc as
(
  SELECT width_bucket(valuenum, 0, 100, 1001) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid in (51300, 51301)
  AND valuenum IS NOT NULL
)
SELECT round((cast(bucket as numeric)/10),2) as white_blood_cell_count, count(*)
FROM wbc
GROUP BY bucket
ORDER BY bucket
  );
17:08:18.714507 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:08:18.721734 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.722158 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
alter table "postgres"."public"."wbc" rename to "wbc__dbt_backup"
17:08:18.723442 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.727195 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.727418 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
alter table "postgres"."public"."wbc__dbt_tmp" rename to "wbc"
17:08:18.728238 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:18.731411 [debug] [Thread-1  ]: On model.mimic.wbc: COMMIT
17:08:18.731625 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.731912 [debug] [Thread-1  ]: On model.mimic.wbc: COMMIT
17:08:18.733116 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:18.735522 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:08:18.735757 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
drop table if exists "postgres"."public"."wbc__dbt_backup" cascade
17:08:18.738270 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:18.741240 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.741466 [debug] [Thread-1  ]: On model.mimic.wbc: Close
17:08:18.742422 [info ] [Thread-1  ]: 78 of 107 OK created table model public.wbc .................................... [[32mSELECT 0[0m in 0.20s]
17:08:18.743237 [debug] [Thread-1  ]: Finished running node model.mimic.wbc
17:08:18.743726 [debug] [Thread-1  ]: Began running node model.mimic.suspicion_of_infection
17:08:18.744454 [info ] [Thread-1  ]: 79 of 107 START table model public.suspicion_of_infection ...................... [RUN]
17:08:18.745271 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.suspicion_of_infection"
17:08:18.745532 [debug] [Thread-1  ]: Began compiling node model.mimic.suspicion_of_infection
17:08:18.745885 [debug] [Thread-1  ]: Compiling model.mimic.suspicion_of_infection
17:08:18.748917 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.suspicion_of_infection"
17:08:18.749336 [debug] [Thread-1  ]: finished collecting timing info
17:08:18.749956 [debug] [Thread-1  ]: Began executing node model.mimic.suspicion_of_infection
17:08:18.759875 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.suspicion_of_infection"
17:08:18.760651 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:18.760859 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: BEGIN
17:08:18.761015 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:18.766468 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:18.766964 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:18.767205 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */


  create  table "postgres"."public"."suspicion_of_infection__dbt_tmp"
  as (
     

-- defines suspicion of infection using prescriptions + microbiologyevents
with abx as
(
  select pr.hadm_id
  , pr.drug as antibiotic_name
  , pr.startdate as antibiotic_time
  , pr.enddate as antibiotic_endtime
  from prescriptions pr
  -- inner join to subselect to only antibiotic prescriptions
  inner join "postgres"."public"."abx_prescriptions_list" ab
      on pr.drug = ab.drug
)
-- get cultures for each icustay
-- note this duplicates prescriptions
-- each ICU stay in the same hospitalization will get a copy of all prescriptions for that hospitalization
, ab_tbl as
(
  select
        ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime, ie.outtime
      , abx.antibiotic_name
      , abx.antibiotic_time
      , abx.antibiotic_endtime
  from icustays ie
  left join abx
      on ie.hadm_id = abx.hadm_id
)
, me as
(
  select hadm_id
    , chartdate, charttime
    , spec_type_desc
    , max(case when org_name is not null and org_name != '' then 1 else 0 end) as PositiveCulture
  from microbiologyevents
  group by hadm_id, chartdate, charttime, spec_type_desc
)
, ab_fnl as
(
  select
      ab_tbl.icustay_id, ab_tbl.intime, ab_tbl.outtime
    , ab_tbl.antibiotic_name
    , ab_tbl.antibiotic_time
    , coalesce(me72.charttime,me72.chartdate) as last72_charttime
    , coalesce(me24.charttime,me24.chartdate) as next24_charttime
    , me72.positiveculture as last72_positiveculture
    , me72.spec_type_desc as last72_specimen
    , me24.positiveculture as next24_positiveculture
    , me24.spec_type_desc as next24_specimen
  from ab_tbl
  -- blood culture in last 72 hours
  left join me me72
    on ab_tbl.hadm_id = me72.hadm_id
    and ab_tbl.antibiotic_time is not null
    and
    (
      -- if charttime is available, use it
      (
          ab_tbl.antibiotic_time >= me72.charttime
      and ab_tbl.antibiotic_time <= datetime_add(me72.charttime, INTERVAL '72 HOUR')
      )
      OR
      (
      -- if charttime is not available, use chartdate
          me72.charttime is null
      and ab_tbl.antibiotic_time >= me72.chartdate
      and ab_tbl.antibiotic_time <= datetime_add(me72.chartdate, INTERVAL '96 HOUR')
      )
    )
  -- blood culture in subsequent 24 hours
  left join me me24
    on ab_tbl.hadm_id = me24.hadm_id
    and ab_tbl.antibiotic_time is not null
    and
    (
      -- if charttime is available, use it
      (
          ab_tbl.antibiotic_time <= me24.charttime
      and ab_tbl.antibiotic_time >= datetime_sub(me24.charttime, INTERVAL '24 HOUR')
      )
      OR
      (
      -- if charttime is not available, use chartdate
          me24.charttime is null
      and ab_tbl.antibiotic_time <= me24.chartdate
      and ab_tbl.antibiotic_time >= datetime_sub(me24.chartdate, INTERVAL '24 HOUR')
      )
    )
)
, ab_laststg as
(
select
  icustay_id
  , antibiotic_name
  , antibiotic_time
  , last72_charttime
  , next24_charttime

  -- time of suspected infection: either the culture time (if before antibiotic), or the antibiotic time
  , case
      when coalesce(last72_charttime,next24_charttime) is null
        then 0
      else 1 end as suspected_infection

  , coalesce(last72_charttime,next24_charttime) as suspected_infection_time

  -- the specimen that was cultured
  , case
      when last72_charttime is not null
        then last72_specimen
      when next24_charttime is not null
        then next24_specimen
    else null
  end as specimen

  -- whether the cultured specimen ended up being positive or not
  , case
      when last72_charttime is not null
        then last72_positiveculture
      when next24_charttime is not null
        then next24_positiveculture
    else null
  end as positiveculture
from ab_fnl
)
select
  icustay_id
  , antibiotic_name
  , antibiotic_time
  , last72_charttime
  , next24_charttime
  , suspected_infection_time
  -- -- the below two fields are used to extract data - modifying them facilitates sensitivity analyses
  -- , suspected_infection_time - interval '48' hour as si_starttime
  -- , suspected_infection_time + interval '24' hour as si_endtime
  , specimen, positiveculture
from ab_laststg
order by icustay_id, antibiotic_time
  );
17:08:28.839847 [debug] [Thread-1  ]: SQL status: SELECT 1374912 in 10.07 seconds
17:08:28.844933 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:28.845130 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
alter table "postgres"."public"."suspicion_of_infection" rename to "suspicion_of_infection__dbt_backup"
17:08:28.845991 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:28.852731 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:28.852935 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
alter table "postgres"."public"."suspicion_of_infection__dbt_tmp" rename to "suspicion_of_infection"
17:08:28.853763 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:28.857347 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: COMMIT
17:08:28.857551 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:28.857868 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: COMMIT
17:08:28.864138 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:28.866265 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:08:28.866454 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
drop table if exists "postgres"."public"."suspicion_of_infection__dbt_backup" cascade
17:08:28.870134 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:28.873062 [debug] [Thread-1  ]: finished collecting timing info
17:08:28.873296 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: Close
17:08:28.874336 [info ] [Thread-1  ]: 79 of 107 OK created table model public.suspicion_of_infection ................. [[32mSELECT 1374912[0m in 10.13s]
17:08:28.875231 [debug] [Thread-1  ]: Finished running node model.mimic.suspicion_of_infection
17:08:28.875674 [debug] [Thread-1  ]: Began running node model.mimic.blood_gas_first_day_arterial
17:08:28.876295 [info ] [Thread-1  ]: 80 of 107 START table model public.blood_gas_first_day_arterial ................ [RUN]
17:08:28.877103 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.877453 [debug] [Thread-1  ]: Began compiling node model.mimic.blood_gas_first_day_arterial
17:08:28.877841 [debug] [Thread-1  ]: Compiling model.mimic.blood_gas_first_day_arterial
17:08:28.881718 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.blood_gas_first_day_arterial"
17:08:28.882135 [debug] [Thread-1  ]: finished collecting timing info
17:08:28.882268 [debug] [Thread-1  ]: Began executing node model.mimic.blood_gas_first_day_arterial
17:08:28.894752 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.blood_gas_first_day_arterial"
17:08:28.895874 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.896251 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: BEGIN
17:08:28.896393 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:28.902310 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:28.902672 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.902830 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */


  create  table "postgres"."public"."blood_gas_first_day_arterial__dbt_tmp"
  as (
    with stg_spo2 as
(
  select subject_id, hadm_id, icustay_id, charttime
    -- max here is just used to group SpO2 by charttime
    , max(case when valuenum <= 0 or valuenum > 100 then null else valuenum end) as SpO2
  FROM chartevents
  -- o2 sat
  where ITEMID in
  (
    646 -- SpO2
  , 220277 -- O2 saturation pulseoxymetry
  )
  group by subject_id, hadm_id, icustay_id, charttime
)
, stg_fio2 as
(
  select subject_id, hadm_id, icustay_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , max(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
  group by subject_id, hadm_id, icustay_id, charttime
)
, stg2 as
(
select bg.*
  , ROW_NUMBER() OVER (partition by bg.icustay_id, bg.charttime order by s1.charttime DESC) as lastRowSpO2
  , s1.spo2
from "postgres"."public"."blood_gas_first_day" bg
left join stg_spo2 s1
  -- same patient
  on  bg.icustay_id = s1.icustay_id
  -- spo2 occurred at most 2 hours before this blood gas
  and s1.charttime >= DATETIME_SUB(bg.charttime, INTERVAL '2' HOUR)
  and s1.charttime <= bg.charttime
where bg.po2 is not null
)
, stg3 as
(
select bg.*
  , ROW_NUMBER() OVER (partition by bg.icustay_id, bg.charttime order by s2.charttime DESC) as lastRowFiO2
  , s2.fio2_chartevents

  -- create our specimen prediction
  ,  1/(1+exp(-(-0.02544
  +    0.04598 * po2
  + coalesce(-0.15356 * spo2             , -0.15356 *   97.49420 +    0.13429)
  + coalesce( 0.00621 * fio2_chartevents ,  0.00621 *   51.49550 +   -0.24958)
  + coalesce( 0.10559 * hemoglobin       ,  0.10559 *   10.32307 +    0.05954)
  + coalesce( 0.13251 * so2              ,  0.13251 *   93.66539 +   -0.23172)
  + coalesce(-0.01511 * pco2             , -0.01511 *   42.08866 +   -0.01630)
  + coalesce( 0.01480 * fio2             ,  0.01480 *   63.97836 +   -0.31142)
  + coalesce(-0.00200 * aado2            , -0.00200 *  442.21186 +   -0.01328)
  + coalesce(-0.03220 * bicarbonate      , -0.03220 *   22.96894 +   -0.06535)
  + coalesce( 0.05384 * totalco2         ,  0.05384 *   24.72632 +   -0.01405)
  + coalesce( 0.08202 * lactate          ,  0.08202 *    3.06436 +    0.06038)
  + coalesce( 0.10956 * ph               ,  0.10956 *    7.36233 +   -0.00617)
  + coalesce( 0.00848 * o2flow           ,  0.00848 *    7.59362 +   -0.35803)
  ))) as SPECIMEN_PROB
from stg2 bg
left join stg_fio2 s2
  -- same patient
  on  bg.icustay_id = s2.icustay_id
  -- fio2 occurred at most 4 hours before this blood gas
  and s2.charttime between DATETIME_SUB(bg.charttime, INTERVAL '4' HOUR) and bg.charttime
where bg.lastRowSpO2 = 1 -- only the row with the most recent SpO2 (if no SpO2 found lastRowSpO2 = 1)
)

select subject_id, hadm_id,
icustay_id, charttime
, specimen -- raw data indicating sample type, only present 80% of the time

-- prediction of specimen for missing data
, case
      when SPECIMEN is not null then SPECIMEN
      when SPECIMEN_PROB > 0.75 then 'ART'
    else null end as SPECIMEN_PRED
, specimen_prob
-- oxygen related parameters
, so2, spo2 -- note spo2 is FROM chartevents
, po2, pco2
, fio2_chartevents, fio2
, aado2
-- also calculate AADO2
, case
    when  PO2 is not null
      and pco2 is not null
      and coalesce(fio2, fio2_chartevents) is not null
     -- multiple by 100 because FiO2 is in a % but should be a fraction
      then (coalesce(fio2, fio2_chartevents)/100) * (760 - 47) - (pco2/0.8) - po2
    else null
  end as AADO2_calc
, case
    when PO2 is not null and coalesce(fio2, fio2_chartevents) is not null
     -- multiply by 100 because FiO2 is in a % but should be a fraction
      then 100*PO2/(coalesce(fio2, fio2_chartevents))
    else null
  end as PaO2FiO2
-- acid-base parameters
, ph, baseexcess
, bicarbonate, totalco2

-- blood count parameters
, hematocrit
, hemoglobin
, carboxyhemoglobin
, methemoglobin

-- chemistry
, chloride, calcium
, temperature
, potassium, sodium
, lactate
, glucose

-- ventilation stuff that's sometimes input
, intubated, tidalvolume, ventilationrate, ventilator
, peep, o2flow
, requiredo2

from stg3
where lastRowFiO2 = 1 -- only the most recent FiO2
-- restrict it to *only* arterial samples
and (specimen = 'ART' or specimen_prob > 0.75)
order by icustay_id, charttime
  );
17:08:28.924692 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.02 seconds
17:08:28.932249 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.932544 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
alter table "postgres"."public"."blood_gas_first_day_arterial" rename to "blood_gas_first_day_arterial__dbt_backup"
17:08:28.933363 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:28.937977 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.938170 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
alter table "postgres"."public"."blood_gas_first_day_arterial__dbt_tmp" rename to "blood_gas_first_day_arterial"
17:08:28.938959 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:28.942065 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: COMMIT
17:08:28.942226 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.942321 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: COMMIT
17:08:28.943399 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:28.945627 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:08:28.945865 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
drop table if exists "postgres"."public"."blood_gas_first_day_arterial__dbt_backup" cascade
17:08:28.949262 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:28.952234 [debug] [Thread-1  ]: finished collecting timing info
17:08:28.952464 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: Close
17:08:28.952992 [info ] [Thread-1  ]: 80 of 107 OK created table model public.blood_gas_first_day_arterial ........... [[32mSELECT 0[0m in 0.08s]
17:08:28.953286 [debug] [Thread-1  ]: Finished running node model.mimic.blood_gas_first_day_arterial
17:08:28.953414 [debug] [Thread-1  ]: Began running node model.mimic.height_first_day
17:08:28.953864 [info ] [Thread-1  ]: 81 of 107 START table model public.height_first_day ............................ [RUN]
17:08:28.955207 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.height_first_day"
17:08:28.955600 [debug] [Thread-1  ]: Began compiling node model.mimic.height_first_day
17:08:28.955916 [debug] [Thread-1  ]: Compiling model.mimic.height_first_day
17:08:28.959707 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.height_first_day"
17:08:28.960374 [debug] [Thread-1  ]: finished collecting timing info
17:08:28.960758 [debug] [Thread-1  ]: Began executing node model.mimic.height_first_day
17:08:28.971956 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.height_first_day"
17:08:28.972769 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:28.972977 [debug] [Thread-1  ]: On model.mimic.height_first_day: BEGIN
17:08:28.973077 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:28.978076 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:28.978304 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:28.978415 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */


  create  table "postgres"."public"."height_first_day__dbt_tmp"
  as (
    -- This query extracts heights for adult ICU patients.
-- It uses all information from the patient's first ICU day.
-- This is done for consistency with other queries - it's not necessarily needed.
-- Height is unlikely to change throughout a patient's stay.

-- ** Requires the echodata view, generated by concepts/echo-data.sql

-- staging table to ensure all heights are in centimeters
with ce0 as
(
    SELECT
      c.icustay_id
      , case
        -- convert inches to centimetres
          when itemid in (920, 1394, 4187, 3486)
              then valuenum * 2.54
            else valuenum
        end as Height
    FROM chartevents c
    inner join icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (226730,920, 1394, 4187, 3486,3485,4188) -- height
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
)
, ce as
(
    SELECT
        icustay_id
        -- extract the median height from the chart to add robustness against outliers
        , AVG(height) as Height_chart
    from ce0
    where height > 100
    group by icustay_id
)
-- requires the echo-data.sql query to run
-- this adds heights from the free-text echo notes
, echo as
(
    select
        ec.subject_id
        -- all echo heights are in inches
        , 2.54*AVG(height) as Height_Echo
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ec.subject_id = ie.subject_id
        and ec.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    where height is not null
    and height*2.54 > 100
    group by ec.subject_id
)
select
    ie.icustay_id
    , coalesce(ce.Height_chart, ec.Height_Echo) as height

    -- components
    , ce.height_chart
    , ec.height_echo
FROM icustays ie

-- filter to only adults
inner join patients pat
    on ie.subject_id = pat.subject_id
    and ie.intime > DATETIME_ADD(pat.dob, INTERVAL '1' YEAR)

left join ce
    on ie.icustay_id = ce.icustay_id

left join echo ec
    on ie.subject_id = ec.subject_id
  );
17:08:29.077274 [debug] [Thread-1  ]: SQL status: SELECT 53432 in 0.1 seconds
17:08:29.083451 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:29.083672 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
alter table "postgres"."public"."height_first_day" rename to "height_first_day__dbt_backup"
17:08:29.084426 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.088124 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:29.088315 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
alter table "postgres"."public"."height_first_day__dbt_tmp" rename to "height_first_day"
17:08:29.089076 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.094245 [debug] [Thread-1  ]: On model.mimic.height_first_day: COMMIT
17:08:29.094568 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:29.094824 [debug] [Thread-1  ]: On model.mimic.height_first_day: COMMIT
17:08:29.100088 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:29.101741 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:08:29.101904 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
drop table if exists "postgres"."public"."height_first_day__dbt_backup" cascade
17:08:29.104044 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:29.107464 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.107700 [debug] [Thread-1  ]: On model.mimic.height_first_day: Close
17:08:29.108517 [info ] [Thread-1  ]: 81 of 107 OK created table model public.height_first_day ....................... [[32mSELECT 53432[0m in 0.15s]
17:08:29.109188 [debug] [Thread-1  ]: Finished running node model.mimic.height_first_day
17:08:29.109559 [debug] [Thread-1  ]: Began running node model.mimic.weight_durations
17:08:29.110049 [info ] [Thread-1  ]: 82 of 107 START table model public.weight_durations ............................ [RUN]
17:08:29.110693 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.weight_durations"
17:08:29.111014 [debug] [Thread-1  ]: Began compiling node model.mimic.weight_durations
17:08:29.111246 [debug] [Thread-1  ]: Compiling model.mimic.weight_durations
17:08:29.115321 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.weight_durations"
17:08:29.115826 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.116188 [debug] [Thread-1  ]: Began executing node model.mimic.weight_durations
17:08:29.127739 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.weight_durations"
17:08:29.128255 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.128479 [debug] [Thread-1  ]: On model.mimic.weight_durations: BEGIN
17:08:29.128582 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:29.136503 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:29.136827 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.137034 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */


  create  table "postgres"."public"."weight_durations__dbt_tmp"
  as (
    -- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime

-- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime
WITH wt_neonate AS
( 
    SELECT c.icustay_id, c.charttime
    , MAX(CASE WHEN c.itemid = 3580 THEN c.valuenum END) as wt_kg
    , MAX(CASE WHEN c.itemid = 3581 THEN c.valuenum END) as wt_lb
    , MAX(CASE WHEN c.itemid = 3582 THEN c.valuenum END) as wt_oz
    FROM chartevents c
    WHERE c.itemid in (3580, 3581, 3582)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
    -- wt_oz/wt_lb/wt_kg are only 0 erroneously, so drop these rows
    AND c.valuenum > 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, birth_wt AS
(
    SELECT c.icustay_id, c.charttime
    , MAX(
      CASE
      WHEN c.itemid = 4183 THEN
        -- clean free-text birth weight data
        CASE
          -- ignore value if there are any non-numeric characters
          WHEN REGEXP_CONTAINS(c.value, '[^0-9\\.]') THEN NULL 
          -- convert grams to kd
          WHEN CAST(c.value AS NUMERIC) > 100 THEN CAST(c.value AS NUMERIC)/1000
          -- keep kg as is, filtering bad values (largest baby ever born was conveniently 9.98kg)
          WHEN CAST(c.value AS NUMERIC) < 10 THEN CAST(c.value AS NUMERIC)
          -- ignore other values (those between 10-100) - junk data
        ELSE NULL END
      -- itemid 3723 happily has all numeric data - also doesn't store any grams data
      WHEN c.itemid = 3723 AND c.valuenum < 10 THEN c.valuenum
      ELSE NULL END) as wt_kg
    FROM chartevents c
    WHERE c.itemid in (3723, 4183)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, wt_stg as
(
    SELECT
        c.icustay_id
      , c.charttime
      , case when c.itemid in (762,226512) then 'admit'
          else 'daily' end as weight_type
      -- TODO: eliminate obvious outliers if there is a reasonable weight
      , c.valuenum as weight
    FROM chartevents c
    WHERE c.valuenum IS NOT NULL
      AND c.itemid in
      (
          762,226512 -- Admit Wt
        , 763,224639 -- Daily Weight
      )
      AND c.icustay_id IS NOT NULL
      AND c.valuenum > 0
      -- exclude rows marked as error
      AND COALESCE(c.error, 0) = 0
    UNION ALL
    SELECT
        n.icustay_id
      , n.charttime
      , 'daily' AS weight_type
      , CASE
          WHEN wt_kg IS NOT NULL THEN wt_kg
          WHEN wt_lb IS NOT NULL THEN wt_lb*0.45359237 + wt_oz*0.0283495231
        ELSE NULL END AS weight
    FROM wt_neonate n
    UNION ALL
    SELECT
        b.icustay_id
      , b.charttime
      -- birth weight of neonates is treated as admission weight
      , 'admit' AS weight_type
      , wt_kg as weight
    FROM birth_wt b
)
-- get more weights from echo - completes data for ~2500 patients
-- we only use echo data if there is *no* charted data
-- we impute the median echo weight for their entire ICU stay
, echo as
(
  select
    ie.icustay_id
    , ec.charttime
    , 'echo' AS weight_type
    , 0.453592*ec.weight as weight
  from icustays ie
  inner join "postgres"."public"."echo_data" ec
    on ie.hadm_id = ec.hadm_id
  where ec.weight is not null
  and ie.icustay_id not in (select distinct icustay_id from wt_stg)
)
, wt_stg0 AS
(
  SELECT icustay_id, charttime, weight_type, weight
  FROM wt_stg
  UNION ALL
  SELECT icustay_id, charttime, weight_type, weight
  FROM echo
)
-- assign ascending row number
, wt_stg1 as
(
  select
      icustay_id
    , charttime
    , weight_type
    , weight
    , ROW_NUMBER() OVER (partition by icustay_id, weight_type order by charttime) as rn
  from wt_stg0
  WHERE weight IS NOT NULL
)
-- change charttime to intime for the first admission weight recorded
, wt_stg2 AS
(
  SELECT 
      wt_stg1.icustay_id
    , ie.intime, ie.outtime
    , case when wt_stg1.weight_type = 'admit' and wt_stg1.rn = 1
        then DATETIME_SUB(ie.intime, INTERVAL '2' HOUR)
      else wt_stg1.charttime end as starttime
    , wt_stg1.weight
  from wt_stg1
  INNER JOIN icustays ie
    on ie.icustay_id = wt_stg1.icustay_id
)
, wt_stg3 as
(
  select
    icustay_id
    , intime, outtime
    , starttime
    , coalesce(
        LEAD(starttime) OVER (PARTITION BY icustay_id ORDER BY starttime),
        DATETIME_ADD(GREATEST(outtime, starttime), INTERVAL '2' HOUR)
      ) as endtime
    , weight
  from wt_stg2
)
-- this table is the start/stop times from admit/daily weight in charted data
, wt1 as
(
  select
      icustay_id
    , starttime
    , coalesce(endtime,
      LEAD(starttime) OVER (partition by icustay_id order by starttime),
      -- impute ICU discharge as the end of the final weight measurement
      -- plus a 2 hour "fuzziness" window
      DATETIME_ADD(outtime, INTERVAL '2' HOUR)
    ) as endtime
    , weight
  from wt_stg3
)
-- if the intime for the patient is < the first charted daily weight
-- then we will have a "gap" at the start of their stay
-- to prevent this, we look for these gaps and backfill the first weight
-- this adds (153255-149657)=3598 rows, meaning this fix helps for up to 3598 icustay_id
, wt_fix as
(
  select ie.icustay_id
    -- we add a 2 hour "fuzziness" window
    , DATETIME_SUB(ie.intime, INTERVAL '2' HOUR) as starttime
    , wt.starttime as endtime
    , wt.weight
  from icustays ie
  inner join
  -- the below subquery returns one row for each unique icustay_id
  -- the row contains: the first starttime and the corresponding weight
  (
    SELECT wt1.icustay_id, wt1.starttime, wt1.weight
    , ROW_NUMBER() OVER (PARTITION BY wt1.icustay_id ORDER BY wt1.starttime) as rn
    FROM wt1
  ) wt
    ON  ie.icustay_id = wt.icustay_id
    AND wt.rn = 1
    and ie.intime < wt.starttime
)
-- add the backfill rows to the main weight table
select
    wt1.icustay_id
  , wt1.starttime
  , wt1.endtime
  , wt1.weight
from wt1
UNION ALL
SELECT
    wt_fix.icustay_id
  , wt_fix.starttime
  , wt_fix.endtime
  , wt_fix.weight
from wt_fix
  );
17:08:29.147961 [debug] [Thread-1  ]: SQL status: SELECT 15 in 0.01 seconds
17:08:29.156961 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.157179 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations" rename to "weight_durations__dbt_backup"
17:08:29.157673 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.162047 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.162430 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations__dbt_tmp" rename to "weight_durations"
17:08:29.163940 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.167541 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:08:29.167744 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.167926 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:08:29.168990 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:29.170700 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:08:29.170928 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
drop table if exists "postgres"."public"."weight_durations__dbt_backup" cascade
17:08:29.172629 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:29.175980 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.176226 [debug] [Thread-1  ]: On model.mimic.weight_durations: Close
17:08:29.177211 [info ] [Thread-1  ]: 82 of 107 OK created table model public.weight_durations ....................... [[32mSELECT 15[0m in 0.07s]
17:08:29.177643 [debug] [Thread-1  ]: Finished running node model.mimic.weight_durations
17:08:29.177793 [debug] [Thread-1  ]: Began running node model.mimic.weight_first_day
17:08:29.178324 [info ] [Thread-1  ]: 83 of 107 START table model public.weight_first_day ............................ [RUN]
17:08:29.180303 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.weight_first_day"
17:08:29.180849 [debug] [Thread-1  ]: Began compiling node model.mimic.weight_first_day
17:08:29.181196 [debug] [Thread-1  ]: Compiling model.mimic.weight_first_day
17:08:29.184123 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.weight_first_day"
17:08:29.184878 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.185327 [debug] [Thread-1  ]: Began executing node model.mimic.weight_first_day
17:08:29.196000 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.weight_first_day"
17:08:29.197204 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.197544 [debug] [Thread-1  ]: On model.mimic.weight_first_day: BEGIN
17:08:29.197713 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:29.203264 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:29.203507 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.203687 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */


  create  table "postgres"."public"."weight_first_day__dbt_tmp"
  as (
    -- This query extracts weights for adult ICU patients on their first ICU day.
-- It does *not* use any information after the first ICU day, as weight is
-- sometimes used to monitor fluid balance.

-- ** Requires the echodata view, generated by concepts/echo-data.sql

with ce as
(
    SELECT
      c.icustay_id
      -- we take the avg value from roughly first day
      -- TODO: eliminate obvious outliers if there is a reasonable weight
      -- (e.g. weight of 180kg and 90kg would remove 180kg instead of taking the median)
      , AVG(VALUENUM) as Weight_Admit
    FROM chartevents c
    inner join icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (762,226512) -- Admit Wt
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
    group by c.icustay_id
)
, dwt as
(
    SELECT
      c.icustay_id
      , AVG(VALUENUM) as Weight_Daily
    FROM chartevents c
    INNER JOIN icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (763,224639) -- Daily Weight
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
    group by c.icustay_id
)
-- we split in-hospital/out of hospital echoes as we would like to prioritize in-hospital data
, echo_hadm as
(
    select
        ie.icustay_id
        , 0.453592*AVG(weight) as Weight_EchoInHosp
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ec.hadm_id = ie.hadm_id
        and ec.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    where
            ec.HADM_ID is not null
        and ec.weight is not null
    group by ie.icustay_id
)
, echo_nohadm as
(
    select
        ie.icustay_id
        , 0.453592*AVG(weight) as Weight_EchoPreHosp
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ie.subject_id = ec.subject_id
        and ie.intime < DATETIME_ADD(ec.charttime, INTERVAL '1' MONTH)
        and ie.intime > ec.charttime
    where
            ec.HADM_ID is null
        and ec.weight is not null
    group by ie.icustay_id
)
select
    ie.icustay_id
    , round(cast(
    case
        when ce.icustay_id is not null
            then ce.Weight_Admit
        when dwt.icustay_id is not null
            then dwt.Weight_Daily
        when eh.icustay_id is not null
            then eh.Weight_EchoInHosp
        when enh.icustay_id is not null
            then enh.Weight_EchoPreHosp
        else null end
        as numeric), 2)
    as weight

    -- components
    , ce.weight_admit
    , dwt.weight_daily
    , eh.weight_echoinhosp
    , enh.weight_echoprehosp

FROM icustays ie

-- filter to only adults
inner join patients pat
    on ie.subject_id = pat.subject_id
    and ie.intime > DATETIME_ADD(pat.dob, INTERVAL '1' YEAR)

-- admission weight
left join ce
    on ie.icustay_id = ce.icustay_id

-- daily weights
left join dwt
    on ie.icustay_id = dwt.icustay_id

-- in-hospital echo weight
left join echo_hadm eh
    on ie.icustay_id = eh.icustay_id

-- pre-hospitalization echo weights
left join echo_nohadm enh
    on ie.icustay_id = enh.icustay_id
order by ie.icustay_id
  );
17:08:29.308192 [debug] [Thread-1  ]: SQL status: SELECT 53432 in 0.1 seconds
17:08:29.314397 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.314702 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
alter table "postgres"."public"."weight_first_day" rename to "weight_first_day__dbt_backup"
17:08:29.315536 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.319467 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.319695 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
alter table "postgres"."public"."weight_first_day__dbt_tmp" rename to "weight_first_day"
17:08:29.320346 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.323715 [debug] [Thread-1  ]: On model.mimic.weight_first_day: COMMIT
17:08:29.323929 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.324115 [debug] [Thread-1  ]: On model.mimic.weight_first_day: COMMIT
17:08:29.329435 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:29.332328 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:08:29.332532 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
drop table if exists "postgres"."public"."weight_first_day__dbt_backup" cascade
17:08:29.334427 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:29.337310 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.337538 [debug] [Thread-1  ]: On model.mimic.weight_first_day: Close
17:08:29.338332 [info ] [Thread-1  ]: 83 of 107 OK created table model public.weight_first_day ....................... [[32mSELECT 53432[0m in 0.16s]
17:08:29.338869 [debug] [Thread-1  ]: Finished running node model.mimic.weight_first_day
17:08:29.339367 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_score_ahrq
17:08:29.340022 [info ] [Thread-1  ]: 84 of 107 START table model public.elixhauser_score_ahrq ....................... [RUN]
17:08:29.340663 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.340908 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_score_ahrq
17:08:29.341120 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_score_ahrq
17:08:29.343842 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_score_ahrq"
17:08:29.345212 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.345859 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_score_ahrq
17:08:29.356484 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_score_ahrq"
17:08:29.357127 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.357366 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: BEGIN
17:08:29.357530 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:29.362152 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:29.362824 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.363511 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */


  create  table "postgres"."public"."elixhauser_score_ahrq__dbt_tmp"
  as (
    -- This query provides various methods of combining the Elixhauser components into a single score
-- The methods are called "vanWalRaven" and "SID30", and "SID29"
select subject_id, hadm_id
,  -- Below is the van Walraven score
   0 * aids +
   0 * alcohol_abuse +
  -2 * blood_loss_anemia +
   7 * congestive_heart_failure +
   -- Cardiac arrhythmias are not included in van Walraven based on Quan 2007
   3 * chronic_pulmonary +
   3 * coagulopathy +
  -2 * deficiency_anemias +
  -3 * depression +
   0 * diabetes_complicated +
   0 * diabetes_uncomplicated +
  -7 * drug_abuse +
   5 * fluid_electrolyte +
   0 * hypertension +
   0 * hypothyroidism +
   11 * liver_disease +
   9 * lymphoma +
   12 * metastatic_cancer +
   6 * other_neurological +
  -4 * obesity +
   7 * paralysis +
   2 * peripheral_vascular +
   0 * peptic_ulcer +
   0 * psychoses +
   4 * pulmonary_circulation +
   0 * rheumatoid_arthritis +
   5 * renal_failure +
   4 * solid_tumor +
  -1 * valvular_disease +
   6 * weight_loss
as elixhauser_vanwalraven



,  -- Below is the 29 component SID score
   0 * aids +
  -2 * alcohol_abuse +
  -2 * blood_loss_anemia +
   -- Cardiac arrhythmias are not included in SID-29
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
   9 * coagulopathy +
   0 * deficiency_anemias +
  -4 * depression +
   0 * diabetes_complicated +
  -1 * diabetes_uncomplicated +
  -8 * drug_abuse +
   9 * fluid_electrolyte +
  -1 * hypertension +
   0 * hypothyroidism +
   5 * liver_disease +
   6 * lymphoma +
   13 * metastatic_cancer +
   4 * other_neurological +
  -4 * obesity +
   3 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -4 * psychoses +
   5 * pulmonary_circulation +
   6 * renal_failure +
   0 * rheumatoid_arthritis +
   8 * solid_tumor +
   0 * valvular_disease +
   8 * weight_loss
as elixhauser_SID29


,  -- Below is the 30 component SID score
   0 * aids +
   0 * alcohol_abuse +
  -3 * blood_loss_anemia +
   8 * cardiac_arrhythmias +
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
  12 * coagulopathy +
   0 * deficiency_anemias +
  -5 * depression +
   1 * diabetes_complicated +
   0 * diabetes_uncomplicated +
 -11 * drug_abuse +
  11 * fluid_electrolyte +
  -2 * hypertension +
   0 * hypothyroidism +
   7 * liver_disease +
   8 * lymphoma +
  17 * metastatic_cancer +
   5 * other_neurological +
  -5 * obesity +
   4 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -6 * psychoses +
   5 * pulmonary_circulation +
   7 * renal_failure +
   0 * rheumatoid_arthritis +
  10 * solid_tumor +
   0 * valvular_disease +
  10 * weight_loss
as elixhauser_SID30

from "postgres"."public"."elixhauser_ahrq_v37"
  );
17:08:29.416618 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.05 seconds
17:08:29.423002 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.423246 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
alter table "postgres"."public"."elixhauser_score_ahrq" rename to "elixhauser_score_ahrq__dbt_backup"
17:08:29.423928 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.427596 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.427789 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
alter table "postgres"."public"."elixhauser_score_ahrq__dbt_tmp" rename to "elixhauser_score_ahrq"
17:08:29.428364 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.432082 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: COMMIT
17:08:29.432282 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.432484 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: COMMIT
17:08:29.445028 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:29.447724 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:08:29.447923 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
drop table if exists "postgres"."public"."elixhauser_score_ahrq__dbt_backup" cascade
17:08:29.449773 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:29.452500 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.452764 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: Close
17:08:29.453552 [info ] [Thread-1  ]: 84 of 107 OK created table model public.elixhauser_score_ahrq .................. [[32mSELECT 58976[0m in 0.11s]
17:08:29.454132 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_score_ahrq
17:08:29.454447 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_score_quan
17:08:29.455353 [info ] [Thread-1  ]: 85 of 107 START table model public.elixhauser_score_quan ....................... [RUN]
17:08:29.456211 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.456642 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_score_quan
17:08:29.456889 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_score_quan
17:08:29.459941 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_score_quan"
17:08:29.461198 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.461714 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_score_quan
17:08:29.474652 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_score_quan"
17:08:29.475312 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.475835 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: BEGIN
17:08:29.475998 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:29.482883 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:29.483379 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.483524 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */


  create  table "postgres"."public"."elixhauser_score_quan__dbt_tmp"
  as (
    -- This query provides various methods of combining the Elixhauser components into a single score
-- The methods are called "vanWalRaven" and "SID30", and "SID29"

select hadm_id
,  -- Below is the van Walraven score
   0 * aids +
   0 * alcohol_abuse +
  -2 * blood_loss_anemia +
   7 * congestive_heart_failure +
   -- Cardiac arrhythmias are not included in van Walraven based on Quan 2007
   3 * chronic_pulmonary +
   3 * coagulopathy +
  -2 * deficiency_anemias +
  -3 * depression +
   0 * diabetes_complicated +
   0 * diabetes_uncomplicated +
  -7 * drug_abuse +
   5 * fluid_electrolyte +
   0 * hypertension +
   0 * hypothyroidism +
   11 * liver_disease +
   9 * lymphoma +
   12 * metastatic_cancer +
   6 * other_neurological +
  -4 * obesity +
   7 * paralysis +
   2 * peripheral_vascular +
   0 * peptic_ulcer +
   0 * psychoses +
   4 * pulmonary_circulation +
   0 * rheumatoid_arthritis +
   5 * renal_failure +
   4 * solid_tumor +
  -1 * valvular_disease +
   6 * weight_loss
as elixhauser_vanwalraven



,  -- Below is the 29 component SID score
   0 * aids +
  -2 * alcohol_abuse +
  -2 * blood_loss_anemia +
   -- Cardiac arrhythmias are not included in SID-29
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
   9 * coagulopathy +
   0 * deficiency_anemias +
  -4 * depression +
   0 * diabetes_complicated +
  -1 * diabetes_uncomplicated +
  -8 * drug_abuse +
   9 * fluid_electrolyte +
  -1 * hypertension +
   0 * hypothyroidism +
   5 * liver_disease +
   6 * lymphoma +
   13 * metastatic_cancer +
   4 * other_neurological +
  -4 * obesity +
   3 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -4 * psychoses +
   5 * pulmonary_circulation +
   6 * renal_failure +
   0 * rheumatoid_arthritis +
   8 * solid_tumor +
   0 * valvular_disease +
   8 * weight_loss
as elixhauser_SID29


,  -- Below is the 30 component SID score
   0 * aids +
   0 * alcohol_abuse +
  -3 * blood_loss_anemia +
   8 * cardiac_arrhythmias +
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
  12 * coagulopathy +
   0 * deficiency_anemias +
  -5 * depression +
   1 * diabetes_complicated +
   0 * diabetes_uncomplicated +
 -11 * drug_abuse +
  11 * fluid_electrolyte +
  -2 * hypertension +
   0 * hypothyroidism +
   7 * liver_disease +
   8 * lymphoma +
  17 * metastatic_cancer +
   5 * other_neurological +
  -5 * obesity +
   4 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -6 * psychoses +
   5 * pulmonary_circulation +
   7 * renal_failure +
   0 * rheumatoid_arthritis +
  10 * solid_tumor +
   0 * valvular_disease +
  10 * weight_loss
as elixhauser_SID30

from  "postgres"."public"."elixhauser_quan"
  );
17:08:29.539276 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.06 seconds
17:08:29.543317 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.543553 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
alter table "postgres"."public"."elixhauser_score_quan" rename to "elixhauser_score_quan__dbt_backup"
17:08:29.544366 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.550996 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.551312 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
alter table "postgres"."public"."elixhauser_score_quan__dbt_tmp" rename to "elixhauser_score_quan"
17:08:29.551946 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:29.555092 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: COMMIT
17:08:29.555348 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.555552 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: COMMIT
17:08:29.556959 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:29.559185 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:08:29.559457 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
drop table if exists "postgres"."public"."elixhauser_score_quan__dbt_backup" cascade
17:08:29.561294 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:29.566056 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.566323 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: Close
17:08:29.567370 [info ] [Thread-1  ]: 85 of 107 OK created table model public.elixhauser_score_quan .................. [[32mSELECT 58976[0m in 0.11s]
17:08:29.567934 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_score_quan
17:08:29.568235 [debug] [Thread-1  ]: Began running node model.mimic.icustay_hours
17:08:29.568791 [info ] [Thread-1  ]: 86 of 107 START table model public.icustay_hours ............................... [RUN]
17:08:29.569495 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icustay_hours"
17:08:29.569861 [debug] [Thread-1  ]: Began compiling node model.mimic.icustay_hours
17:08:29.570166 [debug] [Thread-1  ]: Compiling model.mimic.icustay_hours
17:08:29.573519 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icustay_hours"
17:08:29.574285 [debug] [Thread-1  ]: finished collecting timing info
17:08:29.574964 [debug] [Thread-1  ]: Began executing node model.mimic.icustay_hours
17:08:29.586808 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icustay_hours"
17:08:29.587583 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:29.587797 [debug] [Thread-1  ]: On model.mimic.icustay_hours: BEGIN
17:08:29.588034 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:29.592460 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:29.592720 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:29.592955 [debug] [Thread-1  ]: On model.mimic.icustay_hours: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_hours"} */


  create  table "postgres"."public"."icustay_hours__dbt_tmp"
  as (
    -- This query generates a row for every hour the patient is in the ICU.
-- The hours are based on clock-hours (i.e. 02:00, 03:00).
-- The hour clock starts 24 hours before the first heart rate measurement.
-- Note that the time of the first heart rate measurement is ceilinged to the hour.

-- this query extracts the cohort and every possible hour they were in the ICU
-- this table can be to other tables on ICUSTAY_ID and (ENDTIME - 1 hour,ENDTIME]

-- get first/last measurement time
with all_hours as
(
select
  it.icustay_id

  -- ceiling the intime to the nearest hour by adding 59 minutes then truncating
  -- note thart we truncate by parsing as string, rather than using DATETIME_TRUNC
  -- this is done to enable compatibility with psql
  , PARSE_DATETIME(
      '%Y-%m-%d %H:00:00',
      FORMAT_DATETIME(
        '%Y-%m-%d %H:00:00',
          DATETIME_ADD(it.intime_hr, '59 MINUTE'::INTERVAL)
  )) AS endtime

  -- create integers for each charttime in hours from admission
  -- so 0 is admission time, 1 is one hour after admission, etc, up to ICU disch
  --  we allow 24 hours before ICU admission (to grab labs before admit)
  , GENERATE_ARRAY(-24, CEIL(DATETIME_DIFF(it.outtime_hr, it.intime_hr, 'HOUR'))::integer) as hrs

  from "postgres"."public"."icustay_times" it
)
SELECT icustay_id
, CAST(hr AS integer) as hr
, DATETIME_ADD(endtime,  (CAST(hr AS integer) || 'HOUR')::INTERVAL) as endtime
FROM all_hours
CROSS JOIN UNNEST(ARRAY[all_hours.hrs]) AS hr
  );
17:08:30.040821 [debug] [Thread-1  ]: SQL status: SELECT 963 in 0.45 seconds
17:08:30.047353 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:30.047559 [debug] [Thread-1  ]: On model.mimic.icustay_hours: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_hours"} */
alter table "postgres"."public"."icustay_hours" rename to "icustay_hours__dbt_backup"
17:08:30.048395 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.052162 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:30.052352 [debug] [Thread-1  ]: On model.mimic.icustay_hours: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_hours"} */
alter table "postgres"."public"."icustay_hours__dbt_tmp" rename to "icustay_hours"
17:08:30.053072 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.056245 [debug] [Thread-1  ]: On model.mimic.icustay_hours: COMMIT
17:08:30.056442 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:30.056674 [debug] [Thread-1  ]: On model.mimic.icustay_hours: COMMIT
17:08:30.057754 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:30.059820 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_hours"
17:08:30.060018 [debug] [Thread-1  ]: On model.mimic.icustay_hours: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_hours"} */
drop table if exists "postgres"."public"."icustay_hours__dbt_backup" cascade
17:08:30.062015 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.065286 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.065518 [debug] [Thread-1  ]: On model.mimic.icustay_hours: Close
17:08:30.066386 [info ] [Thread-1  ]: 86 of 107 OK created table model public.icustay_hours .......................... [[32mSELECT 963[0m in 0.50s]
17:08:30.067081 [debug] [Thread-1  ]: Finished running node model.mimic.icustay_hours
17:08:30.067472 [debug] [Thread-1  ]: Began running node model.mimic.meld
17:08:30.068374 [info ] [Thread-1  ]: 87 of 107 START table model public.meld ........................................ [RUN]
17:08:30.069141 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.meld"
17:08:30.069501 [debug] [Thread-1  ]: Began compiling node model.mimic.meld
17:08:30.069832 [debug] [Thread-1  ]: Compiling model.mimic.meld
17:08:30.073286 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.meld"
17:08:30.074748 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.075105 [debug] [Thread-1  ]: Began executing node model.mimic.meld
17:08:30.084450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.meld"
17:08:30.085136 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.085355 [debug] [Thread-1  ]: On model.mimic.meld: BEGIN
17:08:30.085597 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.090064 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:30.090294 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.090406 [debug] [Thread-1  ]: On model.mimic.meld: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.meld"} */


  create  table "postgres"."public"."meld__dbt_tmp"
  as (
    -- Model for end-stage liver disease (MELD)
-- This model is used to determine prognosis and receipt of liver transplantation.

-- Reference:
--  Kamath PS, Wiesner RH, Malinchoc M, Kremers W, Therneau TM,
--  Kosberg CL, D'Amico G, Dickson ER, Kim WR.
--  A model to predict survival in patients with end-stage liver disease.
--  Hepatology. 2001 Feb33(2):464-70.


-- Updated January 2016 to include serum sodium, see:
--  https://optn.transplant.hrsa.gov/news/meld-serum-sodium-policy-changes/

-- Here is the relevant portion of the policy note:
--    9.1.D MELD Score
--    Candidates who are at least 12 years old receive an initial MELD(i) score equal to:
--    0.957 x ln(creatinine mg/dL) + 0.378 x ln(bilirubin mg/dL) + 1.120 x ln(INR) + 0.643

--    Laboratory values less than 1.0 will be set to 1.0 when calculating a candidate’s MELD
--    score.

--    The following candidates will receive a creatinine value of 4.0 mg/dL:
--    - Candidates with a creatinine value greater than 4.0 mg/dL
--    - Candidates who received two or more dialysis treatments within the prior week
--    - Candidates who received 24 hours of continuous veno-venous hemodialysis (CVVHD) within the prior week

--    The maximum MELD score is 40. The MELD score derived from this calculation will be rounded to the tenth decimal place and then multiplied by 10.

--    For candidates with an initial MELD score greater than 11, The MELD score is then recalculated as follows:
--    MELD = MELD(i) + 1.32*(137-Na) – [0.033*MELD(i)*(137-Na)]
--    Sodium values less than 125 mmol/L will be set to 125, and values greater than 137 mmol/L will be set to 137.



-- TODO needed in this code:
--  1. identify 2x dialysis in the past week, or 24 hours of CVVH
--      at the moment it just checks for any dialysis on the day
--  2. adjust the serum sodium using the corresponding glucose measurement
--      Measured sodium + 0.024 * (Serum glucose - 100)   (Hiller, 1999)

with cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      , labs.creatinine_max
      , labs.bilirubin_max
      , labs.inr_max
      , labs.sodium_min

      , r.rrt

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to custom tables to get more data....
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
left join rrt_first_day r
  on ie.icustay_id = r.icustay_id
)
, score as
(
  select subject_id, hadm_id, icustay_id
    , rrt
    , creatinine_max
    , bilirubin_max
    , inr_max
    , sodium_min

    -- TODO: Corrected Sodium
    , case
        when sodium_min is null
          then 0.0
        when sodium_min > 137
          then 0.0
        when sodium_min < 125
          then 12.0 -- 137 - 125 = 12
        else 137.0-sodium_min
      end as sodium_score

    -- if hemodialysis, value for Creatinine is automatically set to 4.0
    , case
        when rrt = 1 or creatinine_max > 4.0
          then (0.957 * ln(4))
        -- if creatinine < 1, score is 1
        when creatinine_max < 1
          then (0.957 * ln(1))
        else 0.957 * coalesce(ln(creatinine_max),ln(1))
      end as creatinine_score

    , case
        -- if value < 1, score is 1
        when bilirubin_max < 1
          then 0.378 * ln(1)
        else 0.378 * coalesce(ln(bilirubin_max),ln(1))
      end as bilirubin_score

    , case
        when inr_max < 1
          then ( 1.120 * ln(1) + 0.643 )
        else ( 1.120 * coalesce(ln(inr_max),ln(1)) + 0.643 )
      end as inr_score

  from cohort
)
, score2 as
(
  select
    subject_id, hadm_id, icustay_id
    , rrt
    , creatinine_max
    , bilirubin_max
    , inr_max
    , sodium_min

    , creatinine_score
    , sodium_score
    , bilirubin_score
    , inr_score

    , case
        when (creatinine_score + bilirubin_score + inr_score) > 40
          then 40.0
        else
          round(cast(creatinine_score + bilirubin_score + inr_score as numeric),1)*10
        end as meld_initial
  from score
)
select
  subject_id, hadm_id, icustay_id

  -- MELD Score without sodium change
  , meld_initial

  -- MELD Score (2016) = MELD*10 + 1.32*(137-Na) – [0.033*MELD*10*(137-Na)]
  , case
      when meld_initial > 11
        then meld_initial + 1.32*sodium_score - 0.033*meld_initial*sodium_score
      else
        meld_initial
      end as meld

  -- original variables
  , rrt
  , creatinine_max
  , bilirubin_max
  , inr_max
  , sodium_min

from score2
order by icustay_id
  );
17:08:30.309767 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.22 seconds
17:08:30.313685 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.313870 [debug] [Thread-1  ]: On model.mimic.meld: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.meld"} */
alter table "postgres"."public"."meld" rename to "meld__dbt_backup"
17:08:30.314589 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.318192 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.318375 [debug] [Thread-1  ]: On model.mimic.meld: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.meld"} */
alter table "postgres"."public"."meld__dbt_tmp" rename to "meld"
17:08:30.319247 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.322180 [debug] [Thread-1  ]: On model.mimic.meld: COMMIT
17:08:30.322391 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.322584 [debug] [Thread-1  ]: On model.mimic.meld: COMMIT
17:08:30.331067 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:30.333878 [debug] [Thread-1  ]: Using postgres connection "model.mimic.meld"
17:08:30.334178 [debug] [Thread-1  ]: On model.mimic.meld: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.meld"} */
drop table if exists "postgres"."public"."meld__dbt_backup" cascade
17:08:30.336546 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.340575 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.340978 [debug] [Thread-1  ]: On model.mimic.meld: Close
17:08:30.342060 [info ] [Thread-1  ]: 87 of 107 OK created table model public.meld ................................... [[32mSELECT 61532[0m in 0.27s]
17:08:30.342726 [debug] [Thread-1  ]: Finished running node model.mimic.meld
17:08:30.343126 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg_art
17:08:30.343833 [info ] [Thread-1  ]: 88 of 107 START table model public.pivoted_bg_art .............................. [RUN]
17:08:30.344677 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg_art"
17:08:30.345157 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg_art
17:08:30.345457 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg_art
17:08:30.348877 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg_art"
17:08:30.349835 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.350144 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg_art
17:08:30.360560 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg_art"
17:08:30.361205 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.361625 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: BEGIN
17:08:30.361747 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.368498 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:30.368847 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.369050 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */


  create  table "postgres"."public"."pivoted_bg_art__dbt_tmp"
  as (
    -- This query requires the pivoted_bg table to be generated.
-- It extracts only arterial blood gas samples - either explicitly stated or 
-- inferred by a hard-coded logistic regression model.
with stg_spo2 as
(
  select hadm_id, charttime
    -- avg here is just used to group SpO2 by charttime
    , avg(valuenum) as spo2
  FROM chartevents
  -- o2 sat
  where ITEMID in
  (
    646 -- SpO2
  , 220277 -- O2 saturation pulseoxymetry
  )
  and valuenum > 0 and valuenum <= 100
  group by hadm_id, charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , max(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
, stg2 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s1.charttime DESC) as lastrowspo2
  , s1.spo2
from "postgres"."public"."pivoted_bg" bg
left join stg_spo2 s1
  -- same hospitalization
  on  bg.hadm_id = s1.hadm_id
  -- spo2 occurred at most 2 hours before this blood gas
  and s1.charttime between DATETIME_SUB(bg.charttime, INTERVAL '2' HOUR) and bg.charttime
where bg.po2 is not null
)
, stg3 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s2.charttime DESC) as lastrowfio2
  , s2.fio2_chartevents

  -- create our specimen prediction
  ,  1/(1+exp(-(-0.02544
  +    0.04598 * po2
  + coalesce(-0.15356 * spo2             , -0.15356 *   97.49420 +    0.13429)
  + coalesce( 0.00621 * fio2_chartevents ,  0.00621 *   51.49550 +   -0.24958)
  + coalesce( 0.10559 * hemoglobin       ,  0.10559 *   10.32307 +    0.05954)
  + coalesce( 0.13251 * so2              ,  0.13251 *   93.66539 +   -0.23172)
  + coalesce(-0.01511 * pco2             , -0.01511 *   42.08866 +   -0.01630)
  + coalesce( 0.01480 * fio2             ,  0.01480 *   63.97836 +   -0.31142)
  + coalesce(-0.00200 * aado2            , -0.00200 *  442.21186 +   -0.01328)
  + coalesce(-0.03220 * bicarbonate      , -0.03220 *   22.96894 +   -0.06535)
  + coalesce( 0.05384 * totalco2         ,  0.05384 *   24.72632 +   -0.01405)
  + coalesce( 0.08202 * lactate          ,  0.08202 *    3.06436 +    0.06038)
  + coalesce( 0.10956 * ph               ,  0.10956 *    7.36233 +   -0.00617)
  + coalesce( 0.00848 * o2flow           ,  0.00848 *    7.59362 +   -0.35803)
  ))) as specimen_prob
from stg2 bg
left join stg_fio2 s2
  -- same patient
  on  bg.hadm_id = s2.hadm_id
  -- fio2 occurred at most 4 hours before this blood gas
  and s2.charttime between DATETIME_SUB(bg.charttime, INTERVAL '4' HOUR) and bg.charttime
  and s2.fio2_chartevents > 0
where bg.lastRowSpO2 = 1 -- only the row with the most recent SpO2 (if no SpO2 found lastRowSpO2 = 1)
)
select
    stg3.hadm_id
  , stg3.icustay_id
  , stg3.charttime
  , specimen -- raw data indicating sample type, only present 80% of the time
  -- prediction of specimen for missing data
  , case
        when SPECIMEN is not null then SPECIMEN
        when SPECIMEN_PROB > 0.75 then 'ART'
      else null end as specimen_pred
  , specimen_prob

  -- oxygen related parameters
  , so2, spo2 -- note spo2 is FROM chartevents
  , po2, pco2
  , fio2_chartevents, fio2
  , aado2
  -- also calculate AADO2
  , case
      when  PO2 is not null
        and pco2 is not null
        and coalesce(FIO2, fio2_chartevents) is not null
       -- multiple by 100 because FiO2 is in a % but should be a fraction
        then (coalesce(FIO2, fio2_chartevents)/100) * (760 - 47) - (pco2/0.8) - po2
      else null
    end as aado2_calc
  , case
      when PO2 is not null and coalesce(FIO2, fio2_chartevents) is not null
       -- multiply by 100 because FiO2 is in a % but should be a fraction
        then 100*PO2/(coalesce(FIO2, fio2_chartevents))
      else null
    end as pao2fio2ratio
  -- acid-base parameters
  , ph, baseexcess
  , bicarbonate, totalco2

  -- blood count parameters
  , hematocrit
  , hemoglobin
  , carboxyhemoglobin
  , methemoglobin

  -- chemistry
  , chloride, calcium
  , temperature
  , potassium, sodium
  , lactate
  , glucose

  -- ventilation stuff that's sometimes input
  , intubated, tidalvolume, ventilationrate, ventilator
  , peep, o2flow
  , requiredo2
from stg3
where lastRowFiO2 = 1 -- only the most recent FiO2
-- restrict it to *only* arterial samples
and (specimen = 'ART' or specimen_prob > 0.75)
order by hadm_id, charttime
  );
17:08:30.377710 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:08:30.384677 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.385104 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art" rename to "pivoted_bg_art__dbt_backup"
17:08:30.385934 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.389965 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.390158 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art__dbt_tmp" rename to "pivoted_bg_art"
17:08:30.390941 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.394174 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:08:30.394408 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.394653 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:08:30.396926 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:30.400818 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:08:30.401062 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
drop table if exists "postgres"."public"."pivoted_bg_art__dbt_backup" cascade
17:08:30.404091 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.409336 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.409640 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: Close
17:08:30.410343 [info ] [Thread-1  ]: 88 of 107 OK created table model public.pivoted_bg_art ......................... [[32mSELECT 0[0m in 0.07s]
17:08:30.410770 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg_art
17:08:30.410954 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_oasis
17:08:30.411855 [info ] [Thread-1  ]: 89 of 107 START table model public.pivoted_oasis ............................... [RUN]
17:08:30.413223 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_oasis"
17:08:30.413411 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_oasis
17:08:30.413590 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_oasis
17:08:30.418049 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_oasis"
17:08:30.418453 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.418833 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_oasis
17:08:30.427621 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_oasis"
17:08:30.429800 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:08:30.430730 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: BEGIN
17:08:30.431010 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.437403 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:30.437826 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:08:30.437971 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_oasis"} */


  create  table "postgres"."public"."pivoted_oasis__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Oxford Acute Severity of Illness Score (OASIS)
-- This query extracts the Oxford acute severity of illness score.
-- This score is a measure of severity of illness for patients in the ICU.
-- The score is calculated for every hour of the patient's ICU stay.
-- However, as the calculation window is 24 hours, care should be taken when
-- using the score before the end of the first day.
-- ------------------------------------------------------------------

-- Reference for OASIS:
--    Johnson, Alistair EW, Andrew A. Kramer, and Gari D. Clifford.
--    "A new severity of illness scale using a subset of acute physiology and chronic health evaluation data elements shows comparable predictive accuracy*."
--    Critical care medicine 41, no. 7 (2013): 1711-1718.

-- Variables used in OASIS:
--  Heart rate, GCS, MAP, Temperature, Respiratory rate, Ventilation status (sourced from CHARTEVENTS)
--  Urine output (sourced from OUTPUTEVENTS)
--  Elective surgery (sourced from ADMISSIONS and SERVICES)
--  Pre-ICU in-hospital length of stay (sourced from ADMISSIONS and ICUSTAYS)
--  Age (sourced from PATIENTS)

-- The following views are required to run this query:
--  1) uofirstday - generated by urine-output-first-day.sql
--  2) ventfirstday - generated by ventilated-first-day.sql
--  3) vitalsfirstday - generated by vitals-first-day.sql
--  4) gcsfirstday - generated by gcs-first-day.sql


-- Regarding missing values:
--  The ventilation flag is always 0/1. It cannot be missing, since VENT=0 if no data is found for vent settings.

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption 
--  that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to
--  actually use the score values for these patients.

-- The following views required to run this query:
--  1) pivoted_uo - generated by pivoted-uo.sql
--  2) pivoted_lab - generated by pivoted-lab.sql
--  3) pivoted_gcs - generated by pivoted-gcs.sql
--  4) pivoted_vital - generated by pivoted-vital.sql
--  5) ventilation_durations - generated by ../durations/ventilation_durations.sql

-- generate a row for every hour the patient was in the ICU
WITH co_hours AS
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(v.HeartRate) as HeartRate_min
  , max(v.HeartRate) as HeartRate_max
  , min(v.TempC) as TempC_min
  , max(v.TempC) as TempC_max
  , min(v.MeanBP) as MeanBP_min
  , max(v.MeanBP) as MeanBP_max
  , min(v.RespRate) as RespRate_min
  , max(v.RespRate) as RespRate_max
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , MAX(case
        when vd1.icustay_id is not null then 1 
        when vd2.icustay_id is not null then 1
    else 0 end) AS mechvent
  from co_hours co
  left join "postgres"."public"."pivoted_vital" v
    on co.icustay_id = v.icustay_id
    and co.starttime < v.charttime
    and co.endtime >= v.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  -- at the time of this row, was the patient ventilated
  left join ventilation_durations vd1
    on co.icustay_id = vd1.icustay_id
    and co.starttime >= vd1.starttime
    and co.starttime <= vd1.endtime
  left join ventilation_durations vd2
    on co.icustay_id = vd2.icustay_id
    and co.endtime >= vd2.starttime
    and co.endtime <= vd2.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co_hours co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.meanbp_min
    , ma.meanbp_max
    , ma.heartrate_min
    , ma.heartrate_max
    , ma.tempc_min
    , ma.tempc_max
    , ma.resprate_min
    , ma.resprate_max
    , ma.gcs_min
    -- uo
    , uo.urineoutput
    -- static variables that do not change over the ICU stay
    , cast(co.intime as timestamp) - cast(adm.admittime as timestamp) as preiculos
    , case
        when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
        then 1
        when adm.ADMISSION_TYPE is null or sf.surgical is null
        then null
        else 0
    end as electivesurgery
  from co_hours co
  inner join admissions adm
    on co.hadm_id = adm.hadm_id
  left join surgflag sf
    on co.icustay_id = sf.icustay_id
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
    -- Below code calculates the component scores needed for OASIS
    , case when preiculos is null then null
        when preiculos < '0 0:10:12' then 5
        when preiculos < '0 4:57:00' then 3
        when preiculos < '1 0:00:00' then 0
        when preiculos < '12 23:48:00' then 1
        else 2 end as preiculos_score
    ,  case when age is null then null
        when age < 24 then 0
        when age <= 53 then 3
        when age <= 77 then 6
        when age <= 89 then 9
        when age >= 90 then 7
        else 0 end as age_score
    ,  case when mingcs is null then null
        when mingcs <= 7 then 10
        when mingcs < 14 then 4
        when mingcs = 14 then 3
        else 0 end as gcs_score
    ,  case when heartrate_max is null then null
        when heartrate_max > 125 then 6
        when heartrate_min < 33 then 4
        when heartrate_max >= 107 and heartrate_max <= 125 then 3
        when heartrate_max >= 89 and heartrate_max <= 106 then 1
        else 0 end as heartrate_score
    ,  case when meanbp_min is null then null
        when meanbp_min < 20.65 then 4
        when meanbp_min < 51 then 3
        when meanbp_max > 143.44 then 3
        when meanbp_min >= 51 and meanbp_min < 61.33 then 2
        else 0 end as meanbp_score
    ,  case when resprate_min is null then null
        when resprate_min <   6 then 10
        when resprate_max >  44 then  9
        when resprate_max >  30 then  6
        when resprate_max >  22 then  1
        when resprate_min <  13 then 1 else 0
        end as resprate_score
    ,  case when tempc_max is null then null
        when tempc_max > 39.88 then 6
        when tempc_min >= 33.22 and tempc_min <= 35.93 then 4
        when tempc_max >= 33.22 and tempc_max <= 35.93 then 4
        when tempc_min < 33.22 then 3
        when tempc_min > 35.93 and tempc_min <= 36.39 then 2
        when tempc_max >= 36.89 and tempc_max <= 39.88 then 2
        else 0 end as temp_score
    ,  case 
        when SUM(urineoutput) OVER W is null then null
        when SUM(urineoutput) OVER W < 671.09 then 10
        when SUM(urineoutput) OVER W > 6896.80 then 8
        when SUM(urineoutput) OVER W >= 671.09
        and SUM(urineoutput) OVER W <= 1426.99 then 5
        when SUM(urineoutput) OVER W >= 1427.00
        and SUM(urineoutput) OVER W <= 2544.14 then 1
        else 0 end as urineoutput_score
    ,  case when mechvent is null then null
        when mechvent = 1 then 9
        else 0 end as mechvent_score
    ,  case when electivesurgery is null then null
        when electivesurgery = 1 then 0
        else 6 end as electivesurgery_score
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Look for the worst instantaneous score over the last 24 hours
    -- Impute 0 if the score is missing
    , preiculos_score AS preiculos_score_24hours
    , electivesurgery_score as electivesurgery_score_24hours
    , coalesce(MAX(age_score) OVER W, 0)::SMALLINT as age_score_24hours
    , coalesce(MAX(gcs_score) OVER W, 0)::SMALLINT as gcs_score_24hours
    , coalesce(MAX(heartrate_score) OVER W, 0)::SMALLINT as heartrate_score_24hours
    , coalesce(MAX(meanbp_score) OVER W,0)::SMALLINT as meanbp_score_24hours
    , coalesce(MAX(resprate_score) OVER W,0)::SMALLINT as resprate_score_24hours
    , coalesce(MAX(temp_score) OVER W,0)::SMALLINT as temp_score_24hours
    , coalesce(MAX(urineoutput_score) OVER W,0)::SMALLINT as urineoutput_score_24hours
    , coalesce(MAX(mechvent_score) OVER W,0)::SMALLINT as mechvent_score_24hours

    -- sum together data for final OASIS
    , (preiculos_score
    + electivesurgery_score
    + coalesce(MAX(age_score) OVER W, 0)
    + coalesce(MAX(gcs_score) OVER W, 0)
    + coalesce(MAX(heartrate_score) OVER W, 0)
    + coalesce(MAX(meanbp_score) OVER W,0)
    + coalesce(MAX(resprate_score) OVER W,0)
    + coalesce(MAX(temp_score) OVER W,0)
    + coalesce(MAX(urineoutput_score) OVER W,0)
    + coalesce(MAX(mechvent_score) OVER W,0)
    )::SMALLINT
    as OASIS_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:08:30.440413 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "surgflag" does not exist
LINE 145:   left join surgflag sf
                      ^

17:08:30.440690 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: ROLLBACK
17:08:30.441016 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.441157 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: Close
17:08:30.441605 [debug] [Thread-1  ]: Database Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)
  relation "surgflag" does not exist
  LINE 145:   left join surgflag sf
                        ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:08:30.441908 [error] [Thread-1  ]: 89 of 107 ERROR creating table model public.pivoted_oasis ...................... [[31mERROR[0m in 0.03s]
17:08:30.442208 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_oasis
17:08:30.442345 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_durations
17:08:30.442609 [info ] [Thread-1  ]: 90 of 107 START table model public.ventilation_durations ....................... [RUN]
17:08:30.443609 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_durations"
17:08:30.443765 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_durations
17:08:30.444034 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_durations
17:08:30.448635 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_durations"
17:08:30.449565 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.449822 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_durations
17:08:30.459007 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_durations"
17:08:30.459560 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.459769 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: BEGIN
17:08:30.459863 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.464844 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:30.465077 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.465180 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */


  create  table "postgres"."public"."ventilation_durations__dbt_tmp"
  as (
    -- This query extracts the duration of mechanical ventilation
-- The main goal of the query is to aggregate sequential ventilator settings
-- into single mechanical ventilation "events". The start and end time of these
-- events can then be used for various purposes: calculating the total duration
-- of mechanical ventilation, cross-checking values (e.g. PaO2:FiO2 on vent), etc

-- The query's logic is roughly:
--    1) The presence of a mechanical ventilation setting starts a new ventilation event
--    2) Any instance of a setting in the next 8 hours continues the event
--    3) Certain elements end the current ventilation event
--        a) documented extubation ends the current ventilation
--        b) initiation of non-invasive vent and/or oxygen ends the current vent

-- See the ventilation_classification.sql query for step 1 of the above.
-- This query has the logic for converting events into durations.
with vd0 as
(
  select
    icustay_id
    -- this carries over the previous charttime which had a mechanical ventilation event
    , case
        when MechVent=1 then
          LAG(CHARTTIME, 1) OVER (partition by icustay_id, MechVent order by charttime)
        else null
      end as charttime_lag
    , charttime
    , MechVent
    , OxygenTherapy
    , Extubated
    , SelfExtubated
  from "postgres"."public"."ventilation_classification"
)
, vd1 as
(
  select
      icustay_id
      , charttime_lag
      , charttime
      , MechVent
      , OxygenTherapy
      , Extubated
      , SelfExtubated

      -- if this is a mechanical ventilation event, we calculate the time since the last event
      , case
          -- if the current observation indicates mechanical ventilation is present
          -- calculate the time since the last vent event
          when MechVent=1 then
            DATETIME_DIFF(CHARTTIME, charttime_lag, 'MINUTE')/60
          else null
        end as ventduration

      , LAG(Extubated,1)
      OVER
      (
      partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
      order by charttime
      ) as ExtubatedLag

      -- now we determine if the current mech vent event is a "new", i.e. they've just been intubated
      , case
        -- if there is an extubation flag, we mark any subsequent ventilation as a new ventilation event
          --when Extubated = 1 then 0 -- extubation is *not* a new ventilation event, the *subsequent* row is
          when
            LAG(Extubated,1)
            OVER
            (
            partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
            order by charttime
            )
            = 1 then 1
          -- if patient has initiated oxygen therapy, and is not currently vented, start a newvent
          when MechVent = 0 and OxygenTherapy = 1 then 1
            -- if there is less than 8 hours between vent settings, we do not treat this as a new ventilation event
          when CHARTTIME > DATETIME_ADD(charttime_lag, INTERVAL '8' HOUR)
            then 1
        else 0
        end as newvent
  -- use the staging table with only vent settings from chart events
  FROM vd0 ventsettings
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new ventilation
  -- this results in a monotonic integer assigned to each instance of ventilation
  , case when MechVent=1 or Extubated = 1 then
      SUM( newvent )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as ventnum
  --- now we convert CHARTTIME of ventilator settings into durations
  from vd1
)
-- create the durations for each mechanical ventilation instance
select icustay_id
  -- regenerate ventnum so it's sequential
  , ROW_NUMBER() over (partition by icustay_id order by ventnum) as ventnum
  , min(charttime) as starttime
  , max(charttime) as endtime
  , DATETIME_DIFF(max(charttime), min(charttime), 'MINUTE')/60 AS duration_hours
from vd2
group by icustay_id, vd2.ventnum
having min(charttime) != max(charttime)
-- patient had to be mechanically ventilated at least once
-- i.e. max(mechvent) should be 1
-- this excludes a frequent situation of NIV/oxygen before intub
-- in these cases, ventnum=0 and max(mechvent)=0, so they are ignored
and max(mechvent) = 1
order by icustay_id, ventnum
  );
17:08:30.501002 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.04 seconds
17:08:30.507381 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.507734 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations" rename to "ventilation_durations__dbt_backup"
17:08:30.508361 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.513203 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.513405 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations__dbt_tmp" rename to "ventilation_durations"
17:08:30.513867 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.517063 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:08:30.517274 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.517443 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:08:30.518453 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:30.520939 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:08:30.521169 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
drop table if exists "postgres"."public"."ventilation_durations__dbt_backup" cascade
17:08:30.523072 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.525547 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.525749 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: Close
17:08:30.526647 [info ] [Thread-1  ]: 90 of 107 OK created table model public.ventilation_durations .................. [[32mSELECT 3[0m in 0.08s]
17:08:30.527228 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_durations
17:08:30.527604 [debug] [Thread-1  ]: Began running node model.mimic.qsofa
17:08:30.528260 [info ] [Thread-1  ]: 91 of 107 START table model public.qsofa ....................................... [RUN]
17:08:30.529447 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.qsofa"
17:08:30.529791 [debug] [Thread-1  ]: Began compiling node model.mimic.qsofa
17:08:30.529959 [debug] [Thread-1  ]: Compiling model.mimic.qsofa
17:08:30.534173 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.qsofa"
17:08:30.534939 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.535261 [debug] [Thread-1  ]: Began executing node model.mimic.qsofa
17:08:30.544715 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.qsofa"
17:08:30.545747 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.545990 [debug] [Thread-1  ]: On model.mimic.qsofa: BEGIN
17:08:30.546112 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.552083 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:30.553010 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.553278 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */


  create  table "postgres"."public"."qsofa__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Quick Sequential Organ Failure Assessment (qSOFA)
-- This query extracts the quick sequential organ failure assessment.
-- This score was a recent revision of SOFA, aiming to detect patients at risk of sepsis.
-- The score is calculated on the first day of each ICU patients' stay - though needn't be.
-- ------------------------------------------------------------------

-- Reference for qSOFA:
--    Singer M, et al. The Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)
--    Seymour CW, et al. Assessment of Clinical Criteria for Sepsis: For the Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)

-- Variables used in qSOFA:
--  GCS, respiratory rate, systolic blood pressure

-- The following views required to run this query:
--  1) gcsfirstday - generated by gcs-first-day.sql
--  2) vitalsfirstday - generated by vitals-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with scorecomp as
(
select ie.icustay_id
  , v.sysbp_min
  , v.resprate_max
  , gcs.mingcs
FROM icustays ie
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id
  , case
      when sysbp_min is null then null
      when sysbp_min   <= 100 then 1
      else 0 end
    as sysbp_score
  , case
      when mingcs is null then null
      when mingcs   <= 13 then 1
      else 0 end
    as gcs_score
  , case
      when resprate_max is null then null
      when resprate_max   >= 22 then 1
      else 0 end
    as resprate_score
  from scorecomp
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, coalesce(sysbp_score,0)
 + coalesce(gcs_score,0)
 + coalesce(resprate_score,0)
 as qsofa
, sysbp_score
, gcs_score
, resprate_score
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:08:30.674827 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.12 seconds
17:08:30.682010 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.682356 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
alter table "postgres"."public"."qsofa" rename to "qsofa__dbt_backup"
17:08:30.683677 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.688980 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.689251 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
alter table "postgres"."public"."qsofa__dbt_tmp" rename to "qsofa"
17:08:30.689951 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.695239 [debug] [Thread-1  ]: On model.mimic.qsofa: COMMIT
17:08:30.695446 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.695633 [debug] [Thread-1  ]: On model.mimic.qsofa: COMMIT
17:08:30.702662 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:30.704527 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:08:30.704713 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
drop table if exists "postgres"."public"."qsofa__dbt_backup" cascade
17:08:30.706685 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.709538 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.709766 [debug] [Thread-1  ]: On model.mimic.qsofa: Close
17:08:30.710700 [info ] [Thread-1  ]: 91 of 107 OK created table model public.qsofa .................................. [[32mSELECT 61532[0m in 0.18s]
17:08:30.711267 [debug] [Thread-1  ]: Finished running node model.mimic.qsofa
17:08:30.711690 [debug] [Thread-1  ]: Began running node model.mimic.sirs
17:08:30.712420 [info ] [Thread-1  ]: 92 of 107 START table model public.sirs ........................................ [RUN]
17:08:30.713221 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sirs"
17:08:30.713468 [debug] [Thread-1  ]: Began compiling node model.mimic.sirs
17:08:30.713873 [debug] [Thread-1  ]: Compiling model.mimic.sirs
17:08:30.718008 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sirs"
17:08:30.718436 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.718739 [debug] [Thread-1  ]: Began executing node model.mimic.sirs
17:08:30.730221 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sirs"
17:08:30.731447 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.731693 [debug] [Thread-1  ]: On model.mimic.sirs: BEGIN
17:08:30.731856 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.737843 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:30.738150 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.738285 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */


  create  table "postgres"."public"."sirs__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Systemic inflammatory response syndrome (SIRS) criteria
-- This query extracts the Systemic inflammatory response syndrome (SIRS) criteria
-- The criteria quantify the level of inflammatory response of the body
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SIRS:
--    American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference:
--    definitions for sepsis and organ failure and guidelines for the use of innovative therapies in sepsis"
--    Crit. Care Med. 20 (6): 864–74. 1992.
--    doi:10.1097/00003246-199206000-00025. PMID 1597042.

-- Variables used in SIRS:
--  Body temperature (min and max)
--  Heart rate (max)
--  Respiratory rate (max)
--  PaCO2 (min)
--  White blood cell count (min and max)
--  the presence of greater than 10% immature neutrophils (band forms)

-- The following views required to run this query:
--  1) vitals_first_day - generated by vitals-first-day.sql
--  2) labs_first_day - generated by labs-first-day.sql
--  3) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with bg as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select bg.icustay_id
  , min(pco2) as paco2_min
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  where specimen_pred = 'ART'
  group by bg.icustay_id
)
-- Aggregate the components for the score
, scorecomp as
(
select ie.icustay_id
  , v.tempc_min
  , v.tempc_max
  , v.heartrate_max
  , v.resprate_max
  , bg.paco2_min
  , l.wbc_min
  , l.wbc_max
  , l.bands_max
FROM icustays ie
left join bg
 on ie.icustay_id = bg.icustay_id
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."labs_first_day" l
  on ie.icustay_id = l.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id

  , case
      when tempc_min < 36.0 then 1
      when tempc_max > 38.0 then 1
      when tempc_min is null then null
      else 0
    end as temp_score


  , case
      when heartrate_max > 90.0  then 1
      when heartrate_max is null then null
      else 0
    end as heartrate_score

  , case
      when resprate_max > 20.0  then 1
      when paco2_min < 32.0  then 1
      when coalesce(resprate_max, paco2_min) is null then null
      else 0
    end as resp_score

  , case
      when wbc_min <  4.0  then 1
      when wbc_max > 12.0  then 1
      when bands_max > 10 then 1-- > 10% immature neurophils (band forms)
      when coalesce(wbc_min, bands_max) is null then null
      else 0
    end as wbc_score

  from scorecomp
)
select
  ie.subject_id, ie.hadm_id, ie.icustay_id
  -- Combine all the scores to get SOFA
  -- Impute 0 if the score is missing
  , coalesce(temp_score,0)
  + coalesce(heartrate_score,0)
  + coalesce(resp_score,0)
  + coalesce(wbc_score,0)
    as sirs
  , temp_score, heartrate_score, resp_score, wbc_score
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:08:30.870892 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.13 seconds
17:08:30.878084 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.878551 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
alter table "postgres"."public"."sirs" rename to "sirs__dbt_backup"
17:08:30.879814 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.883894 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.884129 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
alter table "postgres"."public"."sirs__dbt_tmp" rename to "sirs"
17:08:30.884996 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:30.888242 [debug] [Thread-1  ]: On model.mimic.sirs: COMMIT
17:08:30.888439 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.888770 [debug] [Thread-1  ]: On model.mimic.sirs: COMMIT
17:08:30.895367 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:30.897148 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:08:30.897344 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
drop table if exists "postgres"."public"."sirs__dbt_backup" cascade
17:08:30.899366 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:30.902196 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.902429 [debug] [Thread-1  ]: On model.mimic.sirs: Close
17:08:30.903571 [info ] [Thread-1  ]: 92 of 107 OK created table model public.sirs ................................... [[32mSELECT 61532[0m in 0.19s]
17:08:30.904344 [debug] [Thread-1  ]: Finished running node model.mimic.sirs
17:08:30.904790 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_dose
17:08:30.905473 [info ] [Thread-1  ]: 93 of 107 START table model public.epinephrine_dose ............................ [RUN]
17:08:30.906204 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_dose"
17:08:30.906370 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_dose
17:08:30.906732 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_dose
17:08:30.909801 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_dose"
17:08:30.910205 [debug] [Thread-1  ]: finished collecting timing info
17:08:30.910337 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_dose
17:08:30.921121 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_dose"
17:08:30.922001 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:30.922230 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: BEGIN
17:08:30.922554 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:30.927657 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:08:30.928367 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:30.928825 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */


  create  table "postgres"."public"."epinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of epinephrine administration

-- Requires the weightfirstday table

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30044 and wd.weight is null then rate / 80.0 -- super rare to be missing weight... affects 2 patients for 14 rows
            when itemid = 30044 then rate / wd.weight -- measured in mcgmin
            when itemid in (30119,30309) then rate -- measured in mcgkgmin
            else null
          end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  and cv.icustay_id is not null
  group by cv.icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:08:31.539188 [debug] [Thread-1  ]: SQL status: SELECT 10562 in 0.61 seconds
17:08:31.545346 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:31.545538 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose" rename to "epinephrine_dose__dbt_backup"
17:08:31.546627 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:31.550220 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:31.550407 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose__dbt_tmp" rename to "epinephrine_dose"
17:08:31.551433 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:31.554314 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:08:31.554673 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:31.554991 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:08:31.556299 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:08:31.558633 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:08:31.558888 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
drop table if exists "postgres"."public"."epinephrine_dose__dbt_backup" cascade
17:08:31.560986 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:31.564246 [debug] [Thread-1  ]: finished collecting timing info
17:08:31.564478 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: Close
17:08:31.565503 [info ] [Thread-1  ]: 93 of 107 OK created table model public.epinephrine_dose ....................... [[32mSELECT 10562[0m in 0.66s]
17:08:31.566188 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_dose
17:08:31.566631 [debug] [Thread-1  ]: Began running node model.mimic.heightweight
17:08:31.567257 [info ] [Thread-1  ]: 94 of 107 START table model public.heightweight ................................ [RUN]
17:08:31.568058 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.heightweight"
17:08:31.568298 [debug] [Thread-1  ]: Began compiling node model.mimic.heightweight
17:08:31.568727 [debug] [Thread-1  ]: Compiling model.mimic.heightweight
17:08:31.571964 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.heightweight"
17:08:31.573272 [debug] [Thread-1  ]: finished collecting timing info
17:08:31.573609 [debug] [Thread-1  ]: Began executing node model.mimic.heightweight
17:08:31.585663 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.heightweight"
17:08:31.587220 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.587535 [debug] [Thread-1  ]: On model.mimic.heightweight: BEGIN
17:08:31.587758 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:31.592294 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:31.592538 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.592639 [debug] [Thread-1  ]: On model.mimic.heightweight: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heightweight"} */


  create  table "postgres"."public"."heightweight__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Extract height and weight for ICUSTAY_IDs
-- Description: This query gets the first, minimum, and maximum weight and height
--        for a single ICUSTAY_ID. It extracts data from the CHARTEVENTS table.
-- MIMIC version: MIMIC-III v1.4
-- ------------------------------------------------------------------

-- prep height
WITH ht_stg AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters, and fix data as needed
    CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
      THEN
        CASE
        -- rule for neonates
        WHEN c.charttime <= DATETIME_ADD(pt.dob, INTERVAL '1 YEAR')
         AND (c.valuenum * 2.54) < 80
          THEN c.valuenum * 2.54
        -- rule for adults
        WHEN c.charttime >  DATETIME_ADD(pt.dob, INTERVAL '1 YEAR')
         AND (c.valuenum * 2.54) > 120
         AND (c.valuenum * 2.54) < 230
          THEN c.valuenum * 2.54
        ELSE NULL END
      ELSE
        CASE
        -- rule for neonates
        WHEN c.charttime <= DATETIME_ADD(pt.dob, INTERVAL '1 YEAR')
         AND c.valuenum < 80
          THEN c.valuenum
        -- rule for adults
        WHEN c.charttime >  DATETIME_ADD(pt.dob, INTERVAL '1 YEAR')
         AND c.valuenum > 120
         AND c.valuenum < 230
          THEN c.valuenum
        ELSE NULL END
    END AS height
  FROM chartevents c
  INNER JOIN patients pt
    ON c.subject_id = pt.subject_id
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  AND c.itemid IN
  (
    -- CareVue
    920, 1394, 4187, 3486,  -- Height inches
    3485, 4188              -- Height cm
    -- Metavision
    , 226707 -- Height (measured in inches)
    -- note we intentionally ignore the below ITEMID in metavision
    -- these are duplicate data in a different unit
    -- , 226730 -- Height (cm)
  )
)
SELECT 
  ie.icustay_id,
  ROUND(CAST(wt.weight_first AS NUMERIC), 2) AS weight_first,
  ROUND(CAST(wt.weight_min AS NUMERIC), 2) AS weight_min,
  ROUND(CAST(wt.weight_max AS NUMERIC), 2) AS weight_max,
  ROUND(CAST(ht.height_first AS NUMERIC), 2) AS height_first,
  ROUND(CAST(ht.height_min AS NUMERIC), 2) AS height_min,
  ROUND(CAST(ht.height_max AS NUMERIC), 2) AS height_max
FROM icustays ie
-- get weight from weight_durations table
LEFT JOIN
(
  SELECT icustay_id,
    MIN(CASE WHEN rn = 1 THEN weight ELSE NULL END) as weight_first,
    MIN(weight) AS weight_min,
    MAX(weight) AS weight_max
  FROM
  (
    SELECT
      icustay_id,
      weight,
      ROW_NUMBER() OVER (PARTITION BY icustay_id ORDER BY starttime) as rn
    FROM "postgres"."public"."weight_durations"
  ) wt_stg
  GROUP BY icustay_id
) wt
  ON ie.icustay_id = wt.icustay_id
-- get first/min/max height from above, after filtering bad data
LEFT JOIN
(
  SELECT icustay_id,
    MIN(CASE WHEN rn = 1 THEN height ELSE NULL END) as height_first,
    MIN(height) AS height_min,
    MAX(height) AS height_max
  FROM
  (
    SELECT
      icustay_id,
      height,
      ROW_NUMBER() OVER (PARTITION BY icustay_id ORDER BY charttime) as rn
    FROM ht_stg
  ) ht_stg2
  GROUP BY icustay_id
) ht
  ON ie.icustay_id = ht.icustay_id
ORDER BY icustay_id
  );
17:08:31.667899 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.08 seconds
17:08:31.673968 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.674329 [debug] [Thread-1  ]: On model.mimic.heightweight: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heightweight"} */
alter table "postgres"."public"."heightweight" rename to "heightweight__dbt_backup"
17:08:31.675655 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:31.680853 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.681055 [debug] [Thread-1  ]: On model.mimic.heightweight: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heightweight"} */
alter table "postgres"."public"."heightweight__dbt_tmp" rename to "heightweight"
17:08:31.681781 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:08:31.684886 [debug] [Thread-1  ]: On model.mimic.heightweight: COMMIT
17:08:31.685098 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.685283 [debug] [Thread-1  ]: On model.mimic.heightweight: COMMIT
17:08:31.691446 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:08:31.740501 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heightweight"
17:08:31.740707 [debug] [Thread-1  ]: On model.mimic.heightweight: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heightweight"} */
drop table if exists "postgres"."public"."heightweight__dbt_backup" cascade
17:08:31.743313 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:08:31.746337 [debug] [Thread-1  ]: finished collecting timing info
17:08:31.746703 [debug] [Thread-1  ]: On model.mimic.heightweight: Close
17:08:31.747586 [info ] [Thread-1  ]: 94 of 107 OK created table model public.heightweight ........................... [[32mSELECT 61532[0m in 0.18s]
17:08:31.748312 [debug] [Thread-1  ]: Finished running node model.mimic.heightweight
17:08:31.748705 [debug] [Thread-1  ]: Began running node model.mimic.kdigo_uo
17:08:31.749349 [info ] [Thread-1  ]: 95 of 107 START table model public.kdigo_uo .................................... [RUN]
17:08:31.750072 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.kdigo_uo"
17:08:31.750235 [debug] [Thread-1  ]: Began compiling node model.mimic.kdigo_uo
17:08:31.750342 [debug] [Thread-1  ]: Compiling model.mimic.kdigo_uo
17:08:31.754001 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.kdigo_uo"
17:08:31.754582 [debug] [Thread-1  ]: finished collecting timing info
17:08:31.754860 [debug] [Thread-1  ]: Began executing node model.mimic.kdigo_uo
17:08:31.766246 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.kdigo_uo"
17:08:31.767333 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:08:31.767587 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: BEGIN
17:08:31.767800 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:08:31.772766 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:08:31.773019 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:08:31.773132 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_uo"} */


  create  table "postgres"."public"."kdigo_uo__dbt_tmp"
  as (
    with ur_stg as
(
  select io.icustay_id, io.charttime
  -- we have joined each row to all rows preceding within 24 hours
  -- we can now sum these rows to get total UO over the last 24 hours
  -- we can use case statements to restrict it to only the last 6/12 hours
  -- therefore we have three sums:
  -- 1) over a 6 hour period
  -- 2) over a 12 hour period
  -- 3) over a 24 hour period

  -- note that we assume data charted at charttime corresponds to 1 hour of UO
  -- therefore we use '5' and '11' to restrict the period, rather than 6/12
  -- this assumption may overestimate UO rate when documentation is done less than hourly
  , sum(case when DATETIME_DIFF(io.charttime, iosum.charttime, 'HOUR') <= 5
      then iosum.VALUE
    else null end) as urineoutput_6hr
  , sum(case when DATETIME_DIFF(io.charttime, iosum.charttime, 'HOUR') <= 11
      then iosum.VALUE
    else null end) as urineoutput_12hr
  -- 24 hours
  , sum(iosum.VALUE) as urineoutput_24hr

  -- retain the earliest time used for each summation
  -- this is later used to tabulate rates
  , MIN(case when io.charttime <= DATETIME_ADD(iosum.charttime, INTERVAL '5 HOUR')
      then iosum.charttime
    else null end)
    AS starttime_6hr
  , MIN(case when io.charttime <= DATETIME_ADD(iosum.charttime, INTERVAL '11 HOUR')
      then iosum.charttime
    else null end)
    AS starttime_12hr
  , MIN(iosum.charttime) AS starttime_24hr
  from "postgres"."public"."urine_output" io
  -- this join gives you all UO measurements over a 24 hour period
  left join "postgres"."public"."urine_output" iosum
    on  io.icustay_id = iosum.icustay_id
    and io.charttime >= iosum.charttime
    and io.charttime <= (DATETIME_ADD(iosum.charttime, INTERVAL '23 HOUR'))
  group by io.icustay_id, io.charttime
)
-- calculate hours used to sum UO over
, ur_stg2 AS
(
  select
    icustay_id
  , charttime
  , urineoutput_6hr
  , urineoutput_12hr
  , urineoutput_24hr
  -- calculate time over which we summed UO
  -- note: adding 1 hour as we assume data charted corresponds to previous hour
  -- i.e. if documentation is:
  --  10:00, 100 mL
  --  11:00, 50 mL
  -- then this is two hours of documentation, even though (11:00 - 10:00) is 1 hour
  , ROUND(DATETIME_DIFF(charttime, starttime_6hr, 'HOUR'), 4) + 1 AS uo_tm_6hr
  , ROUND(DATETIME_DIFF(charttime, starttime_12hr, 'HOUR'), 4) + 1 AS uo_tm_12hr
  , ROUND(DATETIME_DIFF(charttime, starttime_24hr, 'HOUR'), 4) + 1 AS uo_tm_24hr
  from ur_stg
)
select
  ur.icustay_id
, ur.charttime
, wd.weight
, ur.urineoutput_6hr
, ur.urineoutput_12hr
, ur.urineoutput_24hr
, ROUND(CAST((ur.urineoutput_6hr/wd.weight/uo_tm_6hr) AS NUMERIC), 4) AS uo_rt_6hr
, ROUND(CAST((ur.urineoutput_12hr/wd.weight/uo_tm_12hr) AS NUMERIC), 4) AS uo_rt_12hr
, ROUND(CAST((ur.urineoutput_24hr/wd.weight/uo_tm_24hr) AS NUMERIC), 4) AS uo_rt_24hr
-- time of earliest UO measurement that was used to calculate the rate
, uo_tm_6hr
, uo_tm_12hr
, uo_tm_24hr
from ur_stg2 ur
left join "postgres"."public"."weight_durations" wd
  on  ur.icustay_id = wd.icustay_id
  and ur.charttime >= wd.starttime
  and ur.charttime <  wd.endtime
order by icustay_id, charttime
  );
17:15:21.181478 [debug] [Thread-1  ]: SQL status: SELECT 3361794 in 409.41 seconds
17:15:21.189890 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:15:21.190153 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_uo"} */
alter table "postgres"."public"."kdigo_uo" rename to "kdigo_uo__dbt_backup"
17:15:21.191925 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:21.196065 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:15:21.196299 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_uo"} */
alter table "postgres"."public"."kdigo_uo__dbt_tmp" rename to "kdigo_uo"
17:15:21.196968 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:21.200822 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: COMMIT
17:15:21.201025 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:15:21.201119 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: COMMIT
17:15:21.202284 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:15:21.204329 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_uo"
17:15:21.204537 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_uo"} */
drop table if exists "postgres"."public"."kdigo_uo__dbt_backup" cascade
17:15:21.212858 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:15:21.216141 [debug] [Thread-1  ]: finished collecting timing info
17:15:21.216378 [debug] [Thread-1  ]: On model.mimic.kdigo_uo: Close
17:15:21.217310 [info ] [Thread-1  ]: 95 of 107 OK created table model public.kdigo_uo ............................... [[32mSELECT 3361794[0m in 409.47s]
17:15:21.217929 [debug] [Thread-1  ]: Finished running node model.mimic.kdigo_uo
17:15:21.218266 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_dose
17:15:21.218982 [info ] [Thread-1  ]: 96 of 107 START table model public.norepinephrine_dose ......................... [RUN]
17:15:21.220040 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_dose"
17:15:21.220376 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_dose
17:15:21.220757 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_dose
17:15:21.224839 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_dose"
17:15:21.225501 [debug] [Thread-1  ]: finished collecting timing info
17:15:21.225736 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_dose
17:15:21.236691 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_dose"
17:15:21.237267 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:21.237389 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: BEGIN
17:15:21.237494 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:21.244264 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:21.244681 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:21.244809 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */


  create  table "postgres"."public"."norepinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of norepinephrine administration
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

  -- case statement determining whether the ITEMID is an instance of vasopressor usage

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30047 and wd.weight is null then rate / 80.0 -- this is rare, only affects a total of ~400 rows
            when itemid = 30047 then rate / wd.weight -- measured in mcgmin
            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin
          else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in (30047,30120) -- norepinephrine
  and cv.icustay_id is not null
  group by cv.icustay_id, cv.charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:15:31.906851 [debug] [Thread-1  ]: SQL status: SELECT 161449 in 10.66 seconds
17:15:31.913030 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:31.913412 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose" rename to "norepinephrine_dose__dbt_backup"
17:15:31.914996 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:31.920255 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:31.920451 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose__dbt_tmp" rename to "norepinephrine_dose"
17:15:31.921174 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:31.924353 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:15:31.924550 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:31.924789 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:15:31.945175 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
17:15:31.948378 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:15:31.948767 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
drop table if exists "postgres"."public"."norepinephrine_dose__dbt_backup" cascade
17:15:31.951942 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:31.955093 [debug] [Thread-1  ]: finished collecting timing info
17:15:31.955330 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: Close
17:15:31.956195 [info ] [Thread-1  ]: 96 of 107 OK created table model public.norepinephrine_dose .................... [[32mSELECT 161449[0m in 10.74s]
17:15:31.956787 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_dose
17:15:31.957173 [debug] [Thread-1  ]: Began running node model.mimic.lods
17:15:31.957795 [info ] [Thread-1  ]: 97 of 107 START table model public.lods ........................................ [RUN]
17:15:31.958563 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.lods"
17:15:31.958846 [debug] [Thread-1  ]: Began compiling node model.mimic.lods
17:15:31.959205 [debug] [Thread-1  ]: Compiling model.mimic.lods
17:15:31.963743 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.lods"
17:15:31.964813 [debug] [Thread-1  ]: finished collecting timing info
17:15:31.965070 [debug] [Thread-1  ]: Began executing node model.mimic.lods
17:15:31.973156 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.lods"
17:15:31.973899 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:31.974110 [debug] [Thread-1  ]: On model.mimic.lods: BEGIN
17:15:31.974271 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:31.979501 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:31.979850 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:31.980076 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */


  create  table "postgres"."public"."lods__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Logistic Organ Dysfunction Score (LODS)
-- This query extracts the logistic organ dysfunction system.
-- This score is a measure of organ failure in a patient.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Variables used in LODS:
--  GCS
--  VITALS: Heart rate, systolic blood pressure
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: blood urea nitrogen, WBC, bilirubin, creatinine, prothrombin time (PT), platelets
--  ABG: PaO2 with associated FiO2

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_durations - generated by ventilation_durations.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql
--  5) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(pao2fio2) as pao2fio2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select  ie.subject_id
      , ie.hadm_id
      , ie.icustay_id
      , ie.intime
      , ie.outtime

      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.pao2fio2_vent_min

      , labs.bun_max
      , labs.bun_min
      , labs.wbc_max
      , labs.wbc_min
      , labs.bilirubin_max
      , labs.creatinine_max
      , labs.pt_min
      , labs.pt_max
      , labs.platelet_min

      , uo.urineoutput

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get pao2/fio2 ratio
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS

  -- neurologic
  , case
    when mingcs is null then null
      when mingcs <  3 then null -- erroneous value/on trach
      when mingcs <=  5 then 5
      when mingcs <=  8 then 3
      when mingcs <= 13 then 1
    else 0
  end as neurologic

  -- cardiovascular
  , case
      when heartrate_max is null
      and sysbp_min is null then null
      when heartrate_min < 30 then 5
      when sysbp_min < 40 then 5
      when sysbp_min <  70 then 3
      when sysbp_max >= 270 then 3
      when heartrate_max >= 140 then 1
      when sysbp_max >= 240 then 1
      when sysbp_min < 90 then 1
    else 0
  end as cardiovascular

  -- renal
  , case
      when bun_max is null
        or urineoutput is null
        or creatinine_max is null
        then null
      when urineoutput <   500.0 then 5
      when bun_max >= 56.0 then 5
      when creatinine_max >= 1.60 then 3
      when urineoutput <   750.0 then 3
      when bun_max >= 28.0 then 3
      when urineoutput >= 10000.0 then 3
      when creatinine_max >= 1.20 then 1
      when bun_max >= 17.0 then 1
      when bun_max >= 7.50 then 1
    else 0
  end as renal

  -- pulmonary
  , case
      when pao2fio2_vent_min is null then 0
      when pao2fio2_vent_min >= 150 then 1
      when pao2fio2_vent_min < 150 then 3
    else null
  end as pulmonary

  -- hematologic
  , case
      when wbc_max is null
        and platelet_min is null
          then null
      when wbc_min <   1.0 then 3
      when wbc_min <   2.5 then 1
      when platelet_min < 50.0 then 1
      when wbc_max >= 50.0 then 1
    else 0
  end as hematologic

  -- hepatic
  -- We have defined the "standard" PT as 12 seconds.
  -- This is an assumption and subsequent analyses may be affected by this assumption.
  , case
      when pt_max is null
        and bilirubin_max is null
          then null
      when bilirubin_max >= 2.0 then 1
      when pt_max > (12+3) then 1
      when pt_min < (12*0.25) then 1
    else 0
  end as hepatic

from cohort
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(neurologic,0)
+ coalesce(cardiovascular,0)
+ coalesce(renal,0)
+ coalesce(pulmonary,0)
+ coalesce(hematologic,0)
+ coalesce(hepatic,0)
  as LODS
, neurologic
, cardiovascular
, renal
, pulmonary
, hematologic
, hepatic
FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:32.272186 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.29 seconds
17:15:32.279640 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:32.279851 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
alter table "postgres"."public"."lods" rename to "lods__dbt_backup"
17:15:32.280581 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:32.286422 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:32.286761 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
alter table "postgres"."public"."lods__dbt_tmp" rename to "lods"
17:15:32.287528 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:32.290401 [debug] [Thread-1  ]: On model.mimic.lods: COMMIT
17:15:32.290764 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:32.291000 [debug] [Thread-1  ]: On model.mimic.lods: COMMIT
17:15:32.297633 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:32.300609 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:15:32.300814 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
drop table if exists "postgres"."public"."lods__dbt_backup" cascade
17:15:32.302927 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:32.305563 [debug] [Thread-1  ]: finished collecting timing info
17:15:32.305788 [debug] [Thread-1  ]: On model.mimic.lods: Close
17:15:32.306648 [info ] [Thread-1  ]: 97 of 107 OK created table model public.lods ................................... [[32mSELECT 61532[0m in 0.35s]
17:15:32.307254 [debug] [Thread-1  ]: Finished running node model.mimic.lods
17:15:32.307594 [debug] [Thread-1  ]: Began running node model.mimic.mlods
17:15:32.308276 [info ] [Thread-1  ]: 98 of 107 START table model public.mlods ....................................... [RUN]
17:15:32.308997 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.mlods"
17:15:32.309195 [debug] [Thread-1  ]: Began compiling node model.mimic.mlods
17:15:32.309488 [debug] [Thread-1  ]: Compiling model.mimic.mlods
17:15:32.313903 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.mlods"
17:15:32.314712 [debug] [Thread-1  ]: finished collecting timing info
17:15:32.314985 [debug] [Thread-1  ]: Began executing node model.mimic.mlods
17:15:32.325897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.mlods"
17:15:32.326581 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.326823 [debug] [Thread-1  ]: On model.mimic.mlods: BEGIN
17:15:32.326985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:32.332640 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:32.332896 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.333065 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */


  create  table "postgres"."public"."mlods__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Modified Logistic organ dysfunction system (mLODS)
-- This query extracts a modified version of the logistic organ dysfunction system.
-- This score was used in the third international definition of sepsis: Sepsis-3.
-- This score is a measure of organ failure in a patient.
-- ------------------------------------------------------------------

-- Reference for LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Reference for modified LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Variables used in mLODS:
--  GCS
--  VITALS: Heart rate, systolic blood pressure
--  FLAGS: ventilation/cpap
--  LABS: WBC, bilirubin, creatinine, platelets
--  ABG: PaO2 with associated FiO2

-- Variables *excluded*, that are used in the original LODS:
--  prothrombin time (PT), blood urea nitrogen, urine output

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and ie.outtime
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , PaO2FiO2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(PaO2FiO2) as PaO2FiO2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select  ie.subject_id
      , ie.hadm_id
      , ie.icustay_id
      , ie.intime
      , ie.outtime

      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.PaO2FiO2_vent_min

      , labs.wbc_max
      , labs.wbc_min
      , labs.bilirubin_max
      , labs.creatinine_max
      , labs.platelet_min

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get pao2/fio2 ratio
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*

  -- neurologic
  , case
    when mingcs is null then null
      when mingcs <  3 then null -- erroneous value/on trach
      when mingcs <=  5 then 5
      when mingcs <=  8 then 3
      when mingcs <= 13 then 1
    else 0
  end as neurologic

  -- cardiovascular
  , case
      when heartrate_max is null
      and sysbp_min is null then null
      when heartrate_min < 30 then 5
      when sysbp_min < 40 then 5
      when sysbp_min <  70 then 3
      when sysbp_max >= 270 then 3
      when heartrate_max >= 140 then 1
      when sysbp_max >= 240 then 1
      when sysbp_min < 90 then 1
    else 0
  end as cardiovascular

  -- renal
  , case
      when creatinine_max is null
        -- or UrineOutput is null
        -- or bun_max is null
        then null
      -- when UrineOutput <   500.0 then 5
      -- when bun_max >= 56.0 then 5
      when creatinine_max >= 1.60 then 3
      -- when UrineOutput <   750.0 then 3
      -- when bun_max >= 28.0 then 3
      -- when UrineOutput >= 10000.0 then 3
      when creatinine_max >= 1.20 then 1
      -- when bun_max >= 17.0 then 1
      -- when bun_max >= 7.50 then 1
    else 0
  end as renal

  -- pulmonary
  , case
      when PaO2FiO2_vent_min is null then 0
      when PaO2FiO2_vent_min >= 150 then 1
      when PaO2FiO2_vent_min < 150 then 3
    else null
  end as pulmonary

  -- hematologic
  , case
      when wbc_max is null
        and platelet_min is null
          then null
      when wbc_min <   1.0 then 3
      when wbc_min <   2.5 then 1
      when platelet_min < 50.0 then 1
      when wbc_max >= 50.0 then 1
    else 0
  end as hematologic

  -- hepatic
  , case
      when bilirubin_max is null
        -- and pt_max is null
          then null
      when bilirubin_max >= 2.0 then 1
      -- when pt_max > (12+3) then 1
      -- when pt_min < (12*0.25) then 1
    else 0
  end as hepatic

from cohort
)
select ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(neurologic,0)
+ coalesce(cardiovascular,0)
+ coalesce(renal,0)
+ coalesce(pulmonary,0)
+ coalesce(hematologic,0)
+ coalesce(hepatic,0)
  as mLODS
, neurologic
, cardiovascular
, renal
, pulmonary
, hematologic
, hepatic
FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:32.545202 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.21 seconds
17:15:32.552382 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.552625 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
alter table "postgres"."public"."mlods" rename to "mlods__dbt_backup"
17:15:32.553358 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:32.557215 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.557440 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
alter table "postgres"."public"."mlods__dbt_tmp" rename to "mlods"
17:15:32.558156 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:32.561074 [debug] [Thread-1  ]: On model.mimic.mlods: COMMIT
17:15:32.561281 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.561451 [debug] [Thread-1  ]: On model.mimic.mlods: COMMIT
17:15:32.567360 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:32.570099 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:15:32.570298 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
drop table if exists "postgres"."public"."mlods__dbt_backup" cascade
17:15:32.572187 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:32.575015 [debug] [Thread-1  ]: finished collecting timing info
17:15:32.575252 [debug] [Thread-1  ]: On model.mimic.mlods: Close
17:15:32.576104 [info ] [Thread-1  ]: 98 of 107 OK created table model public.mlods .................................. [[32mSELECT 61532[0m in 0.27s]
17:15:32.576691 [debug] [Thread-1  ]: Finished running node model.mimic.mlods
17:15:32.577051 [debug] [Thread-1  ]: Began running node model.mimic.sapsii
17:15:32.577594 [info ] [Thread-1  ]: 99 of 107 START table model public.sapsii ...................................... [RUN]
17:15:32.578671 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sapsii"
17:15:32.579094 [debug] [Thread-1  ]: Began compiling node model.mimic.sapsii
17:15:32.579487 [debug] [Thread-1  ]: Compiling model.mimic.sapsii
17:15:32.584702 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sapsii"
17:15:32.585398 [debug] [Thread-1  ]: finished collecting timing info
17:15:32.585763 [debug] [Thread-1  ]: Began executing node model.mimic.sapsii
17:15:32.596878 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sapsii"
17:15:32.597523 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:32.597745 [debug] [Thread-1  ]: On model.mimic.sapsii: BEGIN
17:15:32.597907 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:32.605977 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:32.606284 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:32.606388 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */


  create  table "postgres"."public"."sapsii__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Simplified Acute Physiology Score II (SAPS II)
-- This query extracts the simplified acute physiology score II.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SAPS II:
--    Le Gall, Jean-Roger, Stanley Lemeshow, and Fabienne Saulnier.
--    "A new simplified acute physiology score (SAPS II) based on a European/North American multicenter study."
--    JAMA 270, no. 24 (1993): 2957-2963.

-- Variables used in SAPS II:
--  Age, GCS
--  VITALS: Heart rate, systolic blood pressure, temperature
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: PaO2/FiO2 ratio, blood urea nitrogen, WBC, potassium, sodium, HCO3

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_durations - generated by ventilation_durations.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql
--  6) blood_gas_arterial_first_day - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
-- extract a flag for surgical service
-- this combined with "elective" FROM admissions table defines elective/non-elective surgery
, surgflag as
(
  select adm.hadm_id
    , case when lower(curr_service) like '%surg%' then 1 else 0 end as surgical
    , ROW_NUMBER() over
    (
      PARTITION BY adm.HADM_ID
      ORDER BY TRANSFERTIME
    ) as serviceOrder
  FROM admissions adm
  left join services se
    on adm.hadm_id = se.hadm_id
)
-- icd-9 diagnostic codes are our best source for comorbidity information
-- unfortunately, they are technically a-causal
-- however, this shouldn't matter too much for the SAPS II comorbidities
, comorb as
(
select hadm_id
-- these are slightly different than elixhauser comorbidities, but based on them
-- they include some non-comorbid ICD-9 codes (e.g. 20302, relapse of multiple myeloma)
  , max(CASE
    when SUBSTR(icd9_code,1,3) BETWEEN '042' AND '044' THEN 1
  		end) as aids      /* HIV and AIDS */
  , max(CASE
    when icd9_code between '20000' and '20238' then 1 -- lymphoma
    when icd9_code between '20240' and '20248' then 1 -- leukemia
    when icd9_code between '20250' and '20302' then 1 -- lymphoma
    when icd9_code between '20310' and '20312' then 1 -- leukemia
    when icd9_code between '20302' and '20382' then 1 -- lymphoma
    when icd9_code between '20400' and '20522' then 1 -- chronic leukemia
    when icd9_code between '20580' and '20702' then 1 -- other myeloid leukemia
    when icd9_code between '20720' and '20892' then 1 -- other myeloid leukemia
    when SUBSTR(icd9_code,1,4) = '2386' then 1 -- lymphoma
    when SUBSTR(icd9_code,1,4) = '2733' then 1 -- lymphoma
  		end) as hem
  , max(CASE
    when SUBSTR(icd9_code,1,4) BETWEEN '1960' AND '1991' THEN 1
    when icd9_code between '20970' and '20975' then 1
    when icd9_code = '20979' then 1
    when icd9_code = '78951' then 1
  		end) as mets      /* Metastatic cancer */
  from diagnoses_icd
  group by hadm_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(pao2fio2) as pao2fio2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      -- the casts ensure the result is numeric.. we could equally extract EPOCH from the interval
      -- however this code works in Oracle and Postgres
      , DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') as age

      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min
      , vital.tempc_max
      , vital.tempc_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.pao2fio2_vent_min

      , uo.urineoutput

      , labs.bun_min
      , labs.bun_max
      , labs.wbc_min
      , labs.wbc_max
      , labs.potassium_min
      , labs.potassium_max
      , labs.sodium_min
      , labs.sodium_max
      , labs.bicarbonate_min
      , labs.bicarbonate_max
      , labs.bilirubin_min
      , labs.bilirubin_max

      , gcs.mingcs

      , comorb.aids
      , comorb.hem
      , comorb.mets

      , case
          when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
            then 'ScheduledSurgical'
          when adm.ADMISSION_TYPE != 'ELECTIVE' and sf.surgical = 1
            then 'UnscheduledSurgical'
          else 'Medical'
        end as admissiontype


FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above views
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id
left join surgflag sf
  on adm.hadm_id = sf.hadm_id and sf.serviceOrder = 1
left join comorb
  on ie.hadm_id = comorb.hadm_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS
  , case
      when age is null then null
      when age <  40 then 0
      when age <  60 then 7
      when age <  70 then 12
      when age <  75 then 15
      when age <  80 then 16
      when age >= 80 then 18
    end as age_score

  , case
      when heartrate_max is null then null
      when heartrate_min <   40 then 11
      when heartrate_max >= 160 then 7
      when heartrate_max >= 120 then 4
      when heartrate_min  <  70 then 2
      when  heartrate_max >= 70 and heartrate_max < 120
        and heartrate_min >= 70 and heartrate_min < 120
      then 0
    end as hr_score

  , case
      when  sysbp_min is null then null
      when  sysbp_min <   70 then 13
      when  sysbp_min <  100 then 5
      when  sysbp_max >= 200 then 2
      when  sysbp_max >= 100 and sysbp_max < 200
        and sysbp_min >= 100 and sysbp_min < 200
        then 0
    end as sysbp_score

  , case
      when tempc_max is null then null
      when tempc_min <  39.0 then 0
      when tempc_max >= 39.0 then 3
    end as temp_score

  , case
      when pao2fio2_vent_min is null then null
      when pao2fio2_vent_min <  100 then 11
      when pao2fio2_vent_min <  200 then 9
      when pao2fio2_vent_min >= 200 then 6
    end as pao2fio2_score

  , case
      when urineoutput is null then null
      when urineoutput <   500.0 then 11
      when urineoutput <  1000.0 then 4
      when urineoutput >= 1000.0 then 0
    end as uo_score

  , case
      when bun_max is null then null
      when bun_max <  28.0 then 0
      when bun_max <  84.0 then 6
      when bun_max >= 84.0 then 10
    end as bun_score

  , case
      when wbc_max is null then null
      when wbc_min <   1.0 then 12
      when wbc_max >= 20.0 then 3
      when wbc_max >=  1.0 and wbc_max < 20.0
       and wbc_min >=  1.0 and wbc_min < 20.0
        then 0
    end as wbc_score

  , case
      when potassium_max is null then null
      when potassium_min <  3.0 then 3
      when potassium_max >= 5.0 then 3
      when potassium_max >= 3.0 and potassium_max < 5.0
       and potassium_min >= 3.0 and potassium_min < 5.0
        then 0
      end as potassium_score

  , case
      when sodium_max is null then null
      when sodium_min  < 125 then 5
      when sodium_max >= 145 then 1
      when sodium_max >= 125 and sodium_max < 145
       and sodium_min >= 125 and sodium_min < 145
        then 0
      end as sodium_score

  , case
      when bicarbonate_max is null then null
      when bicarbonate_min <  15.0 then 5
      when bicarbonate_min <  20.0 then 3
      when bicarbonate_max >= 20.0
       and bicarbonate_min >= 20.0
          then 0
      end as bicarbonate_score

  , case
      when bilirubin_max is null then null
      when bilirubin_max  < 4.0 then 0
      when bilirubin_max  < 6.0 then 4
      when bilirubin_max >= 6.0 then 9
      end as bilirubin_score

   , case
      when mingcs is null then null
        when mingcs <  3 then null -- erroneous value/on trach
        when mingcs <  6 then 26
        when mingcs <  9 then 13
        when mingcs < 11 then 7
        when mingcs < 14 then 5
        when mingcs >= 14
         and mingcs <= 15
          then 0
        end as gcs_score

    , case
        when aids = 1 then 17
        when hem  = 1 then 10
        when mets = 1 then 9
        else 0
      end as comorbidity_score

    , case
        when admissiontype = 'ScheduledSurgical' then 0
        when admissiontype = 'Medical' then 6
        when admissiontype = 'UnscheduledSurgical' then 8
        else null
      end as admissiontype_score

from cohort
)
-- Calculate SAPS II here so we can use it in the probability calculation below
, score as
(
  select s.*
  -- coalesce statements impute normal score of zero if data element is missing
  , coalesce(age_score,0)
  + coalesce(hr_score,0)
  + coalesce(sysbp_score,0)
  + coalesce(temp_score,0)
  + coalesce(pao2fio2_score,0)
  + coalesce(uo_score,0)
  + coalesce(bun_score,0)
  + coalesce(wbc_score,0)
  + coalesce(potassium_score,0)
  + coalesce(sodium_score,0)
  + coalesce(bicarbonate_score,0)
  + coalesce(bilirubin_score,0)
  + coalesce(gcs_score,0)
  + coalesce(comorbidity_score,0)
  + coalesce(admissiontype_score,0)
    as sapsii
  from scorecomp s
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, sapsii
, 1 / (1 + exp(- (-7.7631 + 0.0737*(sapsii) + 0.9971*(ln(sapsii + 1))) )) as sapsii_prob
, age_score
, hr_score
, sysbp_score
, temp_score
, pao2fio2_score
, uo_score
, bun_score
, wbc_score
, potassium_score
, sodium_score
, bicarbonate_score
, bilirubin_score
, gcs_score
, comorbidity_score
, admissiontype_score
FROM icustays ie
left join score s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:34.704990 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 2.1 seconds
17:15:34.712887 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:34.713297 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
alter table "postgres"."public"."sapsii" rename to "sapsii__dbt_backup"
17:15:34.714696 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:34.718957 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:34.719176 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
alter table "postgres"."public"."sapsii__dbt_tmp" rename to "sapsii"
17:15:34.719876 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:34.723389 [debug] [Thread-1  ]: On model.mimic.sapsii: COMMIT
17:15:34.723597 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:34.723805 [debug] [Thread-1  ]: On model.mimic.sapsii: COMMIT
17:15:34.731835 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:34.733833 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:15:34.734036 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
drop table if exists "postgres"."public"."sapsii__dbt_backup" cascade
17:15:34.736175 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:34.739307 [debug] [Thread-1  ]: finished collecting timing info
17:15:34.739547 [debug] [Thread-1  ]: On model.mimic.sapsii: Close
17:15:34.740416 [info ] [Thread-1  ]: 99 of 107 OK created table model public.sapsii ................................. [[32mSELECT 61532[0m in 2.16s]
17:15:34.741019 [debug] [Thread-1  ]: Finished running node model.mimic.sapsii
17:15:34.741613 [debug] [Thread-1  ]: Began running node model.mimic.sofa
17:15:34.742366 [info ] [Thread-1  ]: 100 of 107 START table model public.sofa ....................................... [RUN]
17:15:34.743599 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sofa"
17:15:34.744185 [debug] [Thread-1  ]: Began compiling node model.mimic.sofa
17:15:34.744433 [debug] [Thread-1  ]: Compiling model.mimic.sofa
17:15:34.750882 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sofa"
17:15:34.751459 [debug] [Thread-1  ]: finished collecting timing info
17:15:34.751750 [debug] [Thread-1  ]: Began executing node model.mimic.sofa
17:15:34.765757 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sofa"
17:15:34.766306 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:34.766518 [debug] [Thread-1  ]: On model.mimic.sofa: BEGIN
17:15:34.767153 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:34.775017 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:34.775399 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:34.775755 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */


  create  table "postgres"."public"."sofa__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Sequential Organ Failure Assessment (SOFA)
-- This query extracts the sequential organ failure assessment (formally: sepsis-related organ failure assessment).
-- This score is a measure of organ failure for patients in the ICU.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SOFA:
--    Jean-Louis Vincent, Rui Moreno, Jukka Takala, Sheila Willatts, Arnaldo De Mendonça,
--    Hajo Bruining, C. K. Reinhart, Peter M Suter, and L. G. Thijs.
--    "The SOFA (Sepsis-related Organ Failure Assessment) score to describe organ dysfunction/failure."
--    Intensive care medicine 22, no. 7 (1996): 707-710.

-- Variables used in SOFA:
--  GCS, MAP, FiO2, Ventilation status (sourced FROM chartevents)
--  Creatinine, Bilirubin, FiO2, PaO2, Platelets (sourced FROM labevents)
--  Dobutamine, Epinephrine, Norepinephrine (sourced FROM inputevents_mv and INPUTEVENTS_CV)
--  Urine output (sourced from OUTPUTEVENTS)

-- The following views required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vitals_first_day - generated by vitals-first-day.sql
--  3) gcs_first_day - generated by gcs-first-day.sql
--  4) labs_first_day - generated by labs-first-day.sql
--  5) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql
--  6) echodata - generated by echo-data.sql
--  7) ventilation_durations - generated by ventilation_durations.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with wt AS
(
  SELECT ie.icustay_id
    -- ensure weight is measured in kg
    , avg(CASE
        WHEN itemid IN (762, 763, 3723, 3580, 226512)
          THEN valuenum
        -- convert lbs to kgs
        WHEN itemid IN (3581)
          THEN valuenum * 0.45359237
        WHEN itemid IN (3582)
          THEN valuenum * 0.0283495231
        ELSE null
      END) AS weight

  FROM icustays ie
  left join chartevents c
    on ie.icustay_id = c.icustay_id
  WHERE valuenum IS NOT NULL
  AND itemid IN
  (
    762, 763, 3723, 3580,                     -- Weight Kg
    3581,                                     -- Weight lb
    3582,                                     -- Weight oz
    226512 -- Metavision: Admission Weight (Kg)
  )
  AND valuenum != 0
  and charttime between DATETIME_SUB(ie.intime, INTERVAL '1' DAY) and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  -- exclude rows marked as error
  AND (c.error IS NULL OR c.error = 0)
  group by ie.icustay_id
)
-- 5% of patients are missing a weight, but we can impute weight using their echo notes
, echo2 as(
  select ie.icustay_id, avg(weight * 0.45359237) as weight
  FROM icustays ie
  left join "postgres"."public"."echo_data" echo
    on ie.hadm_id = echo.hadm_id
    and echo.charttime > DATETIME_SUB(ie.intime, INTERVAL '7' DAY)
    and echo.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  group by ie.icustay_id
)
, vaso_cv as
(
  select ie.icustay_id
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case
            when itemid = 30047 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin
            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin
            else null
          end) as rate_norepinephrine

    , max(case
            when itemid =  30044 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin
            when itemid in (30119,30309) then rate -- measured in mcgkgmin
            else null
          end) as rate_epinephrine

    , max(case when itemid in (30043,30307) then rate end) as rate_dopamine
    , max(case when itemid in (30042,30306) then rate end) as rate_dobutamine

  FROM icustays ie
  inner join inputevents_cv cv
    on ie.icustay_id = cv.icustay_id and cv.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  left join wt
    on ie.icustay_id = wt.icustay_id
  left join echo2 ec
    on ie.icustay_id = ec.icustay_id
  where itemid in (30047,30120,30044,30119,30309,30043,30307,30042,30306)
  and rate is not null
  group by ie.icustay_id
)
, vaso_mv as
(
  select ie.icustay_id
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 221906 then rate end) as rate_norepinephrine
    , max(case when itemid = 221289 then rate end) as rate_epinephrine
    , max(case when itemid = 221662 then rate end) as rate_dopamine
    , max(case when itemid = 221653 then rate end) as rate_dobutamine
  FROM icustays ie
  inner join inputevents_mv mv
    on ie.icustay_id = mv.icustay_id and mv.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in (221906,221289,221662,221653)
  -- 'Rewritten' orders are not delivered to the patient
  and statusdescription != 'Rewritten'
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as isvent
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  order by bg.icustay_id, bg.charttime
)
, pafi2 as
(
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  select icustay_id
  , min(case when isvent = 0 then pao2fio2 else null end) as pao2fio2_novent_min
  , min(case when isvent = 1 then pao2fio2 else null end) as pao2fio2_vent_min
  from pafi1
  group by icustay_id
)
-- Aggregate the components for the score
, scorecomp as
(
select ie.icustay_id
  , v.meanbp_min
  , coalesce(cv.rate_norepinephrine, mv.rate_norepinephrine) as rate_norepinephrine
  , coalesce(cv.rate_epinephrine, mv.rate_epinephrine) as rate_epinephrine
  , coalesce(cv.rate_dopamine, mv.rate_dopamine) as rate_dopamine
  , coalesce(cv.rate_dobutamine, mv.rate_dobutamine) as rate_dobutamine

  , l.creatinine_max
  , l.bilirubin_max
  , l.platelet_min

  , pf.pao2fio2_novent_min
  , pf.pao2fio2_vent_min

  , uo.urineoutput

  , gcs.mingcs
FROM icustays ie
left join vaso_cv cv
  on ie.icustay_id = cv.icustay_id
left join vaso_mv mv
  on ie.icustay_id = mv.icustay_id
left join pafi2 pf
 on ie.icustay_id = pf.icustay_id
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."labs_first_day" l
  on ie.icustay_id = l.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id
  -- Respiration
  , case
      when pao2fio2_vent_min   < 100 then 4
      when pao2fio2_vent_min   < 200 then 3
      when pao2fio2_novent_min < 300 then 2
      when pao2fio2_novent_min < 400 then 1
      when coalesce(pao2fio2_vent_min, pao2fio2_novent_min) is null then null
      else 0
    end as respiration

  -- Coagulation
  , case
      when platelet_min < 20  then 4
      when platelet_min < 50  then 3
      when platelet_min < 100 then 2
      when platelet_min < 150 then 1
      when platelet_min is null then null
      else 0
    end as coagulation

  -- Liver
  , case
      -- Bilirubin checks in mg/dL
        when bilirubin_max >= 12.0 then 4
        when bilirubin_max >= 6.0  then 3
        when bilirubin_max >= 2.0  then 2
        when bilirubin_max >= 1.2  then 1
        when bilirubin_max is null then null
        else 0
      end as liver

  -- Cardiovascular
  , case
      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4
      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3
      when rate_dopamine >  0 or rate_dobutamine > 0 then 2
      when meanbp_min < 70 then 1
      when coalesce(meanbp_min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null
      else 0
    end as cardiovascular

  -- Neurological failure (GCS)
  , case
      when (mingcs >= 13 and mingcs <= 14) then 1
      when (mingcs >= 10 and mingcs <= 12) then 2
      when (mingcs >=  6 and mingcs <=  9) then 3
      when  mingcs <   6 then 4
      when  mingcs is null then null
  else 0 end
    as cns

  -- Renal failure - high creatinine or low urine output
  , case
    when (creatinine_max >= 5.0) then 4
    when  urineoutput < 200 then 4
    when (creatinine_max >= 3.5 and creatinine_max < 5.0) then 3
    when  urineoutput < 500 then 3
    when (creatinine_max >= 2.0 and creatinine_max < 3.5) then 2
    when (creatinine_max >= 1.2 and creatinine_max < 2.0) then 1
    when coalesce(urineoutput, creatinine_max) is null then null
  else 0 end
    as renal
  from scorecomp
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
  -- Combine all the scores to get SOFA
  -- Impute 0 if the score is missing
  , coalesce(respiration,0)
  + coalesce(coagulation,0)
  + coalesce(liver,0)
  + coalesce(cardiovascular,0)
  + coalesce(cns,0)
  + coalesce(renal,0)
  as SOFA
, respiration
, coagulation
, liver
, cardiovascular
, cns
, renal
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:40.279699 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 5.5 seconds
17:15:40.285212 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:40.285468 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
alter table "postgres"."public"."sofa" rename to "sofa__dbt_backup"
17:15:40.287796 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:40.292073 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:40.292279 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
alter table "postgres"."public"."sofa__dbt_tmp" rename to "sofa"
17:15:40.293073 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:40.296689 [debug] [Thread-1  ]: On model.mimic.sofa: COMMIT
17:15:40.296890 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:40.297082 [debug] [Thread-1  ]: On model.mimic.sofa: COMMIT
17:15:40.304586 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:40.306305 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:15:40.306585 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
drop table if exists "postgres"."public"."sofa__dbt_backup" cascade
17:15:40.310182 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:40.313684 [debug] [Thread-1  ]: finished collecting timing info
17:15:40.313915 [debug] [Thread-1  ]: On model.mimic.sofa: Close
17:15:40.314793 [info ] [Thread-1  ]: 100 of 107 OK created table model public.sofa .................................. [[32mSELECT 61532[0m in 5.57s]
17:15:40.315481 [debug] [Thread-1  ]: Finished running node model.mimic.sofa
17:15:40.315928 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_first_day
17:15:40.316694 [info ] [Thread-1  ]: 101 of 107 START table model public.ventilation_first_day ...................... [RUN]
17:15:40.317491 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_first_day"
17:15:40.317790 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_first_day
17:15:40.318054 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_first_day
17:15:40.320417 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_first_day"
17:15:40.321488 [debug] [Thread-1  ]: finished collecting timing info
17:15:40.321867 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_first_day
17:15:40.335893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_first_day"
17:15:40.336718 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.336939 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: BEGIN
17:15:40.337130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:40.343471 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:40.343727 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.343903 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */


  create  table "postgres"."public"."ventilation_first_day__dbt_tmp"
  as (
    -- Determines if a patient is ventilated on the first day of their ICU stay.
-- Creates a table with the result.
-- Requires the ventilation_durations table, generated by ../ventilation-durations.sql

select
  ie.subject_id, ie.hadm_id, ie.icustay_id
  -- if vd.icustay_id is not null, then they have a valid ventilation event
  -- in this case, we say they are ventilated
  -- otherwise, they are not
  , max(case
      when vd.icustay_id is not null then 1
    else 0 end) as vent
FROM icustays ie
left join "postgres"."public"."ventilation_durations" vd
  on ie.icustay_id = vd.icustay_id
  and
  (
    -- ventilation duration overlaps with ICU admission -> vented on admission
    (vd.starttime <= ie.intime and vd.endtime >= ie.intime)
    -- ventilation started during the first day
    OR (vd.starttime >= ie.intime and vd.starttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
  )
group by ie.subject_id, ie.hadm_id, ie.icustay_id
order by ie.subject_id, ie.hadm_id, ie.icustay_id
  );
17:15:40.438886 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.09 seconds
17:15:40.443329 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.443541 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
alter table "postgres"."public"."ventilation_first_day" rename to "ventilation_first_day__dbt_backup"
17:15:40.444240 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:40.448178 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.448380 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
alter table "postgres"."public"."ventilation_first_day__dbt_tmp" rename to "ventilation_first_day"
17:15:40.449064 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:40.452347 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: COMMIT
17:15:40.452541 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.452763 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: COMMIT
17:15:40.463711 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:40.466147 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:15:40.466367 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
drop table if exists "postgres"."public"."ventilation_first_day__dbt_backup" cascade
17:15:40.468392 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:40.471108 [debug] [Thread-1  ]: finished collecting timing info
17:15:40.471352 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: Close
17:15:40.472366 [info ] [Thread-1  ]: 101 of 107 OK created table model public.ventilation_first_day ................. [[32mSELECT 61532[0m in 0.15s]
17:15:40.473106 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_first_day
17:15:40.473565 [debug] [Thread-1  ]: Began running node model.mimic.kdigo_stages
17:15:40.474279 [info ] [Thread-1  ]: 102 of 107 START table model public.kdigo_stages ............................... [RUN]
17:15:40.475640 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.kdigo_stages"
17:15:40.475940 [debug] [Thread-1  ]: Began compiling node model.mimic.kdigo_stages
17:15:40.476199 [debug] [Thread-1  ]: Compiling model.mimic.kdigo_stages
17:15:40.479718 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.kdigo_stages"
17:15:40.480710 [debug] [Thread-1  ]: finished collecting timing info
17:15:40.481014 [debug] [Thread-1  ]: Began executing node model.mimic.kdigo_stages
17:15:40.491427 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.kdigo_stages"
17:15:40.492036 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:40.492329 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: BEGIN
17:15:40.492641 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:40.498309 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:40.498810 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:40.499048 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages"} */


  create  table "postgres"."public"."kdigo_stages__dbt_tmp"
  as (
    -- This query checks if the patient had AKI according to KDIGO.
-- AKI is calculated every time a creatinine or urine output measurement occurs.
-- Baseline creatinine is defined as the lowest creatinine in the past 7 days.

-- get creatinine stages
with cr_stg AS
(
  SELECT
    cr.icustay_id
    , cr.charttime
    , cr.creat
    , case
        -- 3x baseline
        when cr.creat >= (cr.creat_low_past_7day*3.0) then 3
        -- *OR* cr >= 4.0 with associated increase
        when cr.creat >= 4
        -- For patients reaching Stage 3 by SCr >4.0 mg/dl
        -- require that the patient first achieve ... acute increase >= 0.3 within 48 hr
        -- *or* an increase of >= 1.5 times baseline
        and (cr.creat_low_past_48hr <= 3.7 OR cr.creat >= (1.5*cr.creat_low_past_7day))
            then 3 
        -- TODO: initiation of RRT
        when cr.creat >= (cr.creat_low_past_7day*2.0) then 2
        when cr.creat >= (cr.creat_low_past_48hr+0.3) then 1
        when cr.creat >= (cr.creat_low_past_7day*1.5) then 1
    else 0 end as aki_stage_creat
  FROM "postgres"."public"."kdigo_creatinine" cr
)
-- stages for UO / creat
, uo_stg as
(
  select
      uo.icustay_id
    , uo.charttime
    , uo.weight
    , uo.uo_rt_6hr
    , uo.uo_rt_12hr
    , uo.uo_rt_24hr
    -- AKI stages according to urine output
    , CASE
        WHEN uo.uo_rt_6hr IS NULL THEN NULL
        -- require patient to be in ICU for at least 6 hours to stage UO
        WHEN uo.charttime <= DATETIME_ADD(ie.intime, INTERVAL '6' HOUR) THEN 0
        -- require the UO rate to be calculated over half the period
        -- i.e. for uo rate over 24 hours, require documentation at least 12 hr apart
        WHEN uo.uo_tm_24hr >= 11 AND uo.uo_rt_24hr < 0.3 THEN 3
        WHEN uo.uo_tm_12hr >= 5 AND uo.uo_rt_12hr = 0 THEN 3
        WHEN uo.uo_tm_12hr >= 5 AND uo.uo_rt_12hr < 0.5 THEN 2
        WHEN uo.uo_tm_6hr >= 2 AND uo.uo_rt_6hr  < 0.5 THEN 1
    ELSE 0 END AS aki_stage_uo
  from "postgres"."public"."kdigo_uo" uo
  INNER JOIN icustays ie
    ON uo.icustay_id = ie.icustay_id
)
-- get all charttimes documented
, tm_stg AS
(
    SELECT
      icustay_id, charttime
    FROM cr_stg
    UNION DISTINCT
    SELECT
      icustay_id, charttime
    FROM uo_stg
)
select
    ie.icustay_id
  , tm.charttime
  , cr.creat
  , cr.aki_stage_creat
  , uo.uo_rt_6hr
  , uo.uo_rt_12hr
  , uo.uo_rt_24hr
  , uo.aki_stage_uo
  -- Classify AKI using both creatinine/urine output criteria
  , GREATEST(
      COALESCE(cr.aki_stage_creat, 0),
      COALESCE(uo.aki_stage_uo, 0)
    ) AS aki_stage
FROM icustays ie
-- get all possible charttimes as listed in tm_stg
LEFT JOIN tm_stg tm
  ON ie.icustay_id = tm.icustay_id
LEFT JOIN cr_stg cr
  ON ie.icustay_id = cr.icustay_id
  AND tm.charttime = cr.charttime
LEFT JOIN uo_stg uo
  ON ie.icustay_id = uo.icustay_id
  AND tm.charttime = uo.charttime
order by ie.icustay_id, tm.charttime
  );
17:15:48.536171 [debug] [Thread-1  ]: SQL status: SELECT 3423326 in 8.04 seconds
17:15:48.543149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:48.543370 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages"} */
alter table "postgres"."public"."kdigo_stages" rename to "kdigo_stages__dbt_backup"
17:15:48.544169 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:48.548433 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:48.548658 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages"} */
alter table "postgres"."public"."kdigo_stages__dbt_tmp" rename to "kdigo_stages"
17:15:48.549264 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:48.552643 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: COMMIT
17:15:48.552865 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:48.553047 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: COMMIT
17:15:48.555284 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:15:48.557678 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages"
17:15:48.557883 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages"} */
drop table if exists "postgres"."public"."kdigo_stages__dbt_backup" cascade
17:15:48.564343 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:15:48.567397 [debug] [Thread-1  ]: finished collecting timing info
17:15:48.567653 [debug] [Thread-1  ]: On model.mimic.kdigo_stages: Close
17:15:48.568473 [info ] [Thread-1  ]: 102 of 107 OK created table model public.kdigo_stages .......................... [[32mSELECT 3423326[0m in 8.09s]
17:15:48.569080 [debug] [Thread-1  ]: Finished running node model.mimic.kdigo_stages
17:15:48.569642 [debug] [Thread-1  ]: Began running node model.mimic.apsiii
17:15:48.570160 [info ] [Thread-1  ]: 103 of 107 START table model public.apsiii ..................................... [RUN]
17:15:48.572010 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.apsiii"
17:15:48.572765 [debug] [Thread-1  ]: Began compiling node model.mimic.apsiii
17:15:48.573145 [debug] [Thread-1  ]: Compiling model.mimic.apsiii
17:15:48.580433 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.apsiii"
17:15:48.581153 [debug] [Thread-1  ]: finished collecting timing info
17:15:48.581512 [debug] [Thread-1  ]: Began executing node model.mimic.apsiii
17:15:48.602965 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.apsiii"
17:15:48.604299 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:48.604679 [debug] [Thread-1  ]: On model.mimic.apsiii: BEGIN
17:15:48.605177 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:48.613434 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:48.613795 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:48.614038 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */


  create  table "postgres"."public"."apsiii__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Acute Physiology Score III (APS III)
-- This query extracts the acute physiology score III.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for APS III:
--    Knaus WA, Wagner DP, Draper EA, Zimmerman JE, Bergner M, Bastos PG, Sirio CA, Murphy DJ, Lotring T, Damiano A.
--    The APACHE III prognostic system. Risk prediction of hospital mortality for critically ill hospitalized adults.
--    Chest Journal. 1991 Dec 1100(6):1619-36.

-- Reference for the equation for calibrating APS III to hospital mortality:
--    Johnson, A. E. W. (2015). Mortality prediction and acuity assessment in critical care.
--    University of Oxford, Oxford, UK.

-- Variables used in APS III:
--  GCS
--  VITALS: Heart rate, mean blood pressure, temperature, respiration rate
--  FLAGS: ventilation/cpap, chronic dialysis
--  IO: urine output
--  LABS: pao2, A-aDO2, hematocrit, WBC, creatinine
--        , blood urea nitrogen, sodium, albumin, bilirubin, glucose, pH, pCO2

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate icustay_ids.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- List of TODO:
-- The site of temperature is not incorporated. Axillary measurements should be increased by 1 degree.
-- Unfortunately the data for metavision is not available at the moment.
--  674 | Temp. Site
--  224642 | Temperature Site

with pa as
(
  select bg.icustay_id, bg.charttime
  , po2 as PaO2
  , ROW_NUMBER() over (partition by bg.icustay_id ORDER BY bg.po2 DESC) as rn
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join ventilation_durations vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  WHERE vd.icustay_id is null -- patient is *not* ventilated
  -- and fio2 < 50, or if no fio2, assume room air
  AND coalesce(fio2, fio2_chartevents, 21) < 50
  AND bg.po2 IS NOT NULL
)
, aa as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , bg.aado2
  , ROW_NUMBER() over (partition by bg.icustay_id ORDER BY bg.aado2 DESC) as rn
  -- row number indicating the highest AaDO2
  from blood_gas_first_day_arterial bg
  INNER JOIN ventilation_durations vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  WHERE vd.icustay_id is not null -- patient is ventilated
  AND coalesce(fio2, fio2_chartevents) >= 50
  AND bg.aado2 IS NOT NULL
)
-- because ph/pco2 rules are an interaction *within* a blood gas, we calculate them here
-- the worse score is then taken for the final calculation
, acidbase as
(
  select bg.icustay_id
  , ph, pco2 as paco2
  , case
      when ph is null or pco2 is null then null
      when ph < 7.20 then
        case
          when pco2 < 50 then 12
          else 4
        end
      when ph < 7.30 then
        case
          when pco2 < 30 then 9
          when pco2 < 40 then 6
          when pco2 < 50 then 3
          else 2
        end
      when ph < 7.35 then
        case
          when pco2 < 30 then 9
          when pco2 < 45 then 0
          else 1
        end
      when ph < 7.45 then
        case
          when pco2 < 30 then 5
          when pco2 < 45 then 0
          else 1
        end
      when ph < 7.50 then
        case
          when pco2 < 30 then 5
          when pco2 < 35 then 0
          when pco2 < 45 then 2
          else 12
        end
      when ph < 7.60 then
        case
          when pco2 < 40 then 3
          else 12
        end
      else -- ph >= 7.60
        case
          when pco2 < 25 then 0
          when pco2 < 40 then 3
          else 12
        end
    end as acidbase_score
  from blood_gas_first_day_arterial bg
  where ph is not null and pco2 is not null
)
, acidbase_max as
(
  select icustay_id, acidbase_score, ph, paco2
    -- create integer which indexes maximum value of score with 1
  , ROW_NUMBER() over (partition by icustay_id ORDER BY acidbase_score DESC) as acidbase_rn
  from acidbase
)
-- define acute renal failure (ARF) as:
--  creatinine >=1.5 mg/dl
--  and urine output <410 cc/day
--  and no chronic dialysis
, arf as
(
  select ie.icustay_id
    , case
        when labs.creatinine_max >= 1.5
        and  uo.urineoutput < 410
        -- acute renal failure is only coded if the patient is not on chronic dialysis
        -- we use ICD-9 coding of ESRD as a proxy for chronic dialysis
        and  icd.ckd = 0
          then 1
      else 0 end as arf
  FROM icustays ie
  left join "postgres"."public"."urine_output_first_day" uo
    on ie.icustay_id = uo.icustay_id
  left join "postgres"."public"."labs_first_day" labs
    on ie.icustay_id = labs.icustay_id
  left join
  (
    select hadm_id
      , max(case
          -- severe kidney failure requiring use of dialysis
          when icd9_code in  ('5854','5855','5856') then 1
          -- we do not include 5859 as that is sometimes coded for acute-on-chronic ARF
        else 0 end)
      as ckd
    from diagnoses_icd
    group by hadm_id
  ) icd
    on ie.hadm_id = icd.hadm_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      , vital.heartrate_min
      , vital.heartrate_max
      , vital.meanbp_min
      , vital.meanbp_max
      , vital.tempc_min
      , vital.tempc_max
      , vital.resprate_min
      , vital.resprate_max

      , pa.pao2
      , aa.aado2

      , ab.ph
      , ab.paco2
      , ab.acidbase_score

      , labs.hematocrit_min
      , labs.hematocrit_max
      , labs.wbc_min
      , labs.wbc_max
      , labs.creatinine_min
      , labs.creatinine_max
      , labs.bun_min
      , labs.bun_max
      , labs.sodium_min
      , labs.sodium_max
      , labs.albumin_min
      , labs.albumin_max
      , labs.bilirubin_min
      , labs.bilirubin_max

      , case
          when labs.glucose_max is null and vital.glucose_max is null
            then null
          when labs.glucose_max is null or vital.glucose_max > labs.glucose_max
            then vital.glucose_max
          when vital.glucose_max is null or labs.glucose_max > vital.glucose_max
            then labs.glucose_max
          else labs.glucose_max -- if equal, just pick labs
        end as glucose_max

      , case
          when labs.glucose_min is null and vital.glucose_min is null
            then null
          when labs.glucose_min is null or vital.glucose_min < labs.glucose_min
            then vital.glucose_min
          when vital.glucose_min is null or labs.glucose_min < vital.glucose_min
            then labs.glucose_min
          else labs.glucose_min -- if equal, just pick labs
        end as glucose_min

      -- , labs.bicarbonate_min
      -- , labs.bicarbonate_max
      , vent.vent
      , uo.urineoutput
      -- gcs and its components
      , gcs.mingcs
      , gcs.gcsmotor, gcs.gcsverbal,  gcs.gcseyes, gcs.endotrachflag
      -- acute renal failure
      , arf.arf as arf

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above views - the row number filters to 1 row per icustay_id
left join pa
  on  ie.icustay_id = pa.icustay_id
  and pa.rn = 1
left join aa
  on  ie.icustay_id = aa.icustay_id
  and aa.rn = 1
left join acidbase_max ab
  on  ie.icustay_id = ab.icustay_id
  and ab.acidbase_rn = 1
left join arf
  on ie.icustay_id = arf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
-- First, we calculate the score for the minimum values
, score_min as
(
  select cohort.subject_id, cohort.hadm_id, cohort.icustay_id
  , case
      when heartrate_min is null then null
      when heartrate_min <   40 then 8
      when heartrate_min <   50 then 5
      when heartrate_min <  100 then 0
      when heartrate_min <  110 then 1
      when heartrate_min <  120 then 5
      when heartrate_min <  140 then 7
      when heartrate_min <  155 then 13
      when heartrate_min >= 155 then 17
    end as hr_score

  , case
      when meanbp_min is null then null
      when meanbp_min <   40 then 23
      when meanbp_min <   60 then 15
      when meanbp_min <   70 then 7
      when meanbp_min <   80 then 6
      when meanbp_min <  100 then 0
      when meanbp_min <  120 then 4
      when meanbp_min <  130 then 7
      when meanbp_min <  140 then 9
      when meanbp_min >= 140 then 10
    end as meanbp_score

  -- TODO: add 1 degree to axillary measurements
  , case
      when tempc_min is null then null
      when tempc_min <  33.0 then 20
      when tempc_min <  33.5 then 16
      when tempc_min <  34.0 then 13
      when tempc_min <  35.0 then 8
      when tempc_min <  36.0 then 2
      when tempc_min <  40.0 then 0
      when tempc_min >= 40.0 then 4
    end as temp_score

  , case
      when resprate_min is null then null
      -- special case for ventilated patients
      when vent = 1 and resprate_min < 14 then 0
      when resprate_min <   6 then 17
      when resprate_min <  12 then 8
      when resprate_min <  14 then 7
      when resprate_min <  25 then 0
      when resprate_min <  35 then 6
      when resprate_min <  40 then 9
      when resprate_min <  50 then 11
      when resprate_min >= 50 then 18
    end as resprate_score

  , case
      when hematocrit_min is null then null
      when hematocrit_min <   41.0 then 3
      when hematocrit_min <   50.0 then 0
      when hematocrit_min >=  50.0 then 3
    end as hematocrit_score

  , case
      when wbc_min is null then null
      when wbc_min <   1.0 then 19
      when wbc_min <   3.0 then 5
      when wbc_min <  20.0 then 0
      when wbc_min <  25.0 then 1
      when wbc_min >= 25.0 then 5
    end as wbc_score

  , case
      when creatinine_min is null then null
      when arf = 1 and creatinine_min <  1.5 then 0
      when arf = 1 and creatinine_min >= 1.5 then 10
      when creatinine_min <   0.5 then 3
      when creatinine_min <   1.5 then 0
      when creatinine_min <  1.95 then 4
      when creatinine_min >= 1.95 then 7
    end as creatinine_score

  , case
      when bun_min is null then null
      when bun_min <  17.0 then 0
      when bun_min <  20.0 then 2
      when bun_min <  40.0 then 7
      when bun_min <  80.0 then 11
      when bun_min >= 80.0 then 12
    end as bun_score

  , case
      when sodium_min is null then null
      when sodium_min <  120 then 3
      when sodium_min <  135 then 2
      when sodium_min <  155 then 0
      when sodium_min >= 155 then 4
    end as sodium_score

  , case
      when albumin_min is null then null
      when albumin_min <  2.0 then 11
      when albumin_min <  2.5 then 6
      when albumin_min <  4.5 then 0
      when albumin_min >= 4.5 then 4
    end as albumin_score

  , case
      when bilirubin_min is null then null
      when bilirubin_min <  2.0 then 0
      when bilirubin_min <  3.0 then 5
      when bilirubin_min <  5.0 then 6
      when bilirubin_min <  8.0 then 8
      when bilirubin_min >= 8.0 then 16
    end as bilirubin_score

  , case
      when glucose_min is null then null
      when glucose_min <   40 then 8
      when glucose_min <   60 then 9
      when glucose_min <  200 then 0
      when glucose_min <  350 then 3
      when glucose_min >= 350 then 5
    end as glucose_score

from cohort
)
, score_max as
(
  select cohort.subject_id, cohort.hadm_id, cohort.icustay_id
    , case
        when heartrate_max is null then null
        when heartrate_max <   40 then 8
        when heartrate_max <   50 then 5
        when heartrate_max <  100 then 0
        when heartrate_max <  110 then 1
        when heartrate_max <  120 then 5
        when heartrate_max <  140 then 7
        when heartrate_max <  155 then 13
        when heartrate_max >= 155 then 17
      end as hr_score

    , case
        when meanbp_max is null then null
        when meanbp_max <   40 then 23
        when meanbp_max <   60 then 15
        when meanbp_max <   70 then 7
        when meanbp_max <   80 then 6
        when meanbp_max <  100 then 0
        when meanbp_max <  120 then 4
        when meanbp_max <  130 then 7
        when meanbp_max <  140 then 9
        when meanbp_max >= 140 then 10
      end as meanbp_score

    -- TODO: add 1 degree to axillary measurements
    , case
        when tempc_max is null then null
        when tempc_max <  33.0 then 20
        when tempc_max <  33.5 then 16
        when tempc_max <  34.0 then 13
        when tempc_max <  35.0 then 8
        when tempc_max <  36.0 then 2
        when tempc_max <  40.0 then 0
        when tempc_max >= 40.0 then 4
      end as temp_score

    , case
        when resprate_max is null then null
        -- special case for ventilated patients
        when vent = 1 and resprate_max < 14 then 0
        when resprate_max <   6 then 17
        when resprate_max <  12 then 8
        when resprate_max <  14 then 7
        when resprate_max <  25 then 0
        when resprate_max <  35 then 6
        when resprate_max <  40 then 9
        when resprate_max <  50 then 11
        when resprate_max >= 50 then 18
      end as resprate_score

    , case
        when hematocrit_max is null then null
        when hematocrit_max <   41.0 then 3
        when hematocrit_max <   50.0 then 0
        when hematocrit_max >=  50.0 then 3
      end as hematocrit_score

    , case
        when wbc_max is null then null
        when wbc_max <   1.0 then 19
        when wbc_max <   3.0 then 5
        when wbc_max <  20.0 then 0
        when wbc_max <  25.0 then 1
        when wbc_max >= 25.0 then 5
      end as wbc_score

    , case
        when creatinine_max is null then null
        when arf = 1 and creatinine_max <  1.5 then 0
        when arf = 1 and creatinine_max >= 1.5 then 10
        when creatinine_max <   0.5 then 3
        when creatinine_max <   1.5 then 0
        when creatinine_max <  1.95 then 4
        when creatinine_max >= 1.95 then 7
      end as creatinine_score

    , case
        when bun_max is null then null
        when bun_max <  17.0 then 0
        when bun_max <  20.0 then 2
        when bun_max <  40.0 then 7
        when bun_max <  80.0 then 11
        when bun_max >= 80.0 then 12
      end as bun_score

    , case
        when sodium_max is null then null
        when sodium_max <  120 then 3
        when sodium_max <  135 then 2
        when sodium_max <  155 then 0
        when sodium_max >= 155 then 4
      end as sodium_score

    , case
        when albumin_max is null then null
        when albumin_max <  2.0 then 11
        when albumin_max <  2.5 then 6
        when albumin_max <  4.5 then 0
        when albumin_max >= 4.5 then 4
      end as albumin_score

    , case
        when bilirubin_max is null then null
        when bilirubin_max <  2.0 then 0
        when bilirubin_max <  3.0 then 5
        when bilirubin_max <  5.0 then 6
        when bilirubin_max <  8.0 then 8
        when bilirubin_max >= 8.0 then 16
      end as bilirubin_score

    , case
        when glucose_max is null then null
        when glucose_max <   40 then 8
        when glucose_max <   60 then 9
        when glucose_max <  200 then 0
        when glucose_max <  350 then 3
        when glucose_max >= 350 then 5
      end as glucose_score

from cohort
)
-- Combine together the scores for min/max, using the following rules:
--  1) select the value furthest from a predefined normal value
--  2) if both equidistant, choose the one which gives a worse score
--  3) calculate score for acid-base abnormalities as it requires interactions
-- sometimes the code is a bit redundant, i.e. we know the max would always be furthest from 0
, scorecomp as
(
  select co.*
  -- The rules for APS III require the definition of a "worst" value
  -- This value is defined as whatever value is furthest from a predefined normal
  -- e.g., for heart rate, worst is defined as furthest from 75
  , case
      when heartrate_max is null then null
      when abs(heartrate_max-75) > abs(heartrate_min-75)
        then smax.hr_score
      when abs(heartrate_max-75) < abs(heartrate_min-75)
        then smin.hr_score
      when abs(heartrate_max-75) = abs(heartrate_min-75)
      and  smax.hr_score >= smin.hr_score
        then smax.hr_score
      when abs(heartrate_max-75) = abs(heartrate_min-75)
      and  smax.hr_score < smin.hr_score
        then smin.hr_score
    end as hr_score

  , case
      when meanbp_max is null then null
      when abs(meanbp_max-90) > abs(meanbp_min-90)
        then smax.meanbp_score
      when abs(meanbp_max-90) < abs(meanbp_min-90)
        then smin.meanbp_score
      -- values are equidistant - pick the larger score
      when abs(meanbp_max-90) = abs(meanbp_min-90)
      and  smax.meanbp_score >= smin.meanbp_score
        then smax.meanbp_score
      when abs(meanbp_max-90) = abs(meanbp_min-90)
      and  smax.meanbp_score < smin.meanbp_score
        then smin.meanbp_score
    end as meanbp_score

  , case
      when tempc_max is null then null
      when abs(tempc_max-38) > abs(tempc_min-38)
        then smax.temp_score
      when abs(tempc_max-38) < abs(tempc_min-38)
        then smin.temp_score
      -- values are equidistant - pick the larger score
      when abs(tempc_max-38) = abs(tempc_min-38)
      and  smax.temp_score >= smin.temp_score
        then smax.temp_score
      when abs(tempc_max-38) = abs(tempc_min-38)
      and  smax.temp_score < smin.temp_score
        then smin.temp_score
    end as temp_score

  , case
      when resprate_max is null then null
      when abs(resprate_max-19) > abs(resprate_min-19)
        then smax.resprate_score
      when abs(resprate_max-19) < abs(resprate_min-19)
        then smin.resprate_score
      -- values are equidistant - pick the larger score
      when abs(resprate_max-19) = abs(resprate_max-19)
      and  smax.resprate_score >= smin.resprate_score
        then smax.resprate_score
      when abs(resprate_max-19) = abs(resprate_max-19)
      and  smax.resprate_score < smin.resprate_score
        then smin.resprate_score
    end as resprate_score

  , case
      when hematocrit_max is null then null
      when abs(hematocrit_max-45.5) > abs(hematocrit_min-45.5)
        then smax.hematocrit_score
      when abs(hematocrit_max-45.5) < abs(hematocrit_min-45.5)
        then smin.hematocrit_score
      -- values are equidistant - pick the larger score
      when abs(hematocrit_max-45.5) = abs(hematocrit_max-45.5)
      and  smax.hematocrit_score >= smin.hematocrit_score
        then smax.hematocrit_score
      when abs(hematocrit_max-45.5) = abs(hematocrit_max-45.5)
      and  smax.hematocrit_score < smin.hematocrit_score
        then smin.hematocrit_score
    end as hematocrit_score

  , case
      when wbc_max is null then null
      when abs(wbc_max-11.5) > abs(wbc_min-11.5)
        then smax.wbc_score
      when abs(wbc_max-11.5) < abs(wbc_min-11.5)
        then smin.wbc_score
      -- values are equidistant - pick the larger score
      when abs(wbc_max-11.5) = abs(wbc_max-11.5)
      and  smax.wbc_score >= smin.wbc_score
        then smax.wbc_score
      when abs(wbc_max-11.5) = abs(wbc_max-11.5)
      and  smax.wbc_score < smin.wbc_score
        then smin.wbc_score
    end as wbc_score


  -- For some labs, "furthest from normal" doesn't make sense
  -- e.g. creatinine w/ ARF, the minimum could be 0.3, and the max 1.6
  -- while the minimum of 0.3 is "further from 1", seems like the max should be scored

  , case
      when creatinine_max is null then null
      -- if they have arf then use the max to score
      when arf = 1 then smax.creatinine_score
      -- otherwise furthest from 1
      when abs(creatinine_max-1) > abs(creatinine_min-1)
        then smax.creatinine_score
      when abs(creatinine_max-1) < abs(creatinine_min-1)
        then smin.creatinine_score
      -- values are equidistant
      when smax.creatinine_score >= smin.creatinine_score
        then smax.creatinine_score
      when smax.creatinine_score < smin.creatinine_score
        then smin.creatinine_score
    end as creatinine_score

  -- the rule for BUN is the furthest from 0.. equivalent to the max value
  , case
      when bun_max is null then null
      else smax.bun_score
    end as bun_score

  , case
      when sodium_max is null then null
      when abs(sodium_max-145.5) > abs(sodium_min-145.5)
        then smax.sodium_score
      when abs(sodium_max-145.5) < abs(sodium_min-145.5)
        then smin.sodium_score
      -- values are equidistant - pick the larger score
      when abs(sodium_max-145.5) = abs(sodium_max-145.5)
      and  smax.sodium_score >= smin.sodium_score
        then smax.sodium_score
      when abs(sodium_max-145.5) = abs(sodium_max-145.5)
      and  smax.sodium_score < smin.sodium_score
        then smin.sodium_score
    end as sodium_score

  , case
      when albumin_max is null then null
      when abs(albumin_max-3.5) > abs(albumin_min-3.5)
        then smax.albumin_score
      when abs(albumin_max-3.5) < abs(albumin_min-3.5)
        then smin.albumin_score
      -- values are equidistant - pick the larger score
      when abs(albumin_max-3.5) = abs(albumin_max-3.5)
      and  smax.albumin_score >= smin.albumin_score
        then smax.albumin_score
      when abs(albumin_max-3.5) = abs(albumin_max-3.5)
      and  smax.albumin_score < smin.albumin_score
        then smin.albumin_score
    end as albumin_score

  , case
      when bilirubin_max is null then null
      else smax.bilirubin_score
    end as bilirubin_score

  , case
      when glucose_max is null then null
      when abs(glucose_max-130) > abs(glucose_min-130)
        then smax.glucose_score
      when abs(glucose_max-130) < abs(glucose_min-130)
        then smin.glucose_score
      -- values are equidistant - pick the larger score
      when abs(glucose_max-130) = abs(glucose_max-130)
      and  smax.glucose_score >= smin.glucose_score
        then smax.glucose_score
      when abs(glucose_max-130) = abs(glucose_max-130)
      and  smax.glucose_score < smin.glucose_score
        then smin.glucose_score
    end as glucose_score


  -- Below are interactions/special cases where only 1 value is important
  , case
      when urineoutput is null then null
      when urineoutput <   400 then 15
      when urineoutput <   600 then 8
      when urineoutput <   900 then 7
      when urineoutput <  1500 then 5
      when urineoutput <  2000 then 4
      when urineoutput <  4000 then 0
      when urineoutput >= 4000 then 1
  end as uo_score

  , case
      when endotrachflag = 1
        -- here they are intubated, so their verbal score is inappropriate
        -- normally you are supposed to use "clinical judgement"
        -- we don't have that, so we just assume normal (as was done in the original study)
        then 0
      when gcseyes = 1
        then case
          when gcsverbal = 1 and gcsmotor in (1,2)
            then 48
          when gcsverbal = 1 and gcsmotor in (3,4)
            then 33
          when gcsverbal = 1 and gcsmotor in (5,6)
            then 16
          when gcsverbal in (2,3) and gcsmotor in (1,2)
            then 29
          when gcsverbal in (2,3) and gcsmotor in (3,4)
            then 24
          when gcsverbal in (2,3) and gcsmotor >= 5
            -- highly unlikely clinical combination
            then null
          when gcsverbal >= 4
            then null
          end
      when gcseyes > 1
        then case
          when gcsverbal = 1 and gcsmotor in (1,2)
            then 29
          when gcsverbal = 1 and gcsmotor in (3,4)
            then 24
          when gcsverbal = 1 and gcsmotor in (5,6)
            then 15
          when gcsverbal in (2,3) and gcsmotor in (1,2)
            then 29
          when gcsverbal in (2,3) and gcsmotor in (3,4)
            then 24
          when gcsverbal in (2,3) and gcsmotor = 5
            then 13
          when gcsverbal in (2,3) and gcsmotor = 6
            then 10
          when gcsverbal = 4 and gcsmotor in (1,2,3,4)
            then 13
          when gcsverbal = 4 and gcsmotor = 5
            then 8
          when gcsverbal = 4 and gcsmotor = 6
            then 3
          when gcsverbal = 5 and gcsmotor in (1,2,3,4,5)
            then 3
          when gcsverbal = 5 and gcsmotor = 6
            then 0
          end
      else null
    end as gcs_score

  , case
      when pao2 is null and aado2 is null
        then null
      when pao2 is not null then
        case
          when pao2 < 50 then 15
          when pao2 < 70 then 5
          when pao2 < 80 then 2
        else 0 end
      when aado2 is not null then
        case
          when aado2 <  100 then 0
          when aado2 <  250 then 7
          when aado2 <  350 then 9
          when aado2 <  500 then 11
          when aado2 >= 500 then 14
        else 0 end
      end as pao2_aado2_score

from cohort co
left join score_min smin
  on co.icustay_id = smin.icustay_id
left join score_max smax
  on co.icustay_id = smax.icustay_id
)
-- tabulate the APS III using the scores from the worst values
, score as
(
  select s.*
  -- coalesce statements impute normal score of zero if data element is missing
  , coalesce(hr_score,0)
  + coalesce(meanbp_score,0)
  + coalesce(temp_score,0)
  + coalesce(resprate_score,0)
  + coalesce(pao2_aado2_score,0)
  + coalesce(hematocrit_score,0)
  + coalesce(wbc_score,0)
  + coalesce(creatinine_score,0)
  + coalesce(uo_score,0)
  + coalesce(bun_score,0)
  + coalesce(sodium_score,0)
  + coalesce(albumin_score,0)
  + coalesce(bilirubin_score,0)
  + coalesce(glucose_score,0)
  + coalesce(acidbase_score,0)
  + coalesce(gcs_score,0)
    as apsiii
  from scorecomp s
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, apsiii
-- Calculate probability of hospital mortality using equation from Johnson 2014.
, 1 / (1 + exp(- (-4.4360 + 0.04726*(apsiii) ))) as apsiii_prob
, hr_score
, meanbp_score
, temp_score
, resprate_score
, pao2_aado2_score
, hematocrit_score
, wbc_score
, creatinine_score
, uo_score
, bun_score
, sodium_score
, albumin_score
, bilirubin_score
, glucose_score
, acidbase_score
, gcs_score
FROM icustays ie
left join score s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:53.590341 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 4.98 seconds
17:15:53.597138 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:53.597468 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
alter table "postgres"."public"."apsiii" rename to "apsiii__dbt_backup"
17:15:53.598193 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:53.608163 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:53.608446 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
alter table "postgres"."public"."apsiii__dbt_tmp" rename to "apsiii"
17:15:53.609097 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:53.614280 [debug] [Thread-1  ]: On model.mimic.apsiii: COMMIT
17:15:53.614742 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:53.615188 [debug] [Thread-1  ]: On model.mimic.apsiii: COMMIT
17:15:53.617126 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:15:53.622111 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:15:53.622421 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
drop table if exists "postgres"."public"."apsiii__dbt_backup" cascade
17:15:53.625189 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:53.628858 [debug] [Thread-1  ]: finished collecting timing info
17:15:53.629165 [debug] [Thread-1  ]: On model.mimic.apsiii: Close
17:15:53.629819 [info ] [Thread-1  ]: 103 of 107 OK created table model public.apsiii ................................ [[32mSELECT 61532[0m in 5.06s]
17:15:53.630194 [debug] [Thread-1  ]: Finished running node model.mimic.apsiii
17:15:53.630361 [debug] [Thread-1  ]: Began running node model.mimic.oasis
17:15:53.630900 [info ] [Thread-1  ]: 104 of 107 START table model public.oasis ...................................... [RUN]
17:15:53.632064 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.oasis"
17:15:53.632390 [debug] [Thread-1  ]: Began compiling node model.mimic.oasis
17:15:53.632577 [debug] [Thread-1  ]: Compiling model.mimic.oasis
17:15:53.639695 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.oasis"
17:15:53.640266 [debug] [Thread-1  ]: finished collecting timing info
17:15:53.640451 [debug] [Thread-1  ]: Began executing node model.mimic.oasis
17:15:53.655326 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.oasis"
17:15:53.656088 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:53.656268 [debug] [Thread-1  ]: On model.mimic.oasis: BEGIN
17:15:53.656415 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:53.662077 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:53.662380 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:53.662796 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */


  create  table "postgres"."public"."oasis__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Oxford Acute Severity of Illness Score (oasis)
-- This query extracts the Oxford acute severity of illness score.
-- This score is a measure of severity of illness for patients in the ICU.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for OASIS:
--    Johnson, Alistair EW, Andrew A. Kramer, and Gari D. Clifford.
--    "A new severity of illness scale using a subset of acute physiology and chronic health evaluation data elements shows comparable predictive accuracy*."
--    Critical care medicine 41, no. 7 (2013): 1711-1718.

-- Variables used in OASIS:
--  Heart rate, GCS, MAP, Temperature, Respiratory rate, Ventilation status (sourced FROM chartevents)
--  Urine output (sourced from OUTPUTEVENTS)
--  Elective surgery (sourced FROM admissions and SERVICES)
--  Pre-ICU in-hospital length of stay (sourced FROM admissions and ICUSTAYS)
--  Age (sourced FROM patients)

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vent_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql


-- Regarding missing values:
--  The ventilation flag is always 0/1. It cannot be missing, since VENT=0 if no data is found for vent settings.

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.


with surgflag as
(
  select ie.icustay_id
    , max(case
        when lower(curr_service) like '%surg%' then 1
        when curr_service = 'ORTHO' then 1
    else 0 end) as surgical
  FROM icustays ie
  left join services se
    on ie.hadm_id = se.hadm_id
    and se.transfertime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  group by ie.icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime
      , adm.deathtime
      -- , DATETIME_DIFF(ie.intime, adm.admittime, MINUTE) as preiculos
      , EXTRACT(MINUTE FROM ie.intime-adm.admittime) as preiculos
      , EXTRACT(YEAR FROM ie.intime-pat.dob) as age
      -- , DATETIME_DIFF(ie.intime, pat.dob, `YEAR`) as age
      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.meanbp_max
      , vital.meanbp_min
      , vital.resprate_max
      , vital.resprate_min
      , vital.tempc_max
      , vital.tempc_min
      , vent.vent as mechvent
      , uo.urineoutput

      , case
          when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
            then 1
          when adm.ADMISSION_TYPE is null or sf.surgical is null
            then null
          else 0
        end as electivesurgery

      -- age group
      , case
        when DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') <= 1 then 'neonate'
        when DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') <= 15 then 'middle'
        -- when EXTRACT(YEAR FROM ie.intime-pat.dob) <= 1 then 'neonate'
        -- when EXTRACT(YEAR FROM ie.intime-pat.dob) <= 15 then 'middle'
        else 'adult' end as icustay_age_group

      -- mortality flags
      , case
          when adm.deathtime between ie.intime and ie.outtime
            then 1
          when adm.deathtime <= ie.intime -- sometimes there are typographical errors in the death date
            then 1
          when adm.dischtime <= ie.outtime and adm.discharge_location = 'DEAD/EXPIRED'
            then 1
          else 0 end
        as icustay_expire_flag
      , adm.hospital_expire_flag
FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id
left join surgflag sf
  on ie.icustay_id = sf.icustay_id
-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
)
, scorecomp as
(
select co.subject_id, co.hadm_id, co.icustay_id
, co.icustay_age_group
, co.icustay_expire_flag
, co.hospital_expire_flag

-- Below code calculates the component scores needed for oasis
, case when preiculos is null then null
     when preiculos < 10.2 then 5
     when preiculos < 297 then 3
     when preiculos < 1440 then 0
     when preiculos < 18708 then 1
     else 2 end as preiculos_score
,  case when age is null then null
      when age < 24 then 0
      when age <= 53 then 3
      when age <= 77 then 6
      when age <= 89 then 9
      when age >= 90 then 7
      else 0 end as age_score
,  case when mingcs is null then null
      when mingcs <= 7 then 10
      when mingcs < 14 then 4
      when mingcs = 14 then 3
      else 0 end as gcs_score
,  case when heartrate_max is null then null
      when heartrate_max > 125 then 6
      when heartrate_min < 33 then 4
      when heartrate_max >= 107 and heartrate_max <= 125 then 3
      when heartrate_max >= 89 and heartrate_max <= 106 then 1
      else 0 end as heartrate_score
,  case when meanbp_min is null then null
      when meanbp_min < 20.65 then 4
      when meanbp_min < 51 then 3
      when meanbp_max > 143.44 then 3
      when meanbp_min >= 51 and meanbp_min < 61.33 then 2
      else 0 end as meanbp_score
,  case when resprate_min is null then null
      when resprate_min <   6 then 10
      when resprate_max >  44 then  9
      when resprate_max >  30 then  6
      when resprate_max >  22 then  1
      when resprate_min <  13 then 1 else 0
      end as resprate_score
,  case when tempc_max is null then null
      when tempc_max > 39.88 then 6
      when tempc_min >= 33.22 and tempc_min <= 35.93 then 4
      when tempc_max >= 33.22 and tempc_max <= 35.93 then 4
      when tempc_min < 33.22 then 3
      when tempc_min > 35.93 and tempc_min <= 36.39 then 2
      when tempc_max >= 36.89 and tempc_max <= 39.88 then 2
      else 0 end as temp_score
,  case when UrineOutput is null then null
      when UrineOutput < 671.09 then 10
      when UrineOutput > 6896.80 then 8
      when UrineOutput >= 671.09
       and UrineOutput <= 1426.99 then 5
      when UrineOutput >= 1427.00
       and UrineOutput <= 2544.14 then 1
      else 0 end as urineoutput_score
,  case when mechvent is null then null
      when mechvent = 1 then 9
      else 0 end as mechvent_score
,  case when electivesurgery is null then null
      when electivesurgery = 1 then 0
      else 6 end as electivesurgery_score


-- The below code gives the component associated with each score
-- This is not needed to calculate oasis, but provided for user convenience.
-- If both the min/max are in the normal range (score of 0), then the average value is stored.
, preiculos
, age
, mingcs as gcs
,  case when heartrate_max is null then null
      when heartrate_max > 125 then heartrate_max
      when heartrate_min < 33 then heartrate_min
      when heartrate_max >= 107 and heartrate_max <= 125 then heartrate_max
      when heartrate_max >= 89 and heartrate_max <= 106 then heartrate_max
      else (heartrate_min+heartrate_max)/2 end as heartrate
,  case when meanbp_min is null then null
      when meanbp_min < 20.65 then meanbp_min
      when meanbp_min < 51 then meanbp_min
      when meanbp_max > 143.44 then meanbp_max
      when meanbp_min >= 51 and meanbp_min < 61.33 then meanbp_min
      else (meanbp_min+meanbp_max)/2 end as meanbp
,  case when resprate_min is null then null
      when resprate_min <   6 then resprate_min
      when resprate_max >  44 then resprate_max
      when resprate_max >  30 then resprate_max
      when resprate_max >  22 then resprate_max
      when resprate_min <  13 then resprate_min
      else (resprate_min+resprate_max)/2 end as resprate
,  case when tempc_max is null then null
      when tempc_max > 39.88 then tempc_max
      when tempc_min >= 33.22 and tempc_min <= 35.93 then tempc_min
      when tempc_max >= 33.22 and tempc_max <= 35.93 then tempc_max
      when tempc_min < 33.22 then tempc_min
      when tempc_min > 35.93 and tempc_min <= 36.39 then tempc_min
      when tempc_max >= 36.89 and tempc_max <= 39.88 then tempc_max
      else (tempc_min+tempc_max)/2 end as temp
,  UrineOutput
,  mechvent
,  electivesurgery
from cohort co
)
, score as
(
select s.*
    , coalesce(age_score,0)
    + coalesce(preiculos_score,0)
    + coalesce(gcs_score,0)
    + coalesce(heartrate_score,0)
    + coalesce(meanbp_score,0)
    + coalesce(resprate_score,0)
    + coalesce(temp_score,0)
    + coalesce(urineoutput_score,0)
    + coalesce(mechvent_score,0)
    + coalesce(electivesurgery_score,0)
    as oasis
from scorecomp s
)
select
  subject_id, hadm_id, icustay_id
  , icustay_age_group
  , hospital_expire_flag
  , icustay_expire_flag
  , oasis
  -- Calculate the probability of in-hospital mortality
  , 1 / (1 + exp(- (-6.1746 + 0.1275*(oasis) ))) as oasis_PROB
  , age, age_score
  , preiculos, preiculos_score
  , gcs, gcs_score
  , heartrate, heartrate_score
  , meanbp, meanbp_score
  , resprate, resprate_score
  , temp, temp_score
  , urineoutput, urineoutput_score
  , mechvent, mechvent_score
  , electivesurgery, electivesurgery_score
from score
order by icustay_id
  );
17:15:54.944916 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.28 seconds
17:15:54.949266 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:54.949489 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
alter table "postgres"."public"."oasis" rename to "oasis__dbt_backup"
17:15:54.950172 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:54.955941 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:54.956165 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
alter table "postgres"."public"."oasis__dbt_tmp" rename to "oasis"
17:15:54.956931 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:54.961172 [debug] [Thread-1  ]: On model.mimic.oasis: COMMIT
17:15:54.961396 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:54.961593 [debug] [Thread-1  ]: On model.mimic.oasis: COMMIT
17:15:54.992981 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
17:15:54.995787 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:15:54.996017 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
drop table if exists "postgres"."public"."oasis__dbt_backup" cascade
17:15:55.045124 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.05 seconds
17:15:55.048965 [debug] [Thread-1  ]: finished collecting timing info
17:15:55.049249 [debug] [Thread-1  ]: On model.mimic.oasis: Close
17:15:55.050526 [info ] [Thread-1  ]: 104 of 107 OK created table model public.oasis ................................. [[32mSELECT 61532[0m in 1.42s]
17:15:55.052537 [debug] [Thread-1  ]: Finished running node model.mimic.oasis
17:15:55.053108 [debug] [Thread-1  ]: Began running node model.mimic.saps
17:15:55.053781 [info ] [Thread-1  ]: 105 of 107 START table model public.saps ....................................... [RUN]
17:15:55.055211 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.saps"
17:15:55.055840 [debug] [Thread-1  ]: Began compiling node model.mimic.saps
17:15:55.056145 [debug] [Thread-1  ]: Compiling model.mimic.saps
17:15:55.062452 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.saps"
17:15:55.064187 [debug] [Thread-1  ]: finished collecting timing info
17:15:55.064601 [debug] [Thread-1  ]: Began executing node model.mimic.saps
17:15:55.082751 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.saps"
17:15:55.083844 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.084626 [debug] [Thread-1  ]: On model.mimic.saps: BEGIN
17:15:55.084884 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:55.094186 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:55.094557 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.095084 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */


  create  table "postgres"."public"."saps__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Simplified Acute Physiology Score (SAPS)
-- This query extracts the simplified acute physiology score.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SAPS:
--    Jean-Roger Le Gall, Philippe Loirat, Annick Alperovitch, Paul Glaser, Claude Granthil,
--    Daniel Mathieu, Philippe Mercier, Remi Thomas, and Daniel Villers.
--    "A simplified acute physiology score for ICU patients."
--    Critical care medicine 12, no. 11 (1984): 975-977.

-- Variables used in SAPS:
--  Age, GCS
--  VITALS: Heart rate, systolic blood pressure, temperature, respiration rate
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: blood urea nitrogen, hematocrit, WBC, glucose, potassium, sodium, HCO3

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vent_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
  , max(CASE
        WHEN lower(ce.value) LIKE '%cpap%' THEN 1
        WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
      else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      -- the casts ensure the result is numeric.. we could equally extract EPOCH from the interval
      -- however this code works in Oracle and Postgres
      , DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') as age
      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min
      , vital.resprate_max
      , vital.resprate_min
      , vital.tempc_max
      , vital.tempc_min

      , coalesce(vital.glucose_max, labs.glucose_max) as glucose_max
      , coalesce(vital.glucose_min, labs.glucose_min) as glucose_min

      , labs.bun_max
      , labs.bun_min
      , labs.hematocrit_max
      , labs.hematocrit_min
      , labs.wbc_max
      , labs.wbc_min
      , labs.sodium_max
      , labs.sodium_min
      , labs.potassium_max
      , labs.potassium_min
      , labs.bicarbonate_max
      , labs.bicarbonate_min

      , vent.vent as mechvent
      , uo.urineoutput

      , cp.cpap

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get CPAP
left join cpap cp
  on ie.icustay_id = cp.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS
  , case
      when age is null then null
      when age <= 45 then 0
      when age <= 55 then 1
      when age <= 65 then 2
      when age <= 75 then 3
      when age >  75 then 4
    end as age_score
  , case
      when heartrate_max is null then null
      when heartrate_max >= 180 then 4
      when heartrate_min < 40 then 4
      when heartrate_max >= 140 then 3
      when heartrate_min <= 54 then 3
      when heartrate_max >= 110 then 2
      when heartrate_min <= 69 then 2
      when heartrate_max >= 70 and heartrate_max <= 109
        and heartrate_min >= 70 and heartrate_min <= 109
      then 0
    end as hr_score
  , case
      when sysbp_min is null then null
      when sysbp_max >= 190 then 4
      when sysbp_min < 55 then 4
      when sysbp_max >= 150 then 2
      when sysbp_min <= 79 then 2
      when sysbp_max >= 80 and sysbp_max <= 149
        and sysbp_min >= 80 and sysbp_min <= 149
        then 0
    end as sysbp_score

  , case
      when tempc_max is null then null
      when tempc_max >= 41.0 then 4
      when tempc_min <  30.0 then 4
      when tempc_max >= 39.0 then 3
      when tempc_min <= 31.9  then 3
      when tempc_min <= 33.9  then 2
      when tempc_max >  38.4 then 1
      when tempc_min <  36.0  then 1
      when tempc_max >= 36.0 and tempc_max <= 38.4
       and tempc_min >= 36.0 and tempc_min <= 38.4
        then 0
    end as temp_score

  , case
      when resprate_min is null then null
      when resprate_max >= 50 then 4
      when resprate_min <  6 then 4
      when resprate_max >= 35 then 3
      when resprate_min <= 9 then 2
      when resprate_max >= 25 then 1
      when resprate_min <= 11 then 1
      when  resprate_max >= 12 and resprate_max <= 24
        and resprate_min >= 12 and resprate_min <= 24
          then 0
      end as resp_score

  , case
      when coalesce(mechvent,cpap) is null then null
      when cpap = 1 then 3
      when mechvent = 1 then 3
      else 0
    end as vent_score

  , case
      when UrineOutput is null then null
      when UrineOutput >  5000.0 then 2
      when UrineOutput >= 3500.0 then 1
      when UrineOutput >=  700.0 then 0
      when UrineOutput >=  500.0 then 2
      when UrineOutput >=  200.0 then 3
      when UrineOutput <   200.0 then 4
    end as uo_score

  , case
      when bun_max is null then null
      when bun_max >= 55.0 then 4
      when bun_max >= 36.0 then 3
      when bun_max >= 29.0 then 2
      when bun_max >= 7.50 then 1
      when bun_min < 3.5 then 1
      when  bun_max >= 3.5 and bun_max < 7.5
        and bun_min >= 3.5 and bun_min < 7.5
          then 0
    end as bun_score

  , case
      when hematocrit_max is null then null
      when hematocrit_max >= 60.0 then 4
      when hematocrit_min <  20.0 then 4
      when hematocrit_max >= 50.0 then 2
      when hematocrit_min < 30.0 then 2
      when hematocrit_max >= 46.0 then 1
      when  hematocrit_max >= 30.0 and hematocrit_max < 46.0
        and hematocrit_min >= 30.0 and hematocrit_min < 46.0
          then 0
      end as hematocrit_score

  , case
      when wbc_max is null then null
      when wbc_max >= 40.0 then 4
      when wbc_min <   1.0 then 4
      when wbc_max >= 20.0 then 2
      when wbc_min <   3.0 then 2
      when wbc_max >= 15.0 then 1
      when wbc_max >=  3.0 and wbc_max < 15.0
       and wbc_min >=  3.0 and wbc_min < 15.0
        then 0
    end as wbc_score

  , case
      when glucose_max is null then null
      when glucose_max >= 44.5 then 4
      when glucose_min <   1.6 then 4
      when glucose_max >= 27.8 then 3
      when glucose_min <   2.8 then 3
      when glucose_min <   3.9 then 2
      when glucose_max >= 14.0 then 1
      when glucose_max >=  3.9 and glucose_max < 14.0
       and glucose_min >=  3.9 and glucose_min < 14.0
        then 0
      end as glucose_score

  , case
      when potassium_max is null then null
      when potassium_max >= 7.0 then 4
      when potassium_min <  2.5 then 4
      when potassium_max >= 6.0 then 3
      when potassium_min <  3.0 then 2
      when potassium_max >= 5.5 then 1
      when potassium_min <  3.5 then 1
      when potassium_max >= 3.5 and potassium_max < 5.5
       and potassium_min >= 3.5 and potassium_min < 5.5
        then 0
      end as potassium_score

  , case
      when sodium_max is null then null
      when sodium_max >= 180 then 4
      when sodium_min  < 110 then 4
      when sodium_max >= 161 then 3
      when sodium_min  < 120 then 3
      when sodium_max >= 156 then 2
      when sodium_min  < 130 then 2
      when sodium_max >= 151 then 1
      when sodium_max >= 130 and sodium_max < 151
       and sodium_min >= 130 and sodium_min < 151
        then 0
      end as sodium_score

  , case
      when bicarbonate_max is null then null
      when bicarbonate_min <   5.0 then 4
      when bicarbonate_max >= 40.0 then 3
      when bicarbonate_min <  10.0 then 3
      when bicarbonate_max >= 30.0 then 1
      when bicarbonate_min <  20.0 then 1
      when bicarbonate_max >= 20.0 and bicarbonate_max < 30.0
       and bicarbonate_min >= 20.0 and bicarbonate_min < 30.0
          then 0
      end as bicarbonate_score

   , case
      when mingcs is null then null
        when mingcs <  3 then null -- erroneous value/on trach
        when mingcs =  3 then 4
        when mingcs <  7 then 3
        when mingcs < 10 then 2
        when mingcs < 13 then 1
        when mingcs >= 13
         and mingcs <= 15
          then 0
        end as gcs_score
from cohort
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(age_score,0)
+ coalesce(hr_score,0)
+ coalesce(sysbp_score,0)
+ coalesce(resp_score,0)
+ coalesce(temp_score,0)
+ coalesce(uo_score,0)
+ coalesce(vent_score,0)
+ coalesce(bun_score,0)
+ coalesce(hematocrit_score,0)
+ coalesce(wbc_score,0)
+ coalesce(glucose_score,0)
+ coalesce(potassium_score,0)
+ coalesce(sodium_score,0)
+ coalesce(bicarbonate_score,0)
+ coalesce(gcs_score,0)
  as SAPS
, age_score
, hr_score
, sysbp_score
, resp_score
, temp_score
, uo_score
, vent_score
, bun_score
, hematocrit_score
, wbc_score
, glucose_score
, potassium_score
, sodium_score
, bicarbonate_score
, gcs_score

FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:15:55.781323 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.69 seconds
17:15:55.787969 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.788218 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
alter table "postgres"."public"."saps" rename to "saps__dbt_backup"
17:15:55.790708 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:55.796867 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.797115 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
alter table "postgres"."public"."saps__dbt_tmp" rename to "saps"
17:15:55.797849 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:55.803290 [debug] [Thread-1  ]: On model.mimic.saps: COMMIT
17:15:55.803533 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.803752 [debug] [Thread-1  ]: On model.mimic.saps: COMMIT
17:15:55.810108 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:55.812821 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:15:55.813044 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
drop table if exists "postgres"."public"."saps__dbt_backup" cascade
17:15:55.815443 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:55.821456 [debug] [Thread-1  ]: finished collecting timing info
17:15:55.822208 [debug] [Thread-1  ]: On model.mimic.saps: Close
17:15:55.823235 [info ] [Thread-1  ]: 105 of 107 OK created table model public.saps .................................. [[32mSELECT 61532[0m in 0.77s]
17:15:55.823878 [debug] [Thread-1  ]: Finished running node model.mimic.saps
17:15:55.824208 [debug] [Thread-1  ]: Began running node model.mimic.kdigo_stages_48hr
17:15:55.824783 [info ] [Thread-1  ]: 106 of 107 START table model public.kdigo_stages_48hr .......................... [RUN]
17:15:55.825434 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.kdigo_stages_48hr"
17:15:55.825577 [debug] [Thread-1  ]: Began compiling node model.mimic.kdigo_stages_48hr
17:15:55.825851 [debug] [Thread-1  ]: Compiling model.mimic.kdigo_stages_48hr
17:15:55.831240 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.kdigo_stages_48hr"
17:15:55.831969 [debug] [Thread-1  ]: finished collecting timing info
17:15:55.832346 [debug] [Thread-1  ]: Began executing node model.mimic.kdigo_stages_48hr
17:15:55.853462 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.kdigo_stages_48hr"
17:15:55.854056 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:55.854240 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: BEGIN
17:15:55.854395 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:55.861006 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:55.861405 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:55.861611 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_48hr"} */


  create  table "postgres"."public"."kdigo_stages_48hr__dbt_tmp"
  as (
    -- This query checks if the patient had AKI during the first 48 hours of their ICU
-- stay according to the KDIGO guideline.
-- https://kdigo.org/wp-content/uploads/2016/10/KDIGO-2012-AKI-Guideline-English.pdf

-- get the worst staging of creatinine in the first 48 hours
WITH cr_aki AS
(
  SELECT
    k.icustay_id
    , k.charttime
    , k.creat
    , k.aki_stage_creat
    , ROW_NUMBER() OVER (PARTITION BY k.icustay_id ORDER BY k.aki_stage_creat DESC, k.creat DESC) AS rn
  FROM icustays ie
  INNER JOIN "postgres"."public"."kdigo_stages" k
    ON ie.icustay_id = k.icustay_id
  WHERE DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') > -6
  AND DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') <= 48
  AND k.aki_stage_creat IS NOT NULL
)
-- get the worst staging of urine output in the first 48 hours
, uo_aki AS
(
  SELECT
    k.icustay_id
    , k.charttime
    , k.uo_rt_6hr, k.uo_rt_12hr, k.uo_rt_24hr
    , k.aki_stage_uo
    , ROW_NUMBER() OVER 
    (
      PARTITION BY k.icustay_id
      ORDER BY k.aki_stage_uo DESC, k.uo_rt_24hr DESC, k.uo_rt_12hr DESC, k.uo_rt_6hr DESC
    ) AS rn
  FROM icustays ie
  INNER JOIN "postgres"."public"."kdigo_stages" k
    ON ie.icustay_id = k.icustay_id
  WHERE DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') > -6
  AND DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') <= 48
  AND k.aki_stage_uo IS NOT NULL
)
-- final table is aki_stage, include worst cr/uo for convenience
select
    ie.icustay_id
  , cr.charttime as charttime_creat
  , cr.creat
  , cr.aki_stage_creat
  , uo.charttime as charttime_uo
  , uo.uo_rt_6hr
  , uo.uo_rt_12hr
  , uo.uo_rt_24hr
  , uo.aki_stage_uo

  -- Classify AKI using both creatinine/urine output criteria
  , GREATEST(
      COALESCE(cr.aki_stage_creat, 0),
      COALESCE(uo.aki_stage_uo, 0)
    ) AS aki_stage_48hr
  , CASE WHEN cr.aki_stage_creat > 0 OR uo.aki_stage_uo > 0 THEN 1 ELSE 0 END AS aki_48hr

FROM icustays ie
LEFT JOIN cr_aki cr
  ON ie.icustay_id = cr.icustay_id
  AND cr.rn = 1
LEFT JOIN uo_aki uo
  ON ie.icustay_id = uo.icustay_id
  AND uo.rn = 1
order by ie.icustay_id
  );
17:15:56.618634 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.76 seconds
17:15:56.624468 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:56.624717 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_48hr"} */
alter table "postgres"."public"."kdigo_stages_48hr" rename to "kdigo_stages_48hr__dbt_backup"
17:15:56.625563 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:56.629471 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:56.629671 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_48hr"} */
alter table "postgres"."public"."kdigo_stages_48hr__dbt_tmp" rename to "kdigo_stages_48hr"
17:15:56.630360 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:56.633863 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: COMMIT
17:15:56.634062 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:56.634294 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: COMMIT
17:15:56.635467 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:15:56.637649 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_48hr"
17:15:56.637822 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_48hr"} */
drop table if exists "postgres"."public"."kdigo_stages_48hr__dbt_backup" cascade
17:15:56.640158 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:56.643514 [debug] [Thread-1  ]: finished collecting timing info
17:15:56.643750 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_48hr: Close
17:15:56.644627 [info ] [Thread-1  ]: 106 of 107 OK created table model public.kdigo_stages_48hr ..................... [[32mSELECT 61532[0m in 0.82s]
17:15:56.645208 [debug] [Thread-1  ]: Finished running node model.mimic.kdigo_stages_48hr
17:15:56.645545 [debug] [Thread-1  ]: Began running node model.mimic.kdigo_stages_7day
17:15:56.646040 [info ] [Thread-1  ]: 107 of 107 START table model public.kdigo_stages_7day .......................... [RUN]
17:15:56.646760 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.kdigo_stages_7day"
17:15:56.647106 [debug] [Thread-1  ]: Began compiling node model.mimic.kdigo_stages_7day
17:15:56.647346 [debug] [Thread-1  ]: Compiling model.mimic.kdigo_stages_7day
17:15:56.652316 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.kdigo_stages_7day"
17:15:56.653000 [debug] [Thread-1  ]: finished collecting timing info
17:15:56.653280 [debug] [Thread-1  ]: Began executing node model.mimic.kdigo_stages_7day
17:15:56.668329 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.kdigo_stages_7day"
17:15:56.669056 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:56.669278 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: BEGIN
17:15:56.669469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:56.679997 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:15:56.680377 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:56.680675 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_7day"} */


  create  table "postgres"."public"."kdigo_stages_7day__dbt_tmp"
  as (
    -- This query checks if the patient had AKI during the first 7 days of their ICU
-- stay according to the KDIGO guideline.
-- https://kdigo.org/wp-content/uploads/2016/10/KDIGO-2012-AKI-Guideline-English.pdf

-- get the worst staging of creatinine in the first 48 hours
WITH cr_aki AS
(
  SELECT
    k.icustay_id
    , k.charttime
    , k.creat
    , k.aki_stage_creat
    , ROW_NUMBER() OVER (PARTITION BY k.icustay_id ORDER BY k.aki_stage_creat DESC, k.creat DESC) AS rn
  FROM icustays ie
  INNER JOIN "postgres"."public"."kdigo_stages" k
    ON ie.icustay_id = k.icustay_id
  WHERE DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') > -6
  AND DATETIME_DIFF(k.charttime, ie.intime, 'DAY') <= 7
  AND k.aki_stage_creat IS NOT NULL
)
-- get the worst staging of urine output in the first 48 hours
, uo_aki AS
(
  SELECT
    k.icustay_id
    , k.charttime
    , k.uo_rt_6hr, k.uo_rt_12hr, k.uo_rt_24hr
    , k.aki_stage_uo
    , ROW_NUMBER() OVER 
    (
      PARTITION BY k.icustay_id
      ORDER BY k.aki_stage_uo DESC, k.uo_rt_24hr DESC, k.uo_rt_12hr DESC, k.uo_rt_6hr DESC
    ) AS rn
  FROM icustays ie
  INNER JOIN "postgres"."public"."kdigo_stages" k
    ON ie.icustay_id = k.icustay_id
  WHERE DATETIME_DIFF(k.charttime, ie.intime, 'HOUR') > -6
  AND DATETIME_DIFF(k.charttime, ie.intime, 'DAY') <= 7
  AND k.aki_stage_uo IS NOT NULL
)
-- final table is aki_stage, include worst cr/uo for convenience
select
    ie.icustay_id
  , cr.charttime as charttime_creat
  , cr.creat
  , cr.aki_stage_creat
  , uo.charttime as charttime_uo
  , uo.uo_rt_6hr
  , uo.uo_rt_12hr
  , uo.uo_rt_24hr
  , uo.aki_stage_uo

  -- Classify AKI using both creatinine/urine output criteria
  , GREATEST(
      COALESCE(cr.aki_stage_creat, 0),
      COALESCE(uo.aki_stage_uo, 0)
    ) AS aki_stage_7day
  , CASE WHEN cr.aki_stage_creat > 0 OR uo.aki_stage_uo > 0 THEN 1 ELSE 0 END AS aki_7day

FROM icustays ie
LEFT JOIN cr_aki cr
  ON ie.icustay_id = cr.icustay_id
  AND cr.rn = 1
LEFT JOIN uo_aki uo
  ON ie.icustay_id = uo.icustay_id
  AND uo.rn = 1
order by ie.icustay_id
  );
17:15:57.207918 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.53 seconds
17:15:57.214007 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:57.214213 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_7day"} */
alter table "postgres"."public"."kdigo_stages_7day" rename to "kdigo_stages_7day__dbt_backup"
17:15:57.215029 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:57.218989 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:57.219213 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_7day"} */
alter table "postgres"."public"."kdigo_stages_7day__dbt_tmp" rename to "kdigo_stages_7day"
17:15:57.219850 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:15:57.223871 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: COMMIT
17:15:57.224081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:57.224362 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: COMMIT
17:15:57.230439 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:15:57.232465 [debug] [Thread-1  ]: Using postgres connection "model.mimic.kdigo_stages_7day"
17:15:57.232667 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.kdigo_stages_7day"} */
drop table if exists "postgres"."public"."kdigo_stages_7day__dbt_backup" cascade
17:15:57.235197 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:15:57.237960 [debug] [Thread-1  ]: finished collecting timing info
17:15:57.238266 [debug] [Thread-1  ]: On model.mimic.kdigo_stages_7day: Close
17:15:57.239177 [info ] [Thread-1  ]: 107 of 107 OK created table model public.kdigo_stages_7day ..................... [[32mSELECT 61532[0m in 0.59s]
17:15:57.239757 [debug] [Thread-1  ]: Finished running node model.mimic.kdigo_stages_7day
17:15:57.241746 [debug] [MainThread]: Acquiring new postgres connection "master"
17:15:57.242161 [debug] [MainThread]: Using postgres connection "master"
17:15:57.242378 [debug] [MainThread]: On master: BEGIN
17:15:57.242753 [debug] [MainThread]: Opening a new connection, currently in state closed
17:15:57.249436 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:15:57.249702 [debug] [MainThread]: On master: COMMIT
17:15:57.249912 [debug] [MainThread]: Using postgres connection "master"
17:15:57.250039 [debug] [MainThread]: On master: COMMIT
17:15:57.250437 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:15:57.251344 [debug] [MainThread]: On master: Close
17:15:57.253094 [info ] [MainThread]: 
17:15:57.253924 [info ] [MainThread]: Finished running 107 table models in 580.76s.
17:15:57.254305 [debug] [MainThread]: Connection 'master' was properly closed.
17:15:57.254481 [debug] [MainThread]: Connection 'model.mimic.kdigo_stages_7day' was properly closed.
17:15:57.276654 [info ] [MainThread]: 
17:15:57.277078 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
17:15:57.277434 [info ] [MainThread]: 
17:15:57.277671 [error] [MainThread]: [33mDatabase Error in model icustay_days (models/cookbook/icustay_days.sql)[0m
17:15:57.277882 [error] [MainThread]:   syntax error at or near "DROP"
17:15:57.278066 [error] [MainThread]:   LINE 29: DROP MATERIALIZED VIEW icustay_days;
17:15:57.278246 [error] [MainThread]:            ^
17:15:57.278424 [error] [MainThread]:   compiled SQL at target/run/mimic/models/cookbook/icustay_days.sql
17:15:57.279024 [info ] [MainThread]: 
17:15:57.279349 [error] [MainThread]: [33mDatabase Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)[0m
17:15:57.279721 [error] [MainThread]:   syntax error at or near "﻿with"
17:15:57.279934 [error] [MainThread]:   LINE 6:     ﻿with co as
17:15:57.280121 [error] [MainThread]:               ^
17:15:57.280304 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:15:57.280499 [info ] [MainThread]: 
17:15:57.280693 [error] [MainThread]: [33mDatabase Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)[0m
17:15:57.280882 [error] [MainThread]:   relation "surgflag" does not exist
17:15:57.281061 [error] [MainThread]:   LINE 145:   left join surgflag sf
17:15:57.281239 [error] [MainThread]:                         ^
17:15:57.281419 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:15:57.281734 [info ] [MainThread]: 
17:15:57.281930 [info ] [MainThread]: Done. PASS=104 WARN=0 ERROR=3 SKIP=0 TOTAL=107


============================== 2022-07-16 17:36:45.805057 | 8214d7fc-9af1-45da-82ba-8f87c4f4faa1 ==============================
17:36:45.805070 [info ] [MainThread]: Running with dbt=1.1.1
17:36:45.805827 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['firstday'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:36:45.806028 [debug] [MainThread]: Tracking: tracking
17:36:45.814117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5bc6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5bc6430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5bc61f0>]}
17:36:45.928055 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:36:45.928324 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:36:45.931006 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:36:45.938051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5b4a790>]}
17:36:45.960166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5b9f1c0>]}
17:36:45.960536 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:36:45.960742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5b9f700>]}
17:36:45.963880 [info ] [MainThread]: 
17:36:45.964532 [debug] [MainThread]: Acquiring new postgres connection "master"
17:36:45.965577 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:36:45.978363 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:36:45.978826 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:36:45.979141 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:36:45.987582 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:36:45.994058 [debug] [ThreadPool]: On list_postgres: Close
17:36:45.999595 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:36:46.007085 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:36:46.007360 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:36:46.007685 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:36:46.012453 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:36:46.012703 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:36:46.013059 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:36:46.018287 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:36:46.029201 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:36:46.029676 [debug] [ThreadPool]: On list_postgres_public: Close
17:36:46.041418 [debug] [MainThread]: Using postgres connection "master"
17:36:46.041648 [debug] [MainThread]: On master: BEGIN
17:36:46.041849 [debug] [MainThread]: Opening a new connection, currently in state init
17:36:46.046093 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:36:46.046348 [debug] [MainThread]: Using postgres connection "master"
17:36:46.046658 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:36:46.053940 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:36:46.057180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e5b4a8b0>]}
17:36:46.057639 [debug] [MainThread]: On master: ROLLBACK
17:36:46.058039 [debug] [MainThread]: Using postgres connection "master"
17:36:46.058240 [debug] [MainThread]: On master: BEGIN
17:36:46.058799 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:36:46.059036 [debug] [MainThread]: On master: COMMIT
17:36:46.059217 [debug] [MainThread]: Using postgres connection "master"
17:36:46.059399 [debug] [MainThread]: On master: COMMIT
17:36:46.059791 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:36:46.060045 [debug] [MainThread]: On master: Close
17:36:46.060676 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:36:46.061048 [info ] [MainThread]: 
17:36:46.065072 [debug] [Thread-1  ]: Began running node model.mimic.blood_gas_first_day
17:36:46.065571 [info ] [Thread-1  ]: 1 of 10 START table model public.blood_gas_first_day ........................... [RUN]
17:36:46.066253 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.blood_gas_first_day"
17:36:46.066415 [debug] [Thread-1  ]: Began compiling node model.mimic.blood_gas_first_day
17:36:46.066818 [debug] [Thread-1  ]: Compiling model.mimic.blood_gas_first_day
17:36:46.068428 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.blood_gas_first_day"
17:36:46.069095 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.069420 [debug] [Thread-1  ]: Began executing node model.mimic.blood_gas_first_day
17:36:46.100456 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.blood_gas_first_day"
17:36:46.101151 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.101492 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: BEGIN
17:36:46.101882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:46.109390 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:46.109729 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.109867 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */


  create  table "postgres"."public"."blood_gas_first_day__dbt_tmp"
  as (
    -- The aim of this query is to pivot entries related to blood gases and
-- chemistry values which were found in LABEVENTS

-- things to check:
--  when a mixed venous/arterial blood sample are taken at the same time, is the store time different?

with pvt as
( -- begin query that extracts the data
  select ie.subject_id, ie.hadm_id, ie.icustay_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
      , case
        when itemid = 50800 then 'SPECIMEN'
        when itemid = 50801 then 'AADO2'
        when itemid = 50802 then 'BASEEXCESS'
        when itemid = 50803 then 'BICARBONATE'
        when itemid = 50804 then 'TOTALCO2'
        when itemid = 50805 then 'CARBOXYHEMOGLOBIN'
        when itemid = 50806 then 'CHLORIDE'
        when itemid = 50808 then 'CALCIUM'
        when itemid = 50809 then 'GLUCOSE'
        when itemid = 50810 then 'HEMATOCRIT'
        when itemid = 50811 then 'HEMOGLOBIN'
        when itemid = 50812 then 'INTUBATED'
        when itemid = 50813 then 'LACTATE'
        when itemid = 50814 then 'METHEMOGLOBIN'
        when itemid = 50815 then 'O2FLOW'
        when itemid = 50816 then 'FIO2'
        when itemid = 50817 then 'SO2' -- OXYGENSATURATION
        when itemid = 50818 then 'PCO2'
        when itemid = 50819 then 'PEEP'
        when itemid = 50820 then 'PH'
        when itemid = 50821 then 'PO2'
        when itemid = 50822 then 'POTASSIUM'
        when itemid = 50823 then 'REQUIREDO2'
        when itemid = 50824 then 'SODIUM'
        when itemid = 50825 then 'TEMPERATURE'
        when itemid = 50826 then 'TIDALVOLUME'
        when itemid = 50827 then 'VENTILATIONRATE'
        when itemid = 50828 then 'VENTILATOR'
        else null
        end as label
        , charttime
        , value
        -- add in some sanity checks on the values
        , case
          when valuenum <= 0 and itemid != 50802 then null -- allow negative baseexcess
          when itemid = 50810 and valuenum > 100 then null -- hematocrit
          -- ensure FiO2 is a valid number between 21-100
          -- mistakes are rare (<100 obs out of ~100,000)
          -- there are 862 obs of valuenum == 20 - some people round down!
          -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
          when itemid = 50816 and valuenum < 20 then null
          when itemid = 50816 and valuenum > 100 then null
          when itemid = 50817 and valuenum > 100 then null -- O2 sat
          when itemid = 50815 and valuenum >  70 then null -- O2 flow
          when itemid = 50821 and valuenum > 800 then null -- PO2
           -- conservative upper limit
        else valuenum
        end as valuenum

    FROM icustays ie
    left join labevents le
      on le.subject_id = ie.subject_id and le.hadm_id = ie.hadm_id
      and le.charttime between (DATETIME_SUB(ie.intime, INTERVAL '6' HOUR)) and (DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
      and le.ITEMID in
      -- blood gases
      (
        50800, 50801, 50802, 50803, 50804, 50805, 50806, 50807, 50808, 50809
        , 50810, 50811, 50812, 50813, 50814, 50815, 50816, 50817, 50818, 50819
        , 50820, 50821, 50822, 50823, 50824, 50825, 50826, 50827, 50828
        , 51545
      )
)
select pvt.SUBJECT_ID, pvt.HADM_ID, pvt.ICUSTAY_ID, pvt.CHARTTIME
, max(case when label = 'SPECIMEN' then value else null end) as specimen
, max(case when label = 'AADO2' then valuenum else null end) as aado2
, max(case when label = 'BASEEXCESS' then valuenum else null end) as baseexcess
, max(case when label = 'BICARBONATE' then valuenum else null end) as bicarbonate
, max(case when label = 'TOTALCO2' then valuenum else null end) as totalco2
, max(case when label = 'CARBOXYHEMOGLOBIN' then valuenum else null end) as carboxyhemoglobin
, max(case when label = 'CHLORIDE' then valuenum else null end) as chloride
, max(case when label = 'CALCIUM' then valuenum else null end) as calcium
, max(case when label = 'GLUCOSE' then valuenum else null end) as glucose
, max(case when label = 'HEMATOCRIT' then valuenum else null end) as hematocrit
, max(case when label = 'HEMOGLOBIN' then valuenum else null end) as hemoglobin
, max(case when label = 'INTUBATED' then valuenum else null end) as intubated
, max(case when label = 'LACTATE' then valuenum else null end) as lactate
, max(case when label = 'METHEMOGLOBIN' then valuenum else null end) as methemoglobin
, max(case when label = 'O2FLOW' then valuenum else null end) as o2flow
, max(case when label = 'FIO2' then valuenum else null end) as fio2
, max(case when label = 'SO2' then valuenum else null end) as so2 -- OXYGENSATURATION
, max(case when label = 'PCO2' then valuenum else null end) as pco2
, max(case when label = 'PEEP' then valuenum else null end) as peep
, max(case when label = 'PH' then valuenum else null end) as ph
, max(case when label = 'PO2' then valuenum else null end) as po2
, max(case when label = 'POTASSIUM' then valuenum else null end) as potassium
, max(case when label = 'REQUIREDO2' then valuenum else null end) as requiredo2
, max(case when label = 'SODIUM' then valuenum else null end) as sodium
, max(case when label = 'TEMPERATURE' then valuenum else null end) as temperature
, max(case when label = 'TIDALVOLUME' then valuenum else null end) as tidalvolume
, max(case when label = 'VENTILATIONRATE' then valuenum else null end) as ventilationrate
, max(case when label = 'VENTILATOR' then valuenum else null end) as ventilator
from pvt
group by pvt.subject_id, pvt.hadm_id, pvt.icustay_id, pvt.CHARTTIME
order by pvt.subject_id, pvt.hadm_id, pvt.icustay_id, pvt.CHARTTIME
  );
17:36:46.239459 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.13 seconds
17:36:46.246433 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.246775 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
alter table "postgres"."public"."blood_gas_first_day" rename to "blood_gas_first_day__dbt_backup"
17:36:46.247581 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.251625 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.251835 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
alter table "postgres"."public"."blood_gas_first_day__dbt_tmp" rename to "blood_gas_first_day"
17:36:46.252586 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.262945 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: COMMIT
17:36:46.263228 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.263431 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: COMMIT
17:36:46.267332 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:46.273065 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day"
17:36:46.273327 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day"} */
drop table if exists "postgres"."public"."blood_gas_first_day__dbt_backup" cascade
17:36:46.276051 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:46.279743 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.279974 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day: Close
17:36:46.280959 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50ea490>]}
17:36:46.281631 [info ] [Thread-1  ]: 1 of 10 OK created table model public.blood_gas_first_day ...................... [[32mSELECT 61532[0m in 0.21s]
17:36:46.282328 [debug] [Thread-1  ]: Finished running node model.mimic.blood_gas_first_day
17:36:46.282835 [debug] [Thread-1  ]: Began running node model.mimic.gcs_first_day
17:36:46.283659 [info ] [Thread-1  ]: 2 of 10 START table model public.gcs_first_day ................................. [RUN]
17:36:46.284856 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.gcs_first_day"
17:36:46.285211 [debug] [Thread-1  ]: Began compiling node model.mimic.gcs_first_day
17:36:46.285439 [debug] [Thread-1  ]: Compiling model.mimic.gcs_first_day
17:36:46.287433 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.gcs_first_day"
17:36:46.288814 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.289253 [debug] [Thread-1  ]: Began executing node model.mimic.gcs_first_day
17:36:46.297704 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.gcs_first_day"
17:36:46.298140 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.298246 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: BEGIN
17:36:46.298341 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:46.304567 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:46.304836 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.305354 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */


  create  table "postgres"."public"."gcs_first_day__dbt_tmp"
  as (
    -- ITEMIDs used:

-- CAREVUE
--    723 as GCSVerbal
--    454 as GCSMotor
--    184 as GCSEyes

-- METAVISION
--    223900 GCS - Verbal Response
--    223901 GCS - Motor Response
--    220739 GCS - Eye Opening

-- The code combines the ITEMIDs into the carevue itemids, then pivots those
-- So 223900 is changed to 723, then the ITEMID 723 is pivoted to form GCSVerbal

-- Note:
--  The GCS for sedated patients is defaulted to 15 in this code.
--  This is in line with how the data is meant to be collected.
--  e.g., from the SAPS II publication:
--    For sedated patients, the Glasgow Coma Score before sedation was used.
--    This was ascertained either from interviewing the physician who ordered the sedation,
--    or by reviewing the patient's medical record.

with base as
(
  SELECT pvt.ICUSTAY_ID
  , pvt.charttime

  -- Easier names - note we coalesced Metavision and CareVue IDs below
  , max(case when pvt.itemid = 454 then pvt.valuenum else null end) as GCSMotor
  , max(case when pvt.itemid = 723 then pvt.valuenum else null end) as GCSVerbal
  , max(case when pvt.itemid = 184 then pvt.valuenum else null end) as GCSEyes

  -- If verbal was set to 0 in the below select, then this is an intubated patient
  , case
      when max(case when pvt.itemid = 723 then pvt.valuenum else null end) = 0
    then 1
    else 0
    end as EndoTrachFlag

  , ROW_NUMBER ()
          OVER (PARTITION BY pvt.ICUSTAY_ID ORDER BY pvt.charttime ASC) as rn

  FROM  (
  select l.ICUSTAY_ID
  -- merge the ITEMIDs so that the pivot applies to both metavision/carevue data
  , case
      when l.ITEMID in (723,223900) then 723
      when l.ITEMID in (454,223901) then 454
      when l.ITEMID in (184,220739) then 184
      else l.ITEMID end
    as ITEMID

  -- convert the data into a number, reserving a value of 0 for ET/Trach
  , case
      -- endotrach/vent is assigned a value of 0, later parsed specially
      when l.ITEMID = 723 and l.VALUE = '1.0 ET/Trach' then 0 -- carevue
      when l.ITEMID = 223900 and l.VALUE = 'No Response-ETT' then 0 -- metavision

      else VALUENUM
      end
    as VALUENUM
  , l.CHARTTIME
  FROM chartevents l

  -- get intime for charttime subselection
  inner join icustays b
    on l.icustay_id = b.icustay_id

  -- Isolate the desired GCS variables
  where l.ITEMID in
  (
    -- 198 -- GCS
    -- GCS components, CareVue
    184, 454, 723
    -- GCS components, Metavision
    , 223900, 223901, 220739
  )
  -- Only get data for the first 24 hours
  and l.charttime between b.intime and DATETIME_ADD(b.intime, INTERVAL '1' DAY)
  -- exclude rows marked as error
  AND (l.error IS NULL OR l.error = 0)
  ) pvt
  group by pvt.ICUSTAY_ID, pvt.charttime
)
, gcs as (
  select b.*
  , b2.GCSVerbal as GCSVerbalPrev
  , b2.GCSMotor as GCSMotorPrev
  , b2.GCSEyes as GCSEyesPrev
  -- Calculate GCS, factoring in special case when they are intubated and prev vals
  -- note that the coalesce are used to implement the following if:
  --  if current value exists, use it
  --  if previous value exists, use it
  --  otherwise, default to normal
  , case
      -- replace GCS during sedation with 15
      when b.GCSVerbal = 0
        then 15
      when b.GCSVerbal is null and b2.GCSVerbal = 0
        then 15
      -- if previously they were intub, but they aren't now, do not use previous GCS values
      when b2.GCSVerbal = 0
        then
            coalesce(b.GCSMotor,6)
          + coalesce(b.GCSVerbal,5)
          + coalesce(b.GCSEyes,4)
      -- otherwise, add up score normally, imputing previous value if none available at current time
      else
            coalesce(b.GCSMotor,coalesce(b2.GCSMotor,6))
          + coalesce(b.GCSVerbal,coalesce(b2.GCSVerbal,5))
          + coalesce(b.GCSEyes,coalesce(b2.GCSEyes,4))
      end as GCS

  from base b
  -- join to itself within 6 hours to get previous value
  left join base b2
    on b.ICUSTAY_ID = b2.ICUSTAY_ID and b.rn = b2.rn+1 and b2.charttime > DATETIME_SUB(b.charttime, INTERVAL '6' HOUR)
)
, gcs_final as (
  select gcs.*
  -- This sorts the data by GCS, so rn=1 is the the lowest GCS values to keep
  , ROW_NUMBER ()
          OVER (PARTITION BY gcs.ICUSTAY_ID
                ORDER BY gcs.GCS
               ) as IsMinGCS
  from gcs
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- The minimum GCS is determined by the above row partition, we only join if IsMinGCS=1
, GCS as mingcs
, coalesce(GCSMotor,GCSMotorPrev) as gcsmotor
, coalesce(GCSVerbal,GCSVerbalPrev) as gcsverbal
, coalesce(GCSEyes,GCSEyesPrev) as gcseyes
, EndoTrachFlag as endotrachflag

-- subselect down to the cohort of eligible patients
FROM icustays ie
left join gcs_final gs
  on ie.icustay_id = gs.icustay_id and gs.IsMinGCS = 1
ORDER BY ie.icustay_id
  );
17:36:46.376198 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.07 seconds
17:36:46.380242 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.380443 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
alter table "postgres"."public"."gcs_first_day" rename to "gcs_first_day__dbt_backup"
17:36:46.381263 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.386386 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.386877 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
alter table "postgres"."public"."gcs_first_day__dbt_tmp" rename to "gcs_first_day"
17:36:46.387598 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.390408 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: COMMIT
17:36:46.390988 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.391285 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: COMMIT
17:36:46.394631 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:46.396757 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs_first_day"
17:36:46.396945 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs_first_day"} */
drop table if exists "postgres"."public"."gcs_first_day__dbt_backup" cascade
17:36:46.399843 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:46.402710 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.402969 [debug] [Thread-1  ]: On model.mimic.gcs_first_day: Close
17:36:46.403708 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50e4760>]}
17:36:46.404220 [info ] [Thread-1  ]: 2 of 10 OK created table model public.gcs_first_day ............................ [[32mSELECT 61532[0m in 0.12s]
17:36:46.404766 [debug] [Thread-1  ]: Finished running node model.mimic.gcs_first_day
17:36:46.405126 [debug] [Thread-1  ]: Began running node model.mimic.height_first_day
17:36:46.405524 [info ] [Thread-1  ]: 3 of 10 START table model public.height_first_day .............................. [RUN]
17:36:46.406221 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.height_first_day"
17:36:46.406345 [debug] [Thread-1  ]: Began compiling node model.mimic.height_first_day
17:36:46.406448 [debug] [Thread-1  ]: Compiling model.mimic.height_first_day
17:36:46.409318 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.height_first_day"
17:36:46.410268 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.411170 [debug] [Thread-1  ]: Began executing node model.mimic.height_first_day
17:36:46.422495 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.height_first_day"
17:36:46.423580 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.423806 [debug] [Thread-1  ]: On model.mimic.height_first_day: BEGIN
17:36:46.424178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:46.430127 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:46.430453 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.431236 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */


  create  table "postgres"."public"."height_first_day__dbt_tmp"
  as (
    -- This query extracts heights for adult ICU patients.
-- It uses all information from the patient's first ICU day.
-- This is done for consistency with other queries - it's not necessarily needed.
-- Height is unlikely to change throughout a patient's stay.

-- ** Requires the echodata view, generated by concepts/echo-data.sql

-- staging table to ensure all heights are in centimeters
with ce0 as
(
    SELECT
      c.icustay_id
      , case
        -- convert inches to centimetres
          when itemid in (920, 1394, 4187, 3486)
              then valuenum * 2.54
            else valuenum
        end as Height
    FROM chartevents c
    inner join icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (226730,920, 1394, 4187, 3486,3485,4188) -- height
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
)
, ce as
(
    SELECT
        icustay_id
        -- extract the median height from the chart to add robustness against outliers
        , AVG(height) as Height_chart
    from ce0
    where height > 100
    group by icustay_id
)
-- requires the echo-data.sql query to run
-- this adds heights from the free-text echo notes
, echo as
(
    select
        ec.subject_id
        -- all echo heights are in inches
        , 2.54*AVG(height) as Height_Echo
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ec.subject_id = ie.subject_id
        and ec.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    where height is not null
    and height*2.54 > 100
    group by ec.subject_id
)
select
    ie.icustay_id
    , coalesce(ce.Height_chart, ec.Height_Echo) as height

    -- components
    , ce.height_chart
    , ec.height_echo
FROM icustays ie

-- filter to only adults
inner join patients pat
    on ie.subject_id = pat.subject_id
    and ie.intime > DATETIME_ADD(pat.dob, INTERVAL '1' YEAR)

left join ce
    on ie.icustay_id = ce.icustay_id

left join echo ec
    on ie.subject_id = ec.subject_id
  );
17:36:46.538294 [debug] [Thread-1  ]: SQL status: SELECT 53432 in 0.11 seconds
17:36:46.542066 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.542272 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
alter table "postgres"."public"."height_first_day" rename to "height_first_day__dbt_backup"
17:36:46.543031 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.546413 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.546897 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
alter table "postgres"."public"."height_first_day__dbt_tmp" rename to "height_first_day"
17:36:46.547612 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:46.551003 [debug] [Thread-1  ]: On model.mimic.height_first_day: COMMIT
17:36:46.551207 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.551425 [debug] [Thread-1  ]: On model.mimic.height_first_day: COMMIT
17:36:46.555343 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:46.556919 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height_first_day"
17:36:46.557093 [debug] [Thread-1  ]: On model.mimic.height_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height_first_day"} */
drop table if exists "postgres"."public"."height_first_day__dbt_backup" cascade
17:36:46.559172 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:46.561866 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.562074 [debug] [Thread-1  ]: On model.mimic.height_first_day: Close
17:36:46.562673 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77d7970>]}
17:36:46.563208 [info ] [Thread-1  ]: 3 of 10 OK created table model public.height_first_day ......................... [[32mSELECT 53432[0m in 0.16s]
17:36:46.563807 [debug] [Thread-1  ]: Finished running node model.mimic.height_first_day
17:36:46.564176 [debug] [Thread-1  ]: Began running node model.mimic.labs_first_day
17:36:46.564801 [info ] [Thread-1  ]: 4 of 10 START table model public.labs_first_day ................................ [RUN]
17:36:46.565622 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.labs_first_day"
17:36:46.565971 [debug] [Thread-1  ]: Began compiling node model.mimic.labs_first_day
17:36:46.566234 [debug] [Thread-1  ]: Compiling model.mimic.labs_first_day
17:36:46.567459 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.labs_first_day"
17:36:46.568119 [debug] [Thread-1  ]: finished collecting timing info
17:36:46.568386 [debug] [Thread-1  ]: Began executing node model.mimic.labs_first_day
17:36:46.578694 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.labs_first_day"
17:36:46.579361 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:46.579567 [debug] [Thread-1  ]: On model.mimic.labs_first_day: BEGIN
17:36:46.579666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:46.586066 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:46.586635 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:46.587025 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */


  create  table "postgres"."public"."labs_first_day__dbt_tmp"
  as (
    -- This query pivots lab values taken in the first 24 hours of a patient's stay

-- Have already confirmed that the unit of measurement is always the same: null or the correct unit

SELECT
  pvt.subject_id, pvt.hadm_id, pvt.icustay_id

  , min(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE NULL END) AS aniongap_min
  , max(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE NULL END) AS aniongap_max
  , min(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE NULL END) AS albumin_min
  , max(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE NULL END) AS albumin_max
  , min(CASE WHEN label = 'BANDS' THEN valuenum ELSE NULL END) AS bands_min
  , max(CASE WHEN label = 'BANDS' THEN valuenum ELSE NULL END) AS bands_max
  , min(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE NULL END) AS bicarbonate_min
  , max(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE NULL END) AS bicarbonate_max
  , min(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE NULL END) AS bilirubin_min
  , max(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE NULL END) AS bilirubin_max
  , min(CASE WHEN label = 'CREATININE' THEN valuenum ELSE NULL END) AS creatinine_min
  , max(CASE WHEN label = 'CREATININE' THEN valuenum ELSE NULL END) AS creatinine_max
  , min(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE NULL END) AS chloride_min
  , max(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE NULL END) AS chloride_max
  , min(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE NULL END) AS glucose_min
  , max(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE NULL END) AS glucose_max
  , min(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE NULL END) AS hematocrit_min
  , max(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE NULL END) AS hematocrit_max
  , min(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE NULL END) AS hemoglobin_min
  , max(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE NULL END) AS hemoglobin_max
  , min(CASE WHEN label = 'LACTATE' THEN valuenum ELSE NULL END) AS lactate_min
  , max(CASE WHEN label = 'LACTATE' THEN valuenum ELSE NULL END) AS lactate_max
  , min(CASE WHEN label = 'PLATELET' THEN valuenum ELSE NULL END) AS platelet_min
  , max(CASE WHEN label = 'PLATELET' THEN valuenum ELSE NULL END) AS platelet_max
  , min(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE NULL END) AS potassium_min
  , max(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE NULL END) AS potassium_max
  , min(CASE WHEN label = 'PTT' THEN valuenum ELSE NULL END) AS ptt_min
  , max(CASE WHEN label = 'PTT' THEN valuenum ELSE NULL END) AS ptt_max
  , min(CASE WHEN label = 'INR' THEN valuenum ELSE NULL END) AS inr_min
  , max(CASE WHEN label = 'INR' THEN valuenum ELSE NULL END) AS inr_max
  , min(CASE WHEN label = 'PT' THEN valuenum ELSE NULL END) AS pt_min
  , max(CASE WHEN label = 'PT' THEN valuenum ELSE NULL END) AS pt_max
  , min(CASE WHEN label = 'SODIUM' THEN valuenum ELSE NULL END) AS sodium_min
  , max(CASE WHEN label = 'SODIUM' THEN valuenum ELSE NULL END) AS sodium_max
  , min(CASE WHEN label = 'BUN' THEN valuenum ELSE NULL END) AS bun_min
  , max(CASE WHEN label = 'BUN' THEN valuenum ELSE NULL END) AS bun_max
  , min(CASE WHEN label = 'WBC' THEN valuenum ELSE NULL END) AS wbc_min
  , max(CASE WHEN label = 'WBC' THEN valuenum ELSE NULL END) AS wbc_max


FROM
( -- begin query that extracts the data
  SELECT ie.subject_id, ie.hadm_id, ie.icustay_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
  , CASE
        WHEN itemid = 50868 THEN 'ANION GAP'
        WHEN itemid = 50862 THEN 'ALBUMIN'
        WHEN itemid = 51144 THEN 'BANDS'
        WHEN itemid = 50882 THEN 'BICARBONATE'
        WHEN itemid = 50885 THEN 'BILIRUBIN'
        WHEN itemid = 50912 THEN 'CREATININE'
        WHEN itemid = 50806 THEN 'CHLORIDE'
        WHEN itemid = 50902 THEN 'CHLORIDE'
        WHEN itemid = 50809 THEN 'GLUCOSE'
        WHEN itemid = 50931 THEN 'GLUCOSE'
        WHEN itemid = 50810 THEN 'HEMATOCRIT'
        WHEN itemid = 51221 THEN 'HEMATOCRIT'
        WHEN itemid = 50811 THEN 'HEMOGLOBIN'
        WHEN itemid = 51222 THEN 'HEMOGLOBIN'
        WHEN itemid = 50813 THEN 'LACTATE'
        WHEN itemid = 51265 THEN 'PLATELET'
        WHEN itemid = 50822 THEN 'POTASSIUM'
        WHEN itemid = 50971 THEN 'POTASSIUM'
        WHEN itemid = 51275 THEN 'PTT'
        WHEN itemid = 51237 THEN 'INR'
        WHEN itemid = 51274 THEN 'PT'
        WHEN itemid = 50824 THEN 'SODIUM'
        WHEN itemid = 50983 THEN 'SODIUM'
        WHEN itemid = 51006 THEN 'BUN'
        WHEN itemid = 51300 THEN 'WBC'
        WHEN itemid = 51301 THEN 'WBC'
      ELSE null
    END as label
  , -- add in some sanity checks on the values
  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks
    CASE
      WHEN itemid = 50862 and valuenum >    10 THEN null -- g/dL 'ALBUMIN'
      WHEN itemid = 50868 and valuenum > 10000 THEN null -- mEq/L 'ANION GAP'
      WHEN itemid = 51144 and valuenum <     0 THEN null -- immature band forms, %
      WHEN itemid = 51144 and valuenum >   100 THEN null -- immature band forms, %
      WHEN itemid = 50882 and valuenum > 10000 THEN null -- mEq/L 'BICARBONATE'
      WHEN itemid = 50885 and valuenum >   150 THEN null -- mg/dL 'BILIRUBIN'
      WHEN itemid = 50806 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50902 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50912 and valuenum >   150 THEN null -- mg/dL 'CREATININE'
      WHEN itemid = 50809 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50931 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50810 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 51221 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 50811 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 51222 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 50813 and valuenum >    50 THEN null -- mmol/L 'LACTATE'
      WHEN itemid = 51265 and valuenum > 10000 THEN null -- K/uL 'PLATELET'
      WHEN itemid = 50822 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 50971 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 51275 and valuenum >   150 THEN null -- sec 'PTT'
      WHEN itemid = 51237 and valuenum >    50 THEN null -- 'INR'
      WHEN itemid = 51274 and valuenum >   150 THEN null -- sec 'PT'
      WHEN itemid = 50824 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 50983 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 51006 and valuenum >   300 THEN null -- 'BUN'
      WHEN itemid = 51300 and valuenum >  1000 THEN null -- 'WBC'
      WHEN itemid = 51301 and valuenum >  1000 THEN null -- 'WBC'
    ELSE le.valuenum
    END as valuenum

  FROM icustays ie

  LEFT JOIN labevents le
    ON le.subject_id = ie.subject_id AND le.hadm_id = ie.hadm_id
    AND le.charttime BETWEEN (DATETIME_SUB(ie.intime, INTERVAL '6' HOUR)) AND (DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
    AND le.ITEMID in
    (
      -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS
      50868, -- ANION GAP | CHEMISTRY | BLOOD | 769895
      50862, -- ALBUMIN | CHEMISTRY | BLOOD | 146697
      51144, -- BANDS - hematology
      50882, -- BICARBONATE | CHEMISTRY | BLOOD | 780733
      50885, -- BILIRUBIN, TOTAL | CHEMISTRY | BLOOD | 238277
      50912, -- CREATININE | CHEMISTRY | BLOOD | 797476
      50902, -- CHLORIDE | CHEMISTRY | BLOOD | 795568
      50806, -- CHLORIDE, WHOLE BLOOD | BLOOD GAS | BLOOD | 48187
      50931, -- GLUCOSE | CHEMISTRY | BLOOD | 748981
      50809, -- GLUCOSE | BLOOD GAS | BLOOD | 196734
      51221, -- HEMATOCRIT | HEMATOLOGY | BLOOD | 881846
      50810, -- HEMATOCRIT, CALCULATED | BLOOD GAS | BLOOD | 89715
      51222, -- HEMOGLOBIN | HEMATOLOGY | BLOOD | 752523
      50811, -- HEMOGLOBIN | BLOOD GAS | BLOOD | 89712
      50813, -- LACTATE | BLOOD GAS | BLOOD | 187124
      51265, -- PLATELET COUNT | HEMATOLOGY | BLOOD | 778444
      50971, -- POTASSIUM | CHEMISTRY | BLOOD | 845825
      50822, -- POTASSIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 192946
      51275, -- PTT | HEMATOLOGY | BLOOD | 474937
      51237, -- INR(PT) | HEMATOLOGY | BLOOD | 471183
      51274, -- PT | HEMATOLOGY | BLOOD | 469090
      50983, -- SODIUM | CHEMISTRY | BLOOD | 808489
      50824, -- SODIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 71503
      51006, -- UREA NITROGEN | CHEMISTRY | BLOOD | 791925
      51301, -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301
      51300  -- WBC COUNT | HEMATOLOGY | BLOOD | 2371
    )
    AND valuenum IS NOT null AND valuenum > 0 -- lab values cannot be 0 and cannot be negative
) pvt
GROUP BY pvt.subject_id, pvt.hadm_id, pvt.icustay_id
ORDER BY pvt.subject_id, pvt.hadm_id, pvt.icustay_id
  );
17:36:47.836873 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.25 seconds
17:36:47.844265 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:47.844467 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
alter table "postgres"."public"."labs_first_day" rename to "labs_first_day__dbt_backup"
17:36:47.845154 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:47.849162 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:47.849408 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
alter table "postgres"."public"."labs_first_day__dbt_tmp" rename to "labs_first_day"
17:36:47.850174 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:47.855399 [debug] [Thread-1  ]: On model.mimic.labs_first_day: COMMIT
17:36:47.855642 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:47.855888 [debug] [Thread-1  ]: On model.mimic.labs_first_day: COMMIT
17:36:47.857503 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:47.859720 [debug] [Thread-1  ]: Using postgres connection "model.mimic.labs_first_day"
17:36:47.859925 [debug] [Thread-1  ]: On model.mimic.labs_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.labs_first_day"} */
drop table if exists "postgres"."public"."labs_first_day__dbt_backup" cascade
17:36:47.862248 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:47.865097 [debug] [Thread-1  ]: finished collecting timing info
17:36:47.865336 [debug] [Thread-1  ]: On model.mimic.labs_first_day: Close
17:36:47.865813 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50e49d0>]}
17:36:47.866070 [info ] [Thread-1  ]: 4 of 10 OK created table model public.labs_first_day ........................... [[32mSELECT 61532[0m in 1.30s]
17:36:47.866411 [debug] [Thread-1  ]: Finished running node model.mimic.labs_first_day
17:36:47.867377 [debug] [Thread-1  ]: Began running node model.mimic.rrt_first_day
17:36:47.868853 [info ] [Thread-1  ]: 5 of 10 START table model public.rrt_first_day ................................. [RUN]
17:36:47.870004 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rrt_first_day"
17:36:47.870386 [debug] [Thread-1  ]: Began compiling node model.mimic.rrt_first_day
17:36:47.870747 [debug] [Thread-1  ]: Compiling model.mimic.rrt_first_day
17:36:47.872270 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rrt_first_day"
17:36:47.873092 [debug] [Thread-1  ]: finished collecting timing info
17:36:47.873571 [debug] [Thread-1  ]: Began executing node model.mimic.rrt_first_day
17:36:47.881256 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rrt_first_day"
17:36:47.881831 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:47.882035 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: BEGIN
17:36:47.882195 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:47.888926 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:47.889158 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:47.889446 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */


  create  table "postgres"."public"."rrt_first_day__dbt_tmp"
  as (
    -- determines if patients received any dialysis during their stay

-- Some example aggregate queries which summarize the data here..
-- This query estimates 6.7% of ICU patients received RRT.
    -- select count(rrt.icustay_id) as numobs
    -- , sum(rrt) as numrrt
    -- , sum(case when rrt=1 then 1 else 0 end)*100.0 / count(rrt.icustay_id)
    -- as percent_rrt
    -- from rrt
    -- inner join icustays ie on rrt.icustay_id = ie.icustay_id
    -- inner join patients p
    -- on rrt.subject_id = p.subject_id
    -- and p.dob < ie.intime - interval '1' year
    -- inner join admissions adm
    -- on rrt.hadm_id = adm.hadm_id

-- This query estimates that 4.6% of first ICU stays received RRT.
    -- select
    --   count(rrt.icustay_id) as numobs
    --   , sum(rrt) as numrrt
    --   , sum(case when rrt=1 then 1 else 0 end)*100.0 / count(rrt.icustay_id)
    -- as percent_rrt
    -- from
    -- (
    -- select ie.icustay_id, rrt.rrt
    --   , ROW_NUMBER() over (partition by ie.subject_id order by ie.intime) rn
    -- from rrt
    -- inner join icustays ie
    --   on rrt.icustay_id = ie.icustay_id
    -- inner join patients p
    --   on rrt.subject_id = p.subject_id
    -- and p.dob < ie.intime - interval '1' year
    -- inner join admissions adm
    --   on rrt.hadm_id = adm.hadm_id
    -- ) rrt
    -- where rn = 1

with cv as
(
  select ie.icustay_id
    , max(
        case
          when ce.itemid in (152,148,149,146,147,151,150) and value is not null then 1
          when ce.itemid in (229,235,241,247,253,259,265,271) and value = 'Dialysis Line' then 1
          when ce.itemid = 582 and value in ('CAVH Start','CAVH D/C','CVVHD Start','CVVHD D/C','Hemodialysis st','Hemodialysis end') then 1
        else 0 end
        ) as RRT
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.itemid in
    (
       152 -- "Dialysis Type"61449
      ,148 -- "Dialysis Access Site"60335
      ,149 -- "Dialysis Access Type"60030
      ,146 -- "Dialysate Flow ml/hr"57445
      ,147 -- "Dialysate Infusing"56605
      ,151 -- "Dialysis Site Appear"37345
      ,150 -- "Dialysis Machine"27472
      ,229 -- INV Line#1 [Type]
      ,235 -- INV Line#2 [Type]
      ,241 -- INV Line#3 [Type]
      ,247 -- INV Line#4 [Type]
      ,253 -- INV Line#5 [Type]
      ,259 -- INV Line#6 [Type]
      ,265 -- INV Line#7 [Type]
      ,271 -- INV Line#8 [Type]
      ,582 -- Procedures
    )
    and ce.value is not null
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where ie.dbsource = 'carevue'
  group by ie.icustay_id
)
, mv_ce as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
      -- Checkboxes
        226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
      , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
      , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox
      -- Numeric values
      , 226499 -- | Hemodialysis Output                               | Dialysis                | chartevents        | Numeric
      , 224154 -- | Dialysate Rate                                    | Dialysis                | chartevents        | Numeric
      , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis                | chartevents        | Numeric
      , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis                | chartevents        | Numeric
      , 225183 -- | Current Goal                     | Dialysis | chartevents        | Numeric
      , 227438 -- | Volume not removed               | Dialysis | chartevents        | Numeric
      , 224191 -- | Hourly Patient Fluid Removal     | Dialysis | chartevents        | Numeric
      , 225806 -- | Volume In (PD)                   | Dialysis | chartevents        | Numeric
      , 225807 -- | Volume Out (PD)                  | Dialysis | chartevents        | Numeric
      , 228004 -- | Citrate (ACD-A)                  | Dialysis | chartevents        | Numeric
      , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis | chartevents        | Numeric
      , 228006 -- | Post Filter Replacement Rate     | Dialysis | chartevents        | Numeric
      , 224144 -- | Blood Flow (ml/min)              | Dialysis | chartevents        | Numeric
      , 224145 -- | Heparin Dose (per hour)          | Dialysis | chartevents        | Numeric
      , 224149 -- | Access Pressure                  | Dialysis | chartevents        | Numeric
      , 224150 -- | Filter Pressure                  | Dialysis | chartevents        | Numeric
      , 224151 -- | Effluent Pressure                | Dialysis | chartevents        | Numeric
      , 224152 -- | Return Pressure                  | Dialysis | chartevents        | Numeric
      , 224153 -- | Replacement Rate                 | Dialysis | chartevents        | Numeric
      , 224404 -- | ART Lumen Volume                 | Dialysis | chartevents        | Numeric
      , 224406 -- | VEN Lumen Volume                 | Dialysis | chartevents        | Numeric
      , 226457 -- | Ultrafiltrate Output             | Dialysis | chartevents        | Numeric
    )
    and valuenum > 0 -- also ensures it's not null
  group by ie.icustay_id
)
, mv_ie as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join inputevents_mv tt
    on ie.icustay_id = tt.icustay_id
    and tt.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
        227536 --	KCl (CRRT)	Medications	inputevents_mv	Solution
      , 227525 --	Calcium Gluconate (CRRT)	Medications	inputevents_mv	Solution
    )
    and amount > 0 -- also ensures it's not null
  group by ie.icustay_id
)
, mv_de as
(
  select ie.icustay_id
    , 1 as RRT
  FROM icustays ie
  inner join datetimeevents tt
    on ie.icustay_id = tt.icustay_id
    and tt.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    and itemid in
    (
      -- TODO: unsure how to handle "Last dialysis"
      --  225128 -- | Last dialysis                                     | Adm History/FHPA        | datetimeevents     | Date time
        225318 -- | Dialysis Catheter Cap Change                      | Access Lines - Invasive | datetimeevents     | Date time
      , 225319 -- | Dialysis Catheter Change over Wire Date           | Access Lines - Invasive | datetimeevents     | Date time
      , 225321 -- | Dialysis Catheter Dressing Change                 | Access Lines - Invasive | datetimeevents     | Date time
      , 225322 -- | Dialysis Catheter Insertion Date                  | Access Lines - Invasive | datetimeevents     | Date time
      , 225324 -- | Dialysis CatheterTubing Change                    | Access Lines - Invasive | datetimeevents     | Date time
    )
  group by ie.icustay_id
)
, mv_pe as
(
    select ie.icustay_id
      , 1 as RRT
    FROM icustays ie
    inner join procedureevents_mv tt
      on ie.icustay_id = tt.icustay_id
      and tt.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
      and itemid in
      (
          225441 -- | Hemodialysis                                      | 4-Procedures            | procedureevents_mv | Process
        , 225802 -- | Dialysis - CRRT                                   | Dialysis                | procedureevents_mv | Process
        , 225803 -- | Dialysis - CVVHD                                  | Dialysis                | procedureevents_mv | Process
        , 225805 -- | Peritoneal Dialysis                               | Dialysis                | procedureevents_mv | Process
        , 224270 -- | Dialysis Catheter                                 | Access Lines - Invasive | procedureevents_mv | Process
        , 225809 -- | Dialysis - CVVHDF                                 | Dialysis                | procedureevents_mv | Process
        , 225955 -- | Dialysis - SCUF                                   | Dialysis                | procedureevents_mv | Process
        , 225436 -- | CRRT Filter Change               | Dialysis | procedureevents_mv | Process
      )
    group by ie.icustay_id
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
  , case
      when cv.RRT = 1 then 1
      when mv_ce.RRT = 1 then 1
      when mv_ie.RRT = 1 then 1
      when mv_de.RRT = 1 then 1
      when mv_pe.RRT = 1 then 1
      else 0
    end as rrt
FROM icustays ie
left join cv
  on ie.icustay_id = cv.icustay_id
left join mv_ce
  on ie.icustay_id = mv_ce.icustay_id
left join mv_ie
  on ie.icustay_id = mv_ie.icustay_id
left join mv_de
  on ie.icustay_id = mv_de.icustay_id
left join mv_pe
  on ie.icustay_id = mv_pe.icustay_id
order by ie.icustay_id
  );
17:36:50.761217 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 2.87 seconds
17:36:50.769824 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:50.770181 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
alter table "postgres"."public"."rrt_first_day" rename to "rrt_first_day__dbt_backup"
17:36:50.771497 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:50.775541 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:50.775747 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
alter table "postgres"."public"."rrt_first_day__dbt_tmp" rename to "rrt_first_day"
17:36:50.776606 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:50.779777 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: COMMIT
17:36:50.780104 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:50.780296 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: COMMIT
17:36:50.785893 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:36:50.788522 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rrt_first_day"
17:36:50.788735 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rrt_first_day"} */
drop table if exists "postgres"."public"."rrt_first_day__dbt_backup" cascade
17:36:50.790850 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:50.793522 [debug] [Thread-1  ]: finished collecting timing info
17:36:50.793780 [debug] [Thread-1  ]: On model.mimic.rrt_first_day: Close
17:36:50.794466 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50e4a60>]}
17:36:50.794989 [info ] [Thread-1  ]: 5 of 10 OK created table model public.rrt_first_day ............................ [[32mSELECT 61532[0m in 2.92s]
17:36:50.795560 [debug] [Thread-1  ]: Finished running node model.mimic.rrt_first_day
17:36:50.795936 [debug] [Thread-1  ]: Began running node model.mimic.urine_output_first_day
17:36:50.796629 [info ] [Thread-1  ]: 6 of 10 START table model public.urine_output_first_day ........................ [RUN]
17:36:50.797471 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.urine_output_first_day"
17:36:50.797774 [debug] [Thread-1  ]: Began compiling node model.mimic.urine_output_first_day
17:36:50.798087 [debug] [Thread-1  ]: Compiling model.mimic.urine_output_first_day
17:36:50.799350 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.urine_output_first_day"
17:36:50.800092 [debug] [Thread-1  ]: finished collecting timing info
17:36:50.800417 [debug] [Thread-1  ]: Began executing node model.mimic.urine_output_first_day
17:36:50.813064 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.urine_output_first_day"
17:36:50.813600 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:50.813759 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: BEGIN
17:36:50.813911 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:50.820258 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:50.820561 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:50.820701 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */


  create  table "postgres"."public"."urine_output_first_day__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Purpose: Create a view of the urine output for each ICUSTAY_ID over the first 24 hours.
-- ------------------------------------------------------------------

select
  -- patient identifiers
  ie.subject_id, ie.hadm_id, ie.icustay_id

  -- volumes associated with urine output ITEMIDs
  , sum(
      -- we consider input of GU irrigant as a negative volume
      case
        when oe.itemid = 227488 and oe.value > 0 then -1*oe.value
        else oe.value
    end) as urineoutput
FROM icustays ie
-- Join to the outputevents table to get urine output
left join outputevents oe
-- join on all patient identifiers
on ie.subject_id = oe.subject_id and ie.hadm_id = oe.hadm_id and ie.icustay_id = oe.icustay_id
-- and ensure the data occurs during the first day
and oe.charttime between ie.intime and (DATETIME_ADD(ie.intime, INTERVAL '1' DAY)) -- first ICU day
where itemid in
(
-- these are the most frequently occurring urine output observations in CareVue
40055, -- "Urine Out Foley"
43175, -- "Urine ."
40069, -- "Urine Out Void"
40094, -- "Urine Out Condom Cath"
40715, -- "Urine Out Suprapubic"
40473, -- "Urine Out IleoConduit"
40085, -- "Urine Out Incontinent"
40057, -- "Urine Out Rt Nephrostomy"
40056, -- "Urine Out Lt Nephrostomy"
40405, -- "Urine Out Other"
40428, -- "Urine Out Straight Cath"
40086,--	Urine Out Incontinent
40096, -- "Urine Out Ureteral Stent #1"
40651, -- "Urine Out Ureteral Stent #2"

-- these are the most frequently occurring urine output observations in MetaVision
226559, -- "Foley"
226560, -- "Void"
226561, -- "Condom Cath"
226584, -- "Ileoconduit"
226563, -- "Suprapubic"
226564, -- "R Nephrostomy"
226565, -- "L Nephrostomy"
226567, --	Straight Cath
226557, -- R Ureteral Stent
226558, -- L Ureteral Stent
227488, -- GU Irrigant Volume In
227489  -- GU Irrigant/Urine Volume Out
)
group by ie.subject_id, ie.hadm_id, ie.icustay_id
order by ie.subject_id, ie.hadm_id, ie.icustay_id
  );
17:36:54.319347 [debug] [Thread-1  ]: SQL status: SELECT 53359 in 3.5 seconds
17:36:54.326429 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:54.326856 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
alter table "postgres"."public"."urine_output_first_day" rename to "urine_output_first_day__dbt_backup"
17:36:54.328125 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.333185 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:54.333384 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
alter table "postgres"."public"."urine_output_first_day__dbt_tmp" rename to "urine_output_first_day"
17:36:54.334061 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.336945 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: COMMIT
17:36:54.337142 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:54.337336 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: COMMIT
17:36:54.344215 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:36:54.346895 [debug] [Thread-1  ]: Using postgres connection "model.mimic.urine_output_first_day"
17:36:54.347216 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.urine_output_first_day"} */
drop table if exists "postgres"."public"."urine_output_first_day__dbt_backup" cascade
17:36:54.349311 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:54.352082 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.352315 [debug] [Thread-1  ]: On model.mimic.urine_output_first_day: Close
17:36:54.353080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77d7970>]}
17:36:54.353644 [info ] [Thread-1  ]: 6 of 10 OK created table model public.urine_output_first_day ................... [[32mSELECT 53359[0m in 3.56s]
17:36:54.354118 [debug] [Thread-1  ]: Finished running node model.mimic.urine_output_first_day
17:36:54.354263 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_first_day
17:36:54.355031 [info ] [Thread-1  ]: 7 of 10 START table model public.ventilation_first_day ......................... [RUN]
17:36:54.356033 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_first_day"
17:36:54.356303 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_first_day
17:36:54.356629 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_first_day
17:36:54.359718 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_first_day"
17:36:54.360569 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.360836 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_first_day
17:36:54.372458 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_first_day"
17:36:54.373274 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.373492 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: BEGIN
17:36:54.373733 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:54.378296 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:36:54.379044 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.379390 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */


  create  table "postgres"."public"."ventilation_first_day__dbt_tmp"
  as (
    -- Determines if a patient is ventilated on the first day of their ICU stay.
-- Creates a table with the result.
-- Requires the ventilation_durations table, generated by ../ventilation-durations.sql

select
  ie.subject_id, ie.hadm_id, ie.icustay_id
  -- if vd.icustay_id is not null, then they have a valid ventilation event
  -- in this case, we say they are ventilated
  -- otherwise, they are not
  , max(case
      when vd.icustay_id is not null then 1
    else 0 end) as vent
FROM icustays ie
left join "postgres"."public"."ventilation_durations" vd
  on ie.icustay_id = vd.icustay_id
  and
  (
    -- ventilation duration overlaps with ICU admission -> vented on admission
    (vd.starttime <= ie.intime and vd.endtime >= ie.intime)
    -- ventilation started during the first day
    OR (vd.starttime >= ie.intime and vd.starttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY))
  )
group by ie.subject_id, ie.hadm_id, ie.icustay_id
order by ie.subject_id, ie.hadm_id, ie.icustay_id
  );
17:36:54.469532 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.09 seconds
17:36:54.474395 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.474758 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
alter table "postgres"."public"."ventilation_first_day" rename to "ventilation_first_day__dbt_backup"
17:36:54.475462 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.481822 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.482033 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
alter table "postgres"."public"."ventilation_first_day__dbt_tmp" rename to "ventilation_first_day"
17:36:54.482649 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.487059 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: COMMIT
17:36:54.487278 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.487460 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: COMMIT
17:36:54.493036 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:36:54.496860 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_first_day"
17:36:54.497411 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_first_day"} */
drop table if exists "postgres"."public"."ventilation_first_day__dbt_backup" cascade
17:36:54.499673 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:54.502263 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.502718 [debug] [Thread-1  ]: On model.mimic.ventilation_first_day: Close
17:36:54.503663 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50e4d00>]}
17:36:54.504289 [info ] [Thread-1  ]: 7 of 10 OK created table model public.ventilation_first_day .................... [[32mSELECT 61532[0m in 0.15s]
17:36:54.504818 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_first_day
17:36:54.505135 [debug] [Thread-1  ]: Began running node model.mimic.vitals_first_day
17:36:54.505572 [info ] [Thread-1  ]: 8 of 10 START table model public.vitals_first_day .............................. [RUN]
17:36:54.506103 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vitals_first_day"
17:36:54.506220 [debug] [Thread-1  ]: Began compiling node model.mimic.vitals_first_day
17:36:54.506335 [debug] [Thread-1  ]: Compiling model.mimic.vitals_first_day
17:36:54.508116 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vitals_first_day"
17:36:54.508639 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.508877 [debug] [Thread-1  ]: Began executing node model.mimic.vitals_first_day
17:36:54.523830 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vitals_first_day"
17:36:54.524539 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.524698 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: BEGIN
17:36:54.524807 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:54.531706 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:54.532009 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.532147 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */


  create  table "postgres"."public"."vitals_first_day__dbt_tmp"
  as (
    -- This query pivots the vital signs for the first 24 hours of a patient's stay
-- Vital signs include heart rate, blood pressure, respiration rate, and temperature

SELECT pvt.subject_id, pvt.hadm_id, pvt.icustay_id

-- Easier names
, min(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_min
, max(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_max
, avg(case when VitalID = 1 then valuenum ELSE NULL END) AS heartrate_mean
, min(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_min
, max(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_max
, avg(case when VitalID = 2 then valuenum ELSE NULL END) AS sysbp_mean
, min(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_min
, max(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_max
, avg(case when VitalID = 3 then valuenum ELSE NULL END) AS diasbp_mean
, min(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_min
, max(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_max
, avg(case when VitalID = 4 then valuenum ELSE NULL END) AS meanbp_mean
, min(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_min
, max(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_max
, avg(case when VitalID = 5 then valuenum ELSE NULL END) AS resprate_mean
, min(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_min
, max(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_max
, avg(case when VitalID = 6 then valuenum ELSE NULL END) AS tempc_mean
, min(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_min
, max(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_max
, avg(case when VitalID = 7 then valuenum ELSE NULL END) AS spo2_mean
, min(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_min
, max(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_max
, avg(case when VitalID = 8 then valuenum ELSE NULL END) AS glucose_mean

FROM  (
  select ie.subject_id, ie.hadm_id, ie.icustay_id
  , case
    when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then 1 -- HeartRate
    when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then 2 -- SysBP
    when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then 3 -- DiasBP
    when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then 4 -- MeanBP
    when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then 5 -- RespRate
    when itemid in (223761,678) and valuenum > 70 and valuenum < 120  then 6 -- TempF, converted to degC in valuenum call
    when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then 6 -- TempC
    when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then 7 -- SpO2
    when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then 8 -- Glucose

    else null end as vitalid
      -- convert F to C
  , case when itemid in (223761,678) then (valuenum-32)/1.8 else valuenum end as valuenum

  from icustays ie
  left join chartevents ce
  on ie.icustay_id = ce.icustay_id
  and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1 DAY')
  and DATETIME_DIFF(ce.charttime, ie.intime, 'SECOND') > 0
  and DATETIME_DIFF(ce.charttime, ie.intime, 'HOUR') <= 24
  -- exclude rows marked as error
  and (ce.error IS NULL or ce.error = 0)
  where ce.itemid in
  (
  -- HEART RATE
  211, --"Heart Rate"
  220045, --"Heart Rate"

  -- Systolic/diastolic

  51, --	Arterial BP [Systolic]
  442, --	Manual BP [Systolic]
  455, --	NBP [Systolic]
  6701, --	Arterial BP #2 [Systolic]
  220179, --	Non Invasive Blood Pressure systolic
  220050, --	Arterial Blood Pressure systolic

  8368, --	Arterial BP [Diastolic]
  8440, --	Manual BP [Diastolic]
  8441, --	NBP [Diastolic]
  8555, --	Arterial BP #2 [Diastolic]
  220180, --	Non Invasive Blood Pressure diastolic
  220051, --	Arterial Blood Pressure diastolic


  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312, --"ART BP mean"

  -- RESPIRATORY RATE
  618,--	Respiratory Rate
  615,--	Resp Rate (Total)
  220210,--	Respiratory Rate
  224690, --	Respiratory Rate (Total)


  -- SPO2, peripheral
  646, 220277,

  -- GLUCOSE, both lab and fingerstick
  807,--	Fingerstick Glucose
  811,--	Glucose (70-105)
  1529,--	Glucose
  3745,--	BloodGlucose
  3744,--	Blood Glucose
  225664,--	Glucose finger stick
  220621,--	Glucose (serum)
  226537,--	Glucose (whole blood)

  -- TEMPERATURE
  223762, -- "Temperature Celsius"
  676,	-- "Temperature C"
  223761, -- "Temperature Fahrenheit"
  678 --	"Temperature F"

  )
) pvt
group by pvt.subject_id, pvt.hadm_id, pvt.icustay_id
order by pvt.subject_id, pvt.hadm_id, pvt.icustay_id
  );
17:36:54.582052 [debug] [Thread-1  ]: SQL status: SELECT 13 in 0.05 seconds
17:36:54.587912 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.588146 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
alter table "postgres"."public"."vitals_first_day" rename to "vitals_first_day__dbt_backup"
17:36:54.588852 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.593203 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.593413 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
alter table "postgres"."public"."vitals_first_day__dbt_tmp" rename to "vitals_first_day"
17:36:54.594016 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.599689 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: COMMIT
17:36:54.599942 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.600273 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: COMMIT
17:36:54.601388 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:54.604059 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vitals_first_day"
17:36:54.604261 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vitals_first_day"} */
drop table if exists "postgres"."public"."vitals_first_day__dbt_backup" cascade
17:36:54.606041 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:54.609229 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.609630 [debug] [Thread-1  ]: On model.mimic.vitals_first_day: Close
17:36:54.610182 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77420a0>]}
17:36:54.610769 [info ] [Thread-1  ]: 8 of 10 OK created table model public.vitals_first_day ......................... [[32mSELECT 13[0m in 0.10s]
17:36:54.612147 [debug] [Thread-1  ]: Finished running node model.mimic.vitals_first_day
17:36:54.613603 [debug] [Thread-1  ]: Began running node model.mimic.weight_first_day
17:36:54.614489 [info ] [Thread-1  ]: 9 of 10 START table model public.weight_first_day .............................. [RUN]
17:36:54.615602 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.weight_first_day"
17:36:54.616291 [debug] [Thread-1  ]: Began compiling node model.mimic.weight_first_day
17:36:54.616625 [debug] [Thread-1  ]: Compiling model.mimic.weight_first_day
17:36:54.620749 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.weight_first_day"
17:36:54.621181 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.621309 [debug] [Thread-1  ]: Began executing node model.mimic.weight_first_day
17:36:54.629563 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.weight_first_day"
17:36:54.630336 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.630453 [debug] [Thread-1  ]: On model.mimic.weight_first_day: BEGIN
17:36:54.630917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:54.637214 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:54.637450 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.637569 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */


  create  table "postgres"."public"."weight_first_day__dbt_tmp"
  as (
    -- This query extracts weights for adult ICU patients on their first ICU day.
-- It does *not* use any information after the first ICU day, as weight is
-- sometimes used to monitor fluid balance.

-- ** Requires the echodata view, generated by concepts/echo-data.sql

with ce as
(
    SELECT
      c.icustay_id
      -- we take the avg value from roughly first day
      -- TODO: eliminate obvious outliers if there is a reasonable weight
      -- (e.g. weight of 180kg and 90kg would remove 180kg instead of taking the median)
      , AVG(VALUENUM) as Weight_Admit
    FROM chartevents c
    inner join icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (762,226512) -- Admit Wt
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
    group by c.icustay_id
)
, dwt as
(
    SELECT
      c.icustay_id
      , AVG(VALUENUM) as Weight_Daily
    FROM chartevents c
    INNER JOIN icustays ie
        on c.icustay_id = ie.icustay_id
        and c.charttime <= DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
        and c.charttime > DATETIME_SUB(ie.intime, INTERVAL '1' DAY) -- some fuzziness for admit time
    WHERE c.valuenum IS NOT NULL
    AND c.itemid in (763,224639) -- Daily Weight
    AND c.valuenum != 0
    -- exclude rows marked as error
    AND (c.error IS NULL OR c.error = 0)
    group by c.icustay_id
)
-- we split in-hospital/out of hospital echoes as we would like to prioritize in-hospital data
, echo_hadm as
(
    select
        ie.icustay_id
        , 0.453592*AVG(weight) as Weight_EchoInHosp
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ec.hadm_id = ie.hadm_id
        and ec.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
    where
            ec.HADM_ID is not null
        and ec.weight is not null
    group by ie.icustay_id
)
, echo_nohadm as
(
    select
        ie.icustay_id
        , 0.453592*AVG(weight) as Weight_EchoPreHosp
    from "postgres"."public"."echo_data" ec
    inner join icustays ie
        on ie.subject_id = ec.subject_id
        and ie.intime < DATETIME_ADD(ec.charttime, INTERVAL '1' MONTH)
        and ie.intime > ec.charttime
    where
            ec.HADM_ID is null
        and ec.weight is not null
    group by ie.icustay_id
)
select
    ie.icustay_id
    , round(cast(
    case
        when ce.icustay_id is not null
            then ce.Weight_Admit
        when dwt.icustay_id is not null
            then dwt.Weight_Daily
        when eh.icustay_id is not null
            then eh.Weight_EchoInHosp
        when enh.icustay_id is not null
            then enh.Weight_EchoPreHosp
        else null end
        as numeric), 2)
    as weight

    -- components
    , ce.weight_admit
    , dwt.weight_daily
    , eh.weight_echoinhosp
    , enh.weight_echoprehosp

FROM icustays ie

-- filter to only adults
inner join patients pat
    on ie.subject_id = pat.subject_id
    and ie.intime > DATETIME_ADD(pat.dob, INTERVAL '1' YEAR)

-- admission weight
left join ce
    on ie.icustay_id = ce.icustay_id

-- daily weights
left join dwt
    on ie.icustay_id = dwt.icustay_id

-- in-hospital echo weight
left join echo_hadm eh
    on ie.icustay_id = eh.icustay_id

-- pre-hospitalization echo weights
left join echo_nohadm enh
    on ie.icustay_id = enh.icustay_id
order by ie.icustay_id
  );
17:36:54.758317 [debug] [Thread-1  ]: SQL status: SELECT 53432 in 0.12 seconds
17:36:54.764599 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.764841 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
alter table "postgres"."public"."weight_first_day" rename to "weight_first_day__dbt_backup"
17:36:54.766652 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.771185 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.771428 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
alter table "postgres"."public"."weight_first_day__dbt_tmp" rename to "weight_first_day"
17:36:54.772148 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.775204 [debug] [Thread-1  ]: On model.mimic.weight_first_day: COMMIT
17:36:54.775411 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.775588 [debug] [Thread-1  ]: On model.mimic.weight_first_day: COMMIT
17:36:54.781464 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:36:54.784912 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_first_day"
17:36:54.785239 [debug] [Thread-1  ]: On model.mimic.weight_first_day: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_first_day"} */
drop table if exists "postgres"."public"."weight_first_day__dbt_backup" cascade
17:36:54.787192 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:54.789974 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.790202 [debug] [Thread-1  ]: On model.mimic.weight_first_day: Close
17:36:54.790836 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50e4fa0>]}
17:36:54.791310 [info ] [Thread-1  ]: 9 of 10 OK created table model public.weight_first_day ......................... [[32mSELECT 53432[0m in 0.18s]
17:36:54.791831 [debug] [Thread-1  ]: Finished running node model.mimic.weight_first_day
17:36:54.792152 [debug] [Thread-1  ]: Began running node model.mimic.blood_gas_first_day_arterial
17:36:54.792850 [info ] [Thread-1  ]: 10 of 10 START table model public.blood_gas_first_day_arterial ................. [RUN]
17:36:54.793552 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.793807 [debug] [Thread-1  ]: Began compiling node model.mimic.blood_gas_first_day_arterial
17:36:54.793917 [debug] [Thread-1  ]: Compiling model.mimic.blood_gas_first_day_arterial
17:36:54.800037 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.blood_gas_first_day_arterial"
17:36:54.800715 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.800991 [debug] [Thread-1  ]: Began executing node model.mimic.blood_gas_first_day_arterial
17:36:54.809404 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.blood_gas_first_day_arterial"
17:36:54.809814 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.809921 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: BEGIN
17:36:54.810014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:36:54.817951 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:36:54.818334 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.818447 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */


  create  table "postgres"."public"."blood_gas_first_day_arterial__dbt_tmp"
  as (
    with stg_spo2 as
(
  select subject_id, hadm_id, icustay_id, charttime
    -- max here is just used to group SpO2 by charttime
    , max(case when valuenum <= 0 or valuenum > 100 then null else valuenum end) as SpO2
  FROM chartevents
  -- o2 sat
  where ITEMID in
  (
    646 -- SpO2
  , 220277 -- O2 saturation pulseoxymetry
  )
  group by subject_id, hadm_id, icustay_id, charttime
)
, stg_fio2 as
(
  select subject_id, hadm_id, icustay_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , max(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
  group by subject_id, hadm_id, icustay_id, charttime
)
, stg2 as
(
select bg.*
  , ROW_NUMBER() OVER (partition by bg.icustay_id, bg.charttime order by s1.charttime DESC) as lastRowSpO2
  , s1.spo2
from "postgres"."public"."blood_gas_first_day" bg
left join stg_spo2 s1
  -- same patient
  on  bg.icustay_id = s1.icustay_id
  -- spo2 occurred at most 2 hours before this blood gas
  and s1.charttime >= DATETIME_SUB(bg.charttime, INTERVAL '2' HOUR)
  and s1.charttime <= bg.charttime
where bg.po2 is not null
)
, stg3 as
(
select bg.*
  , ROW_NUMBER() OVER (partition by bg.icustay_id, bg.charttime order by s2.charttime DESC) as lastRowFiO2
  , s2.fio2_chartevents

  -- create our specimen prediction
  ,  1/(1+exp(-(-0.02544
  +    0.04598 * po2
  + coalesce(-0.15356 * spo2             , -0.15356 *   97.49420 +    0.13429)
  + coalesce( 0.00621 * fio2_chartevents ,  0.00621 *   51.49550 +   -0.24958)
  + coalesce( 0.10559 * hemoglobin       ,  0.10559 *   10.32307 +    0.05954)
  + coalesce( 0.13251 * so2              ,  0.13251 *   93.66539 +   -0.23172)
  + coalesce(-0.01511 * pco2             , -0.01511 *   42.08866 +   -0.01630)
  + coalesce( 0.01480 * fio2             ,  0.01480 *   63.97836 +   -0.31142)
  + coalesce(-0.00200 * aado2            , -0.00200 *  442.21186 +   -0.01328)
  + coalesce(-0.03220 * bicarbonate      , -0.03220 *   22.96894 +   -0.06535)
  + coalesce( 0.05384 * totalco2         ,  0.05384 *   24.72632 +   -0.01405)
  + coalesce( 0.08202 * lactate          ,  0.08202 *    3.06436 +    0.06038)
  + coalesce( 0.10956 * ph               ,  0.10956 *    7.36233 +   -0.00617)
  + coalesce( 0.00848 * o2flow           ,  0.00848 *    7.59362 +   -0.35803)
  ))) as SPECIMEN_PROB
from stg2 bg
left join stg_fio2 s2
  -- same patient
  on  bg.icustay_id = s2.icustay_id
  -- fio2 occurred at most 4 hours before this blood gas
  and s2.charttime between DATETIME_SUB(bg.charttime, INTERVAL '4' HOUR) and bg.charttime
where bg.lastRowSpO2 = 1 -- only the row with the most recent SpO2 (if no SpO2 found lastRowSpO2 = 1)
)

select subject_id, hadm_id,
icustay_id, charttime
, specimen -- raw data indicating sample type, only present 80% of the time

-- prediction of specimen for missing data
, case
      when SPECIMEN is not null then SPECIMEN
      when SPECIMEN_PROB > 0.75 then 'ART'
    else null end as SPECIMEN_PRED
, specimen_prob
-- oxygen related parameters
, so2, spo2 -- note spo2 is FROM chartevents
, po2, pco2
, fio2_chartevents, fio2
, aado2
-- also calculate AADO2
, case
    when  PO2 is not null
      and pco2 is not null
      and coalesce(fio2, fio2_chartevents) is not null
     -- multiple by 100 because FiO2 is in a % but should be a fraction
      then (coalesce(fio2, fio2_chartevents)/100) * (760 - 47) - (pco2/0.8) - po2
    else null
  end as AADO2_calc
, case
    when PO2 is not null and coalesce(fio2, fio2_chartevents) is not null
     -- multiply by 100 because FiO2 is in a % but should be a fraction
      then 100*PO2/(coalesce(fio2, fio2_chartevents))
    else null
  end as PaO2FiO2
-- acid-base parameters
, ph, baseexcess
, bicarbonate, totalco2

-- blood count parameters
, hematocrit
, hemoglobin
, carboxyhemoglobin
, methemoglobin

-- chemistry
, chloride, calcium
, temperature
, potassium, sodium
, lactate
, glucose

-- ventilation stuff that's sometimes input
, intubated, tidalvolume, ventilationrate, ventilator
, peep, o2flow
, requiredo2

from stg3
where lastRowFiO2 = 1 -- only the most recent FiO2
-- restrict it to *only* arterial samples
and (specimen = 'ART' or specimen_prob > 0.75)
order by icustay_id, charttime
  );
17:36:54.836720 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.02 seconds
17:36:54.840990 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.841185 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
alter table "postgres"."public"."blood_gas_first_day_arterial" rename to "blood_gas_first_day_arterial__dbt_backup"
17:36:54.841774 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.848047 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.848297 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
alter table "postgres"."public"."blood_gas_first_day_arterial__dbt_tmp" rename to "blood_gas_first_day_arterial"
17:36:54.849365 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:36:54.853384 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: COMMIT
17:36:54.853572 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.853666 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: COMMIT
17:36:54.854706 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:36:54.856759 [debug] [Thread-1  ]: Using postgres connection "model.mimic.blood_gas_first_day_arterial"
17:36:54.856957 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.blood_gas_first_day_arterial"} */
drop table if exists "postgres"."public"."blood_gas_first_day_arterial__dbt_backup" cascade
17:36:54.859039 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:36:54.864415 [debug] [Thread-1  ]: finished collecting timing info
17:36:54.864800 [debug] [Thread-1  ]: On model.mimic.blood_gas_first_day_arterial: Close
17:36:54.865941 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8214d7fc-9af1-45da-82ba-8f87c4f4faa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e50ea130>]}
17:36:54.867190 [info ] [Thread-1  ]: 10 of 10 OK created table model public.blood_gas_first_day_arterial ............ [[32mSELECT 0[0m in 0.07s]
17:36:54.868075 [debug] [Thread-1  ]: Finished running node model.mimic.blood_gas_first_day_arterial
17:36:54.869275 [debug] [MainThread]: Acquiring new postgres connection "master"
17:36:54.869440 [debug] [MainThread]: Using postgres connection "master"
17:36:54.869539 [debug] [MainThread]: On master: BEGIN
17:36:54.869631 [debug] [MainThread]: Opening a new connection, currently in state closed
17:36:54.873569 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:36:54.873805 [debug] [MainThread]: On master: COMMIT
17:36:54.873928 [debug] [MainThread]: Using postgres connection "master"
17:36:54.874046 [debug] [MainThread]: On master: COMMIT
17:36:54.874205 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:36:54.874343 [debug] [MainThread]: On master: Close
17:36:54.875094 [info ] [MainThread]: 
17:36:54.875488 [info ] [MainThread]: Finished running 10 table models in 8.91s.
17:36:54.875854 [debug] [MainThread]: Connection 'master' was properly closed.
17:36:54.876138 [debug] [MainThread]: Connection 'model.mimic.blood_gas_first_day_arterial' was properly closed.
17:36:54.892603 [info ] [MainThread]: 
17:36:54.892868 [info ] [MainThread]: [32mCompleted successfully[0m
17:36:54.893077 [info ] [MainThread]: 
17:36:54.893394 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
17:36:54.893685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11e791a820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77e7b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77e7d60>]}
17:36:54.898380 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:37:03.883401 | 850751a9-1f70-41da-a28c-80642f2915e3 ==============================
17:37:03.883417 [info ] [MainThread]: Running with dbt=1.1.1
17:37:03.883945 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['cookbook'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:37:03.884152 [debug] [MainThread]: Tracking: tracking
17:37:03.892917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9501c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c950280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9502b0>]}
17:37:03.979851 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:37:03.980135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:37:03.982353 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:37:03.990338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9448e0>]}
17:37:04.015531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9a2190>]}
17:37:04.015968 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:37:04.016366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9a2310>]}
17:37:04.019928 [info ] [MainThread]: 
17:37:04.022100 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:04.025524 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:37:04.035145 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:37:04.035379 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:37:04.035557 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:37:04.046354 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:37:04.051509 [debug] [ThreadPool]: On list_postgres: Close
17:37:04.057061 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:37:04.066042 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:04.066321 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:37:04.066461 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:37:04.074722 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:37:04.075145 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:04.075502 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:37:04.079273 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:37:04.090663 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:37:04.091321 [debug] [ThreadPool]: On list_postgres_public: Close
17:37:04.101673 [debug] [MainThread]: Using postgres connection "master"
17:37:04.101894 [debug] [MainThread]: On master: BEGIN
17:37:04.101991 [debug] [MainThread]: Opening a new connection, currently in state init
17:37:04.107575 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:37:04.107819 [debug] [MainThread]: Using postgres connection "master"
17:37:04.108003 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:37:04.114318 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:37:04.117670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c98de50>]}
17:37:04.118078 [debug] [MainThread]: On master: ROLLBACK
17:37:04.118461 [debug] [MainThread]: Using postgres connection "master"
17:37:04.118730 [debug] [MainThread]: On master: BEGIN
17:37:04.119289 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:37:04.119576 [debug] [MainThread]: On master: COMMIT
17:37:04.119801 [debug] [MainThread]: Using postgres connection "master"
17:37:04.119966 [debug] [MainThread]: On master: COMMIT
17:37:04.120343 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:04.120609 [debug] [MainThread]: On master: Close
17:37:04.121234 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:37:04.121617 [info ] [MainThread]: 
17:37:04.125909 [debug] [Thread-1  ]: Began running node model.mimic.age_histogram
17:37:04.126624 [info ] [Thread-1  ]: 1 of 24 START table model public.age_histogram ................................. [RUN]
17:37:04.127790 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.age_histogram"
17:37:04.128220 [debug] [Thread-1  ]: Began compiling node model.mimic.age_histogram
17:37:04.128456 [debug] [Thread-1  ]: Compiling model.mimic.age_histogram
17:37:04.129842 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.age_histogram"
17:37:04.130227 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.130370 [debug] [Thread-1  ]: Began executing node model.mimic.age_histogram
17:37:04.164176 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.age_histogram"
17:37:04.165288 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.165511 [debug] [Thread-1  ]: On model.mimic.age_histogram: BEGIN
17:37:04.165607 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:04.169918 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:04.170387 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.171089 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */


  create  table "postgres"."public"."age_histogram__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of hospital admissions in equally sized bins of age
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- ------------------------------------------------------------------

WITH agetbl AS
(
    SELECT DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') AS age
      FROM admissions ad
      INNER JOIN patients p
      ON ad.subject_id = p.subject_id
)
, agebin AS
(
      SELECT age, width_bucket(age, 15, 100, 85) AS bucket
      FROM agetbl
)
SELECT bucket+15 as age, count(*)
FROM agebin
GROUP BY bucket
ORDER BY bucket
  );
17:37:04.334457 [debug] [Thread-1  ]: SQL status: SELECT 77 in 0.16 seconds
17:37:04.344905 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.345102 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
alter table "postgres"."public"."age_histogram" rename to "age_histogram__dbt_backup"
17:37:04.345848 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.349259 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.349455 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
alter table "postgres"."public"."age_histogram__dbt_tmp" rename to "age_histogram"
17:37:04.350130 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.360294 [debug] [Thread-1  ]: On model.mimic.age_histogram: COMMIT
17:37:04.360516 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.360718 [debug] [Thread-1  ]: On model.mimic.age_histogram: COMMIT
17:37:04.363026 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:04.367629 [debug] [Thread-1  ]: Using postgres connection "model.mimic.age_histogram"
17:37:04.367862 [debug] [Thread-1  ]: On model.mimic.age_histogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.age_histogram"} */
drop table if exists "postgres"."public"."age_histogram__dbt_backup" cascade
17:37:04.369805 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:04.373147 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.373378 [debug] [Thread-1  ]: On model.mimic.age_histogram: Close
17:37:04.374129 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a682430>]}
17:37:04.374644 [info ] [Thread-1  ]: 1 of 24 OK created table model public.age_histogram ............................ [[32mSELECT 77[0m in 0.25s]
17:37:04.375203 [debug] [Thread-1  ]: Finished running node model.mimic.age_histogram
17:37:04.375678 [debug] [Thread-1  ]: Began running node model.mimic.basic_patient_info
17:37:04.376480 [info ] [Thread-1  ]: 2 of 24 START table model public.basic_patient_info ............................ [RUN]
17:37:04.377261 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.basic_patient_info"
17:37:04.377704 [debug] [Thread-1  ]: Began compiling node model.mimic.basic_patient_info
17:37:04.377993 [debug] [Thread-1  ]: Compiling model.mimic.basic_patient_info
17:37:04.381348 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.basic_patient_info"
17:37:04.382464 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.382806 [debug] [Thread-1  ]: Began executing node model.mimic.basic_patient_info
17:37:04.391143 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.basic_patient_info"
17:37:04.391722 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.391936 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: BEGIN
17:37:04.392096 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:04.399200 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:04.399468 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.399647 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */


  create  table "postgres"."public"."basic_patient_info__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Retrieves basic patient information from the patients table
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- ------------------------------------------------------------------


SELECT subject_id, gender, dob
FROM patients
  );
17:37:04.419688 [debug] [Thread-1  ]: SQL status: SELECT 46520 in 0.02 seconds
17:37:04.428563 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.428803 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
alter table "postgres"."public"."basic_patient_info" rename to "basic_patient_info__dbt_backup"
17:37:04.429262 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.433175 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.433376 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
alter table "postgres"."public"."basic_patient_info__dbt_tmp" rename to "basic_patient_info"
17:37:04.433965 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.439398 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: COMMIT
17:37:04.439792 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.440262 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: COMMIT
17:37:04.444031 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:04.446211 [debug] [Thread-1  ]: Using postgres connection "model.mimic.basic_patient_info"
17:37:04.446404 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.basic_patient_info"} */
drop table if exists "postgres"."public"."basic_patient_info__dbt_backup" cascade
17:37:04.448170 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:04.450830 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.451095 [debug] [Thread-1  ]: On model.mimic.basic_patient_info: Close
17:37:04.451788 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee8b20>]}
17:37:04.452243 [info ] [Thread-1  ]: 2 of 24 OK created table model public.basic_patient_info ....................... [[32mSELECT 46520[0m in 0.07s]
17:37:04.452766 [debug] [Thread-1  ]: Finished running node model.mimic.basic_patient_info
17:37:04.452916 [debug] [Thread-1  ]: Began running node model.mimic.bun
17:37:04.454199 [info ] [Thread-1  ]: 3 of 24 START table model public.bun ........................................... [RUN]
17:37:04.455856 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.bun"
17:37:04.456485 [debug] [Thread-1  ]: Began compiling node model.mimic.bun
17:37:04.456793 [debug] [Thread-1  ]: Compiling model.mimic.bun
17:37:04.458397 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.bun"
17:37:04.459060 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.459337 [debug] [Thread-1  ]: Began executing node model.mimic.bun
17:37:04.466237 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.bun"
17:37:04.466880 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.467100 [debug] [Thread-1  ]: On model.mimic.bun: BEGIN
17:37:04.467260 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:04.472674 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:04.472918 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.473130 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */


  create  table "postgres"."public"."bun__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a distribution of BUN values for adult hospital admissions
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
    SELECT ad.subject_id
    FROM admissions ad
    INNER JOIN patients p
    ON ad.subject_id = p.subject_id
    WHERE
     -- filter to only adults
    DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
    -- group by subject_id to ensure there is only 1 subject_id per row
    group by ad.subject_id
)
, bun as
(
  SELECT width_bucket(valuenum, 0, 280, 280) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (51006)
)
SELECT bucket as blood_urea_nitrogen, count(*)
FROM bun
GROUP BY bucket
ORDER BY bucket
  );
17:37:04.621732 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:37:04.627991 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.628403 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
alter table "postgres"."public"."bun" rename to "bun__dbt_backup"
17:37:04.630012 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.635858 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.636105 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
alter table "postgres"."public"."bun__dbt_tmp" rename to "bun"
17:37:04.636826 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.640220 [debug] [Thread-1  ]: On model.mimic.bun: COMMIT
17:37:04.640416 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.640638 [debug] [Thread-1  ]: On model.mimic.bun: COMMIT
17:37:04.641786 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:04.643771 [debug] [Thread-1  ]: Using postgres connection "model.mimic.bun"
17:37:04.643971 [debug] [Thread-1  ]: On model.mimic.bun: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.bun"} */
drop table if exists "postgres"."public"."bun__dbt_backup" cascade
17:37:04.645871 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:04.648990 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.649217 [debug] [Thread-1  ]: On model.mimic.bun: Close
17:37:04.649659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a68d5b0>]}
17:37:04.649912 [info ] [Thread-1  ]: 3 of 24 OK created table model public.bun ...................................... [[32mSELECT 0[0m in 0.19s]
17:37:04.650328 [debug] [Thread-1  ]: Finished running node model.mimic.bun
17:37:04.650755 [debug] [Thread-1  ]: Began running node model.mimic.gcs
17:37:04.651410 [info ] [Thread-1  ]: 4 of 24 START table model public.gcs ........................................... [RUN]
17:37:04.652250 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.gcs"
17:37:04.652567 [debug] [Thread-1  ]: Began compiling node model.mimic.gcs
17:37:04.653023 [debug] [Thread-1  ]: Compiling model.mimic.gcs
17:37:04.654797 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.gcs"
17:37:04.655577 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.655919 [debug] [Thread-1  ]: Began executing node model.mimic.gcs
17:37:04.665027 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.gcs"
17:37:04.665995 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.666217 [debug] [Thread-1  ]: On model.mimic.gcs: BEGIN
17:37:04.666321 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:04.673490 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:04.673939 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.674276 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */


  create  table "postgres"."public"."gcs__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Find the glasgow coma *MOTOR* score for each adult patient
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
    SELECT ad.subject_id
    FROM admissions ad
    INNER JOIN patients p
    ON ad.subject_id = p.subject_id
    WHERE
     -- filter to only adults
    DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
    -- group by subject_id to ensure there is only 1 subject_id per row
    group by ad.subject_id
)
, gcs as
(
    SELECT width_bucket(valuenum, 1, 30, 30) AS bucket
    FROM chartevents ce
    INNER JOIN agetbl
    ON ce.subject_id = agetbl.subject_id
    WHERE itemid IN
    (
        454 -- "Motor Response"
      , 223900 -- "GCS - Motor Response"
    )
)
SELECT bucket as GCS_Motor_Response, count(*)
FROM gcs
GROUP BY bucket
ORDER BY bucket
  );
17:37:04.819103 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:04.826161 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.826681 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
alter table "postgres"."public"."gcs" rename to "gcs__dbt_backup"
17:37:04.828036 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.832790 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.832994 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
alter table "postgres"."public"."gcs__dbt_tmp" rename to "gcs"
17:37:04.833749 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:04.837450 [debug] [Thread-1  ]: On model.mimic.gcs: COMMIT
17:37:04.837669 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.837887 [debug] [Thread-1  ]: On model.mimic.gcs: COMMIT
17:37:04.839064 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:04.840748 [debug] [Thread-1  ]: Using postgres connection "model.mimic.gcs"
17:37:04.840948 [debug] [Thread-1  ]: On model.mimic.gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.gcs"} */
drop table if exists "postgres"."public"."gcs__dbt_backup" cascade
17:37:04.842835 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:04.848029 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.848268 [debug] [Thread-1  ]: On model.mimic.gcs: Close
17:37:04.849182 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4beddfd0>]}
17:37:04.849701 [info ] [Thread-1  ]: 4 of 24 OK created table model public.gcs ...................................... [[32mSELECT 0[0m in 0.20s]
17:37:04.850142 [debug] [Thread-1  ]: Finished running node model.mimic.gcs
17:37:04.850355 [debug] [Thread-1  ]: Began running node model.mimic.glucose
17:37:04.851136 [info ] [Thread-1  ]: 5 of 24 START table model public.glucose ....................................... [RUN]
17:37:04.851924 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.glucose"
17:37:04.852273 [debug] [Thread-1  ]: Began compiling node model.mimic.glucose
17:37:04.852576 [debug] [Thread-1  ]: Compiling model.mimic.glucose
17:37:04.853835 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.glucose"
17:37:04.854252 [debug] [Thread-1  ]: finished collecting timing info
17:37:04.854377 [debug] [Thread-1  ]: Began executing node model.mimic.glucose
17:37:04.865696 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.glucose"
17:37:04.866212 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:04.866421 [debug] [Thread-1  ]: On model.mimic.glucose: BEGIN
17:37:04.866647 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:04.873248 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:04.873570 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:04.873888 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */


  create  table "postgres"."public"."glucose__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves a glucose histogram of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, glc as
(
  SELECT width_bucket(valuenum, 0.5, 1000, 1000) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50809,50931)
  AND valuenum IS NOT NULL
)
SELECT bucket as glucose, count(*)
FROM glc
GROUP BY bucket
ORDER BY bucket
  );
17:37:05.013546 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:05.020098 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:05.020526 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
alter table "postgres"."public"."glucose" rename to "glucose__dbt_backup"
17:37:05.021828 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.026093 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:05.026306 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
alter table "postgres"."public"."glucose__dbt_tmp" rename to "glucose"
17:37:05.027115 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.029879 [debug] [Thread-1  ]: On model.mimic.glucose: COMMIT
17:37:05.030068 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:05.030158 [debug] [Thread-1  ]: On model.mimic.glucose: COMMIT
17:37:05.031389 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.033398 [debug] [Thread-1  ]: Using postgres connection "model.mimic.glucose"
17:37:05.033604 [debug] [Thread-1  ]: On model.mimic.glucose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.glucose"} */
drop table if exists "postgres"."public"."glucose__dbt_backup" cascade
17:37:05.035640 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.038196 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.038414 [debug] [Thread-1  ]: On model.mimic.glucose: Close
17:37:05.039235 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee51c0>]}
17:37:05.039719 [info ] [Thread-1  ]: 5 of 24 OK created table model public.glucose .................................. [[32mSELECT 0[0m in 0.19s]
17:37:05.040271 [debug] [Thread-1  ]: Finished running node model.mimic.glucose
17:37:05.040669 [debug] [Thread-1  ]: Began running node model.mimic.hco
17:37:05.041342 [info ] [Thread-1  ]: 6 of 24 START table model public.hco ........................................... [RUN]
17:37:05.042191 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.hco"
17:37:05.042549 [debug] [Thread-1  ]: Began compiling node model.mimic.hco
17:37:05.042982 [debug] [Thread-1  ]: Compiling model.mimic.hco
17:37:05.044742 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.hco"
17:37:05.045512 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.045925 [debug] [Thread-1  ]: Began executing node model.mimic.hco
17:37:05.061222 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.hco"
17:37:05.061780 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.061995 [debug] [Thread-1  ]: On model.mimic.hco: BEGIN
17:37:05.062087 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.067693 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:05.067947 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.068136 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */


  create  table "postgres"."public"."hco__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram bicarbonate levels for all patients (adults and neonates)
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, hco as
(
  SELECT width_bucket(valuenum, 0, 231, 231) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50803, 50804, 50882)
  AND valuenum IS NOT NULL
)
SELECT bucket as bicarbonate, count(*)
FROM hco
GROUP BY bucket
ORDER BY bucket
  );
17:37:05.208049 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:05.212263 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.212485 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
alter table "postgres"."public"."hco" rename to "hco__dbt_backup"
17:37:05.213202 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.216851 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.217046 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
alter table "postgres"."public"."hco__dbt_tmp" rename to "hco"
17:37:05.217739 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.220958 [debug] [Thread-1  ]: On model.mimic.hco: COMMIT
17:37:05.221161 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.221337 [debug] [Thread-1  ]: On model.mimic.hco: COMMIT
17:37:05.222449 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.224339 [debug] [Thread-1  ]: Using postgres connection "model.mimic.hco"
17:37:05.224535 [debug] [Thread-1  ]: On model.mimic.hco: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.hco"} */
drop table if exists "postgres"."public"."hco__dbt_backup" cascade
17:37:05.226379 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.229449 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.229716 [debug] [Thread-1  ]: On model.mimic.hco: Close
17:37:05.230463 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a6308e0>]}
17:37:05.231119 [info ] [Thread-1  ]: 6 of 24 OK created table model public.hco ...................................... [[32mSELECT 0[0m in 0.19s]
17:37:05.231665 [debug] [Thread-1  ]: Finished running node model.mimic.hco
17:37:05.232018 [debug] [Thread-1  ]: Began running node model.mimic.heart_rate
17:37:05.232721 [info ] [Thread-1  ]: 7 of 24 START table model public.heart_rate .................................... [RUN]
17:37:05.233692 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.heart_rate"
17:37:05.233993 [debug] [Thread-1  ]: Began compiling node model.mimic.heart_rate
17:37:05.234239 [debug] [Thread-1  ]: Compiling model.mimic.heart_rate
17:37:05.235384 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.heart_rate"
17:37:05.235987 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.236297 [debug] [Thread-1  ]: Began executing node model.mimic.heart_rate
17:37:05.246157 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.heart_rate"
17:37:05.247049 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.247348 [debug] [Thread-1  ]: On model.mimic.heart_rate: BEGIN
17:37:05.247541 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.252225 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:05.252609 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.253274 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */


  create  table "postgres"."public"."heart_rate__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram of heart rates for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, hr as
(
  SELECT width_bucket(valuenum, 0, 300, 301) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid in (211,220045)
)
SELECT bucket as heart_rate, count(*)
FROM hr
GROUP BY bucket
ORDER BY bucket
  );
17:37:05.407231 [debug] [Thread-1  ]: SQL status: SELECT 75 in 0.15 seconds
17:37:05.413428 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.413787 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
alter table "postgres"."public"."heart_rate" rename to "heart_rate__dbt_backup"
17:37:05.415134 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.420423 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.420624 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
alter table "postgres"."public"."heart_rate__dbt_tmp" rename to "heart_rate"
17:37:05.421431 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.424832 [debug] [Thread-1  ]: On model.mimic.heart_rate: COMMIT
17:37:05.425034 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.425227 [debug] [Thread-1  ]: On model.mimic.heart_rate: COMMIT
17:37:05.426315 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.429164 [debug] [Thread-1  ]: Using postgres connection "model.mimic.heart_rate"
17:37:05.429352 [debug] [Thread-1  ]: On model.mimic.heart_rate: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.heart_rate"} */
drop table if exists "postgres"."public"."heart_rate__dbt_backup" cascade
17:37:05.431342 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.434673 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.434995 [debug] [Thread-1  ]: On model.mimic.heart_rate: Close
17:37:05.435777 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee5280>]}
17:37:05.436253 [info ] [Thread-1  ]: 7 of 24 OK created table model public.heart_rate ............................... [[32mSELECT 75[0m in 0.20s]
17:37:05.436794 [debug] [Thread-1  ]: Finished running node model.mimic.heart_rate
17:37:05.437135 [debug] [Thread-1  ]: Began running node model.mimic.height
17:37:05.437806 [info ] [Thread-1  ]: 8 of 24 START table model public.height ........................................ [RUN]
17:37:05.438657 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.height"
17:37:05.438955 [debug] [Thread-1  ]: Began compiling node model.mimic.height
17:37:05.439277 [debug] [Thread-1  ]: Compiling model.mimic.height
17:37:05.440523 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.height"
17:37:05.441121 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.441368 [debug] [Thread-1  ]: Began executing node model.mimic.height
17:37:05.451491 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.height"
17:37:05.452199 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.453060 [debug] [Thread-1  ]: On model.mimic.height: BEGIN
17:37:05.453385 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.460925 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:05.461836 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.462139 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */


  create  table "postgres"."public"."height__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Create a histogram of heights for all patients
--  note: some height ITEMIDs were not included, which may implicitly exclude
--  some neonates from this calculation
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH ht AS
(
  SELECT valuenum, width_bucket(valuenum, 1, 200, 200) AS bucket
  FROM chartevents
  WHERE itemid in (920,226730)
  AND valuenum IS NOT NULL
  AND valuenum > 0
  AND valuenum < 500
)
SELECT bucket as height, count(*)
FROM ht
GROUP BY bucket
ORDER BY bucket
  );
17:37:05.465956 [debug] [Thread-1  ]: SQL status: SELECT 6 in 0.0 seconds
17:37:05.473210 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.473426 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
alter table "postgres"."public"."height" rename to "height__dbt_backup"
17:37:05.474241 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.478854 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.479083 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
alter table "postgres"."public"."height__dbt_tmp" rename to "height"
17:37:05.479663 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.482409 [debug] [Thread-1  ]: On model.mimic.height: COMMIT
17:37:05.482786 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.482977 [debug] [Thread-1  ]: On model.mimic.height: COMMIT
17:37:05.484016 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.485975 [debug] [Thread-1  ]: Using postgres connection "model.mimic.height"
17:37:05.486257 [debug] [Thread-1  ]: On model.mimic.height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.height"} */
drop table if exists "postgres"."public"."height__dbt_backup" cascade
17:37:05.489896 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.494207 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.494612 [debug] [Thread-1  ]: On model.mimic.height: Close
17:37:05.495414 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee53a0>]}
17:37:05.496235 [info ] [Thread-1  ]: 8 of 24 OK created table model public.height ................................... [[32mSELECT 6[0m in 0.06s]
17:37:05.496878 [debug] [Thread-1  ]: Finished running node model.mimic.height
17:37:05.497317 [debug] [Thread-1  ]: Began running node model.mimic.icd9agelimited
17:37:05.497887 [info ] [Thread-1  ]: 9 of 24 START table model public.icd9agelimited ................................ [RUN]
17:37:05.498396 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9agelimited"
17:37:05.498796 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9agelimited
17:37:05.499102 [debug] [Thread-1  ]: Compiling model.mimic.icd9agelimited
17:37:05.500218 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9agelimited"
17:37:05.500688 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.500943 [debug] [Thread-1  ]: Began executing node model.mimic.icd9agelimited
17:37:05.510030 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9agelimited"
17:37:05.512202 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.512803 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: BEGIN
17:37:05.513059 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.518025 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:05.518258 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.518359 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */


  create  table "postgres"."public"."icd9agelimited__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code above a certain age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Reference: tompollard, alistairewj, erinhong for code taken
-- from sodium.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH agetbl AS 
	(
	SELECT ad.subject_id 
	FROM admissions ad 
	INNER JOIN patients p 
	ON ad.subject_id = p.subject_id 
	WHERE 
	-- filter to only adults above 30
	DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 30
	-- group by subject_id to ensure there is only 1 subject_id per row
	GROUP BY ad.subject_id
	) 
SELECT COUNT(DISTINCT dia.subject_id) 
AS "Hypertension Age 30+" 
from diagnoses_icd dia 
INNER JOIN agetbl 
ON dia.subject_id = agetbl.subject_id 
WHERE dia.icd9_code 
-- 401% relates to Hypertension
LIKE '401%'
  );
17:37:05.731052 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
17:37:05.736623 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.736824 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
alter table "postgres"."public"."icd9agelimited" rename to "icd9agelimited__dbt_backup"
17:37:05.737581 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.741077 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.741272 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
alter table "postgres"."public"."icd9agelimited__dbt_tmp" rename to "icd9agelimited"
17:37:05.742102 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.744971 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: COMMIT
17:37:05.745164 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.745398 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: COMMIT
17:37:05.747601 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.750199 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9agelimited"
17:37:05.750442 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9agelimited"} */
drop table if exists "postgres"."public"."icd9agelimited__dbt_backup" cascade
17:37:05.752371 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.755050 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.755298 [debug] [Thread-1  ]: On model.mimic.icd9agelimited: Close
17:37:05.756053 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a5d47c0>]}
17:37:05.756524 [info ] [Thread-1  ]: 9 of 24 OK created table model public.icd9agelimited ........................... [[32mSELECT 1[0m in 0.26s]
17:37:05.757068 [debug] [Thread-1  ]: Finished running node model.mimic.icd9agelimited
17:37:05.757411 [debug] [Thread-1  ]: Began running node model.mimic.icd9count
17:37:05.758049 [info ] [Thread-1  ]: 10 of 24 START table model public.icd9count .................................... [RUN]
17:37:05.758956 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9count"
17:37:05.759363 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9count
17:37:05.759806 [debug] [Thread-1  ]: Compiling model.mimic.icd9count
17:37:05.760976 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9count"
17:37:05.761533 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.761781 [debug] [Thread-1  ]: Began executing node model.mimic.icd9count
17:37:05.772420 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9count"
17:37:05.773210 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.773424 [debug] [Thread-1  ]: On model.mimic.icd9count: BEGIN
17:37:05.773583 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.779188 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:05.779483 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.779738 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */


  create  table "postgres"."public"."icd9count__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgement: Credit goes to Kris Kindle
-- ------------------------------------------------------------------

SELECT COUNT(DISTINCT subject_id) 
AS "Hypertension" 
from diagnoses_icd 
WHERE icd9_code 
-- 401% will search for all icd9 codes relating to hypertension
LIKE '401%'
  );
17:37:05.806441 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.03 seconds
17:37:05.813904 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.814105 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
alter table "postgres"."public"."icd9count" rename to "icd9count__dbt_backup"
17:37:05.814938 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.818455 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.819118 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
alter table "postgres"."public"."icd9count__dbt_tmp" rename to "icd9count"
17:37:05.820976 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:05.824756 [debug] [Thread-1  ]: On model.mimic.icd9count: COMMIT
17:37:05.825006 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.825221 [debug] [Thread-1  ]: On model.mimic.icd9count: COMMIT
17:37:05.826193 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:05.829740 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9count"
17:37:05.829948 [debug] [Thread-1  ]: On model.mimic.icd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9count"} */
drop table if exists "postgres"."public"."icd9count__dbt_backup" cascade
17:37:05.832013 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:05.835008 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.835564 [debug] [Thread-1  ]: On model.mimic.icd9count: Close
17:37:05.837038 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a582eb0>]}
17:37:05.837515 [info ] [Thread-1  ]: 10 of 24 OK created table model public.icd9count ............................... [[32mSELECT 1[0m in 0.08s]
17:37:05.838021 [debug] [Thread-1  ]: Finished running node model.mimic.icd9count
17:37:05.838191 [debug] [Thread-1  ]: Began running node model.mimic.icd9vagehistogram
17:37:05.838467 [info ] [Thread-1  ]: 11 of 24 START table model public.icd9vagehistogram ............................ [RUN]
17:37:05.839240 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vagehistogram"
17:37:05.839551 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vagehistogram
17:37:05.839789 [debug] [Thread-1  ]: Compiling model.mimic.icd9vagehistogram
17:37:05.841058 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vagehistogram"
17:37:05.841618 [debug] [Thread-1  ]: finished collecting timing info
17:37:05.841865 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vagehistogram
17:37:05.851270 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vagehistogram"
17:37:05.851896 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:05.852480 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: BEGIN
17:37:05.852882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:05.860066 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:05.860385 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:05.860661 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */


  create  table "postgres"."public"."icd9vagehistogram__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with a specific icd9 code and shows the output as a histogram with groups of age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgements: Made with help from Kris Kindle
-- Reference: tompollard, alistairewj for code taken
-- from age_hist.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH diatbl AS
	(
	SELECT DISTINCT ON (dia.subject_id) dia.subject_id, ad.admittime
	from diagnoses_icd dia
	INNER JOIN admissions ad
	ON dia.subject_id = ad.subject_id
	WHERE dia.icd9_code
	-- 401% relates to hypertension
	LIKE '401%'
	),
agetbl AS
	(
	SELECT dt.subject_id, DATETIME_DIFF(dt.admittime, p.dob, 'YEAR') AS age
	FROM diatbl dt
	INNER JOIN patients p
	ON dt.subject_id = p.subject_id
	)
SELECT
        COUNT(*) AS TOTAL,
        COUNT(CASE WHEN age >= 0 AND age < 16 THEN  '0 - 15' END) AS "0-15",
        COUNT(CASE WHEN age >= 16 AND age < 21 THEN '16 - 20' END) AS "16-20",
        COUNT(CASE WHEN age >= 21 AND age < 26 THEN '21 - 25' END) AS "21-25",
        COUNT(CASE WHEN age >= 26 AND age < 31 THEN '26 - 30' END) AS "26-30",
        COUNT(CASE WHEN age >= 31 AND age < 36 THEN '31 - 35' END) AS "31-35",
        COUNT(CASE WHEN age >= 36 AND age < 41 THEN '36 - 40' END) AS "36-40",
        COUNT(CASE WHEN age >= 41 AND age < 46 THEN '41 - 45' END) AS "41-45",
        COUNT(CASE WHEN age >= 46 AND age < 51 THEN '46 - 50' END) AS "46-50",
        COUNT(CASE WHEN age >= 51 AND age < 56 THEN '51 - 55' END) AS "51-55",
        COUNT(CASE WHEN age >= 56 AND age < 61 THEN '56 - 60' END) AS "56-60",
        COUNT(CASE WHEN age >= 61 AND age < 66 THEN '61 - 65' END) AS "61-65",
        COUNT(CASE WHEN age >= 66 AND age < 71 THEN '66 - 70' END) AS "66-70",
        COUNT(CASE WHEN age >= 71 AND age < 76 THEN '71 - 75' END) AS "71-75",
        COUNT(CASE WHEN age >= 76 AND age < 81 THEN '76 - 80' END) AS "76-80",
        COUNT(CASE WHEN age >= 81 AND age < 86 THEN '81 - 85' END) AS "81-85",
        COUNT(CASE WHEN age >= 86 AND age < 91 THEN '86 - 90' END) AS "86-91",
        COUNT(CASE WHEN age >= 91 THEN 'Over 91' END) AS ">91"
FROM agetbl
  );
17:37:05.997844 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.14 seconds
17:37:06.005410 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:06.005809 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
alter table "postgres"."public"."icd9vagehistogram" rename to "icd9vagehistogram__dbt_backup"
17:37:06.007342 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.012688 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:06.012883 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
alter table "postgres"."public"."icd9vagehistogram__dbt_tmp" rename to "icd9vagehistogram"
17:37:06.013610 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.016587 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: COMMIT
17:37:06.016783 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:06.017007 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: COMMIT
17:37:06.019371 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:06.021240 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vagehistogram"
17:37:06.021433 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vagehistogram"} */
drop table if exists "postgres"."public"."icd9vagehistogram__dbt_backup" cascade
17:37:06.023404 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:06.026321 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.026672 [debug] [Thread-1  ]: On model.mimic.icd9vagehistogram: Close
17:37:06.027539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee5790>]}
17:37:06.028005 [info ] [Thread-1  ]: 11 of 24 OK created table model public.icd9vagehistogram ....................... [[32mSELECT 1[0m in 0.19s]
17:37:06.028632 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vagehistogram
17:37:06.029065 [debug] [Thread-1  ]: Began running node model.mimic.icd9vicd9agelimited
17:37:06.029839 [info ] [Thread-1  ]: 12 of 24 START table model public.icd9vicd9agelimited .......................... [RUN]
17:37:06.030701 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.031160 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vicd9agelimited
17:37:06.031525 [debug] [Thread-1  ]: Compiling model.mimic.icd9vicd9agelimited
17:37:06.032693 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vicd9agelimited"
17:37:06.033281 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.033528 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vicd9agelimited
17:37:06.045460 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vicd9agelimited"
17:37:06.046014 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.046221 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: BEGIN
17:37:06.046315 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:06.052471 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:06.052787 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.052986 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */


  create  table "postgres"."public"."icd9vicd9agelimited__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with two specific icd9 codes above a certain age
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Reference: tompollard, alistairewj, erinhong for code taken
-- from sodium.sql on the MIMIC III github repository
-- ------------------------------------------------------------------

WITH agetbl AS 
	(
	SELECT ad.subject_id 
	FROM admissions ad 
	INNER JOIN patients p 
	ON ad.subject_id = p.subject_id 
	WHERE 
	DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 40 
	GROUP BY ad.subject_id
	) 
SELECT COUNT(DISTINCT dia.subject_id) 
AS "Obesity vs Hypertension Age 40+" 
from diagnoses_icd dia 
INNER JOIN agetbl 
ON dia.subject_id = agetbl.subject_id 
INNER JOIN diagnoses_icd dib 
ON dia.subject_id = dib.subject_id 
WHERE dia.icd9_code 
-- 278% relates to obesity
LIKE '278%' 
AND dib.icd9_code 
-- 401% relates to hypertension
LIKE '401%'
  );
17:37:06.386348 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.33 seconds
17:37:06.392789 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.393190 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
alter table "postgres"."public"."icd9vicd9agelimited" rename to "icd9vicd9agelimited__dbt_backup"
17:37:06.394677 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.400699 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.400994 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
alter table "postgres"."public"."icd9vicd9agelimited__dbt_tmp" rename to "icd9vicd9agelimited"
17:37:06.401719 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.404709 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: COMMIT
17:37:06.404903 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.405123 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: COMMIT
17:37:06.406222 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:06.408151 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9agelimited"
17:37:06.408353 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9agelimited"} */
drop table if exists "postgres"."public"."icd9vicd9agelimited__dbt_backup" cascade
17:37:06.410124 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:06.413656 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.413889 [debug] [Thread-1  ]: On model.mimic.icd9vicd9agelimited: Close
17:37:06.414686 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee5880>]}
17:37:06.415222 [info ] [Thread-1  ]: 12 of 24 OK created table model public.icd9vicd9agelimited ..................... [[32mSELECT 1[0m in 0.38s]
17:37:06.415863 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vicd9agelimited
17:37:06.416313 [debug] [Thread-1  ]: Began running node model.mimic.icd9vicd9count
17:37:06.416984 [info ] [Thread-1  ]: 13 of 24 START table model public.icd9vicd9count ............................... [RUN]
17:37:06.417840 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icd9vicd9count"
17:37:06.418089 [debug] [Thread-1  ]: Began compiling node model.mimic.icd9vicd9count
17:37:06.418400 [debug] [Thread-1  ]: Compiling model.mimic.icd9vicd9count
17:37:06.419880 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icd9vicd9count"
17:37:06.420429 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.420684 [debug] [Thread-1  ]: Began executing node model.mimic.icd9vicd9count
17:37:06.431525 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icd9vicd9count"
17:37:06.432416 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.432631 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: BEGIN
17:37:06.432791 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:06.437866 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:06.438106 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.438233 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */


  create  table "postgres"."public"."icd9vicd9count__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Count the number of patients with two specific icd9 codes
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
-- SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Acknowledgement: Credit goes to Kris Kindle
-- ------------------------------------------------------------------

SELECT COUNT(DISTINCT a.subject_id) 
AS "Obesity and Dyslipidemia" 
from diagnoses_icd a 
INNER JOIN diagnoses_icd b 
ON a.subject_id = b.subject_id 
WHERE a.icd9_code
-- 278% relates to obesity 
LIKE '278%' 
AND b.icd9_code 
-- 272 relates to Dyslipidemia
LIKE '272%'
  );
17:37:06.475004 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.04 seconds
17:37:06.480363 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.480575 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
alter table "postgres"."public"."icd9vicd9count" rename to "icd9vicd9count__dbt_backup"
17:37:06.481392 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.486419 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.487230 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
alter table "postgres"."public"."icd9vicd9count__dbt_tmp" rename to "icd9vicd9count"
17:37:06.488370 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.491431 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: COMMIT
17:37:06.491637 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.491907 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: COMMIT
17:37:06.493029 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:06.496270 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icd9vicd9count"
17:37:06.496478 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icd9vicd9count"} */
drop table if exists "postgres"."public"."icd9vicd9count__dbt_backup" cascade
17:37:06.498211 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:06.501126 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.501469 [debug] [Thread-1  ]: On model.mimic.icd9vicd9count: Close
17:37:06.503066 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a59b670>]}
17:37:06.503613 [info ] [Thread-1  ]: 13 of 24 OK created table model public.icd9vicd9count .......................... [[32mSELECT 1[0m in 0.09s]
17:37:06.504255 [debug] [Thread-1  ]: Finished running node model.mimic.icd9vicd9count
17:37:06.504578 [debug] [Thread-1  ]: Began running node model.mimic.icustay_days
17:37:06.504990 [info ] [Thread-1  ]: 14 of 24 START table model public.icustay_days ................................. [RUN]
17:37:06.505669 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.icustay_days"
17:37:06.505968 [debug] [Thread-1  ]: Began compiling node model.mimic.icustay_days
17:37:06.506156 [debug] [Thread-1  ]: Compiling model.mimic.icustay_days
17:37:06.507494 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.icustay_days"
17:37:06.508109 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.508393 [debug] [Thread-1  ]: Began executing node model.mimic.icustay_days
17:37:06.516001 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.icustay_days"
17:37:06.516700 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_days"
17:37:06.516916 [debug] [Thread-1  ]: On model.mimic.icustay_days: BEGIN
17:37:06.517160 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:06.522008 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:06.522404 [debug] [Thread-1  ]: Using postgres connection "model.mimic.icustay_days"
17:37:06.522745 [debug] [Thread-1  ]: On model.mimic.icustay_days: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.icustay_days"} */


  create  table "postgres"."public"."icustay_days__dbt_tmp"
  as (
    -- ----------------------------------------------------------
-- Create a table that counts each day spent in the ICU    --
-- and assign a timestamp to the start and end of each day --
-- ----------------------------------------------------------

-- ----------
-- Columns:
-- ----------
-- icustay_id
-- intime
-- outime
-- icudayseq_asc:  Counting days since arrival in the ICU
-- 				         0 = day of arrival in the ICU
--                 1 = day 1 after arrival
--                 2 = day 2 after arrival etc
-- icudayseq_desc: Counting down to the day of discharge from the ICU
--                 2 = day 2 before discharge etc
--                 1 = day 1 before discharge
-- 				         0 = day of discharge from the ICU
-- startday: if day of arrival then intime, else midnight at start of day
-- endday: if day of discharge then outtime, else midnight at end of day
-- ----------

DROP MATERIALIZED VIEW icustay_days;
CREATE VIEW icustay_days AS
WITH dayseq AS (
	SELECT icustay_id, intime, outtime,
       GENERATE_SERIES(0,CEIL(los)::INT-1,1) AS icudayseq_asc,
       GENERATE_SERIES(CEIL(los)::INT-1,0,-1) AS icudayseq_desc
	FROM icustays)
SELECT icustay_id, intime, outtime,
    icudayseq_asc, icudayseq_desc,
    CASE WHEN icudayseq_asc = 0 THEN intime
        ELSE DATETIME_ADD(date_trunc('day', intime), INTERVAL icudayseq_asc DAY)
        END AS startday,
    CASE WHEN icudayseq_desc = 0 THEN OUTTIME
        ELSE DATETIME_ADD(date_trunc('day', intime), INTERVAL icudayseq_asc+1 DAY)
				END AS endday
FROM dayseq
  );
17:37:06.523658 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "DROP"
LINE 29: DROP MATERIALIZED VIEW icustay_days;
         ^

17:37:06.524161 [debug] [Thread-1  ]: On model.mimic.icustay_days: ROLLBACK
17:37:06.526013 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.526826 [debug] [Thread-1  ]: On model.mimic.icustay_days: Close
17:37:06.527703 [debug] [Thread-1  ]: Database Error in model icustay_days (models/cookbook/icustay_days.sql)
  syntax error at or near "DROP"
  LINE 29: DROP MATERIALIZED VIEW icustay_days;
           ^
  compiled SQL at target/run/mimic/models/cookbook/icustay_days.sql
17:37:06.528168 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a58feb0>]}
17:37:06.528635 [error] [Thread-1  ]: 14 of 24 ERROR creating table model public.icustay_days ........................ [[31mERROR[0m in 0.02s]
17:37:06.529311 [debug] [Thread-1  ]: Finished running node model.mimic.icustay_days
17:37:06.529596 [debug] [Thread-1  ]: Began running node model.mimic.min_surviving_bp
17:37:06.529971 [info ] [Thread-1  ]: 15 of 24 START table model public.min_surviving_bp ............................. [RUN]
17:37:06.530393 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.min_surviving_bp"
17:37:06.530671 [debug] [Thread-1  ]: Began compiling node model.mimic.min_surviving_bp
17:37:06.530894 [debug] [Thread-1  ]: Compiling model.mimic.min_surviving_bp
17:37:06.532164 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.min_surviving_bp"
17:37:06.532521 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.532636 [debug] [Thread-1  ]: Began executing node model.mimic.min_surviving_bp
17:37:06.540404 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.min_surviving_bp"
17:37:06.540987 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.541197 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: BEGIN
17:37:06.541352 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:06.547072 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:06.547353 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.547528 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */


  create  table "postgres"."public"."min_surviving_bp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the systolic blood pressure of hospital survivors
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, min_surviving_bp as
(
  SELECT p.subject_id, ce.icustay_id, min(valuenum) AS min_sbp
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  -- here we filter down to only survivors
  INNER JOIN patients p
  ON ce.subject_id = p.subject_id and p.expire_flag = 0
  WHERE itemid IN (6, 51, 455, 6701, 220179, 220050)
  GROUP BY p.subject_id, ce.icustay_id
)
, min_surviving_bp_counted as
(
  SELECT width_bucket(min_sbp, 0, 300, 300) AS bucket
  FROM min_surviving_bp
)
SELECT bucket as systolic_blood_pressure, count(*)
FROM min_surviving_bp_counted
GROUP BY bucket
ORDER BY bucket
  );
17:37:06.715587 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.17 seconds
17:37:06.721750 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.722105 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
alter table "postgres"."public"."min_surviving_bp" rename to "min_surviving_bp__dbt_backup"
17:37:06.723269 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.728345 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.728545 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
alter table "postgres"."public"."min_surviving_bp__dbt_tmp" rename to "min_surviving_bp"
17:37:06.729324 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:06.732353 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: COMMIT
17:37:06.732549 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.732754 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: COMMIT
17:37:06.734259 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:06.736310 [debug] [Thread-1  ]: Using postgres connection "model.mimic.min_surviving_bp"
17:37:06.736521 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.min_surviving_bp"} */
drop table if exists "postgres"."public"."min_surviving_bp__dbt_backup" cascade
17:37:06.738316 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:06.740971 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.741182 [debug] [Thread-1  ]: On model.mimic.min_surviving_bp: Close
17:37:06.741951 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee5cd0>]}
17:37:06.742412 [info ] [Thread-1  ]: 15 of 24 OK created table model public.min_surviving_bp ........................ [[32mSELECT 4[0m in 0.21s]
17:37:06.743024 [debug] [Thread-1  ]: Finished running node model.mimic.min_surviving_bp
17:37:06.743426 [debug] [Thread-1  ]: Began running node model.mimic.mortality
17:37:06.744044 [info ] [Thread-1  ]: 16 of 24 START table model public.mortality .................................... [RUN]
17:37:06.744822 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.mortality"
17:37:06.745068 [debug] [Thread-1  ]: Began compiling node model.mimic.mortality
17:37:06.745342 [debug] [Thread-1  ]: Compiling model.mimic.mortality
17:37:06.746718 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.mortality"
17:37:06.747278 [debug] [Thread-1  ]: finished collecting timing info
17:37:06.747558 [debug] [Thread-1  ]: Began executing node model.mimic.mortality
17:37:06.758432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.mortality"
17:37:06.759364 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:06.759572 [debug] [Thread-1  ]: On model.mimic.mortality: BEGIN
17:37:06.759735 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:06.765035 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:06.765265 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:06.765435 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */


  create  table "postgres"."public"."mortality__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Calculate in-hospital, 30-day, and 1 year mortality (from hospital admission)
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- Inclusion criteria: Adult (>15 year old) patients, *MOST RECENT* hospital admission
-- ------------------------------------------------------------------

WITH tmp as
(
    SELECT adm.hadm_id, admittime, dischtime, adm.deathtime, pat.dod
    FROM admissions adm
    INNER JOIN patients pat
    ON adm.subject_id = pat.subject_id
    -- filter out organ donor accounts
    WHERE lower(diagnosis) NOT LIKE '%organ donor%'
    -- at least 15 years old
    AND DATETIME_DIFF(admittime, dob, 'YEAR') > 15
    -- filter that removes hospital admissions with no corresponding ICU data
    AND HAS_CHARTEVENTS_DATA = 1
)
SELECT COUNT(hadm_id) AS NumPat -- total number of patients
, round( cast(COUNT(deathtime) AS NUMERIC)/COUNT(hadm_id)*100 , 4) AS HospMort -- % hospital mortality
, round( cast(SUM(CASE WHEN dod < DATETIME_ADD(admittime, INTERVAL '30' DAY) THEN 1 ELSE 0 END) AS NUMERIC)/COUNT(hadm_id)*100.0 , 4) AS HospMort30day -- % 30 day mortality
, round( cast(SUM(CASE WHEN dod < DATETIME_ADD(admittime, INTERVAL '1' YEAR) THEN 1 ELSE 0 END) AS NUMERIC)/COUNT(hadm_id)*100 , 4) AS HospMort1yr -- % 1 year mortality
FROM tmp
  );
17:37:06.990917 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.23 seconds
17:37:06.997923 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:06.998157 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
alter table "postgres"."public"."mortality" rename to "mortality__dbt_backup"
17:37:06.999373 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.004626 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:07.004821 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
alter table "postgres"."public"."mortality__dbt_tmp" rename to "mortality"
17:37:07.005514 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.008699 [debug] [Thread-1  ]: On model.mimic.mortality: COMMIT
17:37:07.008896 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:07.009101 [debug] [Thread-1  ]: On model.mimic.mortality: COMMIT
17:37:07.012180 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.014976 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mortality"
17:37:07.015198 [debug] [Thread-1  ]: On model.mimic.mortality: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mortality"} */
drop table if exists "postgres"."public"."mortality__dbt_backup" cascade
17:37:07.017383 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.020423 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.020650 [debug] [Thread-1  ]: On model.mimic.mortality: Close
17:37:07.021443 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a639d90>]}
17:37:07.021920 [info ] [Thread-1  ]: 16 of 24 OK created table model public.mortality ............................... [[32mSELECT 1[0m in 0.28s]
17:37:07.022454 [debug] [Thread-1  ]: Finished running node model.mimic.mortality
17:37:07.022836 [debug] [Thread-1  ]: Began running node model.mimic.number_of_patients
17:37:07.023521 [info ] [Thread-1  ]: 17 of 24 START table model public.number_of_patients ........................... [RUN]
17:37:07.024360 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.number_of_patients"
17:37:07.024598 [debug] [Thread-1  ]: Began compiling node model.mimic.number_of_patients
17:37:07.024919 [debug] [Thread-1  ]: Compiling model.mimic.number_of_patients
17:37:07.026205 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.number_of_patients"
17:37:07.026776 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.027055 [debug] [Thread-1  ]: Began executing node model.mimic.number_of_patients
17:37:07.037127 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.number_of_patients"
17:37:07.038135 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.038453 [debug] [Thread-1  ]: On model.mimic.number_of_patients: BEGIN
17:37:07.039003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.044598 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:07.044836 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.045015 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */


  create  table "postgres"."public"."number_of_patients__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Counts the total number of patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

SELECT count(*)
FROM patients
  );
17:37:07.048995 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.0 seconds
17:37:07.058232 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.058435 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
alter table "postgres"."public"."number_of_patients" rename to "number_of_patients__dbt_backup"
17:37:07.059358 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.062984 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.063201 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
alter table "postgres"."public"."number_of_patients__dbt_tmp" rename to "number_of_patients"
17:37:07.063800 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.066844 [debug] [Thread-1  ]: On model.mimic.number_of_patients: COMMIT
17:37:07.067091 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.067306 [debug] [Thread-1  ]: On model.mimic.number_of_patients: COMMIT
17:37:07.068917 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.072775 [debug] [Thread-1  ]: Using postgres connection "model.mimic.number_of_patients"
17:37:07.072984 [debug] [Thread-1  ]: On model.mimic.number_of_patients: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.number_of_patients"} */
drop table if exists "postgres"."public"."number_of_patients__dbt_backup" cascade
17:37:07.074951 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.077745 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.077981 [debug] [Thread-1  ]: On model.mimic.number_of_patients: Close
17:37:07.078881 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee5f10>]}
17:37:07.079441 [info ] [Thread-1  ]: 17 of 24 OK created table model public.number_of_patients ...................... [[32mSELECT 1[0m in 0.05s]
17:37:07.080092 [debug] [Thread-1  ]: Finished running node model.mimic.number_of_patients
17:37:07.080478 [debug] [Thread-1  ]: Began running node model.mimic.potassium
17:37:07.081104 [info ] [Thread-1  ]: 18 of 24 START table model public.potassium .................................... [RUN]
17:37:07.081716 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.potassium"
17:37:07.081863 [debug] [Thread-1  ]: Began compiling node model.mimic.potassium
17:37:07.082124 [debug] [Thread-1  ]: Compiling model.mimic.potassium
17:37:07.083388 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.potassium"
17:37:07.084005 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.084533 [debug] [Thread-1  ]: Began executing node model.mimic.potassium
17:37:07.096175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.potassium"
17:37:07.096886 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.097110 [debug] [Thread-1  ]: On model.mimic.potassium: BEGIN
17:37:07.097274 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.104329 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:07.104874 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.105142 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */


  create  table "postgres"."public"."potassium__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Creates a histogram of serum potassium for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, k as
(
  SELECT width_bucket(valuenum, 0, 10, 100) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50822, 50971)
)
SELECT round(cast(bucket as numeric) / 10,2) as potassium_value, count(*)
FROM k
GROUP BY bucket
ORDER BY bucket
  );
17:37:07.246413 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:07.252600 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.252808 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
alter table "postgres"."public"."potassium" rename to "potassium__dbt_backup"
17:37:07.253578 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.257137 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.257331 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
alter table "postgres"."public"."potassium__dbt_tmp" rename to "potassium"
17:37:07.258044 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.261334 [debug] [Thread-1  ]: On model.mimic.potassium: COMMIT
17:37:07.261536 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.261733 [debug] [Thread-1  ]: On model.mimic.potassium: COMMIT
17:37:07.263118 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.265010 [debug] [Thread-1  ]: Using postgres connection "model.mimic.potassium"
17:37:07.265201 [debug] [Thread-1  ]: On model.mimic.potassium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.potassium"} */
drop table if exists "postgres"."public"."potassium__dbt_backup" cascade
17:37:07.267647 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.270992 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.271241 [debug] [Thread-1  ]: On model.mimic.potassium: Close
17:37:07.272003 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a5e6c10>]}
17:37:07.272525 [info ] [Thread-1  ]: 18 of 24 OK created table model public.potassium ............................... [[32mSELECT 0[0m in 0.19s]
17:37:07.273115 [debug] [Thread-1  ]: Finished running node model.mimic.potassium
17:37:07.273519 [debug] [Thread-1  ]: Began running node model.mimic.rr
17:37:07.274125 [info ] [Thread-1  ]: 19 of 24 START table model public.rr ........................................... [RUN]
17:37:07.274949 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rr"
17:37:07.275313 [debug] [Thread-1  ]: Began compiling node model.mimic.rr
17:37:07.275578 [debug] [Thread-1  ]: Compiling model.mimic.rr
17:37:07.276777 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rr"
17:37:07.277362 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.277673 [debug] [Thread-1  ]: Began executing node model.mimic.rr
17:37:07.287997 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rr"
17:37:07.289075 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.289357 [debug] [Thread-1  ]: On model.mimic.rr: BEGIN
17:37:07.289532 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.297398 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:07.297674 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.297806 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */


  create  table "postgres"."public"."rr__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the respiration rate of adult patients
--        only for patients recorded with carevue
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, rr as
(
  SELECT valuenum, width_bucket(valuenum, 0, 130, 1400) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid in (219, 615, 618)
)
SELECT round(cast(bucket as numeric) / 10,2) as respiration_rate, count(*)
FROM rr
GROUP BY bucket
ORDER BY bucket
  );
17:37:07.442515 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:07.449617 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.449851 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr" rename to "rr__dbt_backup"
17:37:07.451225 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.456459 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.456669 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr__dbt_tmp" rename to "rr"
17:37:07.457508 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.460882 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:37:07.461084 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.461406 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:37:07.462736 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.465041 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:07.465271 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
drop table if exists "postgres"."public"."rr__dbt_backup" cascade
17:37:07.467610 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.470590 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.470908 [debug] [Thread-1  ]: On model.mimic.rr: Close
17:37:07.471828 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a663c70>]}
17:37:07.472394 [info ] [Thread-1  ]: 19 of 24 OK created table model public.rr ...................................... [[32mSELECT 0[0m in 0.20s]
17:37:07.473049 [debug] [Thread-1  ]: Finished running node model.mimic.rr
17:37:07.473478 [debug] [Thread-1  ]: Began running node model.mimic.sbp
17:37:07.474042 [info ] [Thread-1  ]: 20 of 24 START table model public.sbp .......................................... [RUN]
17:37:07.474814 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sbp"
17:37:07.475181 [debug] [Thread-1  ]: Began compiling node model.mimic.sbp
17:37:07.475450 [debug] [Thread-1  ]: Compiling model.mimic.sbp
17:37:07.476798 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sbp"
17:37:07.477524 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.477799 [debug] [Thread-1  ]: Began executing node model.mimic.sbp
17:37:07.489165 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sbp"
17:37:07.489982 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.490182 [debug] [Thread-1  ]: On model.mimic.sbp: BEGIN
17:37:07.490276 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.495236 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:07.495485 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.495662 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */


  create  table "postgres"."public"."sbp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the systolic blood pressure for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, sysbp as
(
  SELECT width_bucket(valuenum, 0, 300, 300) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid IN
  (
      6 -- ABP [Systolic]
    , 51 -- Arterial BP [Systolic]
    , 455 -- NBP [Systolic]
    , 6701 -- Arterial BP #2 [Systolic]
    , 220050 -- Arterial Blood Pressure systolic
    , 220179 -- Non Invasive Blood Pressure systolic
  )
)
SELECT bucket as systolic_blood_pressure, count(*)
FROM sysbp
GROUP BY bucket
ORDER BY bucket
  );
17:37:07.652130 [debug] [Thread-1  ]: SQL status: SELECT 155 in 0.16 seconds
17:37:07.660147 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.660576 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
alter table "postgres"."public"."sbp" rename to "sbp__dbt_backup"
17:37:07.661854 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.666229 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.666426 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
alter table "postgres"."public"."sbp__dbt_tmp" rename to "sbp"
17:37:07.667295 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.670445 [debug] [Thread-1  ]: On model.mimic.sbp: COMMIT
17:37:07.670705 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.670903 [debug] [Thread-1  ]: On model.mimic.sbp: COMMIT
17:37:07.671998 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.674144 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sbp"
17:37:07.674348 [debug] [Thread-1  ]: On model.mimic.sbp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sbp"} */
drop table if exists "postgres"."public"."sbp__dbt_backup" cascade
17:37:07.676245 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.679676 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.679913 [debug] [Thread-1  ]: On model.mimic.sbp: Close
17:37:07.680682 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a5686a0>]}
17:37:07.681171 [info ] [Thread-1  ]: 20 of 24 OK created table model public.sbp ..................................... [[32mSELECT 155[0m in 0.21s]
17:37:07.681790 [debug] [Thread-1  ]: Finished running node model.mimic.sbp
17:37:07.682020 [debug] [Thread-1  ]: Began running node model.mimic.sodium
17:37:07.682229 [info ] [Thread-1  ]: 21 of 24 START table model public.sodium ....................................... [RUN]
17:37:07.683064 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sodium"
17:37:07.683423 [debug] [Thread-1  ]: Began compiling node model.mimic.sodium
17:37:07.683686 [debug] [Thread-1  ]: Compiling model.mimic.sodium
17:37:07.684975 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sodium"
17:37:07.685507 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.685827 [debug] [Thread-1  ]: Began executing node model.mimic.sodium
17:37:07.697048 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sodium"
17:37:07.697466 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.697572 [debug] [Thread-1  ]: On model.mimic.sodium: BEGIN
17:37:07.697679 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.703307 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:07.703561 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.703805 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */


  create  table "postgres"."public"."sodium__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the blood serum sodium levels for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, sodium as
(
  SELECT width_bucket(valuenum, 0, 180, 180) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid IN (50824, 50983)
)
SELECT bucket as sodium, count(*)
FROM sodium
GROUP BY bucket
ORDER BY bucket
  );
17:37:07.843124 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:07.850239 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.850777 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
alter table "postgres"."public"."sodium" rename to "sodium__dbt_backup"
17:37:07.851790 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.855293 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.855519 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
alter table "postgres"."public"."sodium__dbt_tmp" rename to "sodium"
17:37:07.856193 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:07.859214 [debug] [Thread-1  ]: On model.mimic.sodium: COMMIT
17:37:07.859426 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.859617 [debug] [Thread-1  ]: On model.mimic.sodium: COMMIT
17:37:07.860812 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:07.862887 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sodium"
17:37:07.863142 [debug] [Thread-1  ]: On model.mimic.sodium: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sodium"} */
drop table if exists "postgres"."public"."sodium__dbt_backup" cascade
17:37:07.864986 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:07.868481 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.868806 [debug] [Thread-1  ]: On model.mimic.sodium: Close
17:37:07.869601 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a597910>]}
17:37:07.870075 [info ] [Thread-1  ]: 21 of 24 OK created table model public.sodium .................................. [[32mSELECT 0[0m in 0.19s]
17:37:07.870643 [debug] [Thread-1  ]: Finished running node model.mimic.sodium
17:37:07.870886 [debug] [Thread-1  ]: Began running node model.mimic.temp
17:37:07.871527 [info ] [Thread-1  ]: 22 of 24 START table model public.temp ......................................... [RUN]
17:37:07.872347 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.temp"
17:37:07.872688 [debug] [Thread-1  ]: Began compiling node model.mimic.temp
17:37:07.873075 [debug] [Thread-1  ]: Compiling model.mimic.temp
17:37:07.874763 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.temp"
17:37:07.875392 [debug] [Thread-1  ]: finished collecting timing info
17:37:07.875670 [debug] [Thread-1  ]: Began executing node model.mimic.temp
17:37:07.886561 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.temp"
17:37:07.887216 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:07.887429 [debug] [Thread-1  ]: On model.mimic.temp: BEGIN
17:37:07.887644 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:07.893328 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:07.893570 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:07.893672 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */


  create  table "postgres"."public"."temp__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the temperature of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, temp as
(
  SELECT width_bucket(
      CASE
        WHEN itemid IN (223762, 676, 677) THEN valuenum -- celsius
        WHEN itemid IN (223761, 678, 679) THEN (valuenum - 32) * 5 / 9 --fahrenheit
      END
    , 30, 45, 160) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid IN
  (
      676 -- Temperature C
    , 677 -- Temperature C (calc)
    , 678 -- Temperature F
    , 679 -- Temperature F (calc)
    , 223761 -- Temperature Fahrenheit
    , 223762 -- Temperature Celsius
  )
)
SELECT round((cast(bucket as numeric)/10) + 30,2) as temperature, count(*)
FROM temp
GROUP BY bucket
ORDER BY bucket
  );
17:37:08.048699 [debug] [Thread-1  ]: SQL status: SELECT 30 in 0.15 seconds
17:37:08.053593 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:08.053791 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
alter table "postgres"."public"."temp" rename to "temp__dbt_backup"
17:37:08.054541 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:08.057818 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:08.058000 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
alter table "postgres"."public"."temp__dbt_tmp" rename to "temp"
17:37:08.058772 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:08.061847 [debug] [Thread-1  ]: On model.mimic.temp: COMMIT
17:37:08.062044 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:08.062250 [debug] [Thread-1  ]: On model.mimic.temp: COMMIT
17:37:08.063312 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:08.065354 [debug] [Thread-1  ]: Using postgres connection "model.mimic.temp"
17:37:08.065552 [debug] [Thread-1  ]: On model.mimic.temp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.temp"} */
drop table if exists "postgres"."public"."temp__dbt_backup" cascade
17:37:08.067934 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:08.070827 [debug] [Thread-1  ]: finished collecting timing info
17:37:08.071088 [debug] [Thread-1  ]: On model.mimic.temp: Close
17:37:08.071829 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4bee8610>]}
17:37:08.072306 [info ] [Thread-1  ]: 22 of 24 OK created table model public.temp .................................... [[32mSELECT 30[0m in 0.20s]
17:37:08.072899 [debug] [Thread-1  ]: Finished running node model.mimic.temp
17:37:08.073251 [debug] [Thread-1  ]: Began running node model.mimic.uo
17:37:08.073806 [info ] [Thread-1  ]: 23 of 24 START table model public.uo ........................................... [RUN]
17:37:08.074701 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.uo"
17:37:08.075076 [debug] [Thread-1  ]: Began compiling node model.mimic.uo
17:37:08.075408 [debug] [Thread-1  ]: Compiling model.mimic.uo
17:37:08.076748 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.uo"
17:37:08.077387 [debug] [Thread-1  ]: finished collecting timing info
17:37:08.077681 [debug] [Thread-1  ]: Began executing node model.mimic.uo
17:37:08.088835 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.uo"
17:37:08.089393 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:08.089607 [debug] [Thread-1  ]: On model.mimic.uo: BEGIN
17:37:08.089699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:08.095355 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:08.095636 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:08.095929 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */


  create  table "postgres"."public"."uo__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the urine output of adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ie.icustay_id, ie.intime
  FROM icustays ie
  INNER JOIN patients p
  ON ie.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ie.intime, p.dob, 'YEAR') > 15
)
-- Urine output is measured hourly, but the individual values are not of interest
-- Usually, you want an overall picture of patient output
-- This query sums the data over the first 24 hours
, uo_sum as
(
  select oe.icustay_id, sum(oe.VALUE) as urineoutput
  FROM outputevents oe
  INNER JOIN agetbl
  ON oe.icustay_id = agetbl.icustay_id
  -- and ensure the data occurs during the first day
  and oe.charttime between agetbl.intime and (DATETIME_ADD(agetbl.intime, INTERVAL '1' DAY)) -- first ICU day
  WHERE itemid IN
  (
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in Metavision
  226559, -- "Foley"
  226560, -- "Void"
  227510, -- "TF Residual"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- "R Ureteral Stent"
  226558  -- "L Ureteral Stent"
  )
  group by oe.icustay_id
)
, uo as
(
  SELECT width_bucket(urineoutput, 0, 5000, 50) AS bucket
  FROM uo_sum
)
SELECT bucket*100 as UrineOutput, COUNT(*)
FROM uo
GROUP BY bucket
ORDER BY bucket
  );
17:37:11.115901 [debug] [Thread-1  ]: SQL status: SELECT 53 in 3.02 seconds
17:37:11.121971 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:11.122186 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
alter table "postgres"."public"."uo" rename to "uo__dbt_backup"
17:37:11.122939 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:11.126801 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:11.127028 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
alter table "postgres"."public"."uo__dbt_tmp" rename to "uo"
17:37:11.127715 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:11.131343 [debug] [Thread-1  ]: On model.mimic.uo: COMMIT
17:37:11.131605 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:11.131844 [debug] [Thread-1  ]: On model.mimic.uo: COMMIT
17:37:11.141177 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:37:11.143469 [debug] [Thread-1  ]: Using postgres connection "model.mimic.uo"
17:37:11.143675 [debug] [Thread-1  ]: On model.mimic.uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.uo"} */
drop table if exists "postgres"."public"."uo__dbt_backup" cascade
17:37:11.150122 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:37:11.153430 [debug] [Thread-1  ]: finished collecting timing info
17:37:11.153664 [debug] [Thread-1  ]: On model.mimic.uo: Close
17:37:11.154337 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a50f760>]}
17:37:11.154906 [info ] [Thread-1  ]: 23 of 24 OK created table model public.uo ...................................... [[32mSELECT 53[0m in 3.08s]
17:37:11.155496 [debug] [Thread-1  ]: Finished running node model.mimic.uo
17:37:11.155868 [debug] [Thread-1  ]: Began running node model.mimic.wbc
17:37:11.156506 [info ] [Thread-1  ]: 24 of 24 START table model public.wbc .......................................... [RUN]
17:37:11.157326 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.wbc"
17:37:11.157625 [debug] [Thread-1  ]: Began compiling node model.mimic.wbc
17:37:11.157888 [debug] [Thread-1  ]: Compiling model.mimic.wbc
17:37:11.159104 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.wbc"
17:37:11.159785 [debug] [Thread-1  ]: finished collecting timing info
17:37:11.160052 [debug] [Thread-1  ]: Began executing node model.mimic.wbc
17:37:11.171462 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.wbc"
17:37:11.172385 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.172749 [debug] [Thread-1  ]: On model.mimic.wbc: BEGIN
17:37:11.172908 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:11.179991 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:11.180229 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.180501 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */


  create  table "postgres"."public"."wbc__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the white blood cell count for adult patients
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, wbc as
(
  SELECT width_bucket(valuenum, 0, 100, 1001) AS bucket
  FROM labevents le
  INNER JOIN agetbl
  ON le.subject_id = agetbl.subject_id
  WHERE itemid in (51300, 51301)
  AND valuenum IS NOT NULL
)
SELECT round((cast(bucket as numeric)/10),2) as white_blood_cell_count, count(*)
FROM wbc
GROUP BY bucket
ORDER BY bucket
  );
17:37:11.320954 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.14 seconds
17:37:11.328470 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.328875 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
alter table "postgres"."public"."wbc" rename to "wbc__dbt_backup"
17:37:11.330300 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:11.334228 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.334443 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
alter table "postgres"."public"."wbc__dbt_tmp" rename to "wbc"
17:37:11.335308 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:11.338117 [debug] [Thread-1  ]: On model.mimic.wbc: COMMIT
17:37:11.338299 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.338542 [debug] [Thread-1  ]: On model.mimic.wbc: COMMIT
17:37:11.341127 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:11.343622 [debug] [Thread-1  ]: Using postgres connection "model.mimic.wbc"
17:37:11.343823 [debug] [Thread-1  ]: On model.mimic.wbc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.wbc"} */
drop table if exists "postgres"."public"."wbc__dbt_backup" cascade
17:37:11.346076 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:11.350357 [debug] [Thread-1  ]: finished collecting timing info
17:37:11.350796 [debug] [Thread-1  ]: On model.mimic.wbc: Close
17:37:11.351731 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '850751a9-1f70-41da-a28c-80642f2915e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4a5cd6d0>]}
17:37:11.352225 [info ] [Thread-1  ]: 24 of 24 OK created table model public.wbc ..................................... [[32mSELECT 0[0m in 0.19s]
17:37:11.352765 [debug] [Thread-1  ]: Finished running node model.mimic.wbc
17:37:11.354338 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:11.354787 [debug] [MainThread]: Using postgres connection "master"
17:37:11.355049 [debug] [MainThread]: On master: BEGIN
17:37:11.355252 [debug] [MainThread]: Opening a new connection, currently in state closed
17:37:11.360139 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:37:11.360410 [debug] [MainThread]: On master: COMMIT
17:37:11.360606 [debug] [MainThread]: Using postgres connection "master"
17:37:11.360785 [debug] [MainThread]: On master: COMMIT
17:37:11.361079 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:11.361332 [debug] [MainThread]: On master: Close
17:37:11.362015 [info ] [MainThread]: 
17:37:11.362291 [info ] [MainThread]: Finished running 24 table models in 7.34s.
17:37:11.362464 [debug] [MainThread]: Connection 'master' was properly closed.
17:37:11.362784 [debug] [MainThread]: Connection 'model.mimic.wbc' was properly closed.
17:37:11.376107 [info ] [MainThread]: 
17:37:11.376607 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
17:37:11.376957 [info ] [MainThread]: 
17:37:11.377291 [error] [MainThread]: [33mDatabase Error in model icustay_days (models/cookbook/icustay_days.sql)[0m
17:37:11.377680 [error] [MainThread]:   syntax error at or near "DROP"
17:37:11.377853 [error] [MainThread]:   LINE 29: DROP MATERIALIZED VIEW icustay_days;
17:37:11.377999 [error] [MainThread]:            ^
17:37:11.378144 [error] [MainThread]:   compiled SQL at target/run/mimic/models/cookbook/icustay_days.sql
17:37:11.378346 [info ] [MainThread]: 
17:37:11.378821 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=1 SKIP=0 TOTAL=24
17:37:11.379469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4e1a6dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4e797f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf4c9a20d0>]}
17:37:11.383923 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:37:23.917158 | f8986c5d-7dc3-4208-9f75-fc5f0072a75f ==============================
17:37:23.917171 [info ] [MainThread]: Running with dbt=1.1.1
17:37:23.917504 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['rr'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:37:23.917621 [debug] [MainThread]: Tracking: tracking
17:37:23.923865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffb481f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffb482b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffb482e0>]}
17:37:24.012647 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:37:24.012891 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:37:24.015222 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:37:24.021830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f8986c5d-7dc3-4208-9f75-fc5f0072a75f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffb48e20>]}
17:37:24.040478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f8986c5d-7dc3-4208-9f75-fc5f0072a75f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffba71c0>]}
17:37:24.041079 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:37:24.041431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8986c5d-7dc3-4208-9f75-fc5f0072a75f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffb744c0>]}
17:37:24.044859 [info ] [MainThread]: 
17:37:24.046138 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:24.048430 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:37:24.061981 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:37:24.062210 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:37:24.062310 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:37:24.069438 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:37:24.075849 [debug] [ThreadPool]: On list_postgres: Close
17:37:24.082877 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:37:24.090411 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:24.090973 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:37:24.091224 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:37:24.096929 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:37:24.097170 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:24.097272 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:37:24.100459 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:37:24.109872 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:37:24.110268 [debug] [ThreadPool]: On list_postgres_public: Close
17:37:24.123482 [debug] [MainThread]: Using postgres connection "master"
17:37:24.123716 [debug] [MainThread]: On master: BEGIN
17:37:24.123913 [debug] [MainThread]: Opening a new connection, currently in state init
17:37:24.129271 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:37:24.129607 [debug] [MainThread]: Using postgres connection "master"
17:37:24.129783 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:37:24.138283 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:37:24.141507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8986c5d-7dc3-4208-9f75-fc5f0072a75f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82019f7730>]}
17:37:24.141804 [debug] [MainThread]: On master: ROLLBACK
17:37:24.142133 [debug] [MainThread]: Using postgres connection "master"
17:37:24.142249 [debug] [MainThread]: On master: BEGIN
17:37:24.142707 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:37:24.142960 [debug] [MainThread]: On master: COMMIT
17:37:24.143150 [debug] [MainThread]: Using postgres connection "master"
17:37:24.143329 [debug] [MainThread]: On master: COMMIT
17:37:24.143743 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:24.144007 [debug] [MainThread]: On master: Close
17:37:24.144570 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:37:24.144776 [info ] [MainThread]: 
17:37:24.148816 [debug] [Thread-1  ]: Began running node model.mimic.rr
17:37:24.149250 [info ] [Thread-1  ]: 1 of 1 START table model public.rr ............................................. [RUN]
17:37:24.150066 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.rr"
17:37:24.150273 [debug] [Thread-1  ]: Began compiling node model.mimic.rr
17:37:24.150668 [debug] [Thread-1  ]: Compiling model.mimic.rr
17:37:24.152035 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.rr"
17:37:24.152483 [debug] [Thread-1  ]: finished collecting timing info
17:37:24.152635 [debug] [Thread-1  ]: Began executing node model.mimic.rr
17:37:24.186566 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.rr"
17:37:24.187558 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.188151 [debug] [Thread-1  ]: On model.mimic.rr: BEGIN
17:37:24.188527 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:24.196301 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:24.196549 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.196724 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */


  create  table "postgres"."public"."rr__dbt_tmp"
  as (
    -- --------------------------------------------------------
-- Title: Retrieves the respiration rate of adult patients
--        only for patients recorded with carevue
-- MIMIC version: MIMIC-III v1.3
-- Notes: this query does not specify a schema. To run it on your local
-- MIMIC schema, run the following command:
--  SET SEARCH_PATH TO mimiciii
-- Where "mimiciii" is the name of your schema, and may be different.
-- --------------------------------------------------------

WITH agetbl AS
(
  SELECT ad.subject_id
  FROM admissions ad
  INNER JOIN patients p
  ON ad.subject_id = p.subject_id
  WHERE
  -- filter to only adults
  DATETIME_DIFF(ad.admittime, p.dob, 'YEAR') > 15
  -- group by subject_id to ensure there is only 1 subject_id per row
  group by ad.subject_id
)
, rr as
(
  SELECT valuenum, width_bucket(valuenum, 0, 130, 1400) AS bucket
  FROM chartevents ce
  INNER JOIN agetbl
  ON ce.subject_id = agetbl.subject_id
  WHERE itemid in (219, 615, 618)
)
SELECT round(cast(bucket as numeric) / 10,2) as respiration_rate, count(*)
FROM rr
GROUP BY bucket
ORDER BY bucket
  );
17:37:24.342914 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.15 seconds
17:37:24.354697 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.355072 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr" rename to "rr__dbt_backup"
17:37:24.356440 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:24.360856 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.361055 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
alter table "postgres"."public"."rr__dbt_tmp" rename to "rr"
17:37:24.361822 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:24.372165 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:37:24.372456 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.372726 [debug] [Thread-1  ]: On model.mimic.rr: COMMIT
17:37:24.375606 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:24.380466 [debug] [Thread-1  ]: Using postgres connection "model.mimic.rr"
17:37:24.380669 [debug] [Thread-1  ]: On model.mimic.rr: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.rr"} */
drop table if exists "postgres"."public"."rr__dbt_backup" cascade
17:37:24.382856 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:24.386099 [debug] [Thread-1  ]: finished collecting timing info
17:37:24.386420 [debug] [Thread-1  ]: On model.mimic.rr: Close
17:37:24.387369 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f8986c5d-7dc3-4208-9f75-fc5f0072a75f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81fd86d1c0>]}
17:37:24.387903 [info ] [Thread-1  ]: 1 of 1 OK created table model public.rr ........................................ [[32mSELECT 0[0m in 0.24s]
17:37:24.388522 [debug] [Thread-1  ]: Finished running node model.mimic.rr
17:37:24.390328 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:24.390905 [debug] [MainThread]: Using postgres connection "master"
17:37:24.391335 [debug] [MainThread]: On master: BEGIN
17:37:24.391714 [debug] [MainThread]: Opening a new connection, currently in state closed
17:37:24.397350 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:37:24.397584 [debug] [MainThread]: On master: COMMIT
17:37:24.397769 [debug] [MainThread]: Using postgres connection "master"
17:37:24.397868 [debug] [MainThread]: On master: COMMIT
17:37:24.398090 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:24.398210 [debug] [MainThread]: On master: Close
17:37:24.398852 [info ] [MainThread]: 
17:37:24.399868 [info ] [MainThread]: Finished running 1 table model in 0.35s.
17:37:24.400614 [debug] [MainThread]: Connection 'master' was properly closed.
17:37:24.400954 [debug] [MainThread]: Connection 'model.mimic.rr' was properly closed.
17:37:24.416005 [info ] [MainThread]: 
17:37:24.416326 [info ] [MainThread]: [32mCompleted successfully[0m
17:37:24.416858 [info ] [MainThread]: 
17:37:24.417191 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
17:37:24.417501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffba71f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffba7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ffba72b0>]}
17:37:24.420139 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:37:38.167605 | e0257ee1-a60b-435f-a84b-55ef5fdb03a5 ==============================
17:37:38.167622 [info ] [MainThread]: Running with dbt=1.1.1
17:37:38.168300 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['comorbidity'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:37:38.168707 [debug] [MainThread]: Tracking: tracking
17:37:38.175378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e4645ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e4645370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e46450a0>]}
17:37:38.267347 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:37:38.267590 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:37:38.269747 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:37:38.276353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e4641670>]}
17:37:38.295785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e4620220>]}
17:37:38.296566 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:37:38.297284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e46206a0>]}
17:37:38.299917 [info ] [MainThread]: 
17:37:38.300623 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:38.301838 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:37:38.309997 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:37:38.311171 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:37:38.312228 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:37:38.320541 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:37:38.324653 [debug] [ThreadPool]: On list_postgres: Close
17:37:38.331998 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:37:38.337953 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:38.338145 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:37:38.338348 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:37:38.345517 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:37:38.345974 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:37:38.346326 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:37:38.349689 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:37:38.356347 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:37:38.356860 [debug] [ThreadPool]: On list_postgres_public: Close
17:37:38.370454 [debug] [MainThread]: Using postgres connection "master"
17:37:38.370740 [debug] [MainThread]: On master: BEGIN
17:37:38.371022 [debug] [MainThread]: Opening a new connection, currently in state init
17:37:38.377082 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:37:38.377662 [debug] [MainThread]: Using postgres connection "master"
17:37:38.378094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:37:38.384621 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:37:38.388469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e641dbb0>]}
17:37:38.388930 [debug] [MainThread]: On master: ROLLBACK
17:37:38.389341 [debug] [MainThread]: Using postgres connection "master"
17:37:38.389538 [debug] [MainThread]: On master: BEGIN
17:37:38.389930 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:37:38.390132 [debug] [MainThread]: On master: COMMIT
17:37:38.390235 [debug] [MainThread]: Using postgres connection "master"
17:37:38.390329 [debug] [MainThread]: On master: COMMIT
17:37:38.390542 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:38.390809 [debug] [MainThread]: On master: Close
17:37:38.391620 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:37:38.392117 [info ] [MainThread]: 
17:37:38.396838 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_ahrq_v37
17:37:38.397244 [info ] [Thread-1  ]: 1 of 5 START table model public.elixhauser_ahrq_v37 ............................ [RUN]
17:37:38.397918 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:38.398134 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_ahrq_v37
17:37:38.398359 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_ahrq_v37
17:37:38.403562 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_ahrq_v37"
17:37:38.404127 [debug] [Thread-1  ]: finished collecting timing info
17:37:38.404403 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_ahrq_v37
17:37:38.436887 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_ahrq_v37"
17:37:38.437522 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:38.437729 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: BEGIN
17:37:38.437891 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:38.444979 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:38.445408 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:38.445598 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */


  create  table "postgres"."public"."elixhauser_ahrq_v37__dbt_tmp"
  as (
    -- This code uses the latest version of Elixhauser provided by AHRQ
 

with eliflg as (
    select
        hadm_id,
        seq_num,
        icd9_code -- note that these codes will seem incomplete at first
        -- for example, CHF is missing a lot of codes referenced in the literature (402.11, 402.91, etc)
        -- these codes are captured by hypertension flags instead
        -- later there are some complicated rules which confirm/reject those codes as chf
,
        CASE
            when icd9_code = '39891' then 1
            when icd9_code between '4280'
            and '4289' then 1
        end as chf
        /* Congestive heart failure */
        -- cardiac arrhythmias is removed in up to date versions
,
        case
            when icd9_code = '42610' then 1
            when icd9_code = '42611' then 1
            when icd9_code = '42613' then 1
            when icd9_code between '4262'
            and '42653' then 1
            when icd9_code between '4266'
            and '42689' then 1
            when icd9_code = '4270' then 1
            when icd9_code = '4272' then 1
            when icd9_code = '42731' then 1
            when icd9_code = '42760' then 1
            when icd9_code = '4279' then 1
            when icd9_code = '7850' then 1
            when icd9_code between 'V450'
            and 'V4509' then 1
            when icd9_code between 'V533'
            and 'V5339' then 1
        end as arythm
        /* Cardiac arrhythmias */
,
        CASE
            when icd9_code between '09320'
            and '09324' then 1
            when icd9_code between '3940'
            and '3971' then 1
            when icd9_code = '3979' then 1
            when icd9_code between '4240'
            and '42499' then 1
            when icd9_code between '7463'
            and '7466' then 1
            when icd9_code = 'V422' then 1
            when icd9_code = 'V433' then 1
        end as valve
        /* Valvular disease */
,
        CASE
            when icd9_code between '41511'
            and '41519' then 1
            when icd9_code between '4160'
            and '4169' then 1
            when icd9_code = '4179' then 1
        end as pulmcirc
        /* Pulmonary circulation disorder */
,
        CASE
            when icd9_code between '4400'
            and '4409' then 1
            when icd9_code between '44100'
            and '4419' then 1
            when icd9_code between '4420'
            and '4429' then 1
            when icd9_code between '4431'
            and '4439' then 1
            when icd9_code between '44421'
            and '44422' then 1
            when icd9_code = '4471' then 1
            when icd9_code = '449' then 1
            when icd9_code = '5571' then 1
            when icd9_code = '5579' then 1
            when icd9_code = 'V434' then 1
        end as perivasc
        /* Peripheral vascular disorder */
,
        CASE
            when icd9_code = '4011' then 1
            when icd9_code = '4019' then 1
            when icd9_code between '64200'
            and '64204' then 1
        end as htn
        /* Hypertension, uncomplicated */
,
        CASE
            when icd9_code = '4010' then 1
            when icd9_code = '4372' then 1
        end as htncx
        /* Hypertension, complicated */
        /******************************************************************/
        /* The following are special, temporary formats used in the       */
        /* creation of the hypertension complicated comorbidity when      */
        /* overlapping with congestive heart failure or renal failure     */
        /* occurs. These temporary formats are referenced in the program  */
        /* called comoanaly2009.txt.                                      */
        /******************************************************************/
,
        CASE
            when icd9_code between '64220'
            and '64224' then 1
        end as htnpreg
        /* Pre-existing hypertension complicating pregnancy */
,
        CASE
            when icd9_code = '40200' then 1
            when icd9_code = '40210' then 1
            when icd9_code = '40290' then 1
            when icd9_code = '40509' then 1
            when icd9_code = '40519' then 1
            when icd9_code = '40599' then 1
        end as htnwochf
        /* Hypertensive heart disease without heart failure */
,
        CASE
            when icd9_code = '40201' then 1
            when icd9_code = '40211' then 1
            when icd9_code = '40291' then 1
        end as htnwchf
        /* Hypertensive heart disease with heart failure */
,
        CASE
            when icd9_code = '40300' then 1
            when icd9_code = '40310' then 1
            when icd9_code = '40390' then 1
            when icd9_code = '40501' then 1
            when icd9_code = '40511' then 1
            when icd9_code = '40591' then 1
            when icd9_code between '64210'
            and '64214' then 1
        end as hrenworf
        /* Hypertensive renal disease without renal failure */
,
        CASE
            when icd9_code = '40301' then 1
            when icd9_code = '40311' then 1
            when icd9_code = '40391' then 1
        end as hrenwrf
        /* Hypertensive renal disease with renal failure */
,
        CASE
            when icd9_code = '40400' then 1
            when icd9_code = '40410' then 1
            when icd9_code = '40490' then 1
        end as hhrwohrf
        /* Hypertensive heart and renal disease without heart or renal failure */
,
        CASE
            when icd9_code = '40401' then 1
            when icd9_code = '40411' then 1
            when icd9_code = '40491' then 1
        end as hhrwchf
        /* Hypertensive heart and renal disease with heart failure */
,
        CASE
            when icd9_code = '40402' then 1
            when icd9_code = '40412' then 1
            when icd9_code = '40492' then 1
        end as hhrwrf
        /* Hypertensive heart and renal disease with renal failure */
,
        CASE
            when icd9_code = '40403' then 1
            when icd9_code = '40413' then 1
            when icd9_code = '40493' then 1
        end as hhrwhrf
        /* Hypertensive heart and renal disease with heart and renal failure */
,
        CASE
            when icd9_code between '64270'
            and '64274' then 1
            when icd9_code between '64290'
            and '64294' then 1
        end as ohtnpreg
        /* Other hypertension in pregnancy */
        /******************** End Temporary Formats ***********************/
,
        CASE
            when icd9_code between '3420'
            and '3449' then 1
            when icd9_code between '43820'
            and '43853' then 1
            when icd9_code = '78072' then 1
        end as para
        /* Paralysis */
,
        CASE
            when icd9_code between '3300'
            and '3319' then 1
            when icd9_code = '3320' then 1
            when icd9_code = '3334' then 1
            when icd9_code = '3335' then 1
            when icd9_code = '3337' then 1
            when icd9_code in ('33371', '33372', '33379', '33385', '33394') then 1
            when icd9_code between '3340'
            and '3359' then 1
            when icd9_code = '3380' then 1
            when icd9_code = '340' then 1
            when icd9_code between '3411'
            and '3419' then 1
            when icd9_code between '34500'
            and '34511' then 1
            when icd9_code between '3452'
            and '3453' then 1
            when icd9_code between '34540'
            and '34591' then 1
            when icd9_code between '34700'
            and '34701' then 1
            when icd9_code between '34710'
            and '34711' then 1
            when icd9_code = '3483' then 1 -- discontinued icd-9
            when icd9_code between '64940'
            and '64944' then 1
            when icd9_code = '7687' then 1
            when icd9_code between '76870'
            and '76873' then 1
            when icd9_code = '7803' then 1
            when icd9_code = '78031' then 1
            when icd9_code = '78032' then 1
            when icd9_code = '78033' then 1
            when icd9_code = '78039' then 1
            when icd9_code = '78097' then 1
            when icd9_code = '7843' then 1
        end as neuro
        /* Other neurological */
,
        CASE
            when icd9_code between '490'
            and '4928' then 1
            when icd9_code between '49300'
            and '49392' then 1
            when icd9_code between '494'
            and '4941' then 1
            when icd9_code between '4950'
            and '505' then 1
            when icd9_code = '5064' then 1
        end as chrnlung
        /* Chronic pulmonary disease */
,
        CASE
            when icd9_code between '25000'
            and '25033' then 1
            when icd9_code between '64800'
            and '64804' then 1
            when icd9_code between '24900'
            and '24931' then 1
        end as dm
        /* Diabetes w/o chronic complications*/
,
        CASE
            when icd9_code between '25040'
            and '25093' then 1
            when icd9_code = '7751' then 1
            when icd9_code between '24940'
            and '24991' then 1
        end as dmcx
        /* Diabetes w/ chronic complications */
,
        CASE
            when icd9_code between '243'
            and '2442' then 1
            when icd9_code = '2448' then 1
            when icd9_code = '2449' then 1
        end as hypothy
        /* Hypothyroidism */
,
        CASE
            when icd9_code = '585' then 1 -- discontinued code
            when icd9_code = '5853' then 1
            when icd9_code = '5854' then 1
            when icd9_code = '5855' then 1
            when icd9_code = '5856' then 1
            when icd9_code = '5859' then 1
            when icd9_code = '586' then 1
            when icd9_code = 'V420' then 1
            when icd9_code = 'V451' then 1
            when icd9_code between 'V560'
            and 'V5632' then 1
            when icd9_code = 'V568' then 1
            when icd9_code between 'V4511'
            and 'V4512' then 1
        end as renlfail
        /* Renal failure */
,
        CASE
            when icd9_code = '07022' then 1
            when icd9_code = '07023' then 1
            when icd9_code = '07032' then 1
            when icd9_code = '07033' then 1
            when icd9_code = '07044' then 1
            when icd9_code = '07054' then 1
            when icd9_code = '4560' then 1
            when icd9_code = '4561' then 1
            when icd9_code = '45620' then 1
            when icd9_code = '45621' then 1
            when icd9_code = '5710' then 1
            when icd9_code = '5712' then 1
            when icd9_code = '5713' then 1
            when icd9_code between '57140'
            and '57149' then 1
            when icd9_code = '5715' then 1
            when icd9_code = '5716' then 1
            when icd9_code = '5718' then 1
            when icd9_code = '5719' then 1
            when icd9_code = '5723' then 1
            when icd9_code = '5728' then 1
            when icd9_code = '5735' then 1
            when icd9_code = 'V427' then 1
        end as liver
        /* Liver disease */
,
        CASE
            when icd9_code = '53141' then 1
            when icd9_code = '53151' then 1
            when icd9_code = '53161' then 1
            when icd9_code = '53170' then 1
            when icd9_code = '53171' then 1
            when icd9_code = '53191' then 1
            when icd9_code = '53241' then 1
            when icd9_code = '53251' then 1
            when icd9_code = '53261' then 1
            when icd9_code = '53270' then 1
            when icd9_code = '53271' then 1
            when icd9_code = '53291' then 1
            when icd9_code = '53341' then 1
            when icd9_code = '53351' then 1
            when icd9_code = '53361' then 1
            when icd9_code = '53370' then 1
            when icd9_code = '53371' then 1
            when icd9_code = '53391' then 1
            when icd9_code = '53441' then 1
            when icd9_code = '53451' then 1
            when icd9_code = '53461' then 1
            when icd9_code = '53470' then 1
            when icd9_code = '53471' then 1
            when icd9_code = '53491' then 1
        end as ulcer
        /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */
,
        CASE
            when icd9_code between '042'
            and '0449' then 1
        end as aids
        /* HIV and AIDS */
,
        CASE
            when icd9_code between '20000'
            and '20238' then 1
            when icd9_code between '20250'
            and '20301' then 1
            when icd9_code = '2386' then 1
            when icd9_code = '2733' then 1
            when icd9_code between '20302'
            and '20382' then 1
        end as lymph
        /* Lymphoma */
,
        CASE
            when icd9_code between '1960'
            and '1991' then 1
            when icd9_code between '20970'
            and '20975' then 1
            when icd9_code = '20979' then 1
            when icd9_code = '78951' then 1
        end as mets
        /* Metastatic cancer */
,
        CASE
            when icd9_code between '1400'
            and '1729' then 1
            when icd9_code between '1740'
            and '1759' then 1
            when icd9_code between '179'
            and '1958' then 1
            when icd9_code between '20900'
            and '20924' then 1
            when icd9_code between '20925'
            and '2093' then 1
            when icd9_code between '20930'
            and '20936' then 1
            when icd9_code between '25801'
            and '25803' then 1
        end as tumor
        /* Solid tumor without metastasis */
,
        CASE
            when icd9_code = '7010' then 1
            when icd9_code between '7100'
            and '7109' then 1
            when icd9_code between '7140'
            and '7149' then 1
            when icd9_code between '7200'
            and '7209' then 1
            when icd9_code = '725' then 1
        end as arth
        /* Rheumatoid arthritis/collagen vascular diseases */
,
        CASE
            when icd9_code between '2860'
            and '2869' then 1
            when icd9_code = '2871' then 1
            when icd9_code between '2873'
            and '2875' then 1
            when icd9_code between '64930'
            and '64934' then 1
            when icd9_code = '28984' then 1
        end as coag
        /* Coagulation deficiency */
,
        CASE
            when icd9_code = '2780' then 1
            when icd9_code = '27800' then 1
            when icd9_code = '27801' then 1
            when icd9_code = '27803' then 1
            when icd9_code between '64910'
            and '64914' then 1
            when icd9_code between 'V8530'
            and 'V8539' then 1
            when icd9_code = 'V854' then 1 -- hierarchy used for AHRQ v3.6 and earlier
            when icd9_code between 'V8541'
            and 'V8545' then 1
            when icd9_code = 'V8554' then 1
            when icd9_code = '79391' then 1
        end as obese
        /* Obesity      */
,
        CASE
            when icd9_code between '260'
            and '2639' then 1
            when icd9_code between '78321'
            and '78322' then 1
        end as wghtloss
        /* Weight loss */
,
        CASE
            when icd9_code between '2760'
            and '2769' then 1
        end as lytes
        /* Fluid and electrolyte disorders - note:
         this comorbidity should be dropped when
         used with the AHRQ Patient Safety Indicators*/
,
        CASE
            when icd9_code = '2800' then 1
            when icd9_code between '64820'
            and '64824' then 1
        end as bldloss
        /* Blood loss anemia */
,
        CASE
            when icd9_code between '2801'
            and '2819' then 1
            when icd9_code between '28521'
            and '28529' then 1
            when icd9_code = '2859' then 1
        end as anemdef
        /* Deficiency anemias */
,
        CASE
            when icd9_code between '2910'
            and '2913' then 1
            when icd9_code = '2915' then 1
            when icd9_code = '2918' then 1
            when icd9_code = '29181' then 1
            when icd9_code = '29182' then 1
            when icd9_code = '29189' then 1
            when icd9_code = '2919' then 1
            when icd9_code between '30300'
            and '30393' then 1
            when icd9_code between '30500'
            and '30503' then 1
        end as alcohol
        /* Alcohol abuse */
,
        CASE
            when icd9_code = '2920' then 1
            when icd9_code between '29282'
            and '29289' then 1
            when icd9_code = '2929' then 1
            when icd9_code between '30400'
            and '30493' then 1
            when icd9_code between '30520'
            and '30593' then 1
            when icd9_code between '64830'
            and '64834' then 1
        end as drug
        /* Drug abuse */
,
        CASE
            when icd9_code between '29500'
            and '2989' then 1
            when icd9_code = '29910' then 1
            when icd9_code = '29911' then 1
        end as psych
        /* Psychoses */
,
        CASE
            when icd9_code = '3004' then 1
            when icd9_code = '30112' then 1
            when icd9_code = '3090' then 1
            when icd9_code = '3091' then 1
            when icd9_code = '311' then 1
        end as depress
        /* Depression */
    from
        diagnoses_icd icd
    WHERE
        seq_num = 1
) -- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
,
eligrp as (
    select
        hadm_id,
        max(chf) as chf,
        max(arythm) as arythm,
        max(valve) as valve,
        max(pulmcirc) as pulmcirc,
        max(perivasc) as perivasc,
        max(htn) as htn,
        max(htncx) as htncx,
        max(htnpreg) as htnpreg,
        max(htnwochf) as htnwochf,
        max(htnwchf) as htnwchf,
        max(hrenworf) as hrenworf,
        max(hrenwrf) as hrenwrf,
        max(hhrwohrf) as hhrwohrf,
        max(hhrwchf) as hhrwchf,
        max(hhrwrf) as hhrwrf,
        max(hhrwhrf) as hhrwhrf,
        max(ohtnpreg) as ohtnpreg,
        max(para) as para,
        max(neuro) as neuro,
        max(chrnlung) as chrnlung,
        max(dm) as dm,
        max(dmcx) as dmcx,
        max(hypothy) as hypothy,
        max(renlfail) as renlfail,
        max(liver) as liver,
        max(ulcer) as ulcer,
        max(aids) as aids,
        max(lymph) as lymph,
        max(mets) as mets,
        max(tumor) as tumor,
        max(arth) as arth,
        max(coag) as coag,
        max(obese) as obese,
        max(wghtloss) as wghtloss,
        max(lytes) as lytes,
        max(bldloss) as bldloss,
        max(anemdef) as anemdef,
        max(alcohol) as alcohol,
        max(drug) as drug,
        max(psych) as psych,
        max(depress) as depress
    from
        eliflg
    group by
        hadm_id
) -- DRG FILTER --
,
msdrg as (
    select
        hadm_id
        /**** V29 MS-DRG Formats ****/
        /* Cardiac */
,
        case
            when d.drg_code between 001
            and 002 then 1
            when d.drg_code between 215
            and 238 then 1
            when d.drg_code between 242
            and 252 then 1
            when d.drg_code between 253
            and 254 then 1
            when d.drg_code between 258
            and 262 then 1
            when d.drg_code between 265
            and 267 then 1
            when d.drg_code between 280
            and 293 then 1
            when d.drg_code between 296
            and 298 then 1
            when d.drg_code between 302
            and 303 then 1
            when d.drg_code between 306
            and 313 then 1
            else 0
        end as carddrg
        /* Peripheral vascular */
,
        case
            when d.drg_code between 299
            and 301 then 1
            else 0
        end as peridrg
        /* Renal */
,
        case
            when d.drg_code = 652 then 1
            when d.drg_code between 656
            and 661 then 1
            when d.drg_code between 673
            and 675 then 1
            when d.drg_code between 682
            and 700 then 1
            else 0
        end as renaldrg
        /* Nervous system */
,
        case
            when d.drg_code between 020
            and 042 then 1
            when d.drg_code between 052
            and 103 then 1
            else 0
        end as nervdrg
        /* Cerebrovascular */
,
        case
            when d.drg_code between 020
            and 022 then 1
            when d.drg_code between 034
            and 039 then 1
            when d.drg_code between 064
            and 072 then 1
            else 0
        end as ceredrg
        /* COPD asthma */
,
        case
            when d.drg_code between 190
            and 192 then 1
            when d.drg_code between 202
            and 203 then 1
            else 0
        end as pulmdrg
        /* Diabetes */
,
        case
            when d.drg_code between 637
            and 639 then 1
            else 0
        end as DIABDRG
        /* Thyroid endocrine */
,
        case
            when d.drg_code between 625
            and 627 then 1
            when d.drg_code between 643
            and 645 then 1
            else 0
        end as hypodrg
        /* Kidney transp, renal fail/dialysis */
,
        case
            when d.drg_code = 652 then 1
            when d.drg_code between 682
            and 685 then 1
            else 0
        end as renfdrg
        /* Liver */
,
        case
            when d.drg_code between 420
            and 425 then 1
            when d.drg_code between 432
            and 434 then 1
            when d.drg_code between 441
            and 446 then 1
            else 0
        end as liverdrg
        /* GI hemorrhage or ulcer */
,
        case
            when d.drg_code between 377
            and 384 then 1
            else 0
        end as ulcedrg
        /* Human immunodeficiency virus */
,
        case
            when d.drg_code between 969
            and 970 then 1
            when d.drg_code between 974
            and 977 then 1
            else 0
        end as hivdrg
        /* Leukemia/lymphoma */
,
        case
            when d.drg_code between 820
            and 830 then 1
            when d.drg_code between 834
            and 849 then 1
            else 0
        end as leukdrg
        /* Cancer, lymphoma */
,
        case
            when d.drg_code = 054 then 1
            when d.drg_code = 055 then 1
            when d.drg_code between 146
            and 148 then 1
            when d.drg_code between 180
            and 182 then 1
            when d.drg_code between 374
            and 376 then 1
            when d.drg_code between 435
            and 437 then 1
            when d.drg_code between 542
            and 544 then 1
            when d.drg_code between 582
            and 585 then 1
            when d.drg_code between 597
            and 599 then 1
            when d.drg_code between 656
            and 658 then 1
            when d.drg_code between 686
            and 688 then 1
            when d.drg_code between 715
            and 716 then 1
            when d.drg_code between 722
            and 724 then 1
            when d.drg_code between 736
            and 741 then 1
            when d.drg_code between 754
            and 756 then 1
            when d.drg_code between 826
            and 830 then 1
            when d.drg_code between 843
            and 849 then 1
            else 0
        end as cancdrg
        /* Connective tissue */
,
        case
            when d.drg_code between 545
            and 547 then 1
            else 0
        end as arthdrg
        /* Nutrition/metabolic */
,
        case
            when d.drg_code between 640
            and 641 then 1
            else 0
        end as nutrdrg
        /* Anemia */
,
        case
            when d.drg_code between 808
            and 812 then 1
            else 0
        end as anemdrg
        /* Alcohol drug */
,
        case
            when d.drg_code between 894
            and 897 then 1
            else 0
        end as alcdrg
        /*Coagulation disorders*/
,
        case
            when d.drg_code = 813 then 1
            else 0
        end as coagdrg
        /*Hypertensive Complicated  */
,
        case
            when d.drg_code = 077 then 1
            when d.drg_code = 078 then 1
            when d.drg_code = 304 then 1
            else 0
        end as htncxdrg
        /*Hypertensive Uncomplicated  */
,
        case
            when d.drg_code = 079 then 1
            when d.drg_code = 305 then 1
            else 0
        end as htndrg
        /* Psychoses */
,
        case
            when d.drg_code = 885 then 1
            else 0
        end as psydrg
        /* Obesity */
,
        case
            when d.drg_code between 619
            and 621 then 1
            else 0
        end as obesedrg
        /* Depressive Neuroses */
,
        case
            when d.drg_code = 881 then 1
            else 0
        end as deprsdrg
    from
        (
            select
                hadm_id,
                drg_type,
                cast(drg_code as numeric) as drg_code
            from
                drgcodes
            where
                drg_type = 'MS'
        ) d
),
hcfadrg as (
    select
        hadm_id
        /** V24 DRG Formats  **/
        /* Cardiac */
,
        case
            when d.drg_code between 103
            and 112 then 1
            when d.drg_code between 115
            and 118 then 1
            when d.drg_code between 121
            and 127 then 1
            when d.drg_code = 129 then 1
            when d.drg_code = 132 then 1
            when d.drg_code = 133 then 1
            when d.drg_code between 135
            and 143 then 1
            when d.drg_code between 514
            and 518 then 1
            when d.drg_code between 525
            and 527 then 1
            when d.drg_code between 535
            and 536 then 1
            when d.drg_code between 547
            and 550 then 1
            when d.drg_code between 551
            and 558 then 1
            else 0
        end as carddrg
        /* Peripheral vascular */
,
        case
            when d.drg_code = 130 then 1
            when d.drg_code = 131 then 1
            else 0
        end as peridrg
        /* Renal */
,
        case
            when d.drg_code between 302
            and 305 then 1
            when d.drg_code between 315
            and 333 then 1
            else 0
        end as renaldrg
        /* Nervous system */
,
        case
            when d.drg_code between 1
            and 35 then 1
            when d.drg_code = 524 then 1
            when d.drg_code between 528
            and 534 then 1
            when d.drg_code = 543 then 1
            when d.drg_code between 559
            and 564 then 1
            when d.drg_code = 577 then 1
            else 0
        end as nervdrg
        /* Cerebrovascular */
,
        case
            when d.drg_code = 5 then 1
            when d.drg_code between 14
            and 17 then 1
            when d.drg_code = 524 then 1
            when d.drg_code = 528 then 1
            when d.drg_code between 533
            and 534 then 1
            when d.drg_code = 577 then 1
            else 0
        end as ceredrg
        /* COPD asthma */
,
        case
            when d.drg_code = 88 then 1
            when d.drg_code between 96
            and 98 then 1
            else 0
        end as pulmdrg
        /* Diabetes */
,
        case
            when d.drg_code = 294 then 1
            when d.drg_code = 295 then 1
            else 0
        end as diabdrg
        /* Thyroid endocrine */
,
        case
            when d.drg_code = 290 then 1
            when d.drg_code = 300 then 1
            when d.drg_code = 301 then 1
            else 0
        end as hypodrg
        /* Kidney transp, renal fail/dialysis */
,
        case
            when d.drg_code = 302 then 1
            when d.drg_code = 316 then 1
            when d.drg_code = 317 then 1
            else 0
        end as renfdrg
        /* Liver */
,
        case
            when d.drg_code between 199
            and 202 then 1
            when d.drg_code between 205
            and 208 then 1
            else 0
        end as liverdrg
        /* GI hemorrhage or ulcer */
,
        case
            when d.drg_code between 174
            and 178 then 1
            else 0
        end as ulcedrg
        /* Human immunodeficiency virus */
,
        case
            when d.drg_code = 488 then 1
            when d.drg_code = 489 then 1
            when d.drg_code = 490 then 1
            else 0
        end as hivdrg
        /* Leukemia/lymphoma */
,
        case
            when d.drg_code between 400
            and 414 then 1
            when d.drg_code = 473 then 1
            when d.drg_code = 492 then 1
            when d.drg_code between 539
            and 540 then 1
            else 0
        end as leukdrg
        /* Cancer, lymphoma */
,
        case
            when d.drg_code = 10 then 1
            when d.drg_code = 11 then 1
            when d.drg_code = 64 then 1
            when d.drg_code = 82 then 1
            when d.drg_code = 172 then 1
            when d.drg_code = 173 then 1
            when d.drg_code = 199 then 1
            when d.drg_code = 203 then 1
            when d.drg_code = 239 then 1
            when d.drg_code between 257
            and 260 then 1
            when d.drg_code = 274 then 1
            when d.drg_code = 275 then 1
            when d.drg_code = 303 then 1
            when d.drg_code = 318 then 1
            when d.drg_code = 319 then 1
            when d.drg_code = 338 then 1
            when d.drg_code = 344 then 1
            when d.drg_code = 346 then 1
            when d.drg_code = 347 then 1
            when d.drg_code = 354 then 1
            when d.drg_code = 355 then 1
            when d.drg_code = 357 then 1
            when d.drg_code = 363 then 1
            when d.drg_code = 366 then 1
            when d.drg_code = 367 then 1
            when d.drg_code between 406
            and 414 then 1
            else 0
        end as cancdrg
        /* Connective tissue */
,
        case
            when d.drg_code = 240 then 1
            when d.drg_code = 241 then 1
            else 0
        end as arthdrg
        /* Nutrition/metabolic */
,
        case
            when d.drg_code between 296
            and 298 then 1
            else 0
        end as nutrdrg
        /* Anemia */
,
        case
            when d.drg_code = 395 then 1
            when d.drg_code = 396 then 1
            when d.drg_code = 574 then 1
            else 0
        end as anemdrg
        /* Alcohol drug */
,
        case
            when d.drg_code between 433
            and 437 then 1
            when d.drg_code between 521
            and 523 then 1
            else 0
        end as alcdrg
        /* Coagulation disorders */
,
        case
            when d.drg_code = 397 then 1
            else 0
        end as coagdrg
        /* Hypertensive Complicated */
,
        case
            when d.drg_code = 22 then 1
            when d.drg_code = 134 then 1
            else 0
        end as htncxdrg
        /* Hypertensive Uncomplicated */
,
        case
            when d.drg_code = 134 then 1
            else 0
        end as htndrg
        /* Psychoses */
,
        case
            when d.drg_code = 430 then 1
            else 0
        end as psydrg
        /* Obesity */
,
        case
            when d.drg_code = 288 then 1
            else 0
        end as obesedrg
        /* Depressive Neuroses */
,
        case
            when d.drg_code = 426 then 1
            else 0
        end as deprsdrg
    from
        (
            select
                hadm_id,
                drg_type,
                cast(drg_code as numeric) as drg_code
            from
                drgcodes
            where
                drg_type = 'HCFA'
        ) d
) -- merge DRG groups together
,
drggrp as (
    select
        hadm_id,
        max(carddrg) as carddrg,
        max(peridrg) as peridrg,
        max(renaldrg) as renaldrg,
        max(nervdrg) as nervdrg,
        max(ceredrg) as ceredrg,
        max(pulmdrg) as pulmdrg,
        max(diabdrg) as diabdrg,
        max(hypodrg) as hypodrg,
        max(renfdrg) as renfdrg,
        max(liverdrg) as liverdrg,
        max(ulcedrg) as ulcedrg,
        max(hivdrg) as hivdrg,
        max(leukdrg) as leukdrg,
        max(cancdrg) as cancdrg,
        max(arthdrg) as arthdrg,
        max(nutrdrg) as nutrdrg,
        max(anemdrg) as anemdrg,
        max(alcdrg) as alcdrg,
        max(coagdrg) as coagdrg,
        max(htncxdrg) as htncxdrg,
        max(htndrg) as htndrg,
        max(psydrg) as psydrg,
        max(obesedrg) as obesedrg,
        max(deprsdrg) as deprsdrg
    from
        (
            select
                d1.*
            from
                msdrg d1
            UNION
            DISTINCT
            select
                d1.*
            from
                hcfadrg d1
        ) d
    group by
        d.hadm_id
) -- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select
    adm.subject_id,
    adm.hadm_id,
    case
        when carddrg = 1 then 0 -- DRG filter
        when chf = 1 then 1
        when htnwchf = 1 then 1
        when hhrwchf = 1 then 1
        when hhrwhrf = 1 then 1
        else 0
    end as congestive_heart_failure,
    case
        when carddrg = 1 then 0 -- DRG filter
        when arythm = 1 then 1
        else 0
    end as cardiac_arrhythmias,
    case
        when carddrg = 1 then 0
        when valve = 1 then 1
        else 0
    end as valvular_disease,
    case
        when carddrg = 1
        or pulmdrg = 1 then 0
        when pulmcirc = 1 then 1
        else 0
    end as pulmonary_circulation,
    case
        when peridrg = 1 then 0
        when perivasc = 1 then 1
        else 0
    end as peripheral_vascular -- we combine 'htn' and 'htncx' into 'HYPERTENSION'
    -- note 'htn' (hypertension) is only 1 if 'htncx' (complicated hypertension) is 0
    -- also if htncxdrg = 1, then htndrg = 1
    -- In the original Sas code, it appears that:
    --  HTN can be 1
    --  HTNCX is set to 0 by DRGs
    --  but HTN_C is still 1, because HTN is 1
    -- so we have to do this complex addition.
,
    case
        when (
            -- first hypertension
            case
                when htndrg = 0 then 0
                when htn = 1 then 1
                else 0
            end
        ) + (
            -- next complicated hypertension
            case
                when htncx = 1
                and htncxdrg = 1 then 0
                when htnpreg = 1
                and htncxdrg = 1 then 0
                when htnwochf = 1
                and (
                    htncxdrg = 1
                    OR carddrg = 1
                ) then 0
                when htnwchf = 1
                and htncxdrg = 1 then 0
                when htnwchf = 1
                and carddrg = 1 then 0
                when hrenworf = 1
                and (
                    htncxdrg = 1
                    or renaldrg = 1
                ) then 0
                when hrenwrf = 1
                and htncxdrg = 1 then 0
                when hrenwrf = 1
                and renaldrg = 1 then 0
                when hhrwohrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwchf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when hhrwhrf = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when ohtnpreg = 1
                and (
                    htncxdrg = 1
                    or carddrg = 1
                    or renaldrg = 1
                ) then 0
                when htncx = 1 then 1
                when htnpreg = 1 then 1
                when htnwochf = 1 then 1
                when htnwchf = 1 then 1
                when hrenworf = 1 then 1
                when hrenwrf = 1 then 1
                when hhrwohrf = 1 then 1
                when hhrwchf = 1 then 1
                when hhrwrf = 1 then 1
                when hhrwhrf = 1 then 1
                when ohtnpreg = 1 then 1
                else 0
            end
        ) > 0 then 1
        else 0
    end as hypertension,
    case
        when ceredrg = 1 then 0
        when para = 1 then 1
        else 0
    end as paralysis,
    case
        when nervdrg = 1 then 0
        when neuro = 1 then 1
        else 0
    end as other_neurological,
    case
        when pulmdrg = 1 then 0
        when chrnlung = 1 then 1
        else 0
    end as chronic_pulmonary,
    case
        -- only the more severe comorbidity (complicated diabetes) is kept
        when diabdrg = 1 then 0
        when dmcx = 1 then 0
        when dm = 1 then 1
        else 0
    end as diabetes_uncomplicated,
    case
        when diabdrg = 1 then 0
        when dmcx = 1 then 1
        else 0
    end as diabetes_complicated,
    case
        when hypodrg = 1 then 0
        when hypothy = 1 then 1
        else 0
    end as hypothyroidism,
    case
        when renaldrg = 1 then 0
        when renlfail = 1 then 1
        when hrenwrf = 1 then 1
        when hhrwrf = 1 then 1
        when hhrwhrf = 1 then 1
        else 0
    end as renal_failure,
    case
        when liverdrg = 1 then 0
        when liver = 1 then 1
        else 0
    end as liver_disease,
    case
        when ulcedrg = 1 then 0
        when ulcer = 1 then 1
        else 0
    end as peptic_ulcer,
    case
        when hivdrg = 1 then 0
        when aids = 1 then 1
        else 0
    end as aids,
    case
        when leukdrg = 1 then 0
        when lymph = 1 then 1
        else 0
    end as lymphoma,
    case
        when cancdrg = 1 then 0
        when mets = 1 then 1
        else 0
    end as metastatic_cancer,
    case
        when cancdrg = 1 then 0 -- only the more severe comorbidity (metastatic cancer) is kept
        when mets = 1 then 0
        when tumor = 1 then 1
        else 0
    end as solid_tumor,
    case
        when arthdrg = 1 then 0
        when arth = 1 then 1
        else 0
    end as rheumatoid_arthritis,
    case
        when coagdrg = 1 then 0
        when coag = 1 then 1
        else 0
    end as coagulopathy,
    case
        when nutrdrg = 1
        OR obesedrg = 1 then 0
        when obese = 1 then 1
        else 0
    end as obesity,
    case
        when nutrdrg = 1 then 0
        when wghtloss = 1 then 1
        else 0
    end as weight_loss,
    case
        when nutrdrg = 1 then 0
        when lytes = 1 then 1
        else 0
    end as fluid_electrolyte,
    case
        when anemdrg = 1 then 0
        when bldloss = 1 then 1
        else 0
    end as blood_loss_anemia,
    case
        when anemdrg = 1 then 0
        when anemdef = 1 then 1
        else 0
    end as deficiency_anemias,
    case
        when alcdrg = 1 then 0
        when alcohol = 1 then 1
        else 0
    end as alcohol_abuse,
    case
        when alcdrg = 1 then 0
        when drug = 1 then 1
        else 0
    end as drug_abuse,
    case
        when psydrg = 1 then 0
        when psych = 1 then 1
        else 0
    end as psychoses,
    case
        when deprsdrg = 1 then 0
        when depress = 1 then 1
        else 0
    end as depression
FROM
    admissions adm
    left join eligrp eli on adm.hadm_id = eli.hadm_id
    left join drggrp d on adm.hadm_id = d.hadm_id
order by
    adm.hadm_id
  );
17:37:39.935393 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 1.49 seconds
17:37:39.948291 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:39.948514 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
alter table "postgres"."public"."elixhauser_ahrq_v37" rename to "elixhauser_ahrq_v37__dbt_backup"
17:37:39.949253 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:39.952667 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:39.952855 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
alter table "postgres"."public"."elixhauser_ahrq_v37__dbt_tmp" rename to "elixhauser_ahrq_v37"
17:37:39.953530 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:39.963857 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: COMMIT
17:37:39.964146 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:39.964375 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: COMMIT
17:37:39.965538 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:39.974256 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37"
17:37:39.974755 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37"} */
drop table if exists "postgres"."public"."elixhauser_ahrq_v37__dbt_backup" cascade
17:37:39.977587 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:39.980696 [debug] [Thread-1  ]: finished collecting timing info
17:37:39.980924 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37: Close
17:37:39.981758 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e22efbe0>]}
17:37:39.982251 [info ] [Thread-1  ]: 1 of 5 OK created table model public.elixhauser_ahrq_v37 ....................... [[32mSELECT 58976[0m in 1.58s]
17:37:39.982895 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_ahrq_v37
17:37:39.983258 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_ahrq_v37_no_drg
17:37:39.984075 [info ] [Thread-1  ]: 2 of 5 START table model public.elixhauser_ahrq_v37_no_drg ..................... [RUN]
17:37:39.985229 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:39.985729 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_ahrq_v37_no_drg
17:37:39.986006 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_ahrq_v37_no_drg
17:37:39.992057 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:39.992825 [debug] [Thread-1  ]: finished collecting timing info
17:37:39.993192 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_ahrq_v37_no_drg
17:37:40.000948 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.001793 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.002028 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: BEGIN
17:37:40.002139 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:40.007586 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:40.007943 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.008249 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */


  create  table "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_tmp"
  as (
    -- This code uses the latest version of Elixhauser provided by AHRQ
-- However, it does *not* filter based on diagnosis related groups (DRGs)
-- As such, "comorbidities" identified are more likely to be associated with the primary reason for their hospital stay

-- The code:
--  removes "primary" ICD9_CODE (seq_num != 1)
--  uses AHRQ published rules to define comorbidities
 

with
eliflg as
(
select hadm_id, seq_num, icd9_code
-- note that these codes will seem incomplete at first
-- for example, CHF is missing a lot of codes referenced in the literature (402.11, 402.91, etc)
-- these codes are captured by hypertension flags instead
-- later there are some complicated rules which confirm/reject those codes as chf
, CASE
  when icd9_code = '39891' then 1
  when icd9_code between '4280' and '4289' then 1
		end as chf       /* Congestive heart failure */

-- cardiac arrhythmias is removed in up to date versions
, case
    when icd9_code = '42610' then 1
    when icd9_code = '42611' then 1
    when icd9_code = '42613' then 1
    when icd9_code between '4262' and '42653' then 1
    when icd9_code between '4266' and '42689' then 1
    when icd9_code = '4270' then 1
    when icd9_code = '4272' then 1
    when icd9_code = '42731' then 1
    when icd9_code = '42760' then 1
    when icd9_code = '4279' then 1
    when icd9_code = '7850' then 1
    when icd9_code between 'V450' and 'V4509' then 1
    when icd9_code between 'V533' and 'V5339' then 1
  end as arythm /* Cardiac arrhythmias */

, CASE
  when icd9_code between '09320' and '09324' then 1
  when icd9_code between '3940' and '3971' then 1
  when icd9_code = '3979' then 1
  when icd9_code between '4240' and '42499' then 1
  when icd9_code between '7463' and '7466' then 1
  when icd9_code = 'V422' then 1
  when icd9_code = 'V433' then 1
		end as valve     /* Valvular disease */

, CASE
  when icd9_code between '41511' and '41519' then 1
  when icd9_code between '4160' and '4169' then 1
  when icd9_code = '4179' then 1
		end as pulmcirc  /* Pulmonary circulation disorder */

, CASE
  when icd9_code between '4400' and '4409' then 1
  when icd9_code between '44100' and '4419' then 1
  when icd9_code between '4420' and '4429' then 1
  when icd9_code between '4431' and '4439' then 1
  when icd9_code between '44421' and '44422' then 1
  when icd9_code = '4471' then 1
  when icd9_code = '449' then 1
  when icd9_code = '5571' then 1
  when icd9_code = '5579' then 1
  when icd9_code = 'V434' then 1
		end as perivasc  /* Peripheral vascular disorder */

, CASE
  when icd9_code = '4011' then 1
  when icd9_code = '4019' then 1
  when icd9_code between '64200' and '64204' then 1
		end as htn       /* Hypertension, uncomplicated */

, CASE
  when icd9_code = '4010' then 1
  when icd9_code = '4372' then 1
		end as htncx     /* Hypertension, complicated */


      /******************************************************************/
      /* The following are special, temporary formats used in the       */
      /* creation of the hypertension complicated comorbidity when      */
      /* overlapping with congestive heart failure or renal failure     */
      /* occurs. These temporary formats are referenced in the program  */
      /* called comoanaly2009.txt.                                      */
      /******************************************************************/
, CASE
  when icd9_code between '64220' and '64224' then 1
		end as htnpreg   /* Pre-existing hypertension complicating pregnancy */

, CASE
  when icd9_code = '40200' then 1
  when icd9_code = '40210' then 1
  when icd9_code = '40290' then 1
  when icd9_code = '40509' then 1
  when icd9_code = '40519' then 1
  when icd9_code = '40599'         then 1
		end as htnwochf  /* Hypertensive heart disease without heart failure */

, CASE
  when icd9_code = '40201' then 1
  when icd9_code = '40211' then 1
  when icd9_code = '40291'         then 1
		end as htnwchf   /* Hypertensive heart disease with heart failure */

, CASE
  when icd9_code = '40300' then 1
  when icd9_code = '40310' then 1
  when icd9_code = '40390' then 1
  when icd9_code = '40501' then 1
  when icd9_code = '40511' then 1
  when icd9_code = '40591' then 1
  when icd9_code between '64210' and '64214' then 1
		end as hrenworf  /* Hypertensive renal disease without renal failure */

, CASE
  when icd9_code = '40301' then 1
  when icd9_code = '40311' then 1
  when icd9_code = '40391'         then 1
		end as hrenwrf   /* Hypertensive renal disease with renal failure */

, CASE
  when icd9_code = '40400' then 1
  when icd9_code = '40410' then 1
  when icd9_code = '40490'         then 1
		end as hhrwohrf  /* Hypertensive heart and renal disease without heart or renal failure */

, CASE
  when icd9_code = '40401' then 1
  when icd9_code = '40411' then 1
  when icd9_code = '40491'         then 1
		end as hhrwchf   /* Hypertensive heart and renal disease with heart failure */

, CASE
  when icd9_code = '40402' then 1
  when icd9_code = '40412' then 1
  when icd9_code = '40492'         then 1
		end as hhrwrf    /* Hypertensive heart and renal disease with renal failure */

, CASE
  when icd9_code = '40403' then 1
  when icd9_code = '40413' then 1
  when icd9_code = '40493'         then 1
		end as hhrwhrf   /* Hypertensive heart and renal disease with heart and renal failure */

, CASE
  when icd9_code between '64270' and '64274' then 1
  when icd9_code between '64290' and '64294' then 1
		end as ohtnpreg  /* Other hypertension in pregnancy */

      /******************** End Temporary Formats ***********************/

, CASE
  when icd9_code between '3420' and '3449' then 1
  when icd9_code between '43820' and '43853' then 1
  when icd9_code = '78072'         then 1
		end as para      /* Paralysis */

, CASE
  when icd9_code between '3300' and '3319' then 1
  when icd9_code = '3320' then 1
  when icd9_code = '3334' then 1
  when icd9_code = '3335' then 1
  when icd9_code = '3337' then 1
  when icd9_code in ('33371','33372','33379','33385','33394') then 1
  when icd9_code between '3340' and '3359' then 1
  when icd9_code = '3380' then 1
  when icd9_code = '340' then 1
  when icd9_code between '3411' and '3419' then 1
  when icd9_code between '34500' and '34511' then 1
  when icd9_code between '3452' and '3453' then 1
  when icd9_code between '34540' and '34591' then 1
  when icd9_code between '34700' and '34701' then 1
  when icd9_code between '34710' and '34711' then 1
  when icd9_code = '3483' then 1 -- discontinued icd-9
  when icd9_code between '64940' and '64944' then 1
  when icd9_code = '7687' then 1
  when icd9_code between '76870' and '76873' then 1
  when icd9_code = '7803' then 1
  when icd9_code = '78031' then 1
  when icd9_code = '78032' then 1
  when icd9_code = '78033' then 1
  when icd9_code = '78039' then 1
  when icd9_code = '78097' then 1
  when icd9_code = '7843'         then 1
		end as neuro     /* Other neurological */

, CASE
  when icd9_code between '490' and '4928' then 1
  when icd9_code between '49300' and '49392' then 1
  when icd9_code between '494' and '4941' then 1
  when icd9_code between '4950' and '505' then 1
  when icd9_code = '5064'         then 1
		end as chrnlung  /* Chronic pulmonary disease */

, CASE
  when icd9_code between '25000' and '25033' then 1
  when icd9_code between '64800' and '64804' then 1
  when icd9_code between '24900' and '24931' then 1
		end as dm        /* Diabetes w/o chronic complications*/

, CASE
  when icd9_code between '25040' and '25093' then 1
  when icd9_code = '7751' then 1
  when icd9_code between '24940' and '24991' then 1
		end as dmcx      /* Diabetes w/ chronic complications */

, CASE
  when icd9_code between '243' and '2442' then 1
  when icd9_code = '2448' then 1
  when icd9_code = '2449'         then 1
		end as hypothy   /* Hypothyroidism */

, CASE
  when icd9_code = '585' then 1 -- discontinued code
  when icd9_code = '5853' then 1
  when icd9_code = '5854' then 1
  when icd9_code = '5855' then 1
  when icd9_code = '5856' then 1
  when icd9_code = '5859' then 1
  when icd9_code = '586' then 1
  when icd9_code = 'V420' then 1
  when icd9_code = 'V451' then 1
  when icd9_code between 'V560' and 'V5632' then 1
  when icd9_code = 'V568' then 1
  when icd9_code between 'V4511' and 'V4512' then 1
		end as renlfail  /* Renal failure */

, CASE
  when icd9_code = '07022' then 1
  when icd9_code = '07023' then 1
  when icd9_code = '07032' then 1
  when icd9_code = '07033' then 1
  when icd9_code = '07044' then 1
  when icd9_code = '07054' then 1
  when icd9_code = '4560' then 1
  when icd9_code = '4561' then 1
  when icd9_code = '45620' then 1
  when icd9_code = '45621' then 1
  when icd9_code = '5710' then 1
  when icd9_code = '5712' then 1
  when icd9_code = '5713' then 1
  when icd9_code between '57140' and '57149' then 1
  when icd9_code = '5715' then 1
  when icd9_code = '5716' then 1
  when icd9_code = '5718' then 1
  when icd9_code = '5719' then 1
  when icd9_code = '5723' then 1
  when icd9_code = '5728' then 1
  when icd9_code = '5735' then 1
  when icd9_code = 'V427'         then 1
		end as liver     /* Liver disease */

, CASE
  when icd9_code = '53141' then 1
  when icd9_code = '53151' then 1
  when icd9_code = '53161' then 1
  when icd9_code = '53170' then 1
  when icd9_code = '53171' then 1
  when icd9_code = '53191' then 1
  when icd9_code = '53241' then 1
  when icd9_code = '53251' then 1
  when icd9_code = '53261' then 1
  when icd9_code = '53270' then 1
  when icd9_code = '53271' then 1
  when icd9_code = '53291' then 1
  when icd9_code = '53341' then 1
  when icd9_code = '53351' then 1
  when icd9_code = '53361' then 1
  when icd9_code = '53370' then 1
  when icd9_code = '53371' then 1
  when icd9_code = '53391' then 1
  when icd9_code = '53441' then 1
  when icd9_code = '53451' then 1
  when icd9_code = '53461' then 1
  when icd9_code = '53470' then 1
  when icd9_code = '53471' then 1
  when icd9_code = '53491'         then 1
		end as ulcer     /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */

, CASE
  when icd9_code between '042' and '0449' then 1
		end as aids      /* HIV and AIDS */

, CASE
  when icd9_code between '20000' and '20238' then 1
  when icd9_code between '20250' and '20301' then 1
  when icd9_code = '2386' then 1
  when icd9_code = '2733' then 1
  when icd9_code between '20302' and '20382' then 1
		end as lymph     /* Lymphoma */

, CASE
  when icd9_code between '1960' and '1991' then 1
  when icd9_code between '20970' and '20975' then 1
  when icd9_code = '20979' then 1
  when icd9_code = '78951'         then 1
		end as mets      /* Metastatic cancer */

, CASE
  when icd9_code between '1400' and '1729' then 1
  when icd9_code between '1740' and '1759' then 1
  when icd9_code between '179' and '1958' then 1
  when icd9_code between '20900' and '20924' then 1
  when icd9_code between '20925' and '2093' then 1
  when icd9_code between '20930' and '20936' then 1
  when icd9_code between '25801' and '25803' then 1
		end as tumor     /* Solid tumor without metastasis */

, CASE
  when icd9_code = '7010' then 1
  when icd9_code between '7100' and '7109' then 1
  when icd9_code between '7140' and '7149' then 1
  when icd9_code between '7200' and '7209' then 1
  when icd9_code = '725' then 1
		end as arth              /* Rheumatoid arthritis/collagen vascular diseases */

, CASE
  when icd9_code between '2860' and '2869' then 1
  when icd9_code = '2871' then 1
  when icd9_code between '2873' and '2875' then 1
  when icd9_code between '64930' and '64934' then 1
  when icd9_code = '28984'         then 1
		end as coag      /* Coagulation deficiency */

, CASE
  when icd9_code = '2780' then 1
  when icd9_code = '27800' then 1
  when icd9_code = '27801' then 1
  when icd9_code = '27803' then 1
  when icd9_code between '64910' and '64914' then 1
  when icd9_code between 'V8530' and 'V8539' then 1
  when icd9_code = 'V854' then 1 -- hierarchy used for AHRQ v3.6 and earlier
  when icd9_code between 'V8541' and 'V8545' then 1
  when icd9_code = 'V8554' then 1
  when icd9_code = '79391'         then 1
		end as obese     /* Obesity      */

, CASE
  when icd9_code between '260' and '2639' then 1
  when icd9_code between '78321' and '78322' then 1
		end as wghtloss  /* Weight loss */

, CASE
  when icd9_code between '2760' and '2769' then 1
		end as lytes     /* Fluid and electrolyte disorders - note:
                                      this comorbidity should be dropped when
                                      used with the AHRQ Patient Safety Indicators*/
, CASE
  when icd9_code = '2800' then 1
  when icd9_code between '64820' and '64824' then 1
		end as bldloss   /* Blood loss anemia */

, CASE
  when icd9_code between '2801' and '2819' then 1
  when icd9_code between '28521' and '28529' then 1
  when icd9_code = '2859'         then 1
		end as anemdef  /* Deficiency anemias */

, CASE
  when icd9_code between '2910' and '2913' then 1
  when icd9_code = '2915' then 1
  when icd9_code = '2918' then 1
  when icd9_code = '29181' then 1
  when icd9_code = '29182' then 1
  when icd9_code = '29189' then 1
  when icd9_code = '2919' then 1
  when icd9_code between '30300' and '30393' then 1
  when icd9_code between '30500' and '30503' then 1
		end as alcohol   /* Alcohol abuse */

, CASE
  when icd9_code = '2920' then 1
  when icd9_code between '29282' and '29289' then 1
  when icd9_code = '2929' then 1
  when icd9_code between '30400' and '30493' then 1
  when icd9_code between '30520' and '30593' then 1
  when icd9_code between '64830' and '64834' then 1
		end as drug      /* Drug abuse */

, CASE
  when icd9_code between '29500' and '2989' then 1
  when icd9_code = '29910' then 1
  when icd9_code = '29911'         then 1
		end as psych    /* Psychoses */

, CASE
  when icd9_code = '3004' then 1
  when icd9_code = '30112' then 1
  when icd9_code = '3090' then 1
  when icd9_code = '3091' then 1
  when icd9_code = '311'         then 1
		end as depress  /* Depression */
from diagnoses_icd icd
WHERE seq_num = 1
)
-- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
, eligrp as
(
  select hadm_id
  , max(chf) as chf
  , max(arythm) as arythm
  , max(valve) as valve
  , max(pulmcirc) as pulmcirc
  , max(perivasc) as perivasc
  , max(htn) as htn
  , max(htncx) as htncx
  , max(htnpreg) as htnpreg
  , max(htnwochf) as htnwochf
  , max(htnwchf) as htnwchf
  , max(hrenworf) as hrenworf
  , max(hrenwrf) as hrenwrf
  , max(hhrwohrf) as hhrwohrf
  , max(hhrwchf) as hhrwchf
  , max(hhrwrf) as hhrwrf
  , max(hhrwhrf) as hhrwhrf
  , max(ohtnpreg) as ohtnpreg
  , max(para) as para
  , max(neuro) as neuro
  , max(chrnlung) as chrnlung
  , max(dm) as dm
  , max(dmcx) as dmcx
  , max(hypothy) as hypothy
  , max(renlfail) as renlfail
  , max(liver) as liver
  , max(ulcer) as ulcer
  , max(aids) as aids
  , max(lymph) as lymph
  , max(mets) as mets
  , max(tumor) as tumor
  , max(arth) as arth
  , max(coag) as coag
  , max(obese) as obese
  , max(wghtloss) as wghtloss
  , max(lytes) as lytes
  , max(bldloss) as bldloss
  , max(anemdef) as anemdef
  , max(alcohol) as alcohol
  , max(drug) as drug
  , max(psych) as psych
  , max(depress) as depress
from eliflg
group by hadm_id
)
-- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select adm.subject_id, adm.hadm_id
, case
    when chf     = 1 then 1
    when htnwchf = 1 then 1
    when hhrwchf = 1 then 1
    when hhrwhrf = 1 then 1
  else 0 end as congestive_heart_failure
, case
    when arythm = 1 then 1
  else 0 end as cardiac_arrhythmias
, case when    valve = 1 then 1 else 0 end as valvular_disease
, case when pulmcirc = 1 then 1 else 0 end as pulmonary_circulation
, case when perivasc = 1 then 1 else 0 end as peripheral_vascular

-- we combine "htn" and "htncx" into "HYPERTENSION"
-- note "htn" (hypertension) is only 1 if "htncx" (complicated hypertension) is 0
-- this matters if you filter on DRG but for this query we can just merge them immediately
, case
    when htn = 1 then 1
    when htncx = 1 then 1
    when htnpreg = 1 then 1
    when htnwochf = 1 then 1
    when htnwchf = 1 then 1
    when hrenworf = 1 then 1
    when hrenwrf = 1 then 1
    when hhrwohrf = 1 then 1
    when hhrwchf = 1 then 1
    when hhrwrf = 1 then 1
    when hhrwhrf = 1 then 1
    when ohtnpreg = 1 then 1
  else 0 end as hypertension

, case when para      = 1 then 1 else 0 end as paralysis
, case when neuro     = 1 then 1 else 0 end as other_neurological
, case when chrnlung  = 1 then 1 else 0 end as chronic_pulmonary
, case
    -- only the more severe comorbidity (complicated diabetes) is kept
    when dmcx = 1 then 0
    when dm = 1 then 1
  else 0 end as diabetes_uncomplicated
, case when dmcx    = 1 then 1 else 0 end as diabetes_complicated
, case when hypothy = 1 then 1 else 0 end as hypothyroidism
, case
    when renlfail = 1 then 1
    when hrenwrf  = 1 then 1
    when hhrwrf   = 1 then 1
    when hhrwhrf  = 1 then 1
  else 0 end as renal_failure

, case when liver = 1 then 1 else 0 end as liver_disease
, case when ulcer = 1 then 1 else 0 end as peptic_ulcer
, case when aids = 1 then 1 else 0 end as aids
, case when lymph = 1 then 1 else 0 end as lymphoma
, case when mets = 1 then 1 else 0 end as metastatic_cancer
, case
    -- only the more severe comorbidity (metastatic cancer) is kept
    when mets = 1 then 0
    when tumor = 1 then 1
  else 0 end as solid_tumor
, case when arth = 1 then 1 else 0 end as rheumatoid_arthritis
, case when coag = 1 then 1 else 0 end as coagulopathy
, case when obese = 1 then 1 else 0 end as obesity
, case when wghtloss = 1 then 1 else 0 end as weight_loss
, case when lytes = 1 then 1 else 0 end as fluid_electrolyte
, case when bldloss = 1 then 1 else 0 end as blood_loss_anemia
, case when anemdef = 1 then 1 else 0 end as deficiency_anemias
, case when alcohol = 1 then 1 else 0 end as alcohol_abuse
, case when drug = 1 then 1 else 0 end as drug_abuse
, case when psych = 1 then 1 else 0 end as psychoses
, case when depress = 1 then 1 else 0 end as depression

FROM admissions adm
left join eligrp eli
  on adm.hadm_id = eli.hadm_id
order by adm.hadm_id
  );
17:37:40.486305 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.48 seconds
17:37:40.491950 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.492145 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
alter table "postgres"."public"."elixhauser_ahrq_v37_no_drg" rename to "elixhauser_ahrq_v37_no_drg__dbt_backup"
17:37:40.492908 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:40.497387 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.497580 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
alter table "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_tmp" rename to "elixhauser_ahrq_v37_no_drg"
17:37:40.498292 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:40.501307 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: COMMIT
17:37:40.501510 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.501695 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: COMMIT
17:37:40.508325 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:37:40.511028 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_ahrq_v37_no_drg"
17:37:40.511234 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_ahrq_v37_no_drg"} */
drop table if exists "postgres"."public"."elixhauser_ahrq_v37_no_drg__dbt_backup" cascade
17:37:40.513367 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:40.516032 [debug] [Thread-1  ]: finished collecting timing info
17:37:40.516260 [debug] [Thread-1  ]: On model.mimic.elixhauser_ahrq_v37_no_drg: Close
17:37:40.517036 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e230b940>]}
17:37:40.517489 [info ] [Thread-1  ]: 2 of 5 OK created table model public.elixhauser_ahrq_v37_no_drg ................ [[32mSELECT 58976[0m in 0.53s]
17:37:40.518021 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_ahrq_v37_no_drg
17:37:40.518309 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_quan
17:37:40.518978 [info ] [Thread-1  ]: 3 of 5 START table model public.elixhauser_quan ................................ [RUN]
17:37:40.519781 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_quan"
17:37:40.520026 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_quan
17:37:40.520285 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_quan
17:37:40.524735 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_quan"
17:37:40.525290 [debug] [Thread-1  ]: finished collecting timing info
17:37:40.525552 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_quan
17:37:40.536071 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_quan"
17:37:40.537515 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:40.537902 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: BEGIN
17:37:40.538122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:40.544719 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:40.545140 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:40.545282 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */


  create  table "postgres"."public"."elixhauser_quan__dbt_tmp"
  as (
    -- This code calculates the Elixhauser comorbidities as defined in Quan et. al 2009:
-- Quan, Hude, et al. "Coding algorithms for defining comorbidities in
-- ICD-9-CM and ICD-10 administrative data." Medical care (2005): 1130-1139.
--  https://www.ncbi.nlm.nih.gov/pubmed/16224307
-- Quan defined an "Enhanced ICD-9" coding scheme for deriving Elixhauser
-- comorbidities from ICD-9 billing codes. This script implements that calculation.
-- The logic of the code is roughly that, if the comorbidity lists a length 3
-- ICD-9 code (e.g. 585), then we only require a match on the first 3 characters.
-- This code derives each comorbidity as follows:
--  1) ICD9_CODE is directly compared to 5 character codes
--  2) The first 4 characters of ICD9_CODE are compared to 4 character codes
--  3) The first 3 characters of ICD9_CODE are compared to 3 character codes

 

with eliflg as (
    select
        hadm_id,
        seq_num,
        icd9_code,
        CASE
            when icd9_code in (
                '39891',
                '40201',
                '40211',
                '40291',
                '40401',
                '40403',
                '40411',
                '40413',
                '40491',
                '40493'
            ) then 1
            when SUBSTR(icd9_code, 1, 4) in ('4254', '4255', '4257', '4258', '4259') then 1
            when SUBSTR(icd9_code, 1, 3) in ('428') then 1
            else 0
        end as chf
        /* Congestive heart failure */
,
        CASE
            when icd9_code in ('42613', '42610', '42612', '99601', '99604') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '4260',
                '4267',
                '4269',
                '4270',
                '4271',
                '4272',
                '4273',
                '4274',
                '4276',
                '4278',
                '4279',
                '7850',
                'V450',
                'V533'
            ) then 1
            else 0
        end as arrhy,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('0932', '7463', '7464', '7465', '7466', 'V422', 'V433') then 1
            when SUBSTR(icd9_code, 1, 3) in ('394', '395', '396', '397', '424') then 1
            else 0
        end as valve
        /* Valvular disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('4150', '4151', '4170', '4178', '4179') then 1
            when SUBSTR(icd9_code, 1, 3) in ('416') then 1
            else 0
        end as pulmcirc
        /* Pulmonary circulation disorder */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '0930',
                '4373',
                '4431',
                '4432',
                '4438',
                '4439',
                '4471',
                '5571',
                '5579',
                'V434'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('440', '441') then 1
            else 0
        end as perivasc
        /* Peripheral vascular disorder */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('401') then 1
            else 0
        end as htn
        /* Hypertension, uncomplicated */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('402', '403', '404', '405') then 1
            else 0
        end as htncx
        /* Hypertension, complicated */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '3341',
                '3440',
                '3441',
                '3442',
                '3443',
                '3444',
                '3445',
                '3446',
                '3449'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('342', '343') then 1
            else 0
        end as para
        /* Paralysis */
,
        CASE
            when icd9_code in ('33392') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '3319',
                '3320',
                '3321',
                '3334',
                '3335',
                '3362',
                '3481',
                '3483',
                '7803',
                '7843'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('334', '335', '340', '341', '345') then 1
            else 0
        end as neuro
        /* Other neurological */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('4168', '4169', '5064', '5081', '5088') then 1
            when SUBSTR(icd9_code, 1, 3) in (
                '490',
                '491',
                '492',
                '493',
                '494',
                '495',
                '496',
                '500',
                '501',
                '502',
                '503',
                '504',
                '505'
            ) then 1
            else 0
        end as chrnlung
        /* Chronic pulmonary disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2500', '2501', '2502', '2503') then 1
            else 0
        end as dm
        /* Diabetes w/o chronic complications*/
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2504', '2505', '2506', '2507', '2508', '2509') then 1
            else 0
        end as dmcx
        /* Diabetes w/ chronic complications */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2409', '2461', '2468') then 1
            when SUBSTR(icd9_code, 1, 3) in ('243', '244') then 1
            else 0
        end as hypothy
        /* Hypothyroidism */
,
        CASE
            when icd9_code in (
                '40301',
                '40311',
                '40391',
                '40402',
                '40403',
                '40412',
                '40413',
                '40492',
                '40493'
            ) then 1
            when SUBSTR(icd9_code, 1, 4) in ('5880', 'V420', 'V451') then 1
            when SUBSTR(icd9_code, 1, 3) in ('585', '586', 'V56') then 1
            else 0
        end as renlfail
        /* Renal failure */
,
        CASE
            when icd9_code in ('07022', '07023', '07032', '07033', '07044', '07054') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '0706',
                '0709',
                '4560',
                '4561',
                '4562',
                '5722',
                '5723',
                '5724',
                '5728',
                '5733',
                '5734',
                '5738',
                '5739',
                'V427'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('570', '571') then 1
            else 0
        end as liver
        /* Liver disease */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '5317',
                '5319',
                '5327',
                '5329',
                '5337',
                '5339',
                '5347',
                '5349'
            ) then 1
            else 0
        end as ulcer
        /* Chronic Peptic ulcer disease (includes bleeding only if obstruction is also present) */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('042', '043', '044') then 1
            else 0
        end as aids
        /* HIV and AIDS */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2030', '2386') then 1
            when SUBSTR(icd9_code, 1, 3) in ('200', '201', '202') then 1
            else 0
        end as lymph
        /* Lymphoma */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in ('196', '197', '198', '199') then 1
            else 0
        end as mets
        /* Metastatic cancer */
,
        CASE
            when SUBSTR(icd9_code, 1, 3) in (
                '140',
                '141',
                '142',
                '143',
                '144',
                '145',
                '146',
                '147',
                '148',
                '149',
                '150',
                '151',
                '152',
                '153',
                '154',
                '155',
                '156',
                '157',
                '158',
                '159',
                '160',
                '161',
                '162',
                '163',
                '164',
                '165',
                '166',
                '167',
                '168',
                '169',
                '170',
                '171',
                '172',
                '174',
                '175',
                '176',
                '177',
                '178',
                '179',
                '180',
                '181',
                '182',
                '183',
                '184',
                '185',
                '186',
                '187',
                '188',
                '189',
                '190',
                '191',
                '192',
                '193',
                '194',
                '195'
            ) then 1
            else 0
        end as tumor
        /* Solid tumor without metastasis */
,
        CASE
            when icd9_code in ('72889', '72930') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '7010',
                '7100',
                '7101',
                '7102',
                '7103',
                '7104',
                '7108',
                '7109',
                '7112',
                '7193',
                '7285'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('446', '714', '720', '725') then 1
            else 0
        end as arth
        /* Rheumatoid arthritis/collagen vascular diseases */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2871', '2873', '2874', '2875') then 1
            when SUBSTR(icd9_code, 1, 3) in ('286') then 1
            else 0
        end as coag
        /* Coagulation deficiency */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2780') then 1
            else 0
        end as obese
        /* Obesity      */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('7832', '7994') then 1
            when SUBSTR(icd9_code, 1, 3) in ('260', '261', '262', '263') then 1
            else 0
        end as wghtloss
        /* Weight loss */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2536') then 1
            when SUBSTR(icd9_code, 1, 3) in ('276') then 1
            else 0
        end as lytes
        /* Fluid and electrolyte disorders */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2800') then 1
            else 0
        end as bldloss
        /* Blood loss anemia */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2801', '2808', '2809') then 1
            when SUBSTR(icd9_code, 1, 3) in ('281') then 1
            else 0
        end as anemdef
        /* Deficiency anemias */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in (
                '2652',
                '2911',
                '2912',
                '2913',
                '2915',
                '2918',
                '2919',
                '3030',
                '3039',
                '3050',
                '3575',
                '4255',
                '5353',
                '5710',
                '5711',
                '5712',
                '5713',
                'V113'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('980') then 1
            else 0
        end as alcohol
        /* Alcohol abuse */
,
        CASE
            when icd9_code in ('V6542') then 1
            when SUBSTR(icd9_code, 1, 4) in (
                '3052',
                '3053',
                '3054',
                '3055',
                '3056',
                '3057',
                '3058',
                '3059'
            ) then 1
            when SUBSTR(icd9_code, 1, 3) in ('292', '304') then 1
            else 0
        end as drug
        /* Drug abuse */
,
        CASE
            when icd9_code in ('29604', '29614', '29644', '29654') then 1
            when SUBSTR(icd9_code, 1, 4) in ('2938') then 1
            when SUBSTR(icd9_code, 1, 3) in ('295', '297', '298') then 1
            else 0
        end as psych
        /* Psychoses */
,
        CASE
            when SUBSTR(icd9_code, 1, 4) in ('2962', '2963', '2965', '3004') then 1
            when SUBSTR(icd9_code, 1, 3) in ('309', '311') then 1
            else 0
        end as depress
        /* Depression */
    from
        diagnoses_icd icd
    where
        seq_num != 1 -- we do not include the primary icd-9 code
) -- collapse the icd9_code specific flags into hadm_id specific flags
-- this groups comorbidities together for a single patient admission
,
eligrp as (
    select
        hadm_id,
        max(chf) as chf,
        max(arrhy) as arrhy,
        max(valve) as valve,
        max(pulmcirc) as pulmcirc,
        max(perivasc) as perivasc,
        max(htn) as htn,
        max(htncx) as htncx,
        max(para) as para,
        max(neuro) as neuro,
        max(chrnlung) as chrnlung,
        max(dm) as dm,
        max(dmcx) as dmcx,
        max(hypothy) as hypothy,
        max(renlfail) as renlfail,
        max(liver) as liver,
        max(ulcer) as ulcer,
        max(aids) as aids,
        max(lymph) as lymph,
        max(mets) as mets,
        max(tumor) as tumor,
        max(arth) as arth,
        max(coag) as coag,
        max(obese) as obese,
        max(wghtloss) as wghtloss,
        max(lytes) as lytes,
        max(bldloss) as bldloss,
        max(anemdef) as anemdef,
        max(alcohol) as alcohol,
        max(drug) as drug,
        max(psych) as psych,
        max(depress) as depress
    from
        eliflg
    group by
        hadm_id
) -- now merge these flags together to define elixhauser
-- most are straightforward.. but hypertension flags are a bit more complicated
select
    adm.hadm_id,
    chf as congestive_heart_failure,
    arrhy as cardiac_arrhythmias,
    valve as valvular_disease,
    pulmcirc as pulmonary_circulation,
    perivasc as peripheral_vascular -- we combine "htn" and "htncx" into "HYPERTENSION"
,
    case
        when htn = 1 then 1
        when htncx = 1 then 1
        else 0
    end as hypertension,
    para as paralysis,
    neuro as other_neurological,
    chrnlung as chronic_pulmonary -- only the more severe comorbidity (complicated diabetes) is kept
,
    case
        when dmcx = 1 then 0
        when dm = 1 then 1
        else 0
    end as diabetes_uncomplicated,
    dmcx as diabetes_complicated,
    hypothy as hypothyroidism,
    renlfail as renal_failure,
    liver as liver_disease,
    ulcer as peptic_ulcer,
    aids as aids,
    lymph as lymphoma,
    mets as metastatic_cancer -- only the more severe comorbidity (metastatic cancer) is kept
,
    case
        when mets = 1 then 0
        when tumor = 1 then 1
        else 0
    end as solid_tumor,
    arth as rheumatoid_arthritis,
    coag as coagulopathy,
    obese as obesity,
    wghtloss as weight_loss,
    lytes as fluid_electrolyte,
    bldloss as blood_loss_anemia,
    anemdef as deficiency_anemias,
    alcohol as alcohol_abuse,
    drug as drug_abuse,
    psych as psychoses,
    depress as depression
FROM
    admissions adm
    left join eligrp eli on adm.hadm_id = eli.hadm_id
order by
    adm.hadm_id
  );
17:37:42.391779 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 1.85 seconds
17:37:42.398341 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:42.398990 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
alter table "postgres"."public"."elixhauser_quan" rename to "elixhauser_quan__dbt_backup"
17:37:42.400039 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.404925 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:42.405159 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
alter table "postgres"."public"."elixhauser_quan__dbt_tmp" rename to "elixhauser_quan"
17:37:42.405785 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.408800 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: COMMIT
17:37:42.408991 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:42.409085 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: COMMIT
17:37:42.410255 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:42.412812 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_quan"
17:37:42.413001 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_quan"} */
drop table if exists "postgres"."public"."elixhauser_quan__dbt_backup" cascade
17:37:42.415045 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:42.417438 [debug] [Thread-1  ]: finished collecting timing info
17:37:42.417648 [debug] [Thread-1  ]: On model.mimic.elixhauser_quan: Close
17:37:42.418354 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e645d0a0>]}
17:37:42.418968 [info ] [Thread-1  ]: 3 of 5 OK created table model public.elixhauser_quan ........................... [[32mSELECT 58976[0m in 1.90s]
17:37:42.419586 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_quan
17:37:42.419929 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_score_ahrq
17:37:42.420635 [info ] [Thread-1  ]: 4 of 5 START table model public.elixhauser_score_ahrq .......................... [RUN]
17:37:42.421645 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.421948 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_score_ahrq
17:37:42.422216 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_score_ahrq
17:37:42.425528 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_score_ahrq"
17:37:42.426595 [debug] [Thread-1  ]: finished collecting timing info
17:37:42.426970 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_score_ahrq
17:37:42.436264 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_score_ahrq"
17:37:42.437030 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.437257 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: BEGIN
17:37:42.437513 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:42.444352 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:37:42.444602 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.444712 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */


  create  table "postgres"."public"."elixhauser_score_ahrq__dbt_tmp"
  as (
    -- This query provides various methods of combining the Elixhauser components into a single score
-- The methods are called "vanWalRaven" and "SID30", and "SID29"
select subject_id, hadm_id
,  -- Below is the van Walraven score
   0 * aids +
   0 * alcohol_abuse +
  -2 * blood_loss_anemia +
   7 * congestive_heart_failure +
   -- Cardiac arrhythmias are not included in van Walraven based on Quan 2007
   3 * chronic_pulmonary +
   3 * coagulopathy +
  -2 * deficiency_anemias +
  -3 * depression +
   0 * diabetes_complicated +
   0 * diabetes_uncomplicated +
  -7 * drug_abuse +
   5 * fluid_electrolyte +
   0 * hypertension +
   0 * hypothyroidism +
   11 * liver_disease +
   9 * lymphoma +
   12 * metastatic_cancer +
   6 * other_neurological +
  -4 * obesity +
   7 * paralysis +
   2 * peripheral_vascular +
   0 * peptic_ulcer +
   0 * psychoses +
   4 * pulmonary_circulation +
   0 * rheumatoid_arthritis +
   5 * renal_failure +
   4 * solid_tumor +
  -1 * valvular_disease +
   6 * weight_loss
as elixhauser_vanwalraven



,  -- Below is the 29 component SID score
   0 * aids +
  -2 * alcohol_abuse +
  -2 * blood_loss_anemia +
   -- Cardiac arrhythmias are not included in SID-29
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
   9 * coagulopathy +
   0 * deficiency_anemias +
  -4 * depression +
   0 * diabetes_complicated +
  -1 * diabetes_uncomplicated +
  -8 * drug_abuse +
   9 * fluid_electrolyte +
  -1 * hypertension +
   0 * hypothyroidism +
   5 * liver_disease +
   6 * lymphoma +
   13 * metastatic_cancer +
   4 * other_neurological +
  -4 * obesity +
   3 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -4 * psychoses +
   5 * pulmonary_circulation +
   6 * renal_failure +
   0 * rheumatoid_arthritis +
   8 * solid_tumor +
   0 * valvular_disease +
   8 * weight_loss
as elixhauser_SID29


,  -- Below is the 30 component SID score
   0 * aids +
   0 * alcohol_abuse +
  -3 * blood_loss_anemia +
   8 * cardiac_arrhythmias +
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
  12 * coagulopathy +
   0 * deficiency_anemias +
  -5 * depression +
   1 * diabetes_complicated +
   0 * diabetes_uncomplicated +
 -11 * drug_abuse +
  11 * fluid_electrolyte +
  -2 * hypertension +
   0 * hypothyroidism +
   7 * liver_disease +
   8 * lymphoma +
  17 * metastatic_cancer +
   5 * other_neurological +
  -5 * obesity +
   4 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -6 * psychoses +
   5 * pulmonary_circulation +
   7 * renal_failure +
   0 * rheumatoid_arthritis +
  10 * solid_tumor +
   0 * valvular_disease +
  10 * weight_loss
as elixhauser_SID30

from "postgres"."public"."elixhauser_ahrq_v37"
  );
17:37:42.493517 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.05 seconds
17:37:42.499205 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.499573 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
alter table "postgres"."public"."elixhauser_score_ahrq" rename to "elixhauser_score_ahrq__dbt_backup"
17:37:42.500527 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.504462 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.504668 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
alter table "postgres"."public"."elixhauser_score_ahrq__dbt_tmp" rename to "elixhauser_score_ahrq"
17:37:42.505474 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.509183 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: COMMIT
17:37:42.509390 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.509651 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: COMMIT
17:37:42.517689 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:37:42.521565 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_ahrq"
17:37:42.522081 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_ahrq"} */
drop table if exists "postgres"."public"."elixhauser_score_ahrq__dbt_backup" cascade
17:37:42.524674 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:42.527795 [debug] [Thread-1  ]: finished collecting timing info
17:37:42.528029 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_ahrq: Close
17:37:42.528879 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e22c6280>]}
17:37:42.529344 [info ] [Thread-1  ]: 4 of 5 OK created table model public.elixhauser_score_ahrq ..................... [[32mSELECT 58976[0m in 0.11s]
17:37:42.529875 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_score_ahrq
17:37:42.530130 [debug] [Thread-1  ]: Began running node model.mimic.elixhauser_score_quan
17:37:42.530460 [info ] [Thread-1  ]: 5 of 5 START table model public.elixhauser_score_quan .......................... [RUN]
17:37:42.531302 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.531536 [debug] [Thread-1  ]: Began compiling node model.mimic.elixhauser_score_quan
17:37:42.531876 [debug] [Thread-1  ]: Compiling model.mimic.elixhauser_score_quan
17:37:42.534068 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.elixhauser_score_quan"
17:37:42.534433 [debug] [Thread-1  ]: finished collecting timing info
17:37:42.535198 [debug] [Thread-1  ]: Began executing node model.mimic.elixhauser_score_quan
17:37:42.547594 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.elixhauser_score_quan"
17:37:42.548283 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.548495 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: BEGIN
17:37:42.548599 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:37:42.553404 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:37:42.553637 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.553755 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */


  create  table "postgres"."public"."elixhauser_score_quan__dbt_tmp"
  as (
    -- This query provides various methods of combining the Elixhauser components into a single score
-- The methods are called "vanWalRaven" and "SID30", and "SID29"

select hadm_id
,  -- Below is the van Walraven score
   0 * aids +
   0 * alcohol_abuse +
  -2 * blood_loss_anemia +
   7 * congestive_heart_failure +
   -- Cardiac arrhythmias are not included in van Walraven based on Quan 2007
   3 * chronic_pulmonary +
   3 * coagulopathy +
  -2 * deficiency_anemias +
  -3 * depression +
   0 * diabetes_complicated +
   0 * diabetes_uncomplicated +
  -7 * drug_abuse +
   5 * fluid_electrolyte +
   0 * hypertension +
   0 * hypothyroidism +
   11 * liver_disease +
   9 * lymphoma +
   12 * metastatic_cancer +
   6 * other_neurological +
  -4 * obesity +
   7 * paralysis +
   2 * peripheral_vascular +
   0 * peptic_ulcer +
   0 * psychoses +
   4 * pulmonary_circulation +
   0 * rheumatoid_arthritis +
   5 * renal_failure +
   4 * solid_tumor +
  -1 * valvular_disease +
   6 * weight_loss
as elixhauser_vanwalraven



,  -- Below is the 29 component SID score
   0 * aids +
  -2 * alcohol_abuse +
  -2 * blood_loss_anemia +
   -- Cardiac arrhythmias are not included in SID-29
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
   9 * coagulopathy +
   0 * deficiency_anemias +
  -4 * depression +
   0 * diabetes_complicated +
  -1 * diabetes_uncomplicated +
  -8 * drug_abuse +
   9 * fluid_electrolyte +
  -1 * hypertension +
   0 * hypothyroidism +
   5 * liver_disease +
   6 * lymphoma +
   13 * metastatic_cancer +
   4 * other_neurological +
  -4 * obesity +
   3 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -4 * psychoses +
   5 * pulmonary_circulation +
   6 * renal_failure +
   0 * rheumatoid_arthritis +
   8 * solid_tumor +
   0 * valvular_disease +
   8 * weight_loss
as elixhauser_SID29


,  -- Below is the 30 component SID score
   0 * aids +
   0 * alcohol_abuse +
  -3 * blood_loss_anemia +
   8 * cardiac_arrhythmias +
   9 * congestive_heart_failure +
   3 * chronic_pulmonary +
  12 * coagulopathy +
   0 * deficiency_anemias +
  -5 * depression +
   1 * diabetes_complicated +
   0 * diabetes_uncomplicated +
 -11 * drug_abuse +
  11 * fluid_electrolyte +
  -2 * hypertension +
   0 * hypothyroidism +
   7 * liver_disease +
   8 * lymphoma +
  17 * metastatic_cancer +
   5 * other_neurological +
  -5 * obesity +
   4 * paralysis +
   0 * peptic_ulcer +
   4 * peripheral_vascular +
  -6 * psychoses +
   5 * pulmonary_circulation +
   7 * renal_failure +
   0 * rheumatoid_arthritis +
  10 * solid_tumor +
   0 * valvular_disease +
  10 * weight_loss
as elixhauser_SID30

from  "postgres"."public"."elixhauser_quan"
  );
17:37:42.604579 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.05 seconds
17:37:42.612534 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.612889 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
alter table "postgres"."public"."elixhauser_score_quan" rename to "elixhauser_score_quan__dbt_backup"
17:37:42.614453 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.618422 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.618737 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
alter table "postgres"."public"."elixhauser_score_quan__dbt_tmp" rename to "elixhauser_score_quan"
17:37:42.619513 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:37:42.622393 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: COMMIT
17:37:42.622701 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.622985 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: COMMIT
17:37:42.626413 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:37:42.628736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.elixhauser_score_quan"
17:37:42.628925 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.elixhauser_score_quan"} */
drop table if exists "postgres"."public"."elixhauser_score_quan__dbt_backup" cascade
17:37:42.631219 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:37:42.634072 [debug] [Thread-1  ]: finished collecting timing info
17:37:42.634292 [debug] [Thread-1  ]: On model.mimic.elixhauser_score_quan: Close
17:37:42.635080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0257ee1-a60b-435f-a84b-55ef5fdb03a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e22306a0>]}
17:37:42.635588 [info ] [Thread-1  ]: 5 of 5 OK created table model public.elixhauser_score_quan ..................... [[32mSELECT 58976[0m in 0.10s]
17:37:42.636148 [debug] [Thread-1  ]: Finished running node model.mimic.elixhauser_score_quan
17:37:42.637928 [debug] [MainThread]: Acquiring new postgres connection "master"
17:37:42.638162 [debug] [MainThread]: Using postgres connection "master"
17:37:42.638353 [debug] [MainThread]: On master: BEGIN
17:37:42.638664 [debug] [MainThread]: Opening a new connection, currently in state closed
17:37:42.643672 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:37:42.643922 [debug] [MainThread]: On master: COMMIT
17:37:42.644104 [debug] [MainThread]: Using postgres connection "master"
17:37:42.644271 [debug] [MainThread]: On master: COMMIT
17:37:42.644570 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:37:42.644829 [debug] [MainThread]: On master: Close
17:37:42.645519 [info ] [MainThread]: 
17:37:42.645908 [info ] [MainThread]: Finished running 5 table models in 4.35s.
17:37:42.646213 [debug] [MainThread]: Connection 'master' was properly closed.
17:37:42.646348 [debug] [MainThread]: Connection 'model.mimic.elixhauser_score_quan' was properly closed.
17:37:42.659665 [info ] [MainThread]: 
17:37:42.660217 [info ] [MainThread]: [32mCompleted successfully[0m
17:37:42.660702 [info ] [MainThread]: 
17:37:42.661021 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
17:37:42.661381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e450eb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e3b55bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e3b55fa0>]}
17:37:42.666168 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:00.547792 | 7f256088-74a8-4023-b77e-40cf51b457f9 ==============================
17:38:00.547808 [info ] [MainThread]: Running with dbt=1.1.1
17:38:00.548609 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['example'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:00.548818 [debug] [MainThread]: Tracking: tracking
17:38:00.555089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640bc8190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640bc8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640bc8280>]}
17:38:00.640268 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:00.640577 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:00.651525 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:38:00.658310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f256088-74a8-4023-b77e-40cf51b457f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640bbc8e0>]}
17:38:00.682231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f256088-74a8-4023-b77e-40cf51b457f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640c2cf70>]}
17:38:00.682771 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:00.683165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f256088-74a8-4023-b77e-40cf51b457f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640c17250>]}
17:38:00.684210 [warn ] [MainThread]: The selection criterion 'example' does not match any nodes
17:38:00.685802 [info ] [MainThread]: 
17:38:00.686105 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
17:38:00.697933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0642a0ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640c17160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0640c17040>]}
17:38:00.701876 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:14.174598 | a405443d-17f4-4499-bd7a-ac6322945066 ==============================
17:38:14.174610 [info ] [MainThread]: Running with dbt=1.1.1
17:38:14.175436 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['sepsis'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:14.175666 [debug] [MainThread]: Tracking: tracking
17:38:14.181853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81060a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81060a220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81060a250>]}
17:38:14.274620 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:14.274918 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:14.277139 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:38:14.283925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8106176d0>]}
17:38:14.301169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb810646e50>]}
17:38:14.301519 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:14.302064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb810661370>]}
17:38:14.305315 [info ] [MainThread]: 
17:38:14.306184 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:14.307819 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:38:14.319416 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:38:14.319793 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:38:14.320085 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:38:14.330106 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:38:14.337588 [debug] [ThreadPool]: On list_postgres: Close
17:38:14.342973 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:38:14.350062 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:14.350305 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:38:14.350744 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:38:14.356908 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:38:14.357163 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:14.357376 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:38:14.359802 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:38:14.368820 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:38:14.369304 [debug] [ThreadPool]: On list_postgres_public: Close
17:38:14.382345 [debug] [MainThread]: Using postgres connection "master"
17:38:14.382653 [debug] [MainThread]: On master: BEGIN
17:38:14.382950 [debug] [MainThread]: Opening a new connection, currently in state init
17:38:14.388422 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:38:14.388759 [debug] [MainThread]: Using postgres connection "master"
17:38:14.389129 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:38:14.395228 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:38:14.398888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb810554040>]}
17:38:14.399365 [debug] [MainThread]: On master: ROLLBACK
17:38:14.399926 [debug] [MainThread]: Using postgres connection "master"
17:38:14.400167 [debug] [MainThread]: On master: BEGIN
17:38:14.400714 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:14.400959 [debug] [MainThread]: On master: COMMIT
17:38:14.401218 [debug] [MainThread]: Using postgres connection "master"
17:38:14.401475 [debug] [MainThread]: On master: COMMIT
17:38:14.401915 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:14.402158 [debug] [MainThread]: On master: Close
17:38:14.402943 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:38:14.403407 [info ] [MainThread]: 
17:38:14.407158 [debug] [Thread-1  ]: Began running node model.mimic.angus
17:38:14.407587 [info ] [Thread-1  ]: 1 of 3 START table model public.angus .......................................... [RUN]
17:38:14.408463 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.angus"
17:38:14.408890 [debug] [Thread-1  ]: Began compiling node model.mimic.angus
17:38:14.409117 [debug] [Thread-1  ]: Compiling model.mimic.angus
17:38:14.413594 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.angus"
17:38:14.414278 [debug] [Thread-1  ]: finished collecting timing info
17:38:14.414817 [debug] [Thread-1  ]: Began executing node model.mimic.angus
17:38:14.445751 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.angus"
17:38:14.446318 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:14.446918 [debug] [Thread-1  ]: On model.mimic.angus: BEGIN
17:38:14.447447 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:14.455355 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:14.455613 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:14.455797 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */


  create  table "postgres"."public"."angus__dbt_tmp"
  as (
    -- ICD-9 codes for Angus criteria of sepsis

-- Angus et al, 2001. Epidemiology of severe sepsis in the United States
-- http://www.ncbi.nlm.nih.gov/pubmed/11445675

-- Case selection and definitions
-- To identify cases with severe sepsis, we selected all acute care
-- hospitalizations with ICD-9-CM codes for both:
-- (a) a bacterial or fungal infectious process AND
-- (b) a diagnosis of acute organ dysfunction (Appendix 2).

-- ICD-9 codes for infection - as sourced from Appendix 1 of above paper
 

WITH infection_group AS
(
	SELECT subject_id, hadm_id,
	CASE
		WHEN SUBSTR(icd9_code,1,3) IN ('001','002','003','004','005','008',
			   '009','010','011','012','013','014','015','016','017','018',
			   '020','021','022','023','024','025','026','027','030','031',
			   '032','033','034','035','036','037','038','039','040','041',
			   '090','091','092','093','094','095','096','097','098','100',
			   '101','102','103','104','110','111','112','114','115','116',
			   '117','118','320','322','324','325','420','421','451','461',
			   '462','463','464','465','481','482','485','486','494','510',
			   '513','540','541','542','566','567','590','597','601','614',
			   '615','616','681','682','683','686','730') THEN 1
		WHEN SUBSTR(icd9_code,1,4) IN ('5695','5720','5721','5750','5990','7110',
				'7907','9966','9985','9993') THEN 1
		WHEN SUBSTR(icd9_code,1,5) IN ('49121','56201','56203','56211','56213',
				'56983') THEN 1
		ELSE 0 END AS infection
	from diagnoses_icd
),
-- ICD-9 codes for organ dysfunction - as sourced from Appendix 2 of above paper
organ_diag_group as
(
	SELECT subject_id, hadm_id,
		CASE
		-- Acute Organ Dysfunction Diagnosis Codes
		WHEN SUBSTR(icd9_code,1,3) IN ('458','293','570','584') THEN 1
		WHEN SUBSTR(icd9_code,1,4) IN ('7855','3483','3481',
				'2874','2875','2869','2866','5734')  THEN 1
		ELSE 0 END AS organ_dysfunction,
		-- Explicit diagnosis of severe sepsis or septic shock
		CASE
		WHEN SUBSTR(icd9_code,1,5) IN ('99592','78552')  THEN 1
		ELSE 0 END AS explicit_sepsis
	from diagnoses_icd
),
-- Mechanical ventilation
organ_proc_group as
(
	SELECT subject_id, hadm_id,
		CASE
		WHEN icd9_code IN ('9670', '9671', '9672') THEN 1
		ELSE 0 END AS mech_vent
	FROM procedures_icd
),
-- Aggregate above views together
aggregate as
(
	SELECT subject_id, hadm_id,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM infection_group
					WHERE infection = 1)
				THEN 1
			ELSE 0 END AS infection,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM organ_diag_group
					WHERE explicit_sepsis = 1)
				THEN 1
			ELSE 0 END AS explicit_sepsis,
		CASE
			WHEN hadm_id in
					(SELECT DISTINCT hadm_id
					FROM organ_diag_group
					WHERE organ_dysfunction = 1)
				THEN 1
			ELSE 0 END AS organ_dysfunction,
		CASE
		WHEN hadm_id in
				(SELECT DISTINCT hadm_id
				FROM organ_proc_group
				WHERE mech_vent = 1)
			THEN 1
		ELSE 0 END AS mech_vent
	FROM admissions
)
-- Output component flags (explicit sepsis, organ dysfunction) and final flag (angus)
SELECT subject_id, hadm_id, infection,
   explicit_sepsis, organ_dysfunction, mech_vent,
CASE
	WHEN explicit_sepsis = 1 THEN 1
	WHEN infection = 1 AND organ_dysfunction = 1 THEN 1
	WHEN infection = 1 AND mech_vent = 1 THEN 1
	ELSE 0 END
AS angus
FROM aggregate
  );
17:38:16.650084 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 2.19 seconds
17:38:16.658402 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:16.658706 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
alter table "postgres"."public"."angus" rename to "angus__dbt_backup"
17:38:16.659478 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:16.663065 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:16.663292 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
alter table "postgres"."public"."angus__dbt_tmp" rename to "angus"
17:38:16.663972 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:16.674801 [debug] [Thread-1  ]: On model.mimic.angus: COMMIT
17:38:16.675048 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:16.675247 [debug] [Thread-1  ]: On model.mimic.angus: COMMIT
17:38:16.676431 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:16.680760 [debug] [Thread-1  ]: Using postgres connection "model.mimic.angus"
17:38:16.681031 [debug] [Thread-1  ]: On model.mimic.angus: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.angus"} */
drop table if exists "postgres"."public"."angus__dbt_backup" cascade
17:38:16.682987 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:16.685455 [debug] [Thread-1  ]: finished collecting timing info
17:38:16.685670 [debug] [Thread-1  ]: On model.mimic.angus: Close
17:38:16.686362 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80fb99af0>]}
17:38:16.686845 [info ] [Thread-1  ]: 1 of 3 OK created table model public.angus ..................................... [[32mSELECT 58976[0m in 2.28s]
17:38:16.687506 [debug] [Thread-1  ]: Finished running node model.mimic.angus
17:38:16.687894 [debug] [Thread-1  ]: Began running node model.mimic.explicit
17:38:16.688567 [info ] [Thread-1  ]: 2 of 3 START table model public.explicit ....................................... [RUN]
17:38:16.689528 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.explicit"
17:38:16.689910 [debug] [Thread-1  ]: Began compiling node model.mimic.explicit
17:38:16.690201 [debug] [Thread-1  ]: Compiling model.mimic.explicit
17:38:16.693959 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.explicit"
17:38:16.694964 [debug] [Thread-1  ]: finished collecting timing info
17:38:16.695291 [debug] [Thread-1  ]: Began executing node model.mimic.explicit
17:38:16.708868 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.explicit"
17:38:16.709415 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.709569 [debug] [Thread-1  ]: On model.mimic.explicit: BEGIN
17:38:16.709706 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:16.716258 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:16.716570 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.716751 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */


  create  table "postgres"."public"."explicit__dbt_tmp"
  as (
    -- This code extracts explicit sepsis using ICD-9 diagnosis codes
-- That is, the two codes 995.92 (severe sepsis) or 785.52 (septic shock)
-- These codes are extremely specific to sepsis, but have very low sensitivity
-- From Iwashyna et al. (vs. chart reviews): 100% PPV, 9.3% sens, 100% specificity
 

WITH co_dx AS
(
	SELECT hadm_id
	-- sepsis codes
	, MAX(
    	CASE
    		WHEN icd9_code = '99592' THEN 1
      ELSE 0 END
    ) AS severe_sepsis
	, MAX(
    	CASE
    		WHEN icd9_code = '78552' THEN 1
      ELSE 0 END
    ) AS septic_shock
  from diagnoses_icd
  GROUP BY hadm_id
)
select
  adm.subject_id
  , adm.hadm_id
	, co_dx.severe_sepsis
  , co_dx.septic_shock
	, case when co_dx.severe_sepsis = 1 or co_dx.septic_shock = 1
			then 1
		else 0 end as sepsis
FROM admissions adm
left join co_dx
  on adm.hadm_id = co_dx.hadm_id
order by adm.subject_id, adm.hadm_id
  );
17:38:16.916817 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.2 seconds
17:38:16.923403 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.923777 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
alter table "postgres"."public"."explicit" rename to "explicit__dbt_backup"
17:38:16.924895 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:16.929880 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.930090 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
alter table "postgres"."public"."explicit__dbt_tmp" rename to "explicit"
17:38:16.930821 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:16.933812 [debug] [Thread-1  ]: On model.mimic.explicit: COMMIT
17:38:16.934024 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.934120 [debug] [Thread-1  ]: On model.mimic.explicit: COMMIT
17:38:16.940892 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:38:16.943302 [debug] [Thread-1  ]: Using postgres connection "model.mimic.explicit"
17:38:16.943508 [debug] [Thread-1  ]: On model.mimic.explicit: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.explicit"} */
drop table if exists "postgres"."public"."explicit__dbt_backup" cascade
17:38:16.945459 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:16.948261 [debug] [Thread-1  ]: finished collecting timing info
17:38:16.948511 [debug] [Thread-1  ]: On model.mimic.explicit: Close
17:38:16.949127 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80fb896a0>]}
17:38:16.949593 [info ] [Thread-1  ]: 2 of 3 OK created table model public.explicit .................................. [[32mSELECT 58976[0m in 0.26s]
17:38:16.950180 [debug] [Thread-1  ]: Finished running node model.mimic.explicit
17:38:16.950556 [debug] [Thread-1  ]: Began running node model.mimic.martin
17:38:16.951271 [info ] [Thread-1  ]: 3 of 3 START table model public.martin ......................................... [RUN]
17:38:16.952164 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.martin"
17:38:16.952459 [debug] [Thread-1  ]: Began compiling node model.mimic.martin
17:38:16.952746 [debug] [Thread-1  ]: Compiling model.mimic.martin
17:38:16.955529 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.martin"
17:38:16.956232 [debug] [Thread-1  ]: finished collecting timing info
17:38:16.956552 [debug] [Thread-1  ]: Began executing node model.mimic.martin
17:38:16.965289 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.martin"
17:38:16.966072 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:16.966299 [debug] [Thread-1  ]: On model.mimic.martin: BEGIN
17:38:16.966395 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:16.972601 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:16.972923 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:16.973154 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */


  create  table "postgres"."public"."martin__dbt_tmp"
  as (
    -- ICD-9 codes for sepsis as validated by Martin et al.

-- Greg S. Martin, David M. Mannino, Stephanie Eaton, and Marc Moss. The epidemiology of
-- sepsis in the united states from 1979 through 2000. N Engl J Med, 348(16):1546–1554, Apr
-- 2003. doi: 10.1056/NEJMoa022139. URL http://dx.doi.org/10.1056/NEJMoa022139.
 
WITH co_dx AS
(
	SELECT subject_id, hadm_id
  , MAX(
    	CASE
        -- septicemia
    		WHEN SUBSTR(icd9_code,1,3) = '038' THEN 1
        -- septicemic, bacteremia, disseminated fungal infection, disseminated candida infection
				-- NOTE: the paper specifies 020.0 ... but this is bubonic plague
				-- presumably, they meant 020.2, which is septicemic plague
        WHEN SUBSTR(icd9_code,1,4) in ('0202','7907','1179','1125') THEN 1
        -- disseminated fungal endocarditis
        WHEN SUBSTR(icd9_code,1,5) = '11281' THEN 1
      ELSE 0 END
    ) AS sepsis
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('7991') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('51881','51882','51885','78609') THEN 1
      ELSE 0 END
    ) AS respiratory
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('4580','7855','4580','4588','4589','7963') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('785.51','785.59') THEN 1
      ELSE 0 END
    ) AS cardiovascular
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('584','580','585') THEN 1
      ELSE 0 END
    ) AS renal
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('570') THEN 1
        WHEN SUBSTR(icd9_code,1,4) in ('5722','5733') THEN 1
      ELSE 0 END
    ) AS hepatic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('2862','2866','2869','2873','2874','2875') THEN 1
      ELSE 0 END
    ) AS hematologic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,4) in ('2762') THEN 1
      ELSE 0 END
    ) AS metabolic
    , MAX(
      CASE
        WHEN SUBSTR(icd9_code,1,3) in ('293') THEN 1
        WHEN SUBSTR(icd9_code,1,4) in ('3481','3483') THEN 1
        WHEN SUBSTR(icd9_code,1,5) in ('78001','78009') THEN 1
      ELSE 0 END
    ) AS neurologic
  from diagnoses_icd
  GROUP BY subject_id, hadm_id
)
-- procedure codes:
-- "96.7 - Ventilator management"
-- translated:
--    9670	Continuous invasive mechanical ventilation of unspecified duration
--    9671	Continuous invasive mechanical ventilation for less than 96 consecutive hours
--    9672	Continuous invasive mechanical ventilation for 96 consecutive hours or more
-- "39.95 - Hemodialysis"
--    3995	Hemodialysis
-- "89.14 - Electroencephalography"
--    8914	Electroencephalogram
, co_proc as
(
  SELECT subject_id, hadm_id
  , MAX(CASE WHEN icd9_code = '967' then 1 ELSE 0 END) as respiratory
  , MAX(CASE WHEN icd9_code = '3995' then 1 ELSE 0 END) as renal
  , MAX(CASE WHEN icd9_code = '8914' then 1 ELSE 0 END) as neurologic
  FROM procedures_icd
  GROUP BY subject_id, hadm_id
)
select adm.subject_id, adm.hadm_id
, co_dx.sepsis
, CASE
    WHEN co_dx.respiratory = 1 OR co_proc.respiratory = 1
      OR co_dx.cardiovascular = 1
      OR co_dx.renal = 1 OR co_proc.renal = 1
      OR co_dx.hepatic = 1
      OR co_dx.hematologic = 1
      OR co_dx.metabolic = 1
      OR co_dx.neurologic = 1 OR co_proc.neurologic = 1
    THEN 1
  ELSE 0 END as organ_failure
, case when co_dx.respiratory = 1 or co_proc.respiratory = 1 then 1 else 0 end as respiratory
, co_dx.cardiovascular
, case when co_dx.renal = 1 or co_proc.renal = 1 then 1 else 0 end as renal
, co_dx.hepatic
, co_dx.hematologic
, co_dx.metabolic
, case when co_dx.neurologic = 1 or co_proc.neurologic = 1 then 1 else 0 end as neurologic
FROM admissions adm
left join co_dx
  on adm.hadm_id = co_dx.hadm_id
left join co_proc
  on adm.hadm_id = co_proc.hadm_id
  );
17:38:17.797039 [debug] [Thread-1  ]: SQL status: SELECT 58976 in 0.82 seconds
17:38:17.800847 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:17.801040 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
alter table "postgres"."public"."martin" rename to "martin__dbt_backup"
17:38:17.801784 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:17.805536 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:17.805844 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
alter table "postgres"."public"."martin__dbt_tmp" rename to "martin"
17:38:17.806572 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:17.809711 [debug] [Thread-1  ]: On model.mimic.martin: COMMIT
17:38:17.809991 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:17.810207 [debug] [Thread-1  ]: On model.mimic.martin: COMMIT
17:38:17.814616 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:17.819051 [debug] [Thread-1  ]: Using postgres connection "model.mimic.martin"
17:38:17.819276 [debug] [Thread-1  ]: On model.mimic.martin: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.martin"} */
drop table if exists "postgres"."public"."martin__dbt_backup" cascade
17:38:17.821104 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:17.823971 [debug] [Thread-1  ]: finished collecting timing info
17:38:17.824206 [debug] [Thread-1  ]: On model.mimic.martin: Close
17:38:17.824950 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a405443d-17f4-4499-bd7a-ac6322945066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80fb89820>]}
17:38:17.825323 [info ] [Thread-1  ]: 3 of 3 OK created table model public.martin .................................... [[32mSELECT 58976[0m in 0.87s]
17:38:17.825631 [debug] [Thread-1  ]: Finished running node model.mimic.martin
17:38:17.827325 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:17.827616 [debug] [MainThread]: Using postgres connection "master"
17:38:17.827892 [debug] [MainThread]: On master: BEGIN
17:38:17.828163 [debug] [MainThread]: Opening a new connection, currently in state closed
17:38:17.833501 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:38:17.833767 [debug] [MainThread]: On master: COMMIT
17:38:17.833893 [debug] [MainThread]: Using postgres connection "master"
17:38:17.834008 [debug] [MainThread]: On master: COMMIT
17:38:17.834180 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:17.834317 [debug] [MainThread]: On master: Close
17:38:17.835314 [info ] [MainThread]: 
17:38:17.835755 [info ] [MainThread]: Finished running 3 table models in 3.53s.
17:38:17.836188 [debug] [MainThread]: Connection 'master' was properly closed.
17:38:17.836499 [debug] [MainThread]: Connection 'model.mimic.martin' was properly closed.
17:38:17.851299 [info ] [MainThread]: 
17:38:17.851701 [info ] [MainThread]: [32mCompleted successfully[0m
17:38:17.852162 [info ] [MainThread]: 
17:38:17.852542 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
17:38:17.853726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80e299370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80e299c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80e2999a0>]}
17:38:17.857500 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:26.324278 | 6d61a192-2dd9-4c8d-a481-824a00167b3b ==============================
17:38:26.324293 [info ] [MainThread]: Running with dbt=1.1.1
17:38:26.324632 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['seeds'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:26.325157 [debug] [MainThread]: Tracking: tracking
17:38:26.331825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e076a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e076340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e076070>]}
17:38:26.417162 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:26.417456 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:26.419714 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:38:26.425921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d61a192-2dd9-4c8d-a481-824a00167b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89dffa460>]}
17:38:26.447899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6d61a192-2dd9-4c8d-a481-824a00167b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89f88e820>]}
17:38:26.448464 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:26.449030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d61a192-2dd9-4c8d-a481-824a00167b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e04e3d0>]}
17:38:26.450295 [warn ] [MainThread]: The selection criterion 'seeds' does not match any nodes
17:38:26.452799 [info ] [MainThread]: 
17:38:26.453232 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
17:38:26.468381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e04e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e04e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89e04e580>]}
17:38:26.472479 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:38.477718 | 93346ff6-0ea2-4952-8c7c-36ee538e410c ==============================
17:38:38.477734 [info ] [MainThread]: Running with dbt=1.1.1
17:38:38.478092 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['function'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:38.478204 [debug] [MainThread]: Tracking: tracking
17:38:38.484574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975a5fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975c10d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975c1100>]}
17:38:38.574944 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:38.575211 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:38.577521 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:38:38.583987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93346ff6-0ea2-4952-8c7c-36ee538e410c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1697613d00>]}
17:38:38.599476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93346ff6-0ea2-4952-8c7c-36ee538e410c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975f4040>]}
17:38:38.599983 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:38.600541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93346ff6-0ea2-4952-8c7c-36ee538e410c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1698e93df0>]}
17:38:38.601793 [warn ] [MainThread]: The selection criterion 'function' does not match any nodes
17:38:38.604531 [info ] [MainThread]: 
17:38:38.605030 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
17:38:38.619404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975f4220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975f4130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16975f4100>]}
17:38:38.622056 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:44.212489 | 1328ecfe-6e56-4ed3-b818-26030291ace6 ==============================
17:38:44.212503 [info ] [MainThread]: Running with dbt=1.1.1
17:38:44.213164 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['functions'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:44.213412 [debug] [MainThread]: Tracking: tracking
17:38:44.220766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8f53190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8f53250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8f53280>]}
17:38:44.308574 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:44.308835 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:44.311403 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:38:44.318073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1328ecfe-6e56-4ed3-b818-26030291ace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8f478e0>]}
17:38:44.335330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1328ecfe-6e56-4ed3-b818-26030291ace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8fb7f70>]}
17:38:44.335814 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:44.336205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1328ecfe-6e56-4ed3-b818-26030291ace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8fa2250>]}
17:38:44.338413 [info ] [MainThread]: 
17:38:44.340042 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:44.341752 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:38:44.353561 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:38:44.353779 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:38:44.354055 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:38:44.361958 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:38:44.367361 [debug] [ThreadPool]: On list_postgres: Close
17:38:44.374036 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:38:44.381090 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:44.381420 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:38:44.381524 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:38:44.385834 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:38:44.386065 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:44.386166 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:38:44.388456 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:38:44.399082 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:38:44.399592 [debug] [ThreadPool]: On list_postgres_public: Close
17:38:44.411085 [debug] [MainThread]: Using postgres connection "master"
17:38:44.411323 [debug] [MainThread]: On master: BEGIN
17:38:44.411596 [debug] [MainThread]: Opening a new connection, currently in state init
17:38:44.416497 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:44.416761 [debug] [MainThread]: Using postgres connection "master"
17:38:44.416964 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:38:44.425371 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:38:44.431023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1328ecfe-6e56-4ed3-b818-26030291ace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8fb7430>]}
17:38:44.431520 [debug] [MainThread]: On master: ROLLBACK
17:38:44.432070 [debug] [MainThread]: Using postgres connection "master"
17:38:44.432317 [debug] [MainThread]: On master: BEGIN
17:38:44.432945 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:44.433230 [debug] [MainThread]: On master: COMMIT
17:38:44.433419 [debug] [MainThread]: Using postgres connection "master"
17:38:44.433575 [debug] [MainThread]: On master: COMMIT
17:38:44.433903 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:44.434144 [debug] [MainThread]: On master: Close
17:38:44.434696 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:38:44.435085 [info ] [MainThread]: 
17:38:44.439369 [debug] [Thread-1  ]: Began running node model.mimic.auroc
17:38:44.439896 [info ] [Thread-1  ]: 1 of 1 START table model public.auroc .......................................... [RUN]
17:38:44.440914 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.auroc"
17:38:44.441345 [debug] [Thread-1  ]: Began compiling node model.mimic.auroc
17:38:44.441636 [debug] [Thread-1  ]: Compiling model.mimic.auroc
17:38:44.443959 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.auroc"
17:38:44.444768 [debug] [Thread-1  ]: finished collecting timing info
17:38:44.445157 [debug] [Thread-1  ]: Began executing node model.mimic.auroc
17:38:44.483853 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.auroc"
17:38:44.484587 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.484798 [debug] [Thread-1  ]: On model.mimic.auroc: BEGIN
17:38:44.484987 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:44.492987 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:44.493349 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.493711 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */


  create  table "postgres"."public"."auroc__dbt_tmp"
  as (
    -- Calculate the AUROC of age for predicting in-hospital mortality
-- You can easily calculate the AUROC of any model you'd like by:
--  Replacing "PRED" with your predictor
--  Replacing "TAR" with the target (*must* be a binary target)

with datatable as (
select
  -- name the predictor "PRED"
  cast(adm.admittime as date) - cast(pat.dob as date) as PRED -- age is our predictor
  -- name the target variable "TAR"
  , case when adm.deathtime is not null then 1 else 0 end as TAR -- in-hospital mortality
FROM admissions adm
inner join patients pat
  on adm.subject_id = pat.subject_id
)
, datacs as (
select
  TAR
  -- calculate the cumulative sum of negative targets, then multiply by positive targets
  -- this has the effect of returning 0 for negative targets, and the # of negative targets below each positive target
  , TAR * SUM(1-TAR) OVER (ORDER BY PRED ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS AUROC
from datatable
)
select
  -- Calculate the AUROC as:
  --    SUM( number of negative targets below each positive target )
  -- /  number of possible negative/positive target pairs
  round(sum(AUROC) / (sum(TAR)*sum(1-TAR)),4) as AUROC
from datacs
  );
17:38:44.561821 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.07 seconds
17:38:44.573322 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.573539 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
alter table "postgres"."public"."auroc" rename to "auroc__dbt_backup"
17:38:44.574157 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:44.577444 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.577644 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
alter table "postgres"."public"."auroc__dbt_tmp" rename to "auroc"
17:38:44.578263 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:44.588704 [debug] [Thread-1  ]: On model.mimic.auroc: COMMIT
17:38:44.588984 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.589182 [debug] [Thread-1  ]: On model.mimic.auroc: COMMIT
17:38:44.591575 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:44.596232 [debug] [Thread-1  ]: Using postgres connection "model.mimic.auroc"
17:38:44.596512 [debug] [Thread-1  ]: On model.mimic.auroc: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.auroc"} */
drop table if exists "postgres"."public"."auroc__dbt_backup" cascade
17:38:44.599134 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:44.602252 [debug] [Thread-1  ]: finished collecting timing info
17:38:44.602458 [debug] [Thread-1  ]: On model.mimic.auroc: Close
17:38:44.603310 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1328ecfe-6e56-4ed3-b818-26030291ace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b847d160>]}
17:38:44.603770 [info ] [Thread-1  ]: 1 of 1 OK created table model public.auroc ..................................... [[32mSELECT 1[0m in 0.16s]
17:38:44.604359 [debug] [Thread-1  ]: Finished running node model.mimic.auroc
17:38:44.605917 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:44.606151 [debug] [MainThread]: Using postgres connection "master"
17:38:44.606250 [debug] [MainThread]: On master: BEGIN
17:38:44.606343 [debug] [MainThread]: Opening a new connection, currently in state closed
17:38:44.611795 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:38:44.612049 [debug] [MainThread]: On master: COMMIT
17:38:44.612226 [debug] [MainThread]: Using postgres connection "master"
17:38:44.612407 [debug] [MainThread]: On master: COMMIT
17:38:44.612769 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:44.612999 [debug] [MainThread]: On master: Close
17:38:44.613478 [info ] [MainThread]: 
17:38:44.613798 [info ] [MainThread]: Finished running 1 table model in 0.27s.
17:38:44.614255 [debug] [MainThread]: Connection 'master' was properly closed.
17:38:44.614970 [debug] [MainThread]: Connection 'model.mimic.auroc' was properly closed.
17:38:44.628498 [info ] [MainThread]: 
17:38:44.628898 [info ] [MainThread]: [32mCompleted successfully[0m
17:38:44.629383 [info ] [MainThread]: 
17:38:44.629830 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
17:38:44.630925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0bad9af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8fa2190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b8fa22b0>]}
17:38:44.635796 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:38:52.424740 | 3038711d-5f40-475a-bcf4-62bbb35a5a8f ==============================
17:38:52.424752 [info ] [MainThread]: Running with dbt=1.1.1
17:38:52.425083 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['pivot'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:38:52.425191 [debug] [MainThread]: Tracking: tracking
17:38:52.431855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c51fb130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c51fb1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c51fb220>]}
17:38:52.517593 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:38:52.517789 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:38:52.520120 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:38:52.526404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c51f1640>]}
17:38:52.546274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c5243e50>]}
17:38:52.546769 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:38:52.547125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c5260340>]}
17:38:52.551603 [info ] [MainThread]: 
17:38:52.552713 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:52.554178 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:38:52.563441 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:38:52.563666 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:38:52.563863 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:38:52.573292 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:38:52.578373 [debug] [ThreadPool]: On list_postgres: Close
17:38:52.585158 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:38:52.592575 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:52.592783 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:38:52.592976 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:38:52.597078 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:38:52.597328 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:38:52.597499 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:38:52.603458 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.01 seconds
17:38:52.611216 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:38:52.611746 [debug] [ThreadPool]: On list_postgres_public: Close
17:38:52.623846 [debug] [MainThread]: Using postgres connection "master"
17:38:52.624104 [debug] [MainThread]: On master: BEGIN
17:38:52.624311 [debug] [MainThread]: Opening a new connection, currently in state init
17:38:52.629137 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:52.629387 [debug] [MainThread]: Using postgres connection "master"
17:38:52.629583 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:38:52.637743 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:38:52.640997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c523aac0>]}
17:38:52.641430 [debug] [MainThread]: On master: ROLLBACK
17:38:52.641927 [debug] [MainThread]: Using postgres connection "master"
17:38:52.642151 [debug] [MainThread]: On master: BEGIN
17:38:52.642435 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:52.642750 [debug] [MainThread]: On master: COMMIT
17:38:52.642943 [debug] [MainThread]: Using postgres connection "master"
17:38:52.643097 [debug] [MainThread]: On master: COMMIT
17:38:52.643472 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:52.643734 [debug] [MainThread]: On master: Close
17:38:52.644291 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:38:52.644610 [info ] [MainThread]: 
17:38:52.648157 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg
17:38:52.648584 [info ] [Thread-1  ]: 1 of 13 START table model public.pivoted_bg .................................... [RUN]
17:38:52.649886 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg"
17:38:52.650132 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg
17:38:52.650251 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg
17:38:52.651621 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg"
17:38:52.652185 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.652680 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg
17:38:52.690014 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg"
17:38:52.690868 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.691284 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: BEGIN
17:38:52.691488 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:52.695884 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:38:52.696149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.696259 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */


  create  table "postgres"."public"."pivoted_bg__dbt_tmp"
  as (
    -- The aim of this query is to pivot entries related to blood gases and
-- chemistry values which were found in LABEVENTS

-- create a table which has fuzzy boundaries on ICU admission
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  FROM icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (cast(round((DATETIME_DIFF(i.intime, i.outtime_lag, 'hour')/2)) as integer) || 'HOUR')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (cast(round((DATETIME_DIFF(i.intime_lead, i.outtime, 'minute')/2)) as integer) || 'MINUTE')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
, pvt as
( -- begin query that extracts the data
  select le.hadm_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
      , case
        when itemid = 50800 then 'SPECIMEN'
        when itemid = 50801 then 'AADO2'
        when itemid = 50802 then 'BASEEXCESS'
        when itemid = 50803 then 'BICARBONATE'
        when itemid = 50804 then 'TOTALCO2'
        when itemid = 50805 then 'CARBOXYHEMOGLOBIN'
        when itemid = 50806 then 'CHLORIDE'
        when itemid = 50808 then 'CALCIUM'
        when itemid = 50809 then 'GLUCOSE'
        when itemid = 50810 then 'HEMATOCRIT'
        when itemid = 50811 then 'HEMOGLOBIN'
        when itemid = 50812 then 'INTUBATED'
        when itemid = 50813 then 'LACTATE'
        when itemid = 50814 then 'METHEMOGLOBIN'
        when itemid = 50815 then 'O2FLOW'
        when itemid = 50816 then 'FIO2'
        when itemid = 50817 then 'SO2' -- OXYGENSATURATION
        when itemid = 50818 then 'PCO2'
        when itemid = 50819 then 'PEEP'
        when itemid = 50820 then 'PH'
        when itemid = 50821 then 'PO2'
        when itemid = 50822 then 'POTASSIUM'
        when itemid = 50823 then 'REQUIREDO2'
        when itemid = 50824 then 'SODIUM'
        when itemid = 50825 then 'TEMPERATURE'
        when itemid = 50826 then 'TIDALVOLUME'
        when itemid = 50827 then 'VENTILATIONRATE'
        when itemid = 50828 then 'VENTILATOR'
        else null
        end as label
        , charttime
        , value
        -- add in some sanity checks on the values
        , case
          when valuenum <= 0 then null
          when itemid = 50810 and valuenum > 100 then null -- hematocrit
          -- ensure FiO2 is a valid number between 21-100
          -- mistakes are rare (<100 obs out of ~100,000)
          -- there are 862 obs of valuenum == 20 - some people round down!
          -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
          when itemid = 50816 and valuenum < 20 then null
          when itemid = 50816 and valuenum > 100 then null
          when itemid = 50817 and valuenum > 100 then null -- O2 sat
          when itemid = 50815 and valuenum >  70 then null -- O2 flow
          when itemid = 50821 and valuenum > 800 then null -- PO2
           -- conservative upper limit
        else valuenum
        end as valuenum
    FROM labevents le
    where le.ITEMID in
    -- blood gases
    (
      50800, 50801, 50802, 50803, 50804, 50805, 50806, 50807, 50808, 50809
      , 50810, 50811, 50812, 50813, 50814, 50815, 50816, 50817, 50818, 50819
      , 50820, 50821, 50822, 50823, 50824, 50825, 50826, 50827, 50828
      , 51545
    )
)
, grp as
(
  select pvt.hadm_id, pvt.charttime
  , max(case when label = 'SPECIMEN' then value else null end) as specimen
  , avg(case when label = 'AADO2' then valuenum else null end) as aado2
  , avg(case when label = 'BASEEXCESS' then valuenum else null end) as baseexcess
  , avg(case when label = 'BICARBONATE' then valuenum else null end) as bicarbonate
  , avg(case when label = 'TOTALCO2' then valuenum else null end) as totalco2
  , avg(case when label = 'CARBOXYHEMOGLOBIN' then valuenum else null end) as carboxyhemoglobin
  , avg(case when label = 'CHLORIDE' then valuenum else null end) as chloride
  , avg(case when label = 'CALCIUM' then valuenum else null end) as calcium
  , avg(case when label = 'GLUCOSE' then valuenum else null end) as glucose
  , avg(case when label = 'HEMATOCRIT' then valuenum else null end) as hematocrit
  , avg(case when label = 'HEMOGLOBIN' then valuenum else null end) as hemoglobin
  , avg(case when label = 'INTUBATED' then valuenum else null end) as intubated
  , avg(case when label = 'LACTATE' then valuenum else null end) as lactate
  , avg(case when label = 'METHEMOGLOBIN' then valuenum else null end) as methemoglobin
  , avg(case when label = 'O2FLOW' then valuenum else null end) as o2flow
  , avg(case when label = 'FIO2' then valuenum else null end) as fio2
  , avg(case when label = 'SO2' then valuenum else null end) as so2 -- OXYGENSATURATION
  , avg(case when label = 'PCO2' then valuenum else null end) as pco2
  , avg(case when label = 'PEEP' then valuenum else null end) as peep
  , avg(case when label = 'PH' then valuenum else null end) as ph
  , avg(case when label = 'PO2' then valuenum else null end) as po2
  , avg(case when label = 'POTASSIUM' then valuenum else null end) as potassium
  , avg(case when label = 'REQUIREDO2' then valuenum else null end) as requiredo2
  , avg(case when label = 'SODIUM' then valuenum else null end) as sodium
  , avg(case when label = 'TEMPERATURE' then valuenum else null end) as temperature
  , avg(case when label = 'TIDALVOLUME' then valuenum else null end) as tidalvolume
  , max(case when label = 'VENTILATIONRATE' then valuenum else null end) as ventilationrate
  , max(case when label = 'VENTILATOR' then valuenum else null end) as ventilator
  from pvt
  group by pvt.hadm_id, pvt.charttime
  -- remove observations if there is more than one specimen listed
  -- we do not know whether these are arterial or mixed venous, etc...
  -- happily this is a small fraction of the total number of observations
  having sum(case when label = 'SPECIMEN' then 1 else 0 end)<2
)
select
  iid.icustay_id, grp.*
from grp
inner join admissions adm
  on grp.hadm_id = adm.hadm_id
left join iid_assign iid
  on adm.subject_id = iid.subject_id
  and grp.charttime >= iid.data_start
  and grp.charttime < iid.data_end
order by grp.hadm_id, grp.charttime
  );
17:38:52.777886 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.08 seconds
17:38:52.788769 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.788977 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg" rename to "pivoted_bg__dbt_backup"
17:38:52.790875 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.794952 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.795175 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg__dbt_tmp" rename to "pivoted_bg"
17:38:52.796487 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.805963 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:38:52.806194 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.806530 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:38:52.807836 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:52.812223 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:38:52.812431 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
drop table if exists "postgres"."public"."pivoted_bg__dbt_backup" cascade
17:38:52.815175 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:52.818679 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.818958 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: Close
17:38:52.819815 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c472ae20>]}
17:38:52.820363 [info ] [Thread-1  ]: 1 of 13 OK created table model public.pivoted_bg ............................... [[32mSELECT 0[0m in 0.17s]
17:38:52.821044 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg
17:38:52.821512 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_fio2
17:38:52.822207 [info ] [Thread-1  ]: 2 of 13 START table model public.pivoted_fio2 .................................. [RUN]
17:38:52.822971 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_fio2"
17:38:52.823665 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_fio2
17:38:52.823980 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_fio2
17:38:52.825520 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_fio2"
17:38:52.825918 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.826282 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_fio2
17:38:52.838388 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_fio2"
17:38:52.839555 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.839983 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: BEGIN
17:38:52.840392 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:52.845267 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:38:52.845487 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.845587 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */


  create  table "postgres"."public"."pivoted_fio2__dbt_tmp"
  as (
    with pvt as
( -- begin query that extracts the data
  select le.hadm_id
  , le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
    -- add in some sanity checks on the values
    , ROUND(MAX((case
        when valuenum <= 0 then null
        -- ensure FiO2 is a valid number between 21-100
        -- mistakes are rare (<100 obs out of ~100,000)
        -- there are 862 obs of valuenum == 20 - some people round down!
        -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
        when itemid = 50816 and valuenum < 20 then null
        when itemid = 50816 and valuenum > 100 then null
    ELSE valuenum END))::numeric, 2) AS valuenum
    FROM labevents le
    where le.ITEMID = 50816
    GROUP BY le.hadm_id, le.charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , ROUND((MAX(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ))::numeric, 2) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
select
  ie.icustay_id
  , COALESCE(pvt.charttime, fi.charttime) AS charttime
  , COALESCE(pvt.valuenum, fi.fio2_chartevents) AS fio2
from 
(
    -- one row per icustay_id/charttime
    SELECT hadm_id, charttime
    from pvt
    UNION DISTINCT
    SELECT hadm_id, charttime
    from stg_fio2
) base
INNER JOIN icustays ie
  on base.hadm_id = ie.hadm_id
  AND base.charttime >= DATETIME_SUB(ie.intime, INTERVAL '12' HOUR)
  AND base.charttime <= DATETIME_ADD(ie.outtime, INTERVAL '12' HOUR)
LEFT JOIN pvt
  ON base.hadm_id = pvt.hadm_id
  AND base.charttime = pvt.charttime
LEFT JOIN stg_fio2 fi
  ON base.hadm_id = fi.hadm_id
  AND base.charttime = fi.charttime
ORDER BY icustay_id, charttime
  );
17:38:52.856099 [debug] [Thread-1  ]: SQL status: SELECT 28 in 0.01 seconds
17:38:52.860557 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.860764 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2" rename to "pivoted_fio2__dbt_backup"
17:38:52.861238 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.865171 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.865557 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2__dbt_tmp" rename to "pivoted_fio2"
17:38:52.867014 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.873108 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:38:52.873529 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.873845 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:38:52.875049 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:52.876965 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:38:52.877137 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
drop table if exists "postgres"."public"."pivoted_fio2__dbt_backup" cascade
17:38:52.879124 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:52.881925 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.882416 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: Close
17:38:52.884741 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c4791550>]}
17:38:52.885576 [info ] [Thread-1  ]: 2 of 13 OK created table model public.pivoted_fio2 ............................. [[32mSELECT 28[0m in 0.06s]
17:38:52.886260 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_fio2
17:38:52.886639 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_gcs
17:38:52.887807 [info ] [Thread-1  ]: 3 of 13 START table model public.pivoted_gcs ................................... [RUN]
17:38:52.888564 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_gcs"
17:38:52.888856 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_gcs
17:38:52.889053 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_gcs
17:38:52.890652 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_gcs"
17:38:52.891160 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.891413 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_gcs
17:38:52.898423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_gcs"
17:38:52.900048 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.900575 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: BEGIN
17:38:52.900932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:52.906982 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:52.907317 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.908112 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */


  create  table "postgres"."public"."pivoted_gcs__dbt_tmp"
  as (
    -- This query extracts the Glasgow Coma Scale, a measure of neurological function.
-- The query has a few special rules:
--    (1) The verbal component can be set to 0 if the patient is ventilated.
--    This is corrected to 5 - the overall GCS is set to 15 in these cases.
--    (2) Often only one of three components is documented. The other components
--    are carried forward.

-- ITEMIDs used:

-- CAREVUE
--    723 as gcsverbal
--    454 as gcsmotor
--    184 as gcseyes

-- METAVISION
--    223900 GCS - Verbal Response
--    223901 GCS - Motor Response
--    220739 GCS - Eye Opening

-- The code combines the ITEMIDs into the carevue itemids, then pivots those
-- So 223900 is changed to 723, then the ITEMID 723 is pivoted to form gcsverbal

-- Note:
--  The GCS for sedated patients is defaulted to 15 in this code.
--  This is in line with how the data is meant to be collected.
--  e.g., from the SAPS II publication:
--    For sedated patients, the Glasgow Coma Score before sedation was used.
--    This was ascertained either from interviewing the physician who ordered the sedation,
--    or by reviewing the patient's medical record.

with base as
(
  select ce.icustay_id, ce.charttime
  -- pivot each value into its own column
  , max(case when ce.ITEMID in (454,223901) then ce.valuenum else null end) as gcsmotor
  , max(case
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 0
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 0
      when ce.ITEMID in (723,223900) then ce.valuenum
      else null 
    end) as gcsverbal
  , max(case when ce.ITEMID in (184,220739) then ce.valuenum else null end) as gcseyes
  -- convert the data into a number, reserving a value of 0 for ET/Trach
  , max(case
      -- endotrach/vent is assigned a value of 0, later parsed specially
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 1 -- carevue
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 1 -- metavision
    else 0 end)
    as endotrachflag
  , ROW_NUMBER ()
          OVER (PARTITION BY ce.icustay_id ORDER BY ce.charttime ASC) as rn
  FROM chartevents ce
  -- Isolate the desired GCS variables
  where ce.ITEMID in
  (
    -- 198 -- GCS
    -- GCS components, CareVue
    184, 454, 723
    -- GCS components, Metavision
    , 223900, 223901, 220739
  )
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error != 1)
  group by ce.icustay_id, ce.charttime
)
, gcs_stg0 as (
  select b.*
  , b2.gcsverbal as gcsverbalprev
  , b2.gcsmotor as gcsmotorprev
  , b2.gcseyes as gcseyesprev
  -- Calculate GCS, factoring in special case when they are intubated and prev vals
  -- note that the coalesce are used to implement the following if:
  --  if current value exists, use it
  --  if previous value exists, use it
  --  otherwise, default to normal
  , case
      -- replace GCS during sedation with 15
      when b.gcsverbal = 0
        then 15
      when b.gcsverbal is null and b2.gcsverbal = 0
        then 15
      -- if previously they were intub, but they aren't now, do not use previous GCS values
      when b2.gcsverbal = 0
        then
            coalesce(b.gcsmotor,6)
          + coalesce(b.gcsverbal,5)
          + coalesce(b.gcseyes,4)
      -- otherwise, add up score normally, imputing previous value if none available at current time
      else
            coalesce(b.gcsmotor,coalesce(b2.gcsmotor,6))
          + coalesce(b.gcsverbal,coalesce(b2.gcsverbal,5))
          + coalesce(b.gcseyes,coalesce(b2.gcseyes,4))
      end as gcs

  from base b
  -- join to itself within 6 hours to get previous value
  left join base b2
    on b.icustay_id = b2.icustay_id
    and b.rn = b2.rn+1
    and b2.charttime > DATETIME_SUB(b.charttime, INTERVAL '6' HOUR)
)
-- combine components with previous within 6 hours
-- filter down to cohort which is not excluded
-- truncate charttime to the hour
, gcs_stg1 as
(
  select gs.icustay_id, gs.charttime
  , gs.gcs
  , coalesce(gcsmotor,gcsmotorprev) as gcsmotor
  , coalesce(gcsverbal,gcsverbalprev) as gcsverbal
  , coalesce(gcseyes,gcseyesprev) as gcseyes
  , case when coalesce(gcsmotor,gcsmotorprev) is null then 0 else 1 end
  + case when coalesce(gcsverbal,gcsverbalprev) is null then 0 else 1 end
  + case when coalesce(gcseyes,gcseyesprev) is null then 0 else 1 end
    as components_measured
  , endotrachflag
  from gcs_stg0 gs
)
-- priority is:
--  (i) complete data, (ii) non-sedated GCS, (iii) lowest GCS, (iv) charttime
, gcs_priority as
(
  select icustay_id
    , charttime
    , gcs
    , gcsmotor
    , gcsverbal
    , gcseyes
    , endotrachflag
    , ROW_NUMBER() over
      (
        PARTITION BY icustay_id, charttime
        ORDER BY components_measured DESC, endotrachflag, gcs, charttime DESC
      ) as rn
  from gcs_stg1
)
select icustay_id
  , charttime
  , gcs
  , gcsmotor
  , gcsverbal
  , gcseyes
  , endotrachflag
from gcs_priority gs
where rn = 1
ORDER BY icustay_id, charttime
  );
17:38:52.913871 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:38:52.919949 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.920633 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs" rename to "pivoted_gcs__dbt_backup"
17:38:52.921302 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.927149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.927353 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs__dbt_tmp" rename to "pivoted_gcs"
17:38:52.927991 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.930945 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:38:52.931149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.931316 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:38:52.932768 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:52.936892 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:38:52.937128 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
drop table if exists "postgres"."public"."pivoted_gcs__dbt_backup" cascade
17:38:52.939748 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:52.943334 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.943582 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: Close
17:38:52.944242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c47915b0>]}
17:38:52.944652 [info ] [Thread-1  ]: 3 of 13 OK created table model public.pivoted_gcs .............................. [[32mSELECT 0[0m in 0.06s]
17:38:52.945173 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_gcs
17:38:52.945504 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_height
17:38:52.945915 [info ] [Thread-1  ]: 4 of 13 START table model public.pivoted_height ................................ [RUN]
17:38:52.946435 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_height"
17:38:52.946771 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_height
17:38:52.946967 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_height
17:38:52.948453 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_height"
17:38:52.949882 [debug] [Thread-1  ]: finished collecting timing info
17:38:52.950775 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_height
17:38:52.960767 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_height"
17:38:52.961421 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:52.961636 [debug] [Thread-1  ]: On model.mimic.pivoted_height: BEGIN
17:38:52.961796 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:52.968473 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:52.968808 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:52.968979 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */


  create  table "postgres"."public"."pivoted_height__dbt_tmp"
  as (
    -- prep height
WITH ht_in AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN ROUND((c.valuenum * 2.54)::numeric, 2)
        -- ROUND(value::numeric, 2)
      ELSE c.valuenum
    END)::numeric, 2) AS height
    , c.valuenum as height_orig
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height (measured in inches)
  AND c.itemid IN
  (
    -- CareVue
    920, 1394, 4187, 3486
    -- Metavision
    , 226707
  )
)
, ht_cm AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN c.valuenum * 2.54
      ELSE c.valuenum
    END)::numeric, 2) AS height
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height cm
  AND c.itemid IN
  (
    -- CareVue
    3485, 4188
    -- MetaVision
    , 226730
  )
)
-- merge cm/height, only take 1 value per charted row
, ht_stg0 AS
(
  SELECT
  COALESCE(h1.subject_id, h1.subject_id) as subject_id
  , COALESCE(h1.charttime, h1.charttime) AS charttime
  , COALESCE(h1.height, h2.height) as height
  FROM ht_cm h1
  FULL OUTER JOIN ht_in h2
    ON h1.subject_id = h2.subject_id
    AND h1.charttime = h2.charttime
)
-- filter out bad heights
, ht_stg1 AS
(
  SELECT
    h.subject_id
    , charttime
    , CASE
        -- rule for neonates
        -- [charrtime don't have year coloum?]
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) <= 1 AND height < 80 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) <= 1 AND height < 80 THEN height
        
        -- rule for adults
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) > 1 AND height > 120 AND height < 230 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) > 1 AND height > 120 AND height < 230 THEN height
      ELSE NULL END as height
  FROM ht_stg0 h
  INNER JOIN patients pt
    ON h.subject_id = pt.subject_id
)
-- heights from echo-cardiography notes
, echo_note AS
(
  SELECT
    subject_id
    -- extract the time of the note from the text itself
    -- add this to the structured date in the chartdate column
    , PARSE_DATETIME('%b-%d-%Y%H:%M',
      CONCAT(
        FORMAT_DATE('%b-%d-%Y', chartdate),
        REGEXP_EXTRACT(ne.text, 'Date/Time: [\\[\\]0-9*-]+ at ([0-9:]+)')
       )
    ) AS charttime
    -- sometimes numeric values contain de-id numbers, e.g. [** Numeric Identifier **]
    -- this case is used to ignore that text
    , case
        when REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') like '%*%'
            then null
        else cast(REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') as numeric)
        end * 2.54 as height
  FROM noteevents ne
  WHERE ne.category = 'Echo'
)
-- use documented ideal body weights to back-calculate height
, ibw_note AS
(
    SELECT subject_id
    , ne.category
    , charttime
    , CAST(REGEXP_EXTRACT(text, 'Ideal body weight: ([0-9]+\\.?[0-9]*)') AS NUMERIC) as ibw
    FROM noteevents ne
    WHERE text like '%Ideal body weight:%'
    AND ne.category != 'Echo'
)
, ht_from_ibw AS
(
    -- IBW formulas
    -- inches
    -- F:  IBW = 45.5 kg + 2.3 kg * (height in inches - 60)
    -- M:  IBW = 50 kg + 2.3 kg * (height in inches - 60)
    
    -- cm
    -- F: 45.5 + (0.91 × [height in centimeters − 152.4])
    -- M: 50 + (0.91 × [height in centimeters − 152.4])
    
    SELECT ne.subject_id
    , charttime
    , CASE
        WHEN gender = 'F' THEN (ibw - 45.5)/0.91 + 152.4
        ELSE (ibw - 50)/0.91 + 152.4 END AS height
    FROM ibw_note ne
    INNER JOIN patients pt
      ON ne.subject_id = pt.subject_id
    WHERE ibw IS NOT NULL AND ibw != 0
)
, ht_nutrition AS
(
    -- nutrition notes usually only document height
    -- but the original note formatting has been lost, so we can't do a clever regex
    -- instead, we just look for the unit of measure (cm)
    SELECT subject_id
    , charttime
    , CAST(REGEXP_EXTRACT(ne.text, '([0-9]+) cm') AS NUMERIC) as height
    FROM noteevents ne
    WHERE category = 'Nutrition'
    AND lower(text) like '%height%'
)
SELECT subject_id, charttime, 'chartevents' as source, height
FROM ht_stg1
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - echo' as source, height
FROM echo_note
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - ibw' as source, height
FROM ht_from_ibw
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - nutrition' as source
-- convert the heights
    , CASE 
        WHEN height < 80 THEN height*2.54
        ELSE height
    END AS height
FROM ht_nutrition
WHERE height IS NOT NULL AND height > 0
ORDER BY subject_id, charttime, source, height
  );
17:38:52.984937 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.02 seconds
17:38:52.991694 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:52.991983 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height" rename to "pivoted_height__dbt_backup"
17:38:52.992969 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:52.997965 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:52.998223 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height__dbt_tmp" rename to "pivoted_height"
17:38:52.999914 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.006378 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:38:53.006855 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:53.007128 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:38:53.008277 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:53.011262 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:38:53.011533 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
drop table if exists "postgres"."public"."pivoted_height__dbt_backup" cascade
17:38:53.013489 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:53.017556 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.017819 [debug] [Thread-1  ]: On model.mimic.pivoted_height: Close
17:38:53.018395 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c478b940>]}
17:38:53.019010 [info ] [Thread-1  ]: 4 of 13 OK created table model public.pivoted_height ........................... [[32mSELECT 0[0m in 0.07s]
17:38:53.019526 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_height
17:38:53.019821 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_icp
17:38:53.020441 [info ] [Thread-1  ]: 5 of 13 START table model public.pivoted_icp ................................... [RUN]
17:38:53.021064 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_icp"
17:38:53.021366 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_icp
17:38:53.021566 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_icp
17:38:53.023275 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_icp"
17:38:53.023763 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.024025 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_icp
17:38:53.032032 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_icp"
17:38:53.032780 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.033060 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: BEGIN
17:38:53.033346 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:53.039315 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:53.039674 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.039906 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */


  create  table "postgres"."public"."pivoted_icp__dbt_tmp"
  as (
    with ce as
(
  select ce.icustay_id
    , ce.charttime
    -- TODO: handle high ICPs when monitoring two ICPs
    , case when valuenum > 0 and valuenum < 100 then valuenum else null end as icp
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error = 0)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
   226 -- ICP -- 99159
  ,1374 -- ICP Right -- 100
  ,2045 -- icp left -- 70
  ,2635 -- VENT ICP -- 195
  ,2660 -- ICP Camino -- 40
  ,2733 -- RIGHT VENT ICP -- 203
  ,2745 -- ICP LEFT -- 232
  ,2870 -- ICP-ventriculostomuy -- 114
  ,2956 -- ventriculostomy icp -- 64
  ,2985 -- ICP ventricle -- 85
  ,5856 -- icp -- 7
  ,7116 -- Rt ICP -- 80
  ,8218 -- left icp -- 6
  ,8298 -- L ICP -- 47
  ,8299 -- R ICP -- 16
  ,8305 -- ICP  Right -- 49
  ,220765 -- Intra Cranial Pressure -- 92306
  ,227989 -- Intra Cranial Pressure #2 -- 1052
  )
)
select
    ce.icustay_id
  , ce.charttime
  , MAX(icp) as icp
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:38:53.045118 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:38:53.051874 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.052429 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp" rename to "pivoted_icp__dbt_backup"
17:38:53.053335 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.057734 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.057988 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp__dbt_tmp" rename to "pivoted_icp"
17:38:53.058617 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.061459 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:38:53.061648 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.061864 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:38:53.062823 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:53.065302 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:38:53.065924 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
drop table if exists "postgres"."public"."pivoted_icp__dbt_backup" cascade
17:38:53.069389 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:53.074163 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.074732 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: Close
17:38:53.075516 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c478ba90>]}
17:38:53.075997 [info ] [Thread-1  ]: 5 of 13 OK created table model public.pivoted_icp .............................. [[32mSELECT 0[0m in 0.05s]
17:38:53.076428 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_icp
17:38:53.076591 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_invasive_lines
17:38:53.077115 [info ] [Thread-1  ]: 6 of 13 START table model public.pivoted_invasive_lines ........................ [RUN]
17:38:53.077642 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.077763 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_invasive_lines
17:38:53.077866 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_invasive_lines
17:38:53.079672 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_invasive_lines"
17:38:53.080082 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.080394 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_invasive_lines
17:38:53.089482 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_invasive_lines"
17:38:53.090532 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.090891 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: BEGIN
17:38:53.091149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:53.096216 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:53.096471 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.096573 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */


  create  table "postgres"."public"."pivoted_invasive_lines__dbt_tmp"
  as (
    WITH stg0 AS
(
    SELECT 
        icustay_id
        , charttime
        , storetime
        , itemid
        -- create partition which separates the lines
        , CASE
            WHEN itemid IN (229, 8392) THEN 1
            WHEN itemid IN (235, 8393) THEN 2
            WHEN itemid IN (241, 8394) THEN 3
            WHEN itemid IN (247, 8395) THEN 4
            WHEN itemid IN (253, 8396) THEN 5
            WHEN itemid IN (259, 8397) THEN 6
            WHEN itemid IN (265, 8398) THEN 7
            WHEN itemid IN (271, 8399) THEN 8
          ELSE NULL END AS line_number
        , CASE WHEN itemid < 8000 THEN value ELSE NULL END AS line_type
        , CASE WHEN itemid > 8000 THEN value ELSE NULL END AS line_site
        -- the stopped column is always present for invasive lines
        , CASE 
            --   WHEN ce.stopped = 'D/C\'d' THEN 1
              WHEN ce.stopped = 'D/C''d' THEN 1
              WHEN ce.stopped = 'NotStopd' THEN 0
          ELSE NULL END AS line_dc
    FROM chartevents ce
    WHERE ce.itemid IN 
    (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
    )
    AND icustay_id IS NOT NULL
    AND COALESCE(ce.error, 0) = 0
)
, stg0_rn AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site, line_dc
        -- only keep the last documented value
        , ROW_NUMBER() OVER (PARTITION BY icustay_id, charttime, itemid ORDER BY storetime DESC) as rn_last_stored
    FROM stg0
)
, stg1 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        -- collapse line type/site into a single row
        -- MAX() always collapses a single value, due to where rn_last_stored = 1
        , MAX(line_type) as line_type
        , MAX(line_site) as line_site
        -- any disconnection at this charttime turns off the line
        , MAX(line_dc) AS line_dc
    FROM stg0_rn
    WHERE rn_last_stored = 1
    GROUP BY icustay_id, charttime, line_number
)
, stg2 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site
        , line_dc
        -- carry forward the line type
        , CASE
            -- if the previous line was D/C'd then it's a new line
            WHEN LAG(line_dc) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = 1 THEN 1
            -- if it's the same line as before, within 16 hours, continue the event
            WHEN LAG(line_type) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = line_type
            AND DATETIME_DIFF(
                charttime,
                LAG(charttime) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime),
                'HOUR'
                ) < 16 THEN 0
            -- otherwise, it's been more than 16 hours since the line was last documented
            -- (or it's the first documentation of this line)
            -- so we consider this a new event
            ELSE 1
        END AS rn_part
    FROM stg1
)
-- rn_part is 1 if it's a new event, and 0 if it's a continuation of the previous
-- so cumulatively summing it will result in a sequential integer which partitions
-- distinct line events. we can later group on this integer.
, stg3 AS
(
    SELECT
        icustay_id, charttime, line_number
        , line_type, line_site
        , line_dc
        , SUM(rn_part) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) as line_event
    FROM stg2
)
-- group by line_event to determine line start/stop times
, stg4 AS
(
    SELECT
        icustay_id, line_number
        , line_event
        , line_type, line_site
        , MIN(charttime) as starttime
        , MAX(charttime) as endtime
    FROM stg3
    -- filter out the D/C'd rows so they don't impact the starttime of future events
    WHERE line_dc = 0 
    GROUP BY icustay_id, line_number, line_event, line_type, line_site
)
-- metavision
, mv AS
(
    SELECT 
        icustay_id
        -- since metavision separates lines using itemid, we can use it as the line number
        , mv.itemid AS line_number
        , di.label AS line_type
        , mv.location AS line_site
        , starttime, endtime
    FROM procedureevents_mv mv
    INNER JOIN d_items di
      ON mv.itemid = di.itemid
    WHERE mv.itemid IN
    (
      227719 -- AVA Line
    , 225752 -- Arterial Line
    , 224269 -- CCO PAC
    , 224267 -- Cordis/Introducer
    , 224270 -- Dialysis Catheter
    , 224272 -- IABP line
    , 226124 -- ICP Catheter
    , 228169 -- Impella Line
    , 225202 -- Indwelling Port (PortaCath)
    , 228286 -- Intraosseous Device
    , 225204 -- Midline
    , 224263 -- Multi Lumen
    , 224560 -- PA Catheter
    , 224264 -- PICC Line
    , 225203 -- Pheresis Catheter
    , 224273 -- Presep Catheter
    , 225789 -- Sheath
    , 225761 -- Sheath Insertion
    , 228201 -- Tandem Heart Access Line
    , 228202 -- Tandem Heart Return Line
    , 224268 -- Trauma line
    , 225199 -- Triple Introducer
    , 225315 -- Tunneled (Hickman) Line
    , 225205 -- RIC
    )
    AND icustay_id IS NOT NULL
    AND statusdescription != 'Rewritten'
),
combined AS
(
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM stg4
    UNION DISTINCT
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM mv
)
-- as a final step, combine any similar terms together
-- this was comprehensive as of MIMIC-III v1.4
select 
    icustay_id
    , CASE
        WHEN line_type IN ('Arterial Line', 'A-Line') THEN 'Arterial'
        WHEN line_type IN ('CCO PA Line', 'CCO PAC') THEN 'Continuous Cardiac Output PA'
        WHEN line_type IN ('Dialysis Catheter', 'Dialysis Line') THEN 'Dialysis'
        WHEN line_type IN ('Hickman', 'Tunneled (Hickman) Line') THEN 'Hickman'
        WHEN line_type IN ('IABP', 'IABP line') THEN 'IABP'
        WHEN line_type IN ('Multi Lumen', 'Multi-lumen') THEN 'Multi Lumen'
        WHEN line_type IN ('PA Catheter', 'PA line') THEN 'PA'
        WHEN line_type IN ('PICC Line', 'PICC line') THEN 'PICC'
        WHEN line_type IN ('Pre-Sep Catheter', 'Presep Catheter') THEN 'Pre-Sep'
        WHEN line_type IN ('Trauma Line', 'Trauma line') THEN 'Trauma'
        WHEN line_type IN ('Triple Introducer', 'TripleIntroducer') THEN 'Triple Introducer'
        WHEN line_type IN ('Portacath', 'Indwelling Port (PortaCath)') THEN 'Portacath'
        -- AVA Line
        -- Camino Bolt
        -- Cordis/Introducer
        -- ICP Catheter
        -- Impella Line
        -- Intraosseous Device
        -- Introducer
        -- Lumbar Drain
        -- Midline
        -- Other/Remarks
        -- PacerIntroducer
        -- PermaCath
        -- Pheresis Catheter
        -- RIC
        -- Sheath
        -- Tandem Heart Access Line
        -- Tandem Heart Return Line
        -- Venous Access
        -- Ventriculostomy
    ELSE line_type END AS line_type
    , CASE
        WHEN line_site IN ('Left Antecub', 'Left Antecube') THEN 'Left Antecube'
        WHEN line_site IN ('Left Axilla', 'Left Axilla.') THEN 'Left Axilla'
        WHEN line_site IN ('Left Brachial', 'Left Brachial.') THEN 'Left Brachial'
        WHEN line_site IN ('Left Femoral', 'Left Femoral.') THEN 'Left Femoral'
        WHEN line_site IN ('Right Antecub', 'Right Antecube') THEN 'Right Antecube' 
        WHEN line_site IN ('Right Axilla', 'Right Axilla.') THEN 'Right Axilla' 
        WHEN line_site IN ('Right Brachial', 'Right Brachial.') THEN 'Right Brachial' 
        WHEN line_site IN ('Right Femoral', 'Right Femoral.') THEN 'Right Femoral' 
        -- 'Left Foot'
        -- 'Left IJ'
        -- 'Left Radial'
        -- 'Left Subclavian'
        -- 'Left Ulnar'
        -- 'Left Upper Arm'
        -- 'Right Foot'
        -- 'Right IJ'
        -- 'Right Radial'
        -- 'Right Side Head'
        -- 'Right Subclavian'
        -- 'Right Ulnar'
        -- 'Right Upper Arm'
        -- 'Transthoracic'
        -- 'Other/Remarks'
    ELSE line_site END AS line_site
    , starttime
    , endtime
FROM combined
ORDER BY icustay_id, starttime, line_type, line_site
  );
17:38:53.272351 [debug] [Thread-1  ]: SQL status: SELECT 34483 in 0.18 seconds
17:38:53.278823 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.279196 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines" rename to "pivoted_invasive_lines__dbt_backup"
17:38:53.280046 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.283747 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.283952 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines__dbt_tmp" rename to "pivoted_invasive_lines"
17:38:53.284649 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.288208 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:38:53.288408 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.288654 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:38:53.292978 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:53.295045 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:38:53.295247 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
drop table if exists "postgres"."public"."pivoted_invasive_lines__dbt_backup" cascade
17:38:53.297208 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:53.300088 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.300316 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: Close
17:38:53.301127 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c478bbe0>]}
17:38:53.301601 [info ] [Thread-1  ]: 6 of 13 OK created table model public.pivoted_invasive_lines ................... [[32mSELECT 34483[0m in 0.22s]
17:38:53.302101 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_invasive_lines
17:38:53.302356 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_lab
17:38:53.303036 [info ] [Thread-1  ]: 7 of 13 START table model public.pivoted_lab ................................... [RUN]
17:38:53.303817 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_lab"
17:38:53.304055 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_lab
17:38:53.304278 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_lab
17:38:53.306115 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_lab"
17:38:53.306805 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.307053 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_lab
17:38:53.316179 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_lab"
17:38:53.316911 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.317645 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: BEGIN
17:38:53.318160 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:53.324979 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:53.325290 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.325611 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */


  create  table "postgres"."public"."pivoted_lab__dbt_tmp"
  as (
    -- create a table which has fuzzy boundaries on ICU admission (+- 12 hours from documented time)
-- this is used to assign icustay_id to lab data, which can be collected outside ICU
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  from icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two ICU stays within 24 hours, set the start/stop
    --  time as half way between the two ICU stays
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (CAST(DATETIME_DIFF(i.intime, i.outtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (CAST(DATETIME_DIFF(i.intime_lead, i.outtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
-- also create fuzzy boundaries on hospitalization
, h as
(
  select
    subject_id, hadm_id, admittime, dischtime
    , lag (dischtime) over (partition by subject_id order by admittime) as dischtime_lag
    , lead (admittime) over (partition by subject_id order by admittime) as admittime_lead
  from admissions
)
, adm as
(
  select
    h.subject_id, h.hadm_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when h.dischtime_lag is not null
        and h.dischtime_lag > (DATETIME_SUB(h.admittime, INTERVAL '24' HOUR))
          then DATETIME_SUB(h.admittime, (CAST(DATETIME_DIFF(h.admittime, h.dischtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(h.admittime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when h.admittime_lead is not null
        and h.admittime_lead < (DATETIME_ADD(h.dischtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(h.dischtime, (CAST(DATETIME_DIFF(h.admittime_lead, h.dischtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(h.dischtime, INTERVAL '12' HOUR))
      end as data_end
    from h
)
, le_avg as
(
SELECT
    pvt.subject_id, pvt.charttime
  , avg(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE null END) as ANIONGAP
  , avg(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE null END) as ALBUMIN
  , avg(CASE WHEN label = 'BANDS' THEN valuenum ELSE null END) as BANDS
  , avg(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE null END) as BICARBONATE
  , avg(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE null END) as BILIRUBIN
  , avg(CASE WHEN label = 'CREATININE' THEN valuenum ELSE null END) as CREATININE
  , avg(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE null END) as CHLORIDE
  , avg(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE null END) as GLUCOSE
  , avg(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE null END) as HEMATOCRIT
  , avg(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE null END) as HEMOGLOBIN
  , avg(CASE WHEN label = 'LACTATE' THEN valuenum ELSE null END) as LACTATE
  , avg(CASE WHEN label = 'PLATELET' THEN valuenum ELSE null END) as PLATELET
  , avg(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE null END) as POTASSIUM
  , avg(CASE WHEN label = 'PTT' THEN valuenum ELSE null END) as PTT
  , avg(CASE WHEN label = 'INR' THEN valuenum ELSE null END) as INR
  , avg(CASE WHEN label = 'PT' THEN valuenum ELSE null END) as PT
  , avg(CASE WHEN label = 'SODIUM' THEN valuenum ELSE null end) as SODIUM
  , avg(CASE WHEN label = 'BUN' THEN valuenum ELSE null end) as BUN
  , avg(CASE WHEN label = 'WBC' THEN valuenum ELSE null end) as WBC
FROM
( -- begin query that extracts the data
  SELECT le.subject_id, le.hadm_id, le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
  , CASE
        WHEN itemid = 50868 THEN 'ANION GAP'
        WHEN itemid = 50862 THEN 'ALBUMIN'
        WHEN itemid = 51144 THEN 'BANDS'
        WHEN itemid = 50882 THEN 'BICARBONATE'
        WHEN itemid = 50885 THEN 'BILIRUBIN'
        WHEN itemid = 50912 THEN 'CREATININE'
        -- exclude blood gas
        -- WHEN itemid = 50806 THEN 'CHLORIDE'
        WHEN itemid = 50902 THEN 'CHLORIDE'
        -- exclude blood gas
        -- WHEN itemid = 50809 THEN 'GLUCOSE'
        WHEN itemid = 50931 THEN 'GLUCOSE'
        -- exclude blood gas
        --WHEN itemid = 50810 THEN 'HEMATOCRIT'
        WHEN itemid = 51221 THEN 'HEMATOCRIT'
        -- exclude blood gas
        --WHEN itemid = 50811 THEN 'HEMOGLOBIN'
        WHEN itemid = 51222 THEN 'HEMOGLOBIN'
        WHEN itemid = 50813 THEN 'LACTATE'
        WHEN itemid = 51265 THEN 'PLATELET'
        -- exclude blood gas
        -- WHEN itemid = 50822 THEN 'POTASSIUM'
        WHEN itemid = 50971 THEN 'POTASSIUM'
        WHEN itemid = 51275 THEN 'PTT'
        WHEN itemid = 51237 THEN 'INR'
        WHEN itemid = 51274 THEN 'PT'
        -- exclude blood gas
        -- WHEN itemid = 50824 THEN 'SODIUM'
        WHEN itemid = 50983 THEN 'SODIUM'
        WHEN itemid = 51006 THEN 'BUN'
        WHEN itemid = 51300 THEN 'WBC'
        WHEN itemid = 51301 THEN 'WBC'
      ELSE null
    END AS label
  , -- add in some sanity checks on the values
  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks
    CASE
      WHEN itemid = 50862 and valuenum >    10 THEN null -- g/dL 'ALBUMIN'
      WHEN itemid = 50868 and valuenum > 10000 THEN null -- mEq/L 'ANION GAP'
      WHEN itemid = 51144 and valuenum <     0 THEN null -- immature band forms, %
      WHEN itemid = 51144 and valuenum >   100 THEN null -- immature band forms, %
      WHEN itemid = 50882 and valuenum > 10000 THEN null -- mEq/L 'BICARBONATE'
      WHEN itemid = 50885 and valuenum >   150 THEN null -- mg/dL 'BILIRUBIN'
      WHEN itemid = 50806 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50902 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50912 and valuenum >   150 THEN null -- mg/dL 'CREATININE'
      WHEN itemid = 50809 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50931 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50810 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 51221 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 50811 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 51222 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 50813 and valuenum >    50 THEN null -- mmol/L 'LACTATE'
      WHEN itemid = 51265 and valuenum > 10000 THEN null -- K/uL 'PLATELET'
      WHEN itemid = 50822 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 50971 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 51275 and valuenum >   150 THEN null -- sec 'PTT'
      WHEN itemid = 51237 and valuenum >    50 THEN null -- 'INR'
      WHEN itemid = 51274 and valuenum >   150 THEN null -- sec 'PT'
      WHEN itemid = 50824 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 50983 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 51006 and valuenum >   300 THEN null -- 'BUN'
      WHEN itemid = 51300 and valuenum >  1000 THEN null -- 'WBC'
      WHEN itemid = 51301 and valuenum >  1000 THEN null -- 'WBC'
    ELSE valuenum
    END AS valuenum
  FROM labevents le
  WHERE le.ITEMID in
  (
    -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS
    50868, -- ANION GAP | CHEMISTRY | BLOOD | 769895
    50862, -- ALBUMIN | CHEMISTRY | BLOOD | 146697
    51144, -- BANDS - hematology
    50882, -- BICARBONATE | CHEMISTRY | BLOOD | 780733
    50885, -- BILIRUBIN, TOTAL | CHEMISTRY | BLOOD | 238277
    50912, -- CREATININE | CHEMISTRY | BLOOD | 797476
    50902, -- CHLORIDE | CHEMISTRY | BLOOD | 795568
    -- 50806, -- CHLORIDE, WHOLE BLOOD | BLOOD GAS | BLOOD | 48187
    50931, -- GLUCOSE | CHEMISTRY | BLOOD | 748981
    -- 50809, -- GLUCOSE | BLOOD GAS | BLOOD | 196734
    51221, -- HEMATOCRIT | HEMATOLOGY | BLOOD | 881846
    -- 50810, -- HEMATOCRIT, CALCULATED | BLOOD GAS | BLOOD | 89715
    51222, -- HEMOGLOBIN | HEMATOLOGY | BLOOD | 752523
    -- 50811, -- HEMOGLOBIN | BLOOD GAS | BLOOD | 89712
    50813, -- LACTATE | BLOOD GAS | BLOOD | 187124
    51265, -- PLATELET COUNT | HEMATOLOGY | BLOOD | 778444
    50971, -- POTASSIUM | CHEMISTRY | BLOOD | 845825
    -- 50822, -- POTASSIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 192946
    51275, -- PTT | HEMATOLOGY | BLOOD | 474937
    51237, -- INR(PT) | HEMATOLOGY | BLOOD | 471183
    51274, -- PT | HEMATOLOGY | BLOOD | 469090
    50983, -- SODIUM | CHEMISTRY | BLOOD | 808489
    -- 50824, -- SODIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 71503
    51006, -- UREA NITROGEN | CHEMISTRY | BLOOD | 791925
    51301, -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301
    51300  -- WBC COUNT | HEMATOLOGY | BLOOD | 2371
  )
  AND valuenum IS NOT NULL AND valuenum > 0 -- lab values cannot be 0 and cannot be negative
) pvt
GROUP BY pvt.subject_id, pvt.charttime
)
select
  iid.icustay_id, adm.hadm_id, le_avg.*
from le_avg
left join adm
  on le_avg.subject_id  = adm.subject_id
  and le_avg.charttime >= adm.data_start
  and le_avg.charttime  < adm.data_end
left join iid_assign iid
  on  le_avg.subject_id = iid.subject_id
  and le_avg.charttime >= iid.data_start
  and le_avg.charttime  < iid.data_end
order by le_avg.subject_id, le_avg.charttime
  );
17:38:53.409954 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.08 seconds
17:38:53.415690 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.415922 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab" rename to "pivoted_lab__dbt_backup"
17:38:53.418428 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.421735 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.422019 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab__dbt_tmp" rename to "pivoted_lab"
17:38:53.422856 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:53.425995 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:38:53.426208 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.426315 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:38:53.428546 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:53.431118 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:38:53.431335 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
drop table if exists "postgres"."public"."pivoted_lab__dbt_backup" cascade
17:38:53.433136 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:53.436380 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.436606 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: Close
17:38:53.437406 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c478bdf0>]}
17:38:53.437881 [info ] [Thread-1  ]: 7 of 13 OK created table model public.pivoted_lab .............................. [[32mSELECT 0[0m in 0.13s]
17:38:53.438324 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_lab
17:38:53.438463 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_rrt
17:38:53.439151 [info ] [Thread-1  ]: 8 of 13 START table model public.pivoted_rrt ................................... [RUN]
17:38:53.439936 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_rrt"
17:38:53.440172 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_rrt
17:38:53.440448 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_rrt
17:38:53.442737 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_rrt"
17:38:53.443399 [debug] [Thread-1  ]: finished collecting timing info
17:38:53.443703 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_rrt
17:38:53.455195 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_rrt"
17:38:53.456089 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:53.456458 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: BEGIN
17:38:53.456789 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:53.462219 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:53.462504 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:53.462783 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */


  create  table "postgres"."public"."pivoted_rrt__dbt_tmp"
  as (
    -- Creates a table with icustay_id / time / dialysis type (if present)

with ce as
(
  select ce.icustay_id
    , ce.charttime
          -- when ce.itemid in (152,148,149,146,147,151,150) and value is not null then 1
          -- when ce.itemid in (229,235,241,247,253,259,265,271) and value = 'Dialysis Line' then 1
          -- when ce.itemid = 466 and value = 'Dialysis RN' then 1
          -- when ce.itemid = 927 and value = 'Dialysis Solutions' then 1
          -- when ce.itemid = 6250 and value = 'dialys' then 1
          -- when ce.
          -- when ce.itemid = 582 and value in ('CAVH Start','CAVH D/C','CVVHD Start','CVVHD D/C','Hemodialysis st','Hemodialysis end') then 1
    , CASE
        WHEN ce.itemid IN
        (
          146 -- "Dialysate Flow ml/hr"
          , 147 -- "Dialysate Infusing";56605
          , 148 -- "Dialysis Access Site";60335
          , 149 -- "Dialysis Access Type";60030
          , 150 -- "Dialysis Machine";27472 (baxter or gambro)
          , 151 -- "Dialysis Site Appear";37345
          , 152 -- "Dialysis Type";61449
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid IN (229, 235, 241, 247, 253, 259, 265, 271) AND value = 'Dialysis Line' 
          THEN 1
        -- WHEN ce.itemid = 917 AND value IN
        -- (
        --   '+ INITIATE DIALYSIS', 'BLEEDING FROM DIALYSIS CATHETER',
        --   -- 'FAILED DIALYSIS CATH.',
        --   'FEBRILE SYNDROME;DIALYSIS', 'HYPOTENSION WITH HEMODIALYSIS',
        --   'HYPOTENSION.GLOGGED DIALYSIS',
        --   'INFECTED DIALYSIS CATHETER'
        -- )
        -- metavision itemids

        -- checkboxes
        WHEN ce.itemid IN
        (
            226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
          , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
          , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox
        ) THEN 1
        -- numeric data
        WHEN ce.itemid IN
        (
            226499 -- | Hemodialysis Output                               | Dialysis
          , 224154 -- | Dialysate Rate                                    | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224149 -- | Access Pressure                  | Dialysis
          , 224150 -- | Filter Pressure                  | Dialysis
          , 224151 -- | Effluent Pressure                | Dialysis
          , 224152 -- | Return Pressure                  | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 224404 -- | ART Lumen Volume                 | Dialysis
          , 224406 -- | VEN Lumen Volume                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1

        -- text fields
        WHEN ce.itemid IN
        (
            224135 -- | Dialysis Access Site | Dialysis
          , 224139 -- | Dialysis Site Appearance | Dialysis
          , 224146 -- | System Integrity | Dialysis
          , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive
          , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive
          , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225954 -- | Dialysis Access Type | Dialysis
          , 225956 -- | Reason for CRRT Filter Change | Dialysis
          , 225958 -- | Heparin Concentration (units/mL) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 225976 -- | Replacement Fluid | Dialysis
          , 225977 -- | Dialysate Fluid | Dialysis
          , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive
          , 227290 -- | CRRT mode | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
          , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive
        ) THEN 1
      ELSE 0 END
      AS dialysis_present
    , CASE
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end'
        ) THEN 0
        WHEN ce.itemid = 147 AND value = 'Yes' THEN 1 -- "Dialysate Infusing";56605
        WHEN ce.itemid = 225965 -- Peritoneal Dialysis Catheter Status
          AND value = 'In use' THEN 1
        WHEN ce.itemid IN
        (
            146    -- Dialysate Flow ml/hr
          , 226499 -- | Hemodialysis Output              | Dialysis
          , 224154 -- | Dialysate Rate                   | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1
      ELSE 0 END
      AS dialysis_active
    , CASE
        -- dialysis mode
        WHEN ce.itemid in (152, 227290) THEN
          CASE
            WHEN value = 'CVVH' THEN 'CVVH'
            WHEN value = 'CVVHD' THEN 'CVVHD'
            WHEN value = 'CVVHDF' THEN 'CVVHDF'
            WHEN value = 'SCUF' THEN 'SCUF'
            WHEN value = 'Peritoneal' THEN 'Peritoneal'
          END
        -- itemids which imply a certain dialysis mode

        -- peritoneal dialysis
        WHEN ce.itemid IN 
        (
            225810 -- | Dwell Time (Peritoneal Dialysis) | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
        )
          THEN 'Peritoneal'
        WHEN ce.itemid IN (226499)
          THEN 'IHD'
        WHEN ce.itemid = 582 THEN
          CASE
            WHEN value IN ('CAVH Start','CAVH D/C')
              THEN 'CAVH'
            WHEN value IN ('CVVHD Start','CVVHD D/C')
              THEN 'CVVHD'
            WHEN value IN ('Hemodialysis st', 'Hemodialysis end')
              -- null is ambiguous
              THEN NULL
          ELSE NULL
          END
      ELSE NULL END as dialysis_type
  from chartevents ce
  WHERE ce.itemid in
  (
     152 -- "Dialysis Type";61449
    ,146 -- "Dialysate Flow ml/hr";57445
    ,147 -- "Dialysate Infusing";56605
    ,148 -- "Dialysis Access Site";60335
    ,149 -- "Dialysis Access Type";60030
    ,150 -- "Dialysis Machine";27472 (baxter or gambro)
    ,151 -- "Dialysis Site Appear";37345
    ,582 -- Procedures
    -- below indicate existence of a dialysis line
    ,229 -- INV Line#1 [Type]
    ,235 -- INV Line#2 [Type]
    ,241 -- INV Line#3 [Type]
    ,247 -- INV Line#4 [Type]
    ,253 -- INV Line#5 [Type]
    ,259 -- INV Line#6 [Type]
    ,265 -- INV Line#7 [Type]
    ,271 -- INV Line#8 [Type]
    
    -- dialysis consults can't be 100% guaranteed to be active
    -- ,466 -- Nursing Consultation
    -- diagnosis has 6 or 7 dx related to dialysis, probably not worth including
    -- as the chart time isn't going to match the start time of dialysis
    -- , 917 -- Diagnosis/op
    -- ,7949 -- "Calcium for CVVH" - only has 2 null values
    
    -- === MetaVision itemids === --
  
    -- Checkboxes
    , 226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
    , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
    , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox

    -- Numeric values
    , 226499 -- | Hemodialysis Output                               | Dialysis                | chartevents        | Numeric
    , 224154 -- | Dialysate Rate                                    | Dialysis                | chartevents        | Numeric
    , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis                | chartevents        | Numeric
    , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis                | chartevents        | Numeric
    , 225183 -- | Current Goal                     | Dialysis | chartevents        | Numeric
    , 227438 -- | Volume not removed               | Dialysis | chartevents        | Numeric
    , 224191 -- | Hourly Patient Fluid Removal     | Dialysis | chartevents        | Numeric
    , 225806 -- | Volume In (PD)                   | Dialysis | chartevents        | Numeric
    , 225807 -- | Volume Out (PD)                  | Dialysis | chartevents        | Numeric
    , 228004 -- | Citrate (ACD-A)                  | Dialysis | chartevents        | Numeric
    , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis | chartevents        | Numeric
    , 228006 -- | Post Filter Replacement Rate     | Dialysis | chartevents        | Numeric
    , 224144 -- | Blood Flow (ml/min)              | Dialysis | chartevents        | Numeric
    , 224145 -- | Heparin Dose (per hour)          | Dialysis | chartevents        | Numeric
    , 224149 -- | Access Pressure                  | Dialysis | chartevents        | Numeric
    , 224150 -- | Filter Pressure                  | Dialysis | chartevents        | Numeric
    , 224151 -- | Effluent Pressure                | Dialysis | chartevents        | Numeric
    , 224152 -- | Return Pressure                  | Dialysis | chartevents        | Numeric
    , 224153 -- | Replacement Rate                 | Dialysis | chartevents        | Numeric
    , 224404 -- | ART Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 224406 -- | VEN Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 226457 -- | Ultrafiltrate Output             | Dialysis | chartevents        | Numeric
    , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis | chartevents | Numeric
    -- Text values
    , 224135 -- | Dialysis Access Site | Dialysis | chartevents | Text
    , 224139 -- | Dialysis Site Appearance | Dialysis | chartevents | Text
    , 224146 -- | System Integrity | Dialysis | chartevents | Text
    , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive | chartevents | Text
    , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive | chartevents | Text
    , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive | chartevents | Text
    , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis | chartevents | Text
    , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225954 -- | Dialysis Access Type | Dialysis | chartevents | Text
    , 225956 -- | Reason for CRRT Filter Change | Dialysis | chartevents | Text
    , 225958 -- | Heparin Concentration (units/mL) | Dialysis | chartevents | Text
    , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis | chartevents | Text
    , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis | chartevents | Text
    , 225976 -- | Replacement Fluid | Dialysis | chartevents | Text
    , 225977 -- | Dialysate Fluid | Dialysis | chartevents | Text
    , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive | chartevents | Text
    , 227290 -- | CRRT mode | Dialysis | chartevents | Text
    , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive | chartevents | Text
  )
  AND ce.value IS NOT NULL
  AND ce.icustay_id IS NOT NULL
  -- exclude rows marked as error
  and COALESCE(ce.error, 0) = 0
)

-- TODO:
--   charttime + dialysis_present + dialysis_active
--  for inputevents_cv, outputevents
--  for procedures_mv, left join and set the dialysis_type
, cv_ie as
(
  select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          44954 -- OR CVVHDF |  | inputevents_cv
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
            40788 -- PD dialysate in | Free Form Intake | inputevents_cv
          , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
          , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
          , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
          , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
          , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
        ) THEN 'Peritoneal'
        WHEN itemid IN
        (
            45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
          , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
        ) THEN 'CVVH'
        WHEN itemid IN
        (
            45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
          , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
          , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
        ) THEN 'CVVHD'
        WHEN itemid IN
        (
            46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
          , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
          , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
          , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
        ) THEN 'CVVHDF'
      ELSE NULL END AS dialysis_type
  from inputevents_cv
  where itemid in
  (
        40788 -- PD dialysate in | Free Form Intake | inputevents_cv
      , 40907 -- dialysate | Free Form Intake | inputevents_cv
      , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
      , 41147 -- Dialysate instilled | Free Form Intake | inputevents_cv
      , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
      , 41460 -- capd dialysate | Free Form Intake | inputevents_cv
      , 41620 -- dialysate in | Free Form Intake | inputevents_cv
      , 41711 -- CAPD dialysate dwell | Free Form Intake | inputevents_cv
      , 41791 -- 2.5% dialysate in | Free Form Intake | inputevents_cv
      , 41792 -- 1.5% dialysate | Free Form Intake | inputevents_cv
      , 42562 -- pos. dialysate intak | Free Form Intake | inputevents_cv
      , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
      , 44037 -- Dialysate Instilled | Free Form Intake | inputevents_cv
      , 44188 -- rep.+dialysate | Free Form Intake | inputevents_cv
      , 44526 -- dialysate 1.5% dex | Free Form Intake | inputevents_cv
      , 44527 -- dialysate 2.5% | Free Form Intake | inputevents_cv
      , 44584 -- Dialysate IN | Free Form Intake | inputevents_cv
      , 44591 -- dialysate 4.25% | Free Form Intake | inputevents_cv
      , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
      , 44927 -- CRRT HEPARIN | Free Form Intake | inputevents_cv
      , 44954 -- OR CVVHDF |  | inputevents_cv
      , 45157 -- ca+ gtt for cvvh | Free Form Intake | inputevents_cv
      , 45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
      , 45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
      , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
      , 46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
      , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
      , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
      , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
      , 46250 -- EBL  CVVH |  | inputevents_cv
      , 46262 -- dialysate 2.5% in | Free Form Intake | inputevents_cv
      , 46292 -- CRRT Irrigation | Free Form Intake | inputevents_cv
      , 46293 -- CRRT Citrate | Free Form Intake | inputevents_cv
      , 46311 -- crrt irrigation | Free Form Intake | inputevents_cv
      , 46389 -- CRRT FLUSH | Free Form Intake | inputevents_cv
      , 46574 -- CRRT rescue line NS | Free Form Intake | inputevents_cv
      , 46681 -- CRRT Rescue Flush | Free Form Intake | inputevents_cv
      , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
      , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
      , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
  )
  and amount > 0 -- also ensures it's not null
)
, oe as
(
 select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          41897 -- CVVH OUTPUT FROM OR
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
          40789 -- PD dialysate out
        , 40910 -- PERITONEAL DIALYSIS
        , 41069 -- PD Dialysate Output
        , 44843 -- peritoneal dialysis
        , 46394 -- Peritoneal dialysis
        ) THEN 'Peritoneal'
      ELSE NULL END AS dialysis_type
 from outputevents
 where itemid in
 (
       40386 -- hemodialysis
     , 40425 -- dialysis output
     , 40426 -- dialysis out
     , 40507 -- Dialysis out
     , 40613 -- DIALYSIS OUT
     , 40624 -- dialysis
     , 40690 -- DIALYSIS
     , 40745 -- Dialysis
     , 40789 -- PD dialysate out
     , 40881 -- Hemodialysis
     , 40910 -- PERITONEAL DIALYSIS
     , 41016 -- hemodialysis out
     , 41034 -- dialysis in
     , 41069 -- PD Dialysate Output
     , 41112 -- Dialysys out
     , 41250 -- HEMODIALYSIS OUT
     , 41374 -- Dialysis Out
     , 41417 -- Hemodialysis Out
     , 41500 -- hemodialysis output
     , 41527 -- HEMODIALYSIS
     , 41623 -- dialysate out
     , 41635 -- Hemodialysis removal
     , 41713 -- dialyslate out
     , 41750 -- dialysis  out
     , 41829 -- HEMODIALYSIS OUTPUT
     , 41842 -- Dialysis Output.
     , 41897 -- CVVH OUTPUT FROM OR
     , 42289 -- dialysis off
     , 42388 -- DIALYSIS OUTPUT
     , 42464 -- hemodialysis ultrafe
     , 42524 -- HemoDialysis
     , 42536 -- Dialysis output
     , 42868 -- hemodialysis off
     , 42928 -- HEMODIALYSIS.
     , 42972 -- HEMODIALYSIS OFF
     , 43016 -- DIALYSIS TOTAL OUT
     , 43052 -- DIALYSIS REMOVED
     , 43098 -- hemodialysis crystal
     , 43115 -- dialysis net
     , 43687 -- crystalloid/dialysis
     , 43941 -- dialysis/intake
     , 44027 -- dialysis fluid off
     , 44085 -- DIALYSIS OFF
     , 44193 -- Dialysis.
     , 44199 -- HEMODIALYSIS O/P
     , 44216 -- Hemodialysis out
     , 44286 -- Dialysis indwelling
     , 44567 -- Hemodialysis.
     , 44843 -- peritoneal dialysis
     , 44845 -- Dialysis fluids
     , 44857 -- dialysis- fluid off
     , 44901 -- Dialysis Removed
     , 44943 -- fluid removed dialys
     , 45479 -- Dialysis In
     , 45828 -- Hemo dialysis out
     , 46230 -- Dialysis 1.5% IN
     , 46232 -- dialysis flush
     , 46394 -- Peritoneal dialysis
     , 46464 -- Hemodialysis OUT
     , 46712 -- CALCIUM-DIALYSIS
     , 46713 -- KCL-10 MEQ-DIALYSIS
     , 46715 -- Citrate - dialysis
     , 46741 -- dialysis removed
 )
 and value > 0 -- also ensures it's not null
)
, mv_ranges as
(
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , 1 AS dialysis_active
    , 'CRRT' as dialysis_type
  from inputevents_mv
  where itemid in
  (
      227536 --	KCl (CRRT)	Medications	inputevents_mv	Solution
    , 227525 --	Calcium Gluconate (CRRT)	Medications	inputevents_mv	Solution
  )
  and amount > 0 -- also ensures it's not null
  UNION DISTINCT
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , CASE WHEN itemid NOT IN (224270, 225436) THEN 1 ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid = 225441 THEN 'IHD'
        WHEN itemid = 225802 THEN 'CRRT'  -- CVVH (Continuous venovenous hemofiltration)
        WHEN itemid = 225803 THEN 'CVVHD' -- CVVHD (Continuous venovenous hemodialysis)
        WHEN itemid = 225805 THEN 'Peritoneal'
        WHEN itemid = 225809 THEN 'CVVHDF' -- CVVHDF (Continuous venovenous hemodiafiltration)
        WHEN itemid = 225955 THEN 'SCUF' -- SCUF (Slow continuous ultra filtration)
      ELSE NULL END as dialysis_type
  from procedureevents_mv
  where itemid in
  (
      225441 -- | Hemodialysis          | 4-Procedures              | procedureevents_mv | Process
    , 225802 -- | Dialysis - CRRT       | Dialysis                  | procedureevents_mv | Process
    , 225803 -- | Dialysis - CVVHD      | Dialysis                  | procedureevents_mv | Process
    , 225805 -- | Peritoneal Dialysis   | Dialysis                  | procedureevents_mv | Process
    , 224270 -- | Dialysis Catheter     | Access Lines - Invasive   | procedureevents_mv | Process
    , 225809 -- | Dialysis - CVVHDF     | Dialysis                  | procedureevents_mv | Process
    , 225955 -- | Dialysis - SCUF       | Dialysis                  | procedureevents_mv | Process
    , 225436 -- | CRRT Filter Change    | Dialysis                  | procedureevents_mv | Process
  )
  AND value IS NOT NULL
)
-- union together the charttime tables; append times from mv_ranges to guarantee they exist
, stg0 AS
(
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM ce
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM cv_ie
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM oe
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, starttime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
  UNION DISTINCT
  SELECT
    icustay_id, endtime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
)
SELECT
    stg0.icustay_id
    , charttime
    , COALESCE(mv.dialysis_present, stg0.dialysis_present) AS dialysis_present
    , COALESCE(mv.dialysis_active, stg0.dialysis_active) AS dialysis_active
    , COALESCE(mv.dialysis_type, stg0.dialysis_type) AS dialysis_type
FROM stg0
LEFT JOIN mv_ranges mv
  ON stg0.icustay_id = mv.icustay_id
  AND stg0.charttime >= mv.starttime
  AND stg0.charttime <= mv.endtime
WHERE stg0.icustay_id IS NOT NULL
ORDER BY 1,2
  );
17:38:56.393315 [debug] [Thread-1  ]: SQL status: SELECT 301513 in 2.93 seconds
17:38:56.399991 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:56.400193 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt" rename to "pivoted_rrt__dbt_backup"
17:38:56.400969 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:56.404661 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:56.404935 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt__dbt_tmp" rename to "pivoted_rrt"
17:38:56.405672 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:56.408909 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:38:56.409097 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:56.409334 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:38:56.413017 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:56.415041 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:38:56.415249 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
drop table if exists "postgres"."public"."pivoted_rrt__dbt_backup" cascade
17:38:56.417296 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:56.420219 [debug] [Thread-1  ]: finished collecting timing info
17:38:56.420449 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: Close
17:38:56.421181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c478bee0>]}
17:38:56.421650 [info ] [Thread-1  ]: 8 of 13 OK created table model public.pivoted_rrt .............................. [[32mSELECT 301513[0m in 2.98s]
17:38:56.422095 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_rrt
17:38:56.422382 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_sofa
17:38:56.423149 [info ] [Thread-1  ]: 9 of 13 START table model public.pivoted_sofa .................................. [RUN]
17:38:56.424023 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_sofa"
17:38:56.424475 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_sofa
17:38:56.424824 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_sofa
17:38:56.427172 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_sofa"
17:38:56.428001 [debug] [Thread-1  ]: finished collecting timing info
17:38:56.428304 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_sofa
17:38:56.438449 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_sofa"
17:38:56.439288 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:38:56.439555 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: BEGIN
17:38:56.439815 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:56.445948 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:56.446748 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:38:56.447012 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_sofa"} */


  create  table "postgres"."public"."pivoted_sofa__dbt_tmp"
  as (
    ﻿with co as
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
-- get minimum blood pressure FROM chartevents
, bp as
(
  select ce.icustay_id
    , ce.charttime
    , min(valuenum) as meanbp_min
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.itemid in
  (
  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312  --"ART BP mean"
  )
  and valuenum > 0 and valuenum < 300
  group by ce.icustay_id, ce.charttime
)
, pafi as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select ie.icustay_id
  , bg.charttime
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , case when vd.icustay_id is null then pao2fio2ratio else null end pao2fio2ratio_novent
  , case when vd.icustay_id is not null then pao2fio2ratio else null end pao2fio2ratio_vent
  FROM icustays ie
  inner join pivoted_bg_art bg
    on ie.icustay_id = bg.icustay_id
  left join ventilation_durations vd
    on ie.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(bp.meanbp_min) as meanbp_min
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- labs
  , max(labs.bilirubin) as bilirubin_max
  , max(labs.creatinine) as creatinine_max
  , min(labs.platelet) as platelet_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , min(case when vd.icustay_id is null then pao2fio2ratio else null end) AS pao2fio2ratio_novent
  , min(case when vd.icustay_id is not null then pao2fio2ratio else null end) AS pao2fio2ratio_vent
  from co
  left join bp
    on co.icustay_id = bp.icustay_id
    and co.starttime < bp.charttime
    and co.endtime >= bp.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  left join pivoted_lab labs
    on co.hadm_id = labs.hadm_id
    and co.starttime < labs.charttime
    and co.endtime >= labs.charttime
  -- bring in blood gases that occurred during this hour
  left join pivoted_bg_art bg
    on co.icustay_id = bg.icustay_id
    and co.starttime < bg.charttime
    and co.endtime >= bg.charttime
  -- at the time of the blood gas, determine if patient was ventilated
  left join ventilation_durations vd
    on co.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.pao2fio2ratio_novent
    , ma.pao2fio2ratio_vent
    , epi.vaso_rate as rate_epinephrine
    , nor.vaso_rate as rate_norepinephrine
    , dop.vaso_rate as rate_dopamine
    , dob.vaso_rate as rate_dobutamine
    , ma.meanbp_min
    , ma.GCS_min
    -- uo
    , uo.urineoutput
    -- labs
    , ma.bilirubin_max
    , ma.creatinine_max
    , ma.platelet_min
  from co
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
  left join pafi
    on co.icustay_id = pafi.icustay_id
    and co.starttime < pafi.charttime
    and co.endtime  >= pafi.charttime
  left join epinephrine_dose epi
    on co.icustay_id = epi.icustay_id
    and co.endtime > epi.starttime
    and co.endtime <= epi.endtime
  left join norepinephrine_dose nor
    on co.icustay_id = nor.icustay_id
    and co.endtime > nor.starttime
    and co.endtime <= nor.endtime
  left join dopamine_dose dop
    on co.icustay_id = dop.icustay_id
    and co.endtime > dop.starttime
    and co.endtime <= dop.endtime
  left join dobutamine_dose dob
    on co.icustay_id = dob.icustay_id
    and co.endtime > dob.starttime
    and co.endtime <= dob.endtime
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
  -- Respiration
  , cast(case
      when pao2fio2ratio_vent   < 100 then 4
      when pao2fio2ratio_vent   < 200 then 3
      when pao2fio2ratio_novent < 300 then 2
      when pao2fio2ratio_novent < 400 then 1
      when coalesce(pao2fio2ratio_vent, pao2fio2ratio_novent) is null then null
      else 0
    end as SMALLINT) as respiration

  -- Coagulation
  , cast(case
      when platelet_min < 20  then 4
      when platelet_min < 50  then 3
      when platelet_min < 100 then 2
      when platelet_min < 150 then 1
      when platelet_min is null then null
      else 0
    end as SMALLINT) as coagulation

  -- Liver
  , cast(case
      -- Bilirubin checks in mg/dL
        when Bilirubin_Max >= 12.0 then 4
        when Bilirubin_Max >= 6.0  then 3
        when Bilirubin_Max >= 2.0  then 2
        when Bilirubin_Max >= 1.2  then 1
        when Bilirubin_Max is null then null
        else 0
      end as SMALLINT) as liver

  -- Cardiovascular
  , cast(case
      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4
      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3
      when rate_dopamine >  0 or rate_dobutamine > 0 then 2
      when meanbp_min < 70 then 1
      when coalesce(meanbp_min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null
      else 0
    end as SMALLINT) as cardiovascular

  -- Neurological failure (GCS)
  , cast(case
      when (GCS_min >= 13 and GCS_min <= 14) then 1
      when (GCS_min >= 10 and GCS_min <= 12) then 2
      when (GCS_min >=  6 and GCS_min <=  9) then 3
      when  GCS_min <   6 then 4
      when  GCS_min is null then null
  else 0 end as SMALLINT)
    as cns

  -- Renal failure - high creatinine or low urine output
  , cast(case
    when (Creatinine_Max >= 5.0) then 4
    when
      SUM(urineoutput) OVER W < 200
        then 4
    when (Creatinine_Max >= 3.5 and Creatinine_Max < 5.0) then 3
    when
      SUM(urineoutput) OVER W < 500
        then 3
    when (Creatinine_Max >= 2.0 and Creatinine_Max < 3.5) then 2
    when (Creatinine_Max >= 1.2 and Creatinine_Max < 2.0) then 1
    when coalesce
      (
        SUM(urineoutput) OVER W
        , Creatinine_Max
      ) is null then null
  else 0 end as SMALLINT)
    as renal
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Combine all the scores to get SOFA
    -- Impute 0 if the score is missing
   -- the window function takes the max over the last 24 hours
    , cast(coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as respiration_24hours
     , cast(coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
        ,0) as SMALLINT) as coagulation_24hours
    , cast(coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as liver_24hours
    , cast(coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cardiovascular_24hours
    , cast(coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cns_24hours
    , cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as renal_24hours

    -- sum together data for final SOFA
    , coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT)
    as sofa_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:38:56.448525 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "﻿with"
LINE 6:     ﻿with co as
            ^

17:38:56.448943 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: ROLLBACK
17:38:56.449460 [debug] [Thread-1  ]: finished collecting timing info
17:38:56.449806 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: Close
17:38:56.450301 [debug] [Thread-1  ]: Database Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)
  syntax error at or near "﻿with"
  LINE 6:     ﻿with co as
              ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:38:56.451030 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c46a0c70>]}
17:38:56.452138 [error] [Thread-1  ]: 9 of 13 ERROR creating table model public.pivoted_sofa ......................... [[31mERROR[0m in 0.03s]
17:38:56.452682 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_sofa
17:38:56.453149 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_uo
17:38:56.453763 [info ] [Thread-1  ]: 10 of 13 START table model public.pivoted_uo ................................... [RUN]
17:38:56.454442 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_uo"
17:38:56.454808 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_uo
17:38:56.455047 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_uo
17:38:56.456321 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_uo"
17:38:56.456768 [debug] [Thread-1  ]: finished collecting timing info
17:38:56.457023 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_uo
17:38:56.468300 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_uo"
17:38:56.469046 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:56.469176 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: BEGIN
17:38:56.469271 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:56.474478 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:56.474870 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:56.475081 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */


  create  table "postgres"."public"."pivoted_uo__dbt_tmp"
  as (
    select
  icustay_id
  , charttime
  , sum(urineoutput) as urineoutput
from
(
  select
  -- patient identifiers
    oe.icustay_id
  , oe.charttime 
  -- volumes associated with urine output ITEMIDs
  -- note we consider input of GU irrigant as a negative volume
  , case
      when oe.itemid = 227488 and oe.value > 0 then -1*oe.value
      else oe.value
    end as urineoutput
  from outputevents oe
-- exclude rows marked as error
where (oe.iserror IS NULL OR oe.iserror != 1)
  and itemid in
  (
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in CareVue
  226559, -- "Foley"
  226560, -- "Void"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- R Ureteral Stent
  226558, -- L Ureteral Stent
  227488, -- GU Irrigant Volume In
  227489  -- GU Irrigant/Urine Volume Out
  )
) as foo
group by icustay_id, charttime
order by icustay_id, charttime
  );
17:38:59.384855 [debug] [Thread-1  ]: SQL status: SELECT 3381677 in 2.91 seconds
17:38:59.391980 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:59.392377 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo" rename to "pivoted_uo__dbt_backup"
17:38:59.393457 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.397044 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:59.397228 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo__dbt_tmp" rename to "pivoted_uo"
17:38:59.397938 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.401207 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:38:59.401396 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:59.401501 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:38:59.421072 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
17:38:59.423861 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:38:59.424272 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
drop table if exists "postgres"."public"."pivoted_uo__dbt_backup" cascade
17:38:59.430445 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:38:59.433796 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.434019 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: Close
17:38:59.434830 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c47911f0>]}
17:38:59.435310 [info ] [Thread-1  ]: 10 of 13 OK created table model public.pivoted_uo .............................. [[32mSELECT 3381677[0m in 2.98s]
17:38:59.435863 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_uo
17:38:59.436257 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_vital
17:38:59.436660 [info ] [Thread-1  ]: 11 of 13 START table model public.pivoted_vital ................................ [RUN]
17:38:59.437640 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_vital"
17:38:59.437984 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_vital
17:38:59.438217 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_vital
17:38:59.439461 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_vital"
17:38:59.440198 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.440453 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_vital
17:38:59.453177 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_vital"
17:38:59.453936 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.454146 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: BEGIN
17:38:59.454251 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:59.459872 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:59.460398 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.460948 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */


  create  table "postgres"."public"."pivoted_vital__dbt_tmp"
  as (
    -- This query pivots the vital signs for the first 24 hours of a patient's stay
-- Vital signs include heart rate, blood pressure, respiration rate, and temperature

with ce as
(
  select ce.icustay_id
    , ce.charttime
    , (case when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then valuenum else null end) as heartrate
    , (case when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then valuenum else null end) as sysbp
    , (case when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then valuenum else null end) as diasbp
    , (case when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then valuenum else null end) as meanbp
    , (case when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then valuenum else null end) as resprate
    , (case when itemid in (223761,678) and valuenum > 70 and valuenum < 120 then (valuenum-32)/1.8 -- converted to degC in valuenum call
               when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then valuenum else null end) as tempc
    , (case when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then valuenum else null end) as spo2
    , (case when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then valuenum else null end) as glucose
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
  -- HEART RATE
  211, --"Heart Rate"
  220045, --"Heart Rate"

  -- Systolic/diastolic

  51, --	Arterial BP [Systolic]
  442, --	Manual BP [Systolic]
  455, --	NBP [Systolic]
  6701, --	Arterial BP #2 [Systolic]
  220179, --	Non Invasive Blood Pressure systolic
  220050, --	Arterial Blood Pressure systolic

  8368, --	Arterial BP [Diastolic]
  8440, --	Manual BP [Diastolic]
  8441, --	NBP [Diastolic]
  8555, --	Arterial BP #2 [Diastolic]
  220180, --	Non Invasive Blood Pressure diastolic
  220051, --	Arterial Blood Pressure diastolic


  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312, --"ART BP mean"

  -- RESPIRATORY RATE
  618,--	Respiratory Rate
  615,--	Resp Rate (Total)
  220210,--	Respiratory Rate
  224690, --	Respiratory Rate (Total)


  -- spo2, peripheral
  646, 220277,

  -- glucose, both lab and fingerstick
  807,--	Fingerstick glucose
  811,--	glucose (70-105)
  1529,--	glucose
  3745,--	Bloodglucose
  3744,--	Blood glucose
  225664,--	glucose finger stick
  220621,--	glucose (serum)
  226537,--	glucose (whole blood)

  -- TEMPERATURE
  223762, -- "Temperature Celsius"
  676,	-- "Temperature C"
  223761, -- "Temperature Fahrenheit"
  678 --	"Temperature F"

  )
)
select
    ce.icustay_id
  , ce.charttime
  , avg(heartrate) as heartrate
  , avg(sysbp) as sysbp
  , avg(diasbp) as diasbp
  , avg(meanbp) as meanbp
  , avg(resprate) as resprate
  , avg(tempc) as tempc
  , avg(spo2) as spo2
  , avg(glucose) as glucose
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:38:59.474211 [debug] [Thread-1  ]: SQL status: SELECT 1045 in 0.01 seconds
17:38:59.482449 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.482960 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital" rename to "pivoted_vital__dbt_backup"
17:38:59.483738 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.488868 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.489117 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital__dbt_tmp" rename to "pivoted_vital"
17:38:59.489628 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.492883 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:38:59.493142 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.493263 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:38:59.494635 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:59.497933 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:38:59.498122 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
drop table if exists "postgres"."public"."pivoted_vital__dbt_backup" cascade
17:38:59.500020 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:59.503011 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.503255 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: Close
17:38:59.504027 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c4685d60>]}
17:38:59.504506 [info ] [Thread-1  ]: 11 of 13 OK created table model public.pivoted_vital ........................... [[32mSELECT 1045[0m in 0.07s]
17:38:59.505013 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_vital
17:38:59.505323 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg_art
17:38:59.505846 [info ] [Thread-1  ]: 12 of 13 START table model public.pivoted_bg_art ............................... [RUN]
17:38:59.506602 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg_art"
17:38:59.506908 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg_art
17:38:59.507069 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg_art
17:38:59.510901 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg_art"
17:38:59.512211 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.512453 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg_art
17:38:59.524224 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg_art"
17:38:59.524963 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.525189 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: BEGIN
17:38:59.525294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:59.531409 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:59.531685 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.531916 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */


  create  table "postgres"."public"."pivoted_bg_art__dbt_tmp"
  as (
    -- This query requires the pivoted_bg table to be generated.
-- It extracts only arterial blood gas samples - either explicitly stated or 
-- inferred by a hard-coded logistic regression model.
with stg_spo2 as
(
  select hadm_id, charttime
    -- avg here is just used to group SpO2 by charttime
    , avg(valuenum) as spo2
  FROM chartevents
  -- o2 sat
  where ITEMID in
  (
    646 -- SpO2
  , 220277 -- O2 saturation pulseoxymetry
  )
  and valuenum > 0 and valuenum <= 100
  group by hadm_id, charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , max(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
, stg2 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s1.charttime DESC) as lastrowspo2
  , s1.spo2
from "postgres"."public"."pivoted_bg" bg
left join stg_spo2 s1
  -- same hospitalization
  on  bg.hadm_id = s1.hadm_id
  -- spo2 occurred at most 2 hours before this blood gas
  and s1.charttime between DATETIME_SUB(bg.charttime, INTERVAL '2' HOUR) and bg.charttime
where bg.po2 is not null
)
, stg3 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s2.charttime DESC) as lastrowfio2
  , s2.fio2_chartevents

  -- create our specimen prediction
  ,  1/(1+exp(-(-0.02544
  +    0.04598 * po2
  + coalesce(-0.15356 * spo2             , -0.15356 *   97.49420 +    0.13429)
  + coalesce( 0.00621 * fio2_chartevents ,  0.00621 *   51.49550 +   -0.24958)
  + coalesce( 0.10559 * hemoglobin       ,  0.10559 *   10.32307 +    0.05954)
  + coalesce( 0.13251 * so2              ,  0.13251 *   93.66539 +   -0.23172)
  + coalesce(-0.01511 * pco2             , -0.01511 *   42.08866 +   -0.01630)
  + coalesce( 0.01480 * fio2             ,  0.01480 *   63.97836 +   -0.31142)
  + coalesce(-0.00200 * aado2            , -0.00200 *  442.21186 +   -0.01328)
  + coalesce(-0.03220 * bicarbonate      , -0.03220 *   22.96894 +   -0.06535)
  + coalesce( 0.05384 * totalco2         ,  0.05384 *   24.72632 +   -0.01405)
  + coalesce( 0.08202 * lactate          ,  0.08202 *    3.06436 +    0.06038)
  + coalesce( 0.10956 * ph               ,  0.10956 *    7.36233 +   -0.00617)
  + coalesce( 0.00848 * o2flow           ,  0.00848 *    7.59362 +   -0.35803)
  ))) as specimen_prob
from stg2 bg
left join stg_fio2 s2
  -- same patient
  on  bg.hadm_id = s2.hadm_id
  -- fio2 occurred at most 4 hours before this blood gas
  and s2.charttime between DATETIME_SUB(bg.charttime, INTERVAL '4' HOUR) and bg.charttime
  and s2.fio2_chartevents > 0
where bg.lastRowSpO2 = 1 -- only the row with the most recent SpO2 (if no SpO2 found lastRowSpO2 = 1)
)
select
    stg3.hadm_id
  , stg3.icustay_id
  , stg3.charttime
  , specimen -- raw data indicating sample type, only present 80% of the time
  -- prediction of specimen for missing data
  , case
        when SPECIMEN is not null then SPECIMEN
        when SPECIMEN_PROB > 0.75 then 'ART'
      else null end as specimen_pred
  , specimen_prob

  -- oxygen related parameters
  , so2, spo2 -- note spo2 is FROM chartevents
  , po2, pco2
  , fio2_chartevents, fio2
  , aado2
  -- also calculate AADO2
  , case
      when  PO2 is not null
        and pco2 is not null
        and coalesce(FIO2, fio2_chartevents) is not null
       -- multiple by 100 because FiO2 is in a % but should be a fraction
        then (coalesce(FIO2, fio2_chartevents)/100) * (760 - 47) - (pco2/0.8) - po2
      else null
    end as aado2_calc
  , case
      when PO2 is not null and coalesce(FIO2, fio2_chartevents) is not null
       -- multiply by 100 because FiO2 is in a % but should be a fraction
        then 100*PO2/(coalesce(FIO2, fio2_chartevents))
      else null
    end as pao2fio2ratio
  -- acid-base parameters
  , ph, baseexcess
  , bicarbonate, totalco2

  -- blood count parameters
  , hematocrit
  , hemoglobin
  , carboxyhemoglobin
  , methemoglobin

  -- chemistry
  , chloride, calcium
  , temperature
  , potassium, sodium
  , lactate
  , glucose

  -- ventilation stuff that's sometimes input
  , intubated, tidalvolume, ventilationrate, ventilator
  , peep, o2flow
  , requiredo2
from stg3
where lastRowFiO2 = 1 -- only the most recent FiO2
-- restrict it to *only* arterial samples
and (specimen = 'ART' or specimen_prob > 0.75)
order by hadm_id, charttime
  );
17:38:59.540084 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:38:59.547939 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.548307 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art" rename to "pivoted_bg_art__dbt_backup"
17:38:59.548838 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.553841 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.554058 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art__dbt_tmp" rename to "pivoted_bg_art"
17:38:59.554981 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:38:59.558162 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:38:59.558346 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.558443 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:38:59.559844 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:38:59.564088 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:38:59.564291 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
drop table if exists "postgres"."public"."pivoted_bg_art__dbt_backup" cascade
17:38:59.566307 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:38:59.568985 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.569230 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: Close
17:38:59.570135 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c4693c70>]}
17:38:59.570617 [info ] [Thread-1  ]: 12 of 13 OK created table model public.pivoted_bg_art .......................... [[32mSELECT 0[0m in 0.06s]
17:38:59.571255 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg_art
17:38:59.571664 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_oasis
17:38:59.572085 [info ] [Thread-1  ]: 13 of 13 START table model public.pivoted_oasis ................................ [RUN]
17:38:59.572781 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_oasis"
17:38:59.573254 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_oasis
17:38:59.573504 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_oasis
17:38:59.577998 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_oasis"
17:38:59.578687 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.579005 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_oasis
17:38:59.588386 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_oasis"
17:38:59.588971 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:38:59.589182 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: BEGIN
17:38:59.589357 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:38:59.595345 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:38:59.595721 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:38:59.596152 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_oasis"} */


  create  table "postgres"."public"."pivoted_oasis__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Oxford Acute Severity of Illness Score (OASIS)
-- This query extracts the Oxford acute severity of illness score.
-- This score is a measure of severity of illness for patients in the ICU.
-- The score is calculated for every hour of the patient's ICU stay.
-- However, as the calculation window is 24 hours, care should be taken when
-- using the score before the end of the first day.
-- ------------------------------------------------------------------

-- Reference for OASIS:
--    Johnson, Alistair EW, Andrew A. Kramer, and Gari D. Clifford.
--    "A new severity of illness scale using a subset of acute physiology and chronic health evaluation data elements shows comparable predictive accuracy*."
--    Critical care medicine 41, no. 7 (2013): 1711-1718.

-- Variables used in OASIS:
--  Heart rate, GCS, MAP, Temperature, Respiratory rate, Ventilation status (sourced from CHARTEVENTS)
--  Urine output (sourced from OUTPUTEVENTS)
--  Elective surgery (sourced from ADMISSIONS and SERVICES)
--  Pre-ICU in-hospital length of stay (sourced from ADMISSIONS and ICUSTAYS)
--  Age (sourced from PATIENTS)

-- The following views are required to run this query:
--  1) uofirstday - generated by urine-output-first-day.sql
--  2) ventfirstday - generated by ventilated-first-day.sql
--  3) vitalsfirstday - generated by vitals-first-day.sql
--  4) gcsfirstday - generated by gcs-first-day.sql


-- Regarding missing values:
--  The ventilation flag is always 0/1. It cannot be missing, since VENT=0 if no data is found for vent settings.

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption 
--  that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to
--  actually use the score values for these patients.

-- The following views required to run this query:
--  1) pivoted_uo - generated by pivoted-uo.sql
--  2) pivoted_lab - generated by pivoted-lab.sql
--  3) pivoted_gcs - generated by pivoted-gcs.sql
--  4) pivoted_vital - generated by pivoted-vital.sql
--  5) ventilation_durations - generated by ../durations/ventilation_durations.sql

-- generate a row for every hour the patient was in the ICU
WITH co_hours AS
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(v.HeartRate) as HeartRate_min
  , max(v.HeartRate) as HeartRate_max
  , min(v.TempC) as TempC_min
  , max(v.TempC) as TempC_max
  , min(v.MeanBP) as MeanBP_min
  , max(v.MeanBP) as MeanBP_max
  , min(v.RespRate) as RespRate_min
  , max(v.RespRate) as RespRate_max
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , MAX(case
        when vd1.icustay_id is not null then 1 
        when vd2.icustay_id is not null then 1
    else 0 end) AS mechvent
  from co_hours co
  left join "postgres"."public"."pivoted_vital" v
    on co.icustay_id = v.icustay_id
    and co.starttime < v.charttime
    and co.endtime >= v.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  -- at the time of this row, was the patient ventilated
  left join ventilation_durations vd1
    on co.icustay_id = vd1.icustay_id
    and co.starttime >= vd1.starttime
    and co.starttime <= vd1.endtime
  left join ventilation_durations vd2
    on co.icustay_id = vd2.icustay_id
    and co.endtime >= vd2.starttime
    and co.endtime <= vd2.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co_hours co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.meanbp_min
    , ma.meanbp_max
    , ma.heartrate_min
    , ma.heartrate_max
    , ma.tempc_min
    , ma.tempc_max
    , ma.resprate_min
    , ma.resprate_max
    , ma.gcs_min
    -- uo
    , uo.urineoutput
    -- static variables that do not change over the ICU stay
    , cast(co.intime as timestamp) - cast(adm.admittime as timestamp) as preiculos
    , case
        when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
        then 1
        when adm.ADMISSION_TYPE is null or sf.surgical is null
        then null
        else 0
    end as electivesurgery
  from co_hours co
  inner join admissions adm
    on co.hadm_id = adm.hadm_id
  left join surgflag sf
    on co.icustay_id = sf.icustay_id
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
    -- Below code calculates the component scores needed for OASIS
    , case when preiculos is null then null
        when preiculos < '0 0:10:12' then 5
        when preiculos < '0 4:57:00' then 3
        when preiculos < '1 0:00:00' then 0
        when preiculos < '12 23:48:00' then 1
        else 2 end as preiculos_score
    ,  case when age is null then null
        when age < 24 then 0
        when age <= 53 then 3
        when age <= 77 then 6
        when age <= 89 then 9
        when age >= 90 then 7
        else 0 end as age_score
    ,  case when mingcs is null then null
        when mingcs <= 7 then 10
        when mingcs < 14 then 4
        when mingcs = 14 then 3
        else 0 end as gcs_score
    ,  case when heartrate_max is null then null
        when heartrate_max > 125 then 6
        when heartrate_min < 33 then 4
        when heartrate_max >= 107 and heartrate_max <= 125 then 3
        when heartrate_max >= 89 and heartrate_max <= 106 then 1
        else 0 end as heartrate_score
    ,  case when meanbp_min is null then null
        when meanbp_min < 20.65 then 4
        when meanbp_min < 51 then 3
        when meanbp_max > 143.44 then 3
        when meanbp_min >= 51 and meanbp_min < 61.33 then 2
        else 0 end as meanbp_score
    ,  case when resprate_min is null then null
        when resprate_min <   6 then 10
        when resprate_max >  44 then  9
        when resprate_max >  30 then  6
        when resprate_max >  22 then  1
        when resprate_min <  13 then 1 else 0
        end as resprate_score
    ,  case when tempc_max is null then null
        when tempc_max > 39.88 then 6
        when tempc_min >= 33.22 and tempc_min <= 35.93 then 4
        when tempc_max >= 33.22 and tempc_max <= 35.93 then 4
        when tempc_min < 33.22 then 3
        when tempc_min > 35.93 and tempc_min <= 36.39 then 2
        when tempc_max >= 36.89 and tempc_max <= 39.88 then 2
        else 0 end as temp_score
    ,  case 
        when SUM(urineoutput) OVER W is null then null
        when SUM(urineoutput) OVER W < 671.09 then 10
        when SUM(urineoutput) OVER W > 6896.80 then 8
        when SUM(urineoutput) OVER W >= 671.09
        and SUM(urineoutput) OVER W <= 1426.99 then 5
        when SUM(urineoutput) OVER W >= 1427.00
        and SUM(urineoutput) OVER W <= 2544.14 then 1
        else 0 end as urineoutput_score
    ,  case when mechvent is null then null
        when mechvent = 1 then 9
        else 0 end as mechvent_score
    ,  case when electivesurgery is null then null
        when electivesurgery = 1 then 0
        else 6 end as electivesurgery_score
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Look for the worst instantaneous score over the last 24 hours
    -- Impute 0 if the score is missing
    , preiculos_score AS preiculos_score_24hours
    , electivesurgery_score as electivesurgery_score_24hours
    , coalesce(MAX(age_score) OVER W, 0)::SMALLINT as age_score_24hours
    , coalesce(MAX(gcs_score) OVER W, 0)::SMALLINT as gcs_score_24hours
    , coalesce(MAX(heartrate_score) OVER W, 0)::SMALLINT as heartrate_score_24hours
    , coalesce(MAX(meanbp_score) OVER W,0)::SMALLINT as meanbp_score_24hours
    , coalesce(MAX(resprate_score) OVER W,0)::SMALLINT as resprate_score_24hours
    , coalesce(MAX(temp_score) OVER W,0)::SMALLINT as temp_score_24hours
    , coalesce(MAX(urineoutput_score) OVER W,0)::SMALLINT as urineoutput_score_24hours
    , coalesce(MAX(mechvent_score) OVER W,0)::SMALLINT as mechvent_score_24hours

    -- sum together data for final OASIS
    , (preiculos_score
    + electivesurgery_score
    + coalesce(MAX(age_score) OVER W, 0)
    + coalesce(MAX(gcs_score) OVER W, 0)
    + coalesce(MAX(heartrate_score) OVER W, 0)
    + coalesce(MAX(meanbp_score) OVER W,0)
    + coalesce(MAX(resprate_score) OVER W,0)
    + coalesce(MAX(temp_score) OVER W,0)
    + coalesce(MAX(urineoutput_score) OVER W,0)
    + coalesce(MAX(mechvent_score) OVER W,0)
    )::SMALLINT
    as OASIS_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:38:59.598251 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "surgflag" does not exist
LINE 145:   left join surgflag sf
                      ^

17:38:59.598955 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: ROLLBACK
17:38:59.600428 [debug] [Thread-1  ]: finished collecting timing info
17:38:59.600695 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: Close
17:38:59.601248 [debug] [Thread-1  ]: Database Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)
  relation "surgflag" does not exist
  LINE 145:   left join surgflag sf
                        ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:38:59.601476 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3038711d-5f40-475a-bcf4-62bbb35a5a8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c468c430>]}
17:38:59.601744 [error] [Thread-1  ]: 13 of 13 ERROR creating table model public.pivoted_oasis ....................... [[31mERROR[0m in 0.03s]
17:38:59.602043 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_oasis
17:38:59.603330 [debug] [MainThread]: Acquiring new postgres connection "master"
17:38:59.603659 [debug] [MainThread]: Using postgres connection "master"
17:38:59.603868 [debug] [MainThread]: On master: BEGIN
17:38:59.604011 [debug] [MainThread]: Opening a new connection, currently in state closed
17:38:59.608156 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:38:59.608406 [debug] [MainThread]: On master: COMMIT
17:38:59.608605 [debug] [MainThread]: Using postgres connection "master"
17:38:59.608784 [debug] [MainThread]: On master: COMMIT
17:38:59.609104 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:38:59.609351 [debug] [MainThread]: On master: Close
17:38:59.610049 [info ] [MainThread]: 
17:38:59.610303 [info ] [MainThread]: Finished running 13 table models in 7.06s.
17:38:59.610794 [debug] [MainThread]: Connection 'master' was properly closed.
17:38:59.611924 [debug] [MainThread]: Connection 'model.mimic.pivoted_oasis' was properly closed.
17:38:59.625727 [info ] [MainThread]: 
17:38:59.625997 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
17:38:59.626403 [info ] [MainThread]: 
17:38:59.628081 [error] [MainThread]: [33mDatabase Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)[0m
17:38:59.628967 [error] [MainThread]:   syntax error at or near "﻿with"
17:38:59.629994 [error] [MainThread]:   LINE 6:     ﻿with co as
17:38:59.630671 [error] [MainThread]:               ^
17:38:59.631290 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:38:59.631806 [info ] [MainThread]: 
17:38:59.632051 [error] [MainThread]: [33mDatabase Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)[0m
17:38:59.632299 [error] [MainThread]:   relation "surgflag" does not exist
17:38:59.632511 [error] [MainThread]:   LINE 145:   left join surgflag sf
17:38:59.632727 [error] [MainThread]:                         ^
17:38:59.632962 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:38:59.633227 [info ] [MainThread]: 
17:38:59.634128 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 TOTAL=13
17:38:59.634609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c46a6a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c46a6610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91c46a6b80>]}
17:38:59.637243 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:39:08.076973 | adcb8d14-7d4c-44d6-ab39-4f5b185256ea ==============================
17:39:08.076986 [info ] [MainThread]: Running with dbt=1.1.1
17:39:08.077416 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['durations'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:39:08.077529 [debug] [MainThread]: Tracking: tracking
17:39:08.083891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0ec6c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0ec6490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0ec62b0>]}
17:39:08.174759 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:39:08.175050 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:39:08.177205 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:39:08.183821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0e50700>]}
17:39:08.206700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0ea02b0>]}
17:39:08.207292 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:39:08.207533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0ea0070>]}
17:39:08.210951 [info ] [MainThread]: 
17:39:08.211806 [debug] [MainThread]: Acquiring new postgres connection "master"
17:39:08.213665 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:39:08.226090 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:39:08.226366 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:39:08.226907 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:39:08.233197 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:39:08.238842 [debug] [ThreadPool]: On list_postgres: Close
17:39:08.245005 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:39:08.251162 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:39:08.251398 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:39:08.251674 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:39:08.258080 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:39:08.258790 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:39:08.259019 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:39:08.261688 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:39:08.269030 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:39:08.269637 [debug] [ThreadPool]: On list_postgres_public: Close
17:39:08.284672 [debug] [MainThread]: Using postgres connection "master"
17:39:08.284893 [debug] [MainThread]: On master: BEGIN
17:39:08.285075 [debug] [MainThread]: Opening a new connection, currently in state init
17:39:08.291365 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:39:08.291611 [debug] [MainThread]: Using postgres connection "master"
17:39:08.291784 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:39:08.297506 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:39:08.301087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef2ce1be0>]}
17:39:08.301417 [debug] [MainThread]: On master: ROLLBACK
17:39:08.301677 [debug] [MainThread]: Using postgres connection "master"
17:39:08.301778 [debug] [MainThread]: On master: BEGIN
17:39:08.302094 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:39:08.302321 [debug] [MainThread]: On master: COMMIT
17:39:08.302420 [debug] [MainThread]: Using postgres connection "master"
17:39:08.302917 [debug] [MainThread]: On master: COMMIT
17:39:08.304053 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:39:08.304352 [debug] [MainThread]: On master: Close
17:39:08.304980 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:39:08.305365 [info ] [MainThread]: 
17:39:08.309020 [debug] [Thread-1  ]: Began running node model.mimic.adenosine_durations
17:39:08.309354 [info ] [Thread-1  ]: 1 of 23 START table model public.adenosine_durations ........................... [RUN]
17:39:08.309886 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.adenosine_durations"
17:39:08.310110 [debug] [Thread-1  ]: Began compiling node model.mimic.adenosine_durations
17:39:08.310228 [debug] [Thread-1  ]: Compiling model.mimic.adenosine_durations
17:39:08.311590 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.adenosine_durations"
17:39:08.312096 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.312354 [debug] [Thread-1  ]: Began executing node model.mimic.adenosine_durations
17:39:08.342008 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.adenosine_durations"
17:39:08.342938 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.343191 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: BEGIN
17:39:08.343568 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:08.348510 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:08.348776 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.348975 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */


  create  table "postgres"."public"."adenosine_durations__dbt_tmp"
  as (
    -- This query extracts durations of adenosine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- *** COULD NOT FIND ADENOSINE IN THE INPUTEVENTS_MV TABLE ***
-- This drug is rarely used - it could just be that it was never used in MetaVision.
-- If using this code, ensure the durations make sense for carevue patients first

with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 4649 then 1 else 0 end) as vaso -- adenosine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , 0 as vaso_stopped
    , max(case when itemid = 4649 and valuenum is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 4649 then valuenum else null end) as vaso_rate
    , max(case when itemid = 4649 then valuenum else null end) as vaso_amount

  FROM chartevents
  where itemid = 4649 -- adenosine
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221282 -- adenosine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:08.370460 [debug] [Thread-1  ]: SQL status: SELECT 160 in 0.02 seconds
17:39:08.381072 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.381277 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations" rename to "adenosine_durations__dbt_backup"
17:39:08.381917 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.385236 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.385427 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations__dbt_tmp" rename to "adenosine_durations"
17:39:08.386232 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.397166 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:39:08.397446 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.397618 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:39:08.398791 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:08.403590 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:39:08.403830 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
drop table if exists "postgres"."public"."adenosine_durations__dbt_backup" cascade
17:39:08.406004 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:08.408677 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.408895 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: Close
17:39:08.409740 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ee3a0>]}
17:39:08.410211 [info ] [Thread-1  ]: 1 of 23 OK created table model public.adenosine_durations ...................... [[32mSELECT 160[0m in 0.10s]
17:39:08.410837 [debug] [Thread-1  ]: Finished running node model.mimic.adenosine_durations
17:39:08.411208 [debug] [Thread-1  ]: Began running node model.mimic.arterial_line_durations
17:39:08.411868 [info ] [Thread-1  ]: 2 of 23 START table model public.arterial_line_durations ....................... [RUN]
17:39:08.412680 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.arterial_line_durations"
17:39:08.413025 [debug] [Thread-1  ]: Began compiling node model.mimic.arterial_line_durations
17:39:08.413354 [debug] [Thread-1  ]: Compiling model.mimic.arterial_line_durations
17:39:08.415256 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.arterial_line_durations"
17:39:08.415881 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.416158 [debug] [Thread-1  ]: Began executing node model.mimic.arterial_line_durations
17:39:08.429493 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.arterial_line_durations"
17:39:08.430142 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.430345 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: BEGIN
17:39:08.430438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:08.434920 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:08.435171 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.435350 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */


  create  table "postgres"."public"."arterial_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
  , case
      when itemid in (225752, 224272)
        then 1
      when pe.locationcategory = 'Invasive Arterial'
        then 1
      when itemid = 225789 and pe.locationcategory IS NULL
        then 1
      else 0
    end as arterial_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    -- , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    -- , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    -- , 225203 -- Pheresis Catheter | None | 12 | Processes
    -- , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 225789 -- Sheath
    , 224272 -- IABP Line
    -- , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('A-Line', 'IABP'))
     OR (inv2_type in ('A-Line', 'IABP'))
     OR (inv3_type in ('A-Line', 'IABP'))
     OR (inv4_type in ('A-Line', 'IABP'))
     OR (inv5_type in ('A-Line', 'IABP'))
     OR (inv6_type in ('A-Line', 'IABP'))
     OR (inv7_type in ('A-Line', 'IABP'))
     OR (inv8_type in ('A-Line', 'IABP'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as arterial_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as arterial_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( arterial_line_new )
    OVER ( partition by icustay_id order by charttime )
    as arterial_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , arterial_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, arterial_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , arterial_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as arterial_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where arterial_line = 1
order by icustay_id, starttime
  );
17:39:08.504441 [debug] [Thread-1  ]: SQL status: SELECT 13059 in 0.07 seconds
17:39:08.508275 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.508477 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations" rename to "arterial_line_durations__dbt_backup"
17:39:08.509166 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.513082 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.513275 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations__dbt_tmp" rename to "arterial_line_durations"
17:39:08.513923 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.516703 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:39:08.516893 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.517120 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:39:08.518832 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:08.520809 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:39:08.521007 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
drop table if exists "postgres"."public"."arterial_line_durations__dbt_backup" cascade
17:39:08.523153 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:08.525554 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.525756 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: Close
17:39:08.526539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ee190>]}
17:39:08.527126 [info ] [Thread-1  ]: 2 of 23 OK created table model public.arterial_line_durations .................. [[32mSELECT 13059[0m in 0.11s]
17:39:08.527647 [debug] [Thread-1  ]: Finished running node model.mimic.arterial_line_durations
17:39:08.528009 [debug] [Thread-1  ]: Began running node model.mimic.central_line_durations
17:39:08.528625 [info ] [Thread-1  ]: 3 of 23 START table model public.central_line_durations ........................ [RUN]
17:39:08.529362 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.central_line_durations"
17:39:08.529706 [debug] [Thread-1  ]: Began compiling node model.mimic.central_line_durations
17:39:08.530100 [debug] [Thread-1  ]: Compiling model.mimic.central_line_durations
17:39:08.532381 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.central_line_durations"
17:39:08.532910 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.533388 [debug] [Thread-1  ]: Began executing node model.mimic.central_line_durations
17:39:08.545650 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.central_line_durations"
17:39:08.546062 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.546167 [debug] [Thread-1  ]: On model.mimic.central_line_durations: BEGIN
17:39:08.546260 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:08.550740 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:08.550982 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.551153 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */


  create  table "postgres"."public"."central_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
    , case
        when (locationcategory <> 'Invasive Arterial' or locationcategory is null)
          then 1
        else 0
      end as central_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    , 225203 -- Pheresis Catheter | None | 12 | Processes
    , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
    , 224270 -- Dialysis Catheter
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv2_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv3_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv4_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv5_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv6_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv7_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv8_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as central_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as central_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( central_line_new )
    OVER ( partition by icustay_id order by charttime )
    as central_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , central_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, central_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , central_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as central_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where central_line = 1
order by icustay_id, starttime
  );
17:39:08.632103 [debug] [Thread-1  ]: SQL status: SELECT 21211 in 0.08 seconds
17:39:08.637072 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.637284 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations" rename to "central_line_durations__dbt_backup"
17:39:08.637913 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.642131 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.642333 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations__dbt_tmp" rename to "central_line_durations"
17:39:08.643038 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.645749 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:39:08.645927 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.646032 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:39:08.650146 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:08.652489 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:39:08.652702 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
drop table if exists "postgres"."public"."central_line_durations__dbt_backup" cascade
17:39:08.654803 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:08.657680 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.657909 [debug] [Thread-1  ]: On model.mimic.central_line_durations: Close
17:39:08.658388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03e5820>]}
17:39:08.658916 [info ] [Thread-1  ]: 3 of 23 OK created table model public.central_line_durations ................... [[32mSELECT 21211[0m in 0.13s]
17:39:08.659470 [debug] [Thread-1  ]: Finished running node model.mimic.central_line_durations
17:39:08.659855 [debug] [Thread-1  ]: Began running node model.mimic.crrt_durations
17:39:08.660471 [info ] [Thread-1  ]: 4 of 23 START table model public.crrt_durations ................................ [RUN]
17:39:08.661181 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.crrt_durations"
17:39:08.661370 [debug] [Thread-1  ]: Began compiling node model.mimic.crrt_durations
17:39:08.661508 [debug] [Thread-1  ]: Compiling model.mimic.crrt_durations
17:39:08.663928 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.crrt_durations"
17:39:08.664738 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.665172 [debug] [Thread-1  ]: Began executing node model.mimic.crrt_durations
17:39:08.679286 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.crrt_durations"
17:39:08.680261 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.680617 [debug] [Thread-1  ]: On model.mimic.crrt_durations: BEGIN
17:39:08.680938 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:08.685511 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:08.685847 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.686711 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */


  create  table "postgres"."public"."crrt_durations__dbt_tmp"
  as (
    with crrt_settings as
(
  select ce.icustay_id, ce.charttime
  , max(
      case
        when ce.itemid in
        (
          224149, -- Access Pressure
          224144, -- Blood Flow (ml/min)
          228004, -- Citrate (ACD-A)
          225183, -- Current Goal
          225977, -- Dialysate Fluid
          224154, -- Dialysate Rate
          224151, -- Effluent Pressure
          224150, -- Filter Pressure
          225958, -- Heparin Concentration (units/mL)
          224145, -- Heparin Dose (per hour)
          224191, -- Hourly Patient Fluid Removal
          228005, -- PBP (Prefilter) Replacement Rate
          228006, -- Post Filter Replacement Rate
          225976, -- Replacement Fluid
          224153, -- Replacement Rate
          224152, -- Return Pressure
          226457  -- Ultrafiltrate Output
        ) then 1
      when ce.itemid in
        (
        29,  -- Access mmHg
        173, -- Effluent Press mmHg
        192, -- Filter Pressure mmHg
        624, -- Return Pressure mmHg
        79, -- Blood Flow ml/min
        142, -- Current Goal
        146, -- Dialysate Flow ml/hr
        611, -- Replace Rate ml/hr
        5683 -- Hourly PFR
        ) then 1
      when ce.itemid = 665 and value in ('Active','Clot Increasing','Clots Present','No Clot Present')
         then 1
      when ce.itemid = 147 and value = 'Yes'
         then 1
      else 0 end)
      as RRT
  -- Below indicates that a new instance of CRRT has started
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('New Filter','Reinitiated')
        then 1
      when ce.itemid = 665 and value in ('Initiated')
        then 1
    else 0
   end ) as RRT_start
  -- Below indicates that the current instance of CRRT has ended
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('Discontinued','Recirculating')
        then 1
      -- the only value like DC is "DC'D", use like to avoid apostrophe
      when ce.itemid = 665 and (value = 'Clotted' OR value LIKE 'DC%')
        then 1
      -- Reason for CRRT filter change
      when ce.itemid = 225956
        then 1
    else 0
   end ) as RRT_end
  FROM chartevents ce
  where ce.itemid in
  (
    -- MetaVision ITEMIDs
    -- Below require special handling
    224146, -- System Integrity
    225956,  -- Reason for CRRT Filter Change
    -- Below are settings which indicate CRRT is started/continuing
    224149, -- Access Pressure
    224144, -- Blood Flow (ml/min)
    228004, -- Citrate (ACD-A)
    225183, -- Current Goal
    225977, -- Dialysate Fluid
    224154, -- Dialysate Rate
    224151, -- Effluent Pressure
    224150, -- Filter Pressure
    225958, -- Heparin Concentration (units/mL)
    224145, -- Heparin Dose (per hour)
    224191, -- Hourly Patient Fluid Removal
    228005, -- PBP (Prefilter) Replacement Rate
    228006, -- Post Filter Replacement Rate
    225976, -- Replacement Fluid
    224153, -- Replacement Rate
    224152, -- Return Pressure
    226457, -- Ultrafiltrate Output
    -- CareVue ITEMIDs
    -- Below require special handling
    665,  -- System integrity
    147, -- Dialysate Infusing
    612, -- Replace.Fluid Infuse
    -- Below are settings which indicate CRRT is started/continuing
    29,  -- Access mmHg
    173, -- Effluent Press mmHg
    192, -- Filter Pressure mmHg
    624, -- Return Pressure mmHg
    142, -- Current Goal
    79, -- Blood Flow ml/min
    146, -- Dialysate Flow ml/hr
    611, -- Replace Rate ml/hr
    5683 -- Hourly PFR
  )
  and ce.value is not null
  and coalesce(ce.valuenum,1) != 0 -- non-zero rates/values
  group by icustay_id, charttime
)
-- create various lagged variables for future query
, vd_lag AS
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER W AS charttime_prev_row
    , charttime
    , RRT
    , RRT_start
    , RRT_end
    , LAG(RRT_end, 1) OVER W AS rrt_ended_prev_row
  FROM crrt_settings
  WINDOW w AS 
  (
    partition by icustay_id, case when RRT=1 or RRT_end=1 then 1 else 0 end
    order by charttime
  )
)
, vd1 as
(
  select
      icustay_id
      , charttime
      , RRT
      , RRT_start
      , RRT_end

      -- now we determine if the current event is a new instantiation
      , case
          when RRT_start = 1
            then 1
        -- if there is an end flag, we mark any subsequent event as new
          when RRT_end = 1
            -- note the end is *not* a new event, the *subsequent* row is
            -- so here we output 0
            then 0
          when rrt_ended_prev_row = 1
            then 1
            -- if there is less than 2 hours between CRRT settings, we do not treat this as a new CRRT event
          when DATETIME_DIFF(charttime, charttime_prev_row, 'HOUR') <= 2
            then 0
        else 1
      end as NewCRRT
  -- use the temp table with only settings FROM chartevents
  FROM vd_lag
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new CRRT
  -- this results in a monotonically increasing integer assigned to each CRRT
  , case when RRT_start = 1 or RRT=1 or RRT_end = 1 then
      SUM( NewCRRT )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as num
  --- now we convert CHARTTIME of CRRT settings into durations
  from vd1
  -- now we can isolate to just rows with settings
  -- (before we had rows with start/end flags)
  -- this removes any null values for NewCRRT
  where
    RRT_start = 1 or RRT = 1 or RRT_end = 1
)
-- create the durations for each CRRT instance
, fin as
(
select icustay_id
  , num
  , min(charttime) as starttime
  , max(charttime) as endtime
 	, DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  -- add durations
from vd2
group by icustay_id, num
having min(charttime) != max(charttime)
)
select icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as num
  , starttime, endtime, duration_hours
from fin
order by icustay_id, num
  );
17:39:08.696780 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:39:08.700587 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.700966 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations" rename to "crrt_durations__dbt_backup"
17:39:08.701797 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.708824 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.709045 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations__dbt_tmp" rename to "crrt_durations"
17:39:08.709591 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:08.712941 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:39:08.713139 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.713330 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:39:08.714217 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:08.716464 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:39:08.716660 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
drop table if exists "postgres"."public"."crrt_durations__dbt_backup" cascade
17:39:08.718725 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:08.723268 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.723505 [debug] [Thread-1  ]: On model.mimic.crrt_durations: Close
17:39:08.724225 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03e5970>]}
17:39:08.724699 [info ] [Thread-1  ]: 4 of 23 OK created table model public.crrt_durations ........................... [[32mSELECT 0[0m in 0.06s]
17:39:08.725131 [debug] [Thread-1  ]: Finished running node model.mimic.crrt_durations
17:39:08.725377 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_dose
17:39:08.726017 [info ] [Thread-1  ]: 5 of 23 START table model public.dobutamine_dose ............................... [RUN]
17:39:08.726694 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_dose"
17:39:08.727093 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_dose
17:39:08.727330 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_dose
17:39:08.728667 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_dose"
17:39:08.729787 [debug] [Thread-1  ]: finished collecting timing info
17:39:08.730187 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_dose
17:39:08.742253 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_dose"
17:39:08.742958 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:08.743171 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: BEGIN
17:39:08.743368 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:08.747682 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:08.747917 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:08.748093 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */


  create  table "postgres"."public"."dobutamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30042,30306) then 1 else 0 end) as vaso -- dobutamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30042,30306) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30042,30306) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30042,30306) then rate else null end) as vaso_rate
    , max(case when itemid in (30042,30306) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30042,30306) -- dobutamine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221653 -- dobutamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:09.343347 [debug] [Thread-1  ]: SQL status: SELECT 6548 in 0.6 seconds
17:39:09.350202 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:09.350586 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose" rename to "dobutamine_dose__dbt_backup"
17:39:09.351872 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:09.356789 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:09.357061 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose__dbt_tmp" rename to "dobutamine_dose"
17:39:09.357783 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:09.360922 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:39:09.361122 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:09.361297 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:39:09.363163 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:09.365984 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:39:09.366188 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
drop table if exists "postgres"."public"."dobutamine_dose__dbt_backup" cascade
17:39:09.368039 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:09.371397 [debug] [Thread-1  ]: finished collecting timing info
17:39:09.371633 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: Close
17:39:09.372398 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03e5ac0>]}
17:39:09.372887 [info ] [Thread-1  ]: 5 of 23 OK created table model public.dobutamine_dose .......................... [[32mSELECT 6548[0m in 0.65s]
17:39:09.373441 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_dose
17:39:09.373903 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_durations
17:39:09.374657 [info ] [Thread-1  ]: 6 of 23 START table model public.dobutamine_durations .......................... [RUN]
17:39:09.375452 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_durations"
17:39:09.375882 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_durations
17:39:09.376335 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_durations
17:39:09.378127 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_durations"
17:39:09.378819 [debug] [Thread-1  ]: finished collecting timing info
17:39:09.379452 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_durations
17:39:09.391919 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_durations"
17:39:09.392505 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.392716 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: BEGIN
17:39:09.392875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:09.399551 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:09.399876 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.400183 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */


  create  table "postgres"."public"."dobutamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dobutamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID
-- Get drug administration data from CareVue first
with vasocv1 as (
  select
    icustay_id,
    charttime -- case statement determining whether the ITEMID is an instance of vasopressor usage
,
    max(
      case
        when itemid in (30042, 30306) then 1
        else 0
      end
    ) as vaso -- dobutamine
    -- the 'stopped' column indicates if a vasopressor has been disconnected
,
    max(
      case
        when itemid in (30042, 30306)
        and (
          stopped = 'Stopped'
          OR stopped like 'D/C%'
        ) then 1
        else 0
      end
    ) as vaso_stopped,
    max(
      case
        when itemid in (30042, 30306)
        and rate is not null then 1
        else 0
      end
    ) as vaso_null,
    max(
      case
        when itemid in (30042, 30306) then rate
        else null
      end
    ) as vaso_rate,
    max(
      case
        when itemid in (30042, 30306) then amount
        else null
      end
    ) as vaso_amount
  FROM
    inputevents_cv
  where
    itemid in (30042, 30306) -- dobutamine
  group by
    icustay_id,
    charttime
),
vasocv2 as (
  select
    v.*,
    sum(vaso_null) over (
      partition by icustay_id
      order by
        charttime
    ) as vaso_partition
  from
    vasocv1 v
),
vasocv3 as (
  select
    v.*,
    first_value(vaso_rate) over (
      partition by icustay_id,
      vaso_partition
      order by
        charttime
    ) as vaso_prevrate_ifnull
  from
    vasocv2 v
),
vasocv4 as (
  select
    icustay_id,
    charttime -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta
,
    vaso,
    vaso_rate,
    vaso_amount,
    vaso_stopped,
    vaso_prevrate_ifnull -- We define start time here
,
    case
      when vaso = 0 then null -- if this is the first instance of the vasoactive drug
      when vaso_rate > 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso,
        vaso_null
        order by
          charttime
      ) is null then 1 -- you often get a string of 0s
      -- we decide not to set these as 1, just because it makes vasonum sequential
      when vaso_rate = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- sometimes you get a string of NULL, associated with 0 volumes
      -- same reason as before, we decide not to set these as 1
      -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
      when vaso_prevrate_ifnull = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- If the last recorded rate was 0, newvaso = 1
      when LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 1 -- If the last recorded vaso was D/C'd, newvaso = 1
      when LAG(vaso_stopped, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 1 then 1 -- ** not sure if the below is needed
      --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
    end as vaso_start
  FROM
    vasocv3
) -- propagate start/stop flags forward in time
,
vasocv5 as (
  select
    v.*,
    SUM(vaso_start) OVER (
      partition by icustay_id,
      vaso
      order by
        charttime
    ) as vaso_first
  FROM
    vasocv4 v
),
vasocv6 as (
  select
    v.* -- We define end time here
,
    case
      when vaso = 0 then null -- If the recorded vaso was D/C'd, this is an end time
      when vaso_stopped = 1 then vaso_first -- If the rate is zero, this is the end time
      when vaso_rate = 0 then vaso_first -- the last row in the table is always a potential end time
      -- this captures patients who die/are discharged while on vasopressors
      -- in principle, this could add an extra end time for the vasopressor
      -- however, since we later group on vaso_start, any extra end times are ignored
      when LEAD(CHARTTIME, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) is null then vaso_first
      else null
    end as vaso_stop
  from
    vasocv5 v
) -- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime
,
vasocv as (
  -- below groups together vasopressor administrations into groups
  select
    icustay_id -- the first non-null rate is considered the starttime
,
    min(
      case
        when vaso_rate is not null then charttime
        else null
      end
    ) as starttime -- the *first* time the first/last flags agree is the stop time for this duration
,
    min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    ) as endtime
  from
    vasocv6
  where
    vaso_first is not null -- bogus data
    and vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
    and icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
  group by
    icustay_id,
    vaso_first
  having
    -- ensure start time is not the same as end time
    min(charttime) != min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    )
    and max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
) -- now we extract the associated data for metavision patients
,
vasomv as (
  select
    icustay_id,
    linkorderid,
    min(starttime) as starttime,
    max(endtime) as endtime
  FROM
    inputevents_mv
  where
    itemid = 221653 -- dobutamine
    and statusdescription != 'Rewritten' -- only valid orders
  group by
    icustay_id,
    linkorderid
)
select
  icustay_id -- generate a sequential integer for convenience
,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasocv
UNION
ALL
select
  icustay_id,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasomv
order by
  icustay_id,
  vasonum
  );
17:39:09.783944 [debug] [Thread-1  ]: SQL status: SELECT 1792 in 0.38 seconds
17:39:09.788019 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.788224 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations" rename to "dobutamine_durations__dbt_backup"
17:39:09.788993 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:09.792696 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.792895 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations__dbt_tmp" rename to "dobutamine_durations"
17:39:09.793517 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:09.796952 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:39:09.797149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.797406 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:39:09.798731 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:09.800501 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:39:09.800715 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
drop table if exists "postgres"."public"."dobutamine_durations__dbt_backup" cascade
17:39:09.802593 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:09.805025 [debug] [Thread-1  ]: finished collecting timing info
17:39:09.805241 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: Close
17:39:09.806156 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0301490>]}
17:39:09.806856 [info ] [Thread-1  ]: 6 of 23 OK created table model public.dobutamine_durations ..................... [[32mSELECT 1792[0m in 0.43s]
17:39:09.807594 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_durations
17:39:09.808027 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_dose
17:39:09.808747 [info ] [Thread-1  ]: 7 of 23 START table model public.dopamine_dose ................................. [RUN]
17:39:09.809725 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_dose"
17:39:09.810192 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_dose
17:39:09.810403 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_dose
17:39:09.812753 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_dose"
17:39:09.813802 [debug] [Thread-1  ]: finished collecting timing info
17:39:09.814177 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_dose
17:39:09.825149 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_dose"
17:39:09.825735 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:09.825980 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: BEGIN
17:39:09.826163 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:09.830665 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:09.830937 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:09.831135 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */


  create  table "postgres"."public"."dopamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:11.625863 [debug] [Thread-1  ]: SQL status: SELECT 38953 in 1.79 seconds
17:39:11.633175 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:11.633569 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose" rename to "dopamine_dose__dbt_backup"
17:39:11.634905 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:11.640896 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:11.641088 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose__dbt_tmp" rename to "dopamine_dose"
17:39:11.641763 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:11.645250 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:39:11.645459 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:11.645614 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:39:11.651756 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:39:11.653698 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:39:11.653902 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
drop table if exists "postgres"."public"."dopamine_dose__dbt_backup" cascade
17:39:11.655964 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:11.658815 [debug] [Thread-1  ]: finished collecting timing info
17:39:11.659102 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: Close
17:39:11.659957 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03e5e20>]}
17:39:11.660452 [info ] [Thread-1  ]: 7 of 23 OK created table model public.dopamine_dose ............................ [[32mSELECT 38953[0m in 1.85s]
17:39:11.661096 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_dose
17:39:11.661497 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_durations
17:39:11.662121 [info ] [Thread-1  ]: 8 of 23 START table model public.dopamine_durations ............................ [RUN]
17:39:11.663946 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_durations"
17:39:11.664227 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_durations
17:39:11.664490 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_durations
17:39:11.665777 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_durations"
17:39:11.666527 [debug] [Thread-1  ]: finished collecting timing info
17:39:11.667443 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_durations
17:39:11.681186 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_durations"
17:39:11.681857 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:11.682207 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: BEGIN
17:39:11.682398 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:11.689521 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:11.689774 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:11.689891 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */


  create  table "postgres"."public"."dopamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dopamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:13.588113 [debug] [Thread-1  ]: SQL status: SELECT 6524 in 1.9 seconds
17:39:13.595460 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:13.595875 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations" rename to "dopamine_durations__dbt_backup"
17:39:13.597248 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:13.602681 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:13.603006 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations__dbt_tmp" rename to "dopamine_durations"
17:39:13.603885 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:13.607469 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:39:13.607683 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:13.607949 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:39:13.611016 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:13.612995 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:39:13.613192 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
drop table if exists "postgres"."public"."dopamine_durations__dbt_backup" cascade
17:39:13.615726 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:13.620004 [debug] [Thread-1  ]: finished collecting timing info
17:39:13.620316 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: Close
17:39:13.621077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03e5eb0>]}
17:39:13.621594 [info ] [Thread-1  ]: 8 of 23 OK created table model public.dopamine_durations ....................... [[32mSELECT 6524[0m in 1.96s]
17:39:13.622183 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_durations
17:39:13.622608 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_durations
17:39:13.623354 [info ] [Thread-1  ]: 9 of 23 START table model public.epinephrine_durations ......................... [RUN]
17:39:13.624302 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_durations"
17:39:13.624667 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_durations
17:39:13.625104 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_durations
17:39:13.626378 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_durations"
17:39:13.627252 [debug] [Thread-1  ]: finished collecting timing info
17:39:13.627636 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_durations
17:39:13.638274 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_durations"
17:39:13.638966 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:13.639145 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: BEGIN
17:39:13.639618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:13.645813 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:13.646122 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:13.646267 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */


  create  table "postgres"."public"."epinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of epinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30044,30119,30309) then rate else null end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:14.245860 [debug] [Thread-1  ]: SQL status: SELECT 3126 in 0.6 seconds
17:39:14.252967 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:14.253455 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations" rename to "epinephrine_durations__dbt_backup"
17:39:14.254797 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:14.258720 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:14.258987 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations__dbt_tmp" rename to "epinephrine_durations"
17:39:14.259731 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:14.262777 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:39:14.263030 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:14.263227 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:39:14.266031 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:14.268412 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:39:14.268616 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
drop table if exists "postgres"."public"."epinephrine_durations__dbt_backup" cascade
17:39:14.271390 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:14.274552 [debug] [Thread-1  ]: finished collecting timing info
17:39:14.274917 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: Close
17:39:14.275716 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec100>]}
17:39:14.276223 [info ] [Thread-1  ]: 9 of 23 OK created table model public.epinephrine_durations .................... [[32mSELECT 3126[0m in 0.65s]
17:39:14.276821 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_durations
17:39:14.277214 [debug] [Thread-1  ]: Began running node model.mimic.isuprel_durations
17:39:14.277863 [info ] [Thread-1  ]: 10 of 23 START table model public.isuprel_durations ............................ [RUN]
17:39:14.278466 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.isuprel_durations"
17:39:14.278786 [debug] [Thread-1  ]: Began compiling node model.mimic.isuprel_durations
17:39:14.279070 [debug] [Thread-1  ]: Compiling model.mimic.isuprel_durations
17:39:14.280383 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.isuprel_durations"
17:39:14.281254 [debug] [Thread-1  ]: finished collecting timing info
17:39:14.281630 [debug] [Thread-1  ]: Began executing node model.mimic.isuprel_durations
17:39:14.292816 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.isuprel_durations"
17:39:14.293451 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.293664 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: BEGIN
17:39:14.293760 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:14.301556 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:14.302199 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.302333 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */


  create  table "postgres"."public"."isuprel_durations__dbt_tmp"
  as (
    -- This query extracts durations of isuprel administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30046 then 1 else 0 end) as vaso -- Isuprel

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30046 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30046 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30046 then rate else null end) as vaso_rate
    , max(case when itemid = 30046 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30046 -- Isuprel
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 227692 -- Isuprel
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:14.315980 [debug] [Thread-1  ]: SQL status: SELECT 26 in 0.01 seconds
17:39:14.323510 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.323749 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations" rename to "isuprel_durations__dbt_backup"
17:39:14.324674 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:14.328516 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.328720 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations__dbt_tmp" rename to "isuprel_durations"
17:39:14.329269 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:14.335931 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:39:14.336400 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.336612 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:39:14.337632 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:14.339835 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:39:14.340042 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
drop table if exists "postgres"."public"."isuprel_durations__dbt_backup" cascade
17:39:14.342060 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:14.344774 [debug] [Thread-1  ]: finished collecting timing info
17:39:14.344999 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: Close
17:39:14.345753 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec190>]}
17:39:14.346099 [info ] [Thread-1  ]: 10 of 23 OK created table model public.isuprel_durations ....................... [[32mSELECT 26[0m in 0.07s]
17:39:14.346650 [debug] [Thread-1  ]: Finished running node model.mimic.isuprel_durations
17:39:14.346965 [debug] [Thread-1  ]: Began running node model.mimic.milrinone_durations
17:39:14.347730 [info ] [Thread-1  ]: 11 of 23 START table model public.milrinone_durations .......................... [RUN]
17:39:14.350327 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.milrinone_durations"
17:39:14.351240 [debug] [Thread-1  ]: Began compiling node model.mimic.milrinone_durations
17:39:14.351596 [debug] [Thread-1  ]: Compiling model.mimic.milrinone_durations
17:39:14.353011 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.milrinone_durations"
17:39:14.354118 [debug] [Thread-1  ]: finished collecting timing info
17:39:14.354821 [debug] [Thread-1  ]: Began executing node model.mimic.milrinone_durations
17:39:14.366271 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.milrinone_durations"
17:39:14.367557 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:14.367786 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: BEGIN
17:39:14.367980 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:14.375037 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:14.375452 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:14.375718 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */


  create  table "postgres"."public"."milrinone_durations__dbt_tmp"
  as (
    -- This query extracts durations of milrinone administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30125 then 1 else 0 end) as vaso -- milrinone

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30125 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30125 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30125 then rate else null end) as vaso_rate
    , max(case when itemid = 30125 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30125 -- milrinone
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221986 -- milrinone
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:15.388222 [debug] [Thread-1  ]: SQL status: SELECT 3600 in 1.01 seconds
17:39:15.392519 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:15.392745 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations" rename to "milrinone_durations__dbt_backup"
17:39:15.393482 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:15.397359 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:15.397571 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations__dbt_tmp" rename to "milrinone_durations"
17:39:15.398202 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:15.401158 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:39:15.401366 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:15.401470 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:39:15.402996 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:15.405391 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:39:15.405636 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
drop table if exists "postgres"."public"."milrinone_durations__dbt_backup" cascade
17:39:15.407662 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:15.411325 [debug] [Thread-1  ]: finished collecting timing info
17:39:15.411567 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: Close
17:39:15.412346 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec2e0>]}
17:39:15.412825 [info ] [Thread-1  ]: 11 of 23 OK created table model public.milrinone_durations ..................... [[32mSELECT 3600[0m in 1.06s]
17:39:15.413415 [debug] [Thread-1  ]: Finished running node model.mimic.milrinone_durations
17:39:15.413744 [debug] [Thread-1  ]: Began running node model.mimic.neuroblock_dose
17:39:15.414334 [info ] [Thread-1  ]: 12 of 23 START table model public.neuroblock_dose .............................. [RUN]
17:39:15.415205 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.neuroblock_dose"
17:39:15.415582 [debug] [Thread-1  ]: Began compiling node model.mimic.neuroblock_dose
17:39:15.416047 [debug] [Thread-1  ]: Compiling model.mimic.neuroblock_dose
17:39:15.417866 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.neuroblock_dose"
17:39:15.418414 [debug] [Thread-1  ]: finished collecting timing info
17:39:15.419002 [debug] [Thread-1  ]: Began executing node model.mimic.neuroblock_dose
17:39:15.433970 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.neuroblock_dose"
17:39:15.434748 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:15.435055 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: BEGIN
17:39:15.435302 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:15.441222 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:15.441513 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:15.441657 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */


  create  table "postgres"."public"."neuroblock_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of neuromuscular blocking agents
-- Note: we assume that injections will be filtered for carevue as they will have starttime = stopttime.

-- Get drug administration data from CareVue and MetaVision
-- metavision is simple and only requires one temporary table

with drugmv as
(
  select
      icustay_id, orderid
    , rate as drug_rate
    , amount as drug_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid in
  (
      222062 -- Vecuronium (664 rows, 154 infusion rows)
    , 221555 -- Cisatracurium (9334 rows, 8970 infusion rows)
  )
  and statusdescription != 'Rewritten' -- only valid orders
  and rate is not null -- only continuous infusions
)
, drugcv1 as
(
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped

    -- we only include continuous infusions, therefore expect a rate
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 and amount is not null then 1
            when itemid <  40000 and rate is not null then 1
          else 0 end) as drug_null
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 then coalesce(rate, amount)
          else rate end) as drug_rate
    , max(amount) as drug_amount
  from inputevents_cv
  where itemid in
  (
      30114 -- Cisatracurium (63994 rows)
    , 30138	-- Vecuronium	 (5160 rows)
    , 30113 -- Atracurium  (1163 rows)
    -- Below rows are less frequent ad-hoc documentation, but worth including!
    , 42174	-- nimbex cc/hr (207 rows)
    , 42385	-- Cisatracurium gtt (156 rows)
    , 41916	-- NIMBEX	inputevents_cv (136 rows)
    , 42100	-- cistatracurium	(132 rows)
    , 42045	-- nimbex mcg/kg/min (78 rows)
    , 42246 -- CISATRICARIUM CC/HR (70 rows)
    , 42291	-- NIMBEX CC/HR (48 rows)
    , 42590	-- nimbex	inputevents_cv (38 rows)
    , 42284	-- CISATRACURIUM DRIP (9 rows)
    , 45096	-- Vecuronium drip (2 rows)
  )
  group by icustay_id, charttime
  UNION
  -- add data from chartevents
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped
    , max(case when valuenum <= 10 then 0 else 1 end) as drug_null

    -- educated guess!
    , max(case when valuenum <= 10 then valuenum else null end) as drug_rate
    , max(case when valuenum  > 10 then valuenum else null end) as drug_amount
  from chartevents
  where itemid in
  (
      1856 -- Vecuronium mcg/min  (8 rows)
    , 2164 -- NIMBEX MG/KG/HR  (243 rows)
    , 2548 -- nimbex mg/kg/hr  (103 rows)
    , 2285 -- nimbex mcg/kg/min  (85 rows)
    , 2290 -- nimbex mcg/kg/m  (32 rows)
    , 2670 -- nimbex  (38 rows)
    , 2546 -- CISATRACURIUMMG/KG/H  (7 rows)
    , 1098 -- cisatracurium mg/kg  (36 rows)
    , 2390 -- cisatracurium mg/hr  (15 rows)
    , 2511 -- CISATRACURIUM GTT  (4 rows)
    , 1028 -- Cisatracurium  (208 rows)
    , 1858 -- cisatracurium  (351 rows)
  )
  group by icustay_id, charttime

)
, drugcv2 as
(
  select v.*
    , sum(drug_null) over (partition by icustay_id order by charttime) as drug_partition
  from
    drugcv1 v
)
, drugcv3 as
(
  select v.*
    , first_value(drug_rate) over (partition by icustay_id, drug_partition order by charttime) as drug_prevrate_ifnull
  from
    drugcv2 v
)
, drugcv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) AS delta

    , drug
    , drug_rate
    , drug_amount
    , drug_stopped
    , drug_prevrate_ifnull

    -- We define start time here
    , case
        when drug = 0 then null

        -- if this is the first instance of the drug
        when drug_rate > 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug, drug_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes drugnum sequential
        when drug_rate = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- drug_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when drug_prevrate_ifnull = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newdrug = 1
        when LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) = 0
          then 1

        -- If the last recorded drug was D/C'd, newdrug = 1
        when
          LAG(drug_stopped,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 1 then 1

        when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) > (interval '8 hours') then 1
      else null
      end as drug_start

FROM
  drugcv3
)
-- propagate start/stop flags forward in time
, drugcv5 as
(
  select v.*
    , SUM(drug_start) OVER (partition by icustay_id, drug order by charttime) as drug_first
FROM
  drugcv4 v
)
, drugcv6 as
(
  select v.*
    -- We define end time here
    , case
        when drug = 0
          then null

        -- If the recorded drug was D/C'd, this is an end time
        when drug_stopped = 1
          then drug_first

        -- If the rate is zero, this is the end time
        when drug_rate = 0
          then drug_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on drug
        -- in principle, this could add an extra end time for the drug
        -- however, since we later group on drug_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) is null
          then drug_first

        else null
        end as drug_stop
    from drugcv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, drug, drug_rate, drug_amount
--     , drug_stopped
--     , drug_start
--     , drug_first
--     , drug_stop
-- from drugcv6 order by icustay_id, charttime

, drugcv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, drug_first order by charttime) as endtime
  , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
from drugcv6
where
  drug_first is not null -- bogus data
and
  drug_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, drugcv8 as
(
  select
    icustay_id
    , starttime, endtime
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv7
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, drugcv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(drug_rate) OVER (partition by icustay_id order by starttime, endtime) = drug_rate
        THEN 0
      else 1
    end as drug_groups
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv8
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
, drugcv10 as
(
  select
    icustay_id
    , starttime, endtime
    , drug_groups
    , SUM(drug_groups) OVER (partition by icustay_id order by starttime, endtime) as drug_groups_sum
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv9
)
, drugcv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , drug_groups_sum
  , drug_rate
  , sum(drug_amount) as drug_amount
  from drugcv10
  group by icustay_id, drug_groups_sum, drug_rate
)
-- now assign this data to every hour of the patient's stay
-- drug_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugcv
UNION
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugmv
order by icustay_id, starttime
  );
17:39:16.440573 [debug] [Thread-1  ]: SQL status: SELECT 9704 in 1.0 seconds
17:39:16.447571 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:16.447949 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose" rename to "neuroblock_dose__dbt_backup"
17:39:16.449192 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:16.454514 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:16.454929 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose__dbt_tmp" rename to "neuroblock_dose"
17:39:16.455623 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:16.458598 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:39:16.458875 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:16.459079 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:39:16.461211 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:16.463681 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:39:16.463880 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
drop table if exists "postgres"."public"."neuroblock_dose__dbt_backup" cascade
17:39:16.465613 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:16.468874 [debug] [Thread-1  ]: finished collecting timing info
17:39:16.469123 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: Close
17:39:16.469803 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0d9ca60>]}
17:39:16.470336 [info ] [Thread-1  ]: 12 of 23 OK created table model public.neuroblock_dose ......................... [[32mSELECT 9704[0m in 1.05s]
17:39:16.471009 [debug] [Thread-1  ]: Finished running node model.mimic.neuroblock_dose
17:39:16.471401 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_durations
17:39:16.472084 [info ] [Thread-1  ]: 13 of 23 START table model public.norepinephrine_durations ..................... [RUN]
17:39:16.472845 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_durations"
17:39:16.473160 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_durations
17:39:16.473435 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_durations
17:39:16.474873 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_durations"
17:39:16.475486 [debug] [Thread-1  ]: finished collecting timing info
17:39:16.475753 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_durations
17:39:16.487988 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_durations"
17:39:16.488570 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:16.488775 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: BEGIN
17:39:16.488936 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:16.493989 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:16.494228 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:16.494605 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */


  create  table "postgres"."public"."norepinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of norepinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30047,30120) then rate else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30047,30120) -- norepinephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the carevue data before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime

, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:19.730216 [debug] [Thread-1  ]: SQL status: SELECT 23188 in 3.24 seconds
17:39:19.736444 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:19.736647 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations" rename to "norepinephrine_durations__dbt_backup"
17:39:19.737470 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:19.741417 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:19.741634 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations__dbt_tmp" rename to "norepinephrine_durations"
17:39:19.742354 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:19.745500 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:39:19.745696 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:19.745911 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:39:19.748780 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:19.751300 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:39:19.751526 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
drop table if exists "postgres"."public"."norepinephrine_durations__dbt_backup" cascade
17:39:19.753689 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:19.756615 [debug] [Thread-1  ]: finished collecting timing info
17:39:19.756839 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: Close
17:39:19.757655 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef039eb50>]}
17:39:19.758053 [info ] [Thread-1  ]: 13 of 23 OK created table model public.norepinephrine_durations ................ [[32mSELECT 23188[0m in 3.29s]
17:39:19.758368 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_durations
17:39:19.758773 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_dose
17:39:19.759491 [info ] [Thread-1  ]: 14 of 23 START table model public.phenylephrine_dose ........................... [RUN]
17:39:19.760342 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_dose"
17:39:19.760778 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_dose
17:39:19.761199 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_dose
17:39:19.762727 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_dose"
17:39:19.763485 [debug] [Thread-1  ]: finished collecting timing info
17:39:19.763889 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_dose
17:39:19.777984 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_dose"
17:39:19.779091 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:19.779313 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: BEGIN
17:39:19.779502 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:19.785936 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:19.786620 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:19.787000 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */


  create  table "postgres"."public"."phenylephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of phenylephrine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30127,30128) -- phenylephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:24.313577 [debug] [Thread-1  ]: SQL status: SELECT 186281 in 4.53 seconds
17:39:24.320332 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:24.320697 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose" rename to "phenylephrine_dose__dbt_backup"
17:39:24.321956 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:24.326175 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:24.326390 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose__dbt_tmp" rename to "phenylephrine_dose"
17:39:24.327185 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:24.330107 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:39:24.330303 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:24.330408 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:39:24.353843 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
17:39:24.357210 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:39:24.357409 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
drop table if exists "postgres"."public"."phenylephrine_dose__dbt_backup" cascade
17:39:24.359516 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:24.362287 [debug] [Thread-1  ]: finished collecting timing info
17:39:24.362580 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: Close
17:39:24.363399 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec6d0>]}
17:39:24.363886 [info ] [Thread-1  ]: 14 of 23 OK created table model public.phenylephrine_dose ...................... [[32mSELECT 186281[0m in 4.60s]
17:39:24.364440 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_dose
17:39:24.364778 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_durations
17:39:24.365470 [info ] [Thread-1  ]: 15 of 23 START table model public.phenylephrine_durations ...................... [RUN]
17:39:24.366280 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_durations"
17:39:24.366708 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_durations
17:39:24.366971 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_durations
17:39:24.368467 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_durations"
17:39:24.369062 [debug] [Thread-1  ]: finished collecting timing info
17:39:24.369418 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_durations
17:39:24.381949 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_durations"
17:39:24.383402 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:24.383749 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: BEGIN
17:39:24.384058 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:24.389630 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:24.390096 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:24.390244 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */


  create  table "postgres"."public"."phenylephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of phenylephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30127,30128 -- phenylephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:28.144316 [debug] [Thread-1  ]: SQL status: SELECT 33141 in 3.75 seconds
17:39:28.150453 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:28.150893 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations" rename to "phenylephrine_durations__dbt_backup"
17:39:28.152622 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:28.157194 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:28.157390 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations__dbt_tmp" rename to "phenylephrine_durations"
17:39:28.158104 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:28.161410 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:39:28.161617 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:28.161709 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:39:28.166766 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:28.169047 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:39:28.169339 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
drop table if exists "postgres"."public"."phenylephrine_durations__dbt_backup" cascade
17:39:28.172928 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:28.175892 [debug] [Thread-1  ]: finished collecting timing info
17:39:28.176245 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: Close
17:39:28.177084 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec820>]}
17:39:28.177577 [info ] [Thread-1  ]: 15 of 23 OK created table model public.phenylephrine_durations ................. [[32mSELECT 33141[0m in 3.81s]
17:39:28.178008 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_durations
17:39:28.178160 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_dose
17:39:28.178901 [info ] [Thread-1  ]: 16 of 23 START table model public.vasopressin_dose ............................. [RUN]
17:39:28.179703 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_dose"
17:39:28.179942 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_dose
17:39:28.180240 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_dose
17:39:28.181574 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_dose"
17:39:28.181973 [debug] [Thread-1  ]: finished collecting timing info
17:39:28.182091 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_dose
17:39:28.195398 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_dose"
17:39:28.196020 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:28.196247 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: BEGIN
17:39:28.196342 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:28.201650 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:28.201899 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:28.202022 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */


  create  table "postgres"."public"."vasopressin_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of vasopressin administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    -- , CASE WHEN valueuom = 'units/min' THEN rate*60.0 ELSE rate END as vaso_rate
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:29.929559 [debug] [Thread-1  ]: SQL status: SELECT 10537 in 1.73 seconds
17:39:29.936727 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:29.937042 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose" rename to "vasopressin_dose__dbt_backup"
17:39:29.938233 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:29.941867 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:29.942063 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose__dbt_tmp" rename to "vasopressin_dose"
17:39:29.942860 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:29.945677 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:39:29.945871 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:29.945993 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:39:29.948341 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:29.950835 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:39:29.951102 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
drop table if exists "postgres"."public"."vasopressin_dose__dbt_backup" cascade
17:39:29.953460 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:29.956329 [debug] [Thread-1  ]: finished collecting timing info
17:39:29.956571 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: Close
17:39:29.957496 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ec970>]}
17:39:29.957998 [info ] [Thread-1  ]: 16 of 23 OK created table model public.vasopressin_dose ........................ [[32mSELECT 10537[0m in 1.78s]
17:39:29.958425 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_dose
17:39:29.958962 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_durations
17:39:29.959663 [info ] [Thread-1  ]: 17 of 23 START table model public.vasopressin_durations ........................ [RUN]
17:39:29.960568 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_durations"
17:39:29.960896 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_durations
17:39:29.961138 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_durations
17:39:29.962442 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_durations"
17:39:29.963271 [debug] [Thread-1  ]: finished collecting timing info
17:39:29.963560 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_durations
17:39:29.972830 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_durations"
17:39:29.973508 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:29.973708 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: BEGIN
17:39:29.973813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:29.978924 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:29.979176 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:29.979446 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */


  create  table "postgres"."public"."vasopressin_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressin administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:39:31.712181 [debug] [Thread-1  ]: SQL status: SELECT 4190 in 1.73 seconds
17:39:31.718121 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:31.718340 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations" rename to "vasopressin_durations__dbt_backup"
17:39:31.719080 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:31.723065 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:31.723286 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations__dbt_tmp" rename to "vasopressin_durations"
17:39:31.724057 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:31.727165 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:39:31.727380 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:31.727659 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:39:31.737343 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:39:31.739735 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:39:31.739945 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
drop table if exists "postgres"."public"."vasopressin_durations__dbt_backup" cascade
17:39:31.741967 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:31.744613 [debug] [Thread-1  ]: finished collecting timing info
17:39:31.744841 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: Close
17:39:31.745676 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ecac0>]}
17:39:31.746169 [info ] [Thread-1  ]: 17 of 23 OK created table model public.vasopressin_durations ................... [[32mSELECT 4190[0m in 1.79s]
17:39:31.746757 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_durations
17:39:31.747129 [debug] [Thread-1  ]: Began running node model.mimic.vasopressor_durations
17:39:31.747858 [info ] [Thread-1  ]: 18 of 23 START table model public.vasopressor_durations ........................ [RUN]
17:39:31.748619 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressor_durations"
17:39:31.748864 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressor_durations
17:39:31.749155 [debug] [Thread-1  ]: Compiling model.mimic.vasopressor_durations
17:39:31.750375 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressor_durations"
17:39:31.751043 [debug] [Thread-1  ]: finished collecting timing info
17:39:31.751372 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressor_durations
17:39:31.762091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressor_durations"
17:39:31.762693 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:31.763033 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: BEGIN
17:39:31.763476 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:31.771140 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:31.771485 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:31.771794 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */


  create  table "postgres"."public"."vasopressor_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressor administration
-- It groups together any administration of the below list of drugs:
--  norepinephrine - 30047,30120,221906
--  epinephrine - 30044,30119,30309,221289
--  phenylephrine - 30127,30128,221749
--  vasopressin - 30051,222315 (42273, 42802 also for 2 patients)
--  dopamine - 30043,30307,221662
--  dobutamine - 30042,30306,221653
--  milrinone - 30125,221986

-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table
-- by grouping using ICUSTAY_ID

-- select only the ITEMIDs from the inputevents_cv table related to vasopressors
with io_cv as
(
  select
    icustay_id, charttime, itemid, stopped
    -- ITEMIDs (42273, 42802) accidentally store rate in amount column
    , case
        when itemid in (42273, 42802)
          then amount
        else rate
      end as rate
    , case
        when itemid in (42273, 42802)
          then rate
        else amount
      end as amount
  FROM inputevents_cv
  where itemid in
  (
    30047,30120,30044,30119,30309,30127
  , 30128,30051,30043,30307,30042,30306,30125
  , 42273, 42802
  )
)
-- select only the ITEMIDs from the inputevents_mv table related to vasopressors
, io_mv as
(
  select
    icustay_id, linkorderid, starttime, endtime
  FROM inputevents_mv io
  -- Subselect the vasopressor ITEMIDs
  where itemid in
  (
  221906,221289,221749,222315,221662,221653,221986
  )
  and statusdescription != 'Rewritten' -- only valid orders
)
, vasocv1 as
(
  select
    icustay_id, charttime, itemid
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , 1 as vaso

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when rate is not null then 1 else 0 end) as vaso_null
    , max(rate) as vaso_rate
    , max(amount) as vaso_amount

  from io_cv
  group by icustay_id, charttime, itemid
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id, itemid order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, itemid, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    , itemid
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, itemid, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  , itemid
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, itemid, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)
-- we do not group by ITEMID in below query
-- this is because we want to collapse all vasopressors together
, vasocv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasocv s1
INNER JOIN vasocv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasocv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasocv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
-- now we extract the associated data for metavision patients
-- do not need to group by itemid because we group by linkorderid
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  from io_mv
  group by icustay_id, linkorderid
)
, vasomv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasomv s1
INNER JOIN vasomv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasomv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasomv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv_grp

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv_grp

order by icustay_id, vasonum
  );
17:39:40.444084 [debug] [Thread-1  ]: SQL status: SELECT 38832 in 8.67 seconds
17:39:40.451379 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:40.451594 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations" rename to "vasopressor_durations__dbt_backup"
17:39:40.452458 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.456283 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:40.456500 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations__dbt_tmp" rename to "vasopressor_durations"
17:39:40.457200 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.460491 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:39:40.460703 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:40.460806 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:39:40.468655 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:39:40.470810 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:39:40.471035 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
drop table if exists "postgres"."public"."vasopressor_durations__dbt_backup" cascade
17:39:40.473788 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:40.476558 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.476801 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: Close
17:39:40.477542 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ecca0>]}
17:39:40.477953 [info ] [Thread-1  ]: 18 of 23 OK created table model public.vasopressor_durations ................... [[32mSELECT 38832[0m in 8.73s]
17:39:40.478290 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressor_durations
17:39:40.478424 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_classification
17:39:40.479097 [info ] [Thread-1  ]: 19 of 23 START table model public.ventilation_classification ................... [RUN]
17:39:40.479858 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_classification"
17:39:40.480182 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_classification
17:39:40.480408 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_classification
17:39:40.481766 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_classification"
17:39:40.482330 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.482788 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_classification
17:39:40.498172 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_classification"
17:39:40.499219 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.499590 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: BEGIN
17:39:40.499955 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:40.505978 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:40.506216 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.506385 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */


  create  table "postgres"."public"."ventilation_classification__dbt_tmp"
  as (
    -- Identify The presence of a mechanical ventilation using settings
select
  icustay_id, charttime
  -- case statement determining whether it is an instance of mech vent
  , max(
    case
      when itemid is null or value is null then 0 -- can't have null values
      when itemid = 720 and value != 'Other/Remarks' THEN 1  -- VentTypeRecorded
      when itemid = 223848 and value != 'Other' THEN 1
      when itemid = 223849 then 1 -- ventilator mode
      when itemid = 467 and value = 'Ventilator' THEN 1 -- O2 delivery device == ventilator
      when itemid in
        (
        445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
        , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
        , 218,436,535,444,459,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean/Neg insp force ("RespPressure")
        , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
        , 543 -- PlateauPressure
        , 5865,5866,224707,224709,224705,224706 -- APRV pressure
        , 60,437,505,506,686,220339,224700 -- PEEP
        , 3459 -- high pressure relief
        , 501,502,503,224702 -- PCV
        , 223,667,668,669,670,671,672 -- TCPCV
        , 224701 -- PSVlevel
        )
        THEN 1
      else 0
    end
    ) as MechVent
    , max(
      case
        -- initiation of oxygen therapy indicates the ventilation has ended
        when itemid = 226732 and value in
        (
          'Nasal cannula', -- 153714 observations
          'Face tent', -- 24601 observations
          'Aerosol-cool', -- 24560 observations
          'Trach mask ', -- 16435 observations
          'High flow neb', -- 10785 observations
          'Non-rebreather', -- 5182 observations
          'Venti mask ', -- 1947 observations
          'Medium conc mask ', -- 1888 observations
          'T-piece', -- 1135 observations
          'High flow nasal cannula', -- 925 observations
          'Ultrasonic neb', -- 9 observations
          'Vapomist' -- 3 observations
        ) then 1
        when itemid = 467 and value in
        (
          'Cannula', -- 278252 observations
          'Nasal Cannula', -- 248299 observations
          -- 'None', -- 95498 observations
          'Face Tent', -- 35766 observations
          'Aerosol-Cool', -- 33919 observations
          'Trach Mask', -- 32655 observations
          'Hi Flow Neb', -- 14070 observations
          'Non-Rebreather', -- 10856 observations
          'Venti Mask', -- 4279 observations
          'Medium Conc Mask', -- 2114 observations
          'Vapotherm', -- 1655 observations
          'T-Piece', -- 779 observations
          'Hood', -- 670 observations
          'Hut', -- 150 observations
          'TranstrachealCat', -- 78 observations
          'Heated Neb', -- 37 observations
          'Ultrasonic Neb' -- 2 observations
        ) then 1
      else 0
      end
    ) as OxygenTherapy
    , max(
      case when itemid is null or value is null then 0
        -- extubated indicates ventilation event has ended
        when itemid = 640 and value = 'Extubated' then 1
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as Extubated
    , max(
      case when itemid is null or value is null then 0
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as SelfExtubated
from chartevents ce
where ce.value is not null
-- exclude rows marked as error
and (ce.error != 1 or ce.error IS NULL)
and itemid in
(
    -- the below are settings used to indicate ventilation
      720, 223849 -- vent mode
    , 223848 -- vent type
    , 445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
    , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
    , 218,436,535,444,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean ("RespPressure")
    , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
    , 543 -- PlateauPressure
    , 5865,5866,224707,224709,224705,224706 -- APRV pressure
    , 60,437,505,506,686,220339,224700 -- PEEP
    , 3459 -- high pressure relief
    , 501,502,503,224702 -- PCV
    , 223,667,668,669,670,671,672 -- TCPCV
    , 224701 -- PSVlevel

    -- the below are settings used to indicate extubation
    , 640 -- extubated

    -- the below indicate oxygen/NIV, i.e. the end of a mechanical vent event
    , 468 -- O2 Delivery Device#2
    , 469 -- O2 Delivery Mode
    , 470 -- O2 Flow (lpm)
    , 471 -- O2 Flow (lpm) #2
    , 227287 -- O2 Flow (additional cannula)
    , 226732 -- O2 Delivery Device(s)
    , 223834 -- O2 Flow

    -- used in both oxygen + vent calculation
    , 467 -- O2 Delivery Device
)
group by icustay_id, charttime
UNION DISTINCT
-- add in the extubation flags from procedureevents_mv
-- note that we only need the start time for the extubation
-- (extubation is always charted as ending 1 minute after it started)
select
  icustay_id, starttime as charttime
  , 0 as MechVent
  , 0 as OxygenTherapy
  , 1 as Extubated
  , case when itemid = 225468 then 1 else 0 end as SelfExtubated
from procedureevents_mv
where itemid in
(
  227194 -- "Extubation"
, 225468 -- "Unplanned Extubation (patient-initiated)"
, 225477 -- "Unplanned Extubation (non-patient initiated)"
)
  );
17:39:40.620352 [debug] [Thread-1  ]: SQL status: SELECT 8642 in 0.11 seconds
17:39:40.625854 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.626245 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification" rename to "ventilation_classification__dbt_backup"
17:39:40.627060 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.632287 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.632493 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification__dbt_tmp" rename to "ventilation_classification"
17:39:40.633216 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.636329 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:39:40.636537 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.636721 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:39:40.638713 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:40.641029 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:39:40.641211 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
drop table if exists "postgres"."public"."ventilation_classification__dbt_backup" cascade
17:39:40.643275 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:40.646370 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.646620 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: Close
17:39:40.647381 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ecd90>]}
17:39:40.647909 [info ] [Thread-1  ]: 19 of 23 OK created table model public.ventilation_classification .............. [[32mSELECT 8642[0m in 0.17s]
17:39:40.648423 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_classification
17:39:40.648766 [debug] [Thread-1  ]: Began running node model.mimic.weight_durations
17:39:40.649484 [info ] [Thread-1  ]: 20 of 23 START table model public.weight_durations ............................. [RUN]
17:39:40.650974 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.weight_durations"
17:39:40.651388 [debug] [Thread-1  ]: Began compiling node model.mimic.weight_durations
17:39:40.651637 [debug] [Thread-1  ]: Compiling model.mimic.weight_durations
17:39:40.658701 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.weight_durations"
17:39:40.660027 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.660484 [debug] [Thread-1  ]: Began executing node model.mimic.weight_durations
17:39:40.673067 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.weight_durations"
17:39:40.673914 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.674162 [debug] [Thread-1  ]: On model.mimic.weight_durations: BEGIN
17:39:40.674297 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:40.680680 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:40.681081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.681238 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */


  create  table "postgres"."public"."weight_durations__dbt_tmp"
  as (
    -- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime

-- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime
WITH wt_neonate AS
( 
    SELECT c.icustay_id, c.charttime
    , MAX(CASE WHEN c.itemid = 3580 THEN c.valuenum END) as wt_kg
    , MAX(CASE WHEN c.itemid = 3581 THEN c.valuenum END) as wt_lb
    , MAX(CASE WHEN c.itemid = 3582 THEN c.valuenum END) as wt_oz
    FROM chartevents c
    WHERE c.itemid in (3580, 3581, 3582)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
    -- wt_oz/wt_lb/wt_kg are only 0 erroneously, so drop these rows
    AND c.valuenum > 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, birth_wt AS
(
    SELECT c.icustay_id, c.charttime
    , MAX(
      CASE
      WHEN c.itemid = 4183 THEN
        -- clean free-text birth weight data
        CASE
          -- ignore value if there are any non-numeric characters
          WHEN REGEXP_CONTAINS(c.value, '[^0-9\\.]') THEN NULL 
          -- convert grams to kd
          WHEN CAST(c.value AS NUMERIC) > 100 THEN CAST(c.value AS NUMERIC)/1000
          -- keep kg as is, filtering bad values (largest baby ever born was conveniently 9.98kg)
          WHEN CAST(c.value AS NUMERIC) < 10 THEN CAST(c.value AS NUMERIC)
          -- ignore other values (those between 10-100) - junk data
        ELSE NULL END
      -- itemid 3723 happily has all numeric data - also doesn't store any grams data
      WHEN c.itemid = 3723 AND c.valuenum < 10 THEN c.valuenum
      ELSE NULL END) as wt_kg
    FROM chartevents c
    WHERE c.itemid in (3723, 4183)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, wt_stg as
(
    SELECT
        c.icustay_id
      , c.charttime
      , case when c.itemid in (762,226512) then 'admit'
          else 'daily' end as weight_type
      -- TODO: eliminate obvious outliers if there is a reasonable weight
      , c.valuenum as weight
    FROM chartevents c
    WHERE c.valuenum IS NOT NULL
      AND c.itemid in
      (
          762,226512 -- Admit Wt
        , 763,224639 -- Daily Weight
      )
      AND c.icustay_id IS NOT NULL
      AND c.valuenum > 0
      -- exclude rows marked as error
      AND COALESCE(c.error, 0) = 0
    UNION ALL
    SELECT
        n.icustay_id
      , n.charttime
      , 'daily' AS weight_type
      , CASE
          WHEN wt_kg IS NOT NULL THEN wt_kg
          WHEN wt_lb IS NOT NULL THEN wt_lb*0.45359237 + wt_oz*0.0283495231
        ELSE NULL END AS weight
    FROM wt_neonate n
    UNION ALL
    SELECT
        b.icustay_id
      , b.charttime
      -- birth weight of neonates is treated as admission weight
      , 'admit' AS weight_type
      , wt_kg as weight
    FROM birth_wt b
)
-- get more weights from echo - completes data for ~2500 patients
-- we only use echo data if there is *no* charted data
-- we impute the median echo weight for their entire ICU stay
, echo as
(
  select
    ie.icustay_id
    , ec.charttime
    , 'echo' AS weight_type
    , 0.453592*ec.weight as weight
  from icustays ie
  inner join "postgres"."public"."echo_data" ec
    on ie.hadm_id = ec.hadm_id
  where ec.weight is not null
  and ie.icustay_id not in (select distinct icustay_id from wt_stg)
)
, wt_stg0 AS
(
  SELECT icustay_id, charttime, weight_type, weight
  FROM wt_stg
  UNION ALL
  SELECT icustay_id, charttime, weight_type, weight
  FROM echo
)
-- assign ascending row number
, wt_stg1 as
(
  select
      icustay_id
    , charttime
    , weight_type
    , weight
    , ROW_NUMBER() OVER (partition by icustay_id, weight_type order by charttime) as rn
  from wt_stg0
  WHERE weight IS NOT NULL
)
-- change charttime to intime for the first admission weight recorded
, wt_stg2 AS
(
  SELECT 
      wt_stg1.icustay_id
    , ie.intime, ie.outtime
    , case when wt_stg1.weight_type = 'admit' and wt_stg1.rn = 1
        then DATETIME_SUB(ie.intime, INTERVAL '2' HOUR)
      else wt_stg1.charttime end as starttime
    , wt_stg1.weight
  from wt_stg1
  INNER JOIN icustays ie
    on ie.icustay_id = wt_stg1.icustay_id
)
, wt_stg3 as
(
  select
    icustay_id
    , intime, outtime
    , starttime
    , coalesce(
        LEAD(starttime) OVER (PARTITION BY icustay_id ORDER BY starttime),
        DATETIME_ADD(GREATEST(outtime, starttime), INTERVAL '2' HOUR)
      ) as endtime
    , weight
  from wt_stg2
)
-- this table is the start/stop times from admit/daily weight in charted data
, wt1 as
(
  select
      icustay_id
    , starttime
    , coalesce(endtime,
      LEAD(starttime) OVER (partition by icustay_id order by starttime),
      -- impute ICU discharge as the end of the final weight measurement
      -- plus a 2 hour "fuzziness" window
      DATETIME_ADD(outtime, INTERVAL '2' HOUR)
    ) as endtime
    , weight
  from wt_stg3
)
-- if the intime for the patient is < the first charted daily weight
-- then we will have a "gap" at the start of their stay
-- to prevent this, we look for these gaps and backfill the first weight
-- this adds (153255-149657)=3598 rows, meaning this fix helps for up to 3598 icustay_id
, wt_fix as
(
  select ie.icustay_id
    -- we add a 2 hour "fuzziness" window
    , DATETIME_SUB(ie.intime, INTERVAL '2' HOUR) as starttime
    , wt.starttime as endtime
    , wt.weight
  from icustays ie
  inner join
  -- the below subquery returns one row for each unique icustay_id
  -- the row contains: the first starttime and the corresponding weight
  (
    SELECT wt1.icustay_id, wt1.starttime, wt1.weight
    , ROW_NUMBER() OVER (PARTITION BY wt1.icustay_id ORDER BY wt1.starttime) as rn
    FROM wt1
  ) wt
    ON  ie.icustay_id = wt.icustay_id
    AND wt.rn = 1
    and ie.intime < wt.starttime
)
-- add the backfill rows to the main weight table
select
    wt1.icustay_id
  , wt1.starttime
  , wt1.endtime
  , wt1.weight
from wt1
UNION ALL
SELECT
    wt_fix.icustay_id
  , wt_fix.starttime
  , wt_fix.endtime
  , wt_fix.weight
from wt_fix
  );
17:39:40.691608 [debug] [Thread-1  ]: SQL status: SELECT 15 in 0.01 seconds
17:39:40.699567 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.699838 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations" rename to "weight_durations__dbt_backup"
17:39:40.700933 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.706643 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.706984 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations__dbt_tmp" rename to "weight_durations"
17:39:40.707663 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.712833 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:39:40.713182 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.713367 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:39:40.714663 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:40.716876 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:39:40.717073 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
drop table if exists "postgres"."public"."weight_durations__dbt_backup" cascade
17:39:40.718893 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:40.721399 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.721600 [debug] [Thread-1  ]: On model.mimic.weight_durations: Close
17:39:40.722042 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03eceb0>]}
17:39:40.722300 [info ] [Thread-1  ]: 20 of 23 OK created table model public.weight_durations ........................ [[32mSELECT 15[0m in 0.07s]
17:39:40.722929 [debug] [Thread-1  ]: Finished running node model.mimic.weight_durations
17:39:40.723450 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_durations
17:39:40.724022 [info ] [Thread-1  ]: 21 of 23 START table model public.ventilation_durations ........................ [RUN]
17:39:40.725032 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_durations"
17:39:40.725321 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_durations
17:39:40.725446 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_durations
17:39:40.730299 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_durations"
17:39:40.731266 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.731589 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_durations
17:39:40.740086 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_durations"
17:39:40.740690 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.740894 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: BEGIN
17:39:40.740994 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:40.745806 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:39:40.746250 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.746906 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */


  create  table "postgres"."public"."ventilation_durations__dbt_tmp"
  as (
    -- This query extracts the duration of mechanical ventilation
-- The main goal of the query is to aggregate sequential ventilator settings
-- into single mechanical ventilation "events". The start and end time of these
-- events can then be used for various purposes: calculating the total duration
-- of mechanical ventilation, cross-checking values (e.g. PaO2:FiO2 on vent), etc

-- The query's logic is roughly:
--    1) The presence of a mechanical ventilation setting starts a new ventilation event
--    2) Any instance of a setting in the next 8 hours continues the event
--    3) Certain elements end the current ventilation event
--        a) documented extubation ends the current ventilation
--        b) initiation of non-invasive vent and/or oxygen ends the current vent

-- See the ventilation_classification.sql query for step 1 of the above.
-- This query has the logic for converting events into durations.
with vd0 as
(
  select
    icustay_id
    -- this carries over the previous charttime which had a mechanical ventilation event
    , case
        when MechVent=1 then
          LAG(CHARTTIME, 1) OVER (partition by icustay_id, MechVent order by charttime)
        else null
      end as charttime_lag
    , charttime
    , MechVent
    , OxygenTherapy
    , Extubated
    , SelfExtubated
  from "postgres"."public"."ventilation_classification"
)
, vd1 as
(
  select
      icustay_id
      , charttime_lag
      , charttime
      , MechVent
      , OxygenTherapy
      , Extubated
      , SelfExtubated

      -- if this is a mechanical ventilation event, we calculate the time since the last event
      , case
          -- if the current observation indicates mechanical ventilation is present
          -- calculate the time since the last vent event
          when MechVent=1 then
            DATETIME_DIFF(CHARTTIME, charttime_lag, 'MINUTE')/60
          else null
        end as ventduration

      , LAG(Extubated,1)
      OVER
      (
      partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
      order by charttime
      ) as ExtubatedLag

      -- now we determine if the current mech vent event is a "new", i.e. they've just been intubated
      , case
        -- if there is an extubation flag, we mark any subsequent ventilation as a new ventilation event
          --when Extubated = 1 then 0 -- extubation is *not* a new ventilation event, the *subsequent* row is
          when
            LAG(Extubated,1)
            OVER
            (
            partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
            order by charttime
            )
            = 1 then 1
          -- if patient has initiated oxygen therapy, and is not currently vented, start a newvent
          when MechVent = 0 and OxygenTherapy = 1 then 1
            -- if there is less than 8 hours between vent settings, we do not treat this as a new ventilation event
          when CHARTTIME > DATETIME_ADD(charttime_lag, INTERVAL '8' HOUR)
            then 1
        else 0
        end as newvent
  -- use the staging table with only vent settings from chart events
  FROM vd0 ventsettings
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new ventilation
  -- this results in a monotonic integer assigned to each instance of ventilation
  , case when MechVent=1 or Extubated = 1 then
      SUM( newvent )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as ventnum
  --- now we convert CHARTTIME of ventilator settings into durations
  from vd1
)
-- create the durations for each mechanical ventilation instance
select icustay_id
  -- regenerate ventnum so it's sequential
  , ROW_NUMBER() over (partition by icustay_id order by ventnum) as ventnum
  , min(charttime) as starttime
  , max(charttime) as endtime
  , DATETIME_DIFF(max(charttime), min(charttime), 'MINUTE')/60 AS duration_hours
from vd2
group by icustay_id, vd2.ventnum
having min(charttime) != max(charttime)
-- patient had to be mechanically ventilated at least once
-- i.e. max(mechvent) should be 1
-- this excludes a frequent situation of NIV/oxygen before intub
-- in these cases, ventnum=0 and max(mechvent)=0, so they are ignored
and max(mechvent) = 1
order by icustay_id, ventnum
  );
17:39:40.784325 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.04 seconds
17:39:40.788013 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.788218 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations" rename to "ventilation_durations__dbt_backup"
17:39:40.789091 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.793005 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.793207 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations__dbt_tmp" rename to "ventilation_durations"
17:39:40.794323 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:40.798873 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:39:40.799117 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.799369 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:39:40.800484 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:40.802681 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:39:40.802930 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
drop table if exists "postgres"."public"."ventilation_durations__dbt_backup" cascade
17:39:40.804978 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:40.808037 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.808271 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: Close
17:39:40.809060 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0301ac0>]}
17:39:40.809458 [info ] [Thread-1  ]: 21 of 23 OK created table model public.ventilation_durations ................... [[32mSELECT 3[0m in 0.08s]
17:39:40.810198 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_durations
17:39:40.811394 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_dose
17:39:40.812001 [info ] [Thread-1  ]: 22 of 23 START table model public.epinephrine_dose ............................. [RUN]
17:39:40.812778 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_dose"
17:39:40.813100 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_dose
17:39:40.813303 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_dose
17:39:40.816420 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_dose"
17:39:40.816960 [debug] [Thread-1  ]: finished collecting timing info
17:39:40.817290 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_dose
17:39:40.824357 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_dose"
17:39:40.824965 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:40.825173 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: BEGIN
17:39:40.825335 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:40.830744 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:40.831695 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:40.832227 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */


  create  table "postgres"."public"."epinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of epinephrine administration

-- Requires the weightfirstday table

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30044 and wd.weight is null then rate / 80.0 -- super rare to be missing weight... affects 2 patients for 14 rows
            when itemid = 30044 then rate / wd.weight -- measured in mcgmin
            when itemid in (30119,30309) then rate -- measured in mcgkgmin
            else null
          end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  and cv.icustay_id is not null
  group by cv.icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:41.426609 [debug] [Thread-1  ]: SQL status: SELECT 10562 in 0.59 seconds
17:39:41.433796 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:41.434192 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose" rename to "epinephrine_dose__dbt_backup"
17:39:41.435608 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:41.439264 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:41.439480 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose__dbt_tmp" rename to "epinephrine_dose"
17:39:41.440159 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:41.443928 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:39:41.444141 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:41.444386 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:39:41.446498 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:39:41.448182 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:39:41.448434 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
drop table if exists "postgres"."public"."epinephrine_dose__dbt_backup" cascade
17:39:41.450165 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:41.452804 [debug] [Thread-1  ]: finished collecting timing info
17:39:41.453030 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: Close
17:39:41.453834 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef0d8f790>]}
17:39:41.454317 [info ] [Thread-1  ]: 22 of 23 OK created table model public.epinephrine_dose ........................ [[32mSELECT 10562[0m in 0.64s]
17:39:41.454964 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_dose
17:39:41.455367 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_dose
17:39:41.456066 [info ] [Thread-1  ]: 23 of 23 START table model public.norepinephrine_dose .......................... [RUN]
17:39:41.456800 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_dose"
17:39:41.457037 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_dose
17:39:41.457471 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_dose
17:39:41.464455 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_dose"
17:39:41.465085 [debug] [Thread-1  ]: finished collecting timing info
17:39:41.465353 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_dose
17:39:41.478446 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_dose"
17:39:41.479602 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:41.479906 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: BEGIN
17:39:41.480172 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:39:41.485729 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:39:41.485963 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:41.486065 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */


  create  table "postgres"."public"."norepinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of norepinephrine administration
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

  -- case statement determining whether the ITEMID is an instance of vasopressor usage

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30047 and wd.weight is null then rate / 80.0 -- this is rare, only affects a total of ~400 rows
            when itemid = 30047 then rate / wd.weight -- measured in mcgmin
            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin
          else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in (30047,30120) -- norepinephrine
  and cv.icustay_id is not null
  group by cv.icustay_id, cv.charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:39:44.496137 [debug] [Thread-1  ]: SQL status: SELECT 161449 in 3.01 seconds
17:39:44.500114 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:44.500318 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose" rename to "norepinephrine_dose__dbt_backup"
17:39:44.501259 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:44.507930 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:44.508137 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose__dbt_tmp" rename to "norepinephrine_dose"
17:39:44.508842 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:39:44.512379 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:39:44.512580 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:44.512790 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:39:44.525687 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:39:44.527737 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:39:44.527942 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
drop table if exists "postgres"."public"."norepinephrine_dose__dbt_backup" cascade
17:39:44.530134 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:39:44.532772 [debug] [Thread-1  ]: finished collecting timing info
17:39:44.533000 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: Close
17:39:44.533807 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adcb8d14-7d4c-44d6-ab39-4f5b185256ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03ecca0>]}
17:39:44.534312 [info ] [Thread-1  ]: 23 of 23 OK created table model public.norepinephrine_dose ..................... [[32mSELECT 161449[0m in 3.08s]
17:39:44.535012 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_dose
17:39:44.536847 [debug] [MainThread]: Acquiring new postgres connection "master"
17:39:44.537104 [debug] [MainThread]: Using postgres connection "master"
17:39:44.537377 [debug] [MainThread]: On master: BEGIN
17:39:44.537597 [debug] [MainThread]: Opening a new connection, currently in state closed
17:39:44.543826 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:39:44.544311 [debug] [MainThread]: On master: COMMIT
17:39:44.544628 [debug] [MainThread]: Using postgres connection "master"
17:39:44.544883 [debug] [MainThread]: On master: COMMIT
17:39:44.545567 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:39:44.546119 [debug] [MainThread]: On master: Close
17:39:44.547906 [info ] [MainThread]: 
17:39:44.549293 [info ] [MainThread]: Finished running 23 table models in 36.34s.
17:39:44.549582 [debug] [MainThread]: Connection 'master' was properly closed.
17:39:44.549777 [debug] [MainThread]: Connection 'model.mimic.norepinephrine_dose' was properly closed.
17:39:44.565276 [info ] [MainThread]: 
17:39:44.565542 [info ] [MainThread]: [32mCompleted successfully[0m
17:39:44.566456 [info ] [MainThread]: 
17:39:44.567556 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
17:39:44.568242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03dcdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03dcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ef03dcbb0>]}
17:39:44.571312 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:40:31.422880 | 70951921-1d6e-4695-a364-e3b6a912484c ==============================
17:40:31.422899 [info ] [MainThread]: Running with dbt=1.1.1
17:40:31.423421 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['severityscores'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:40:31.423624 [debug] [MainThread]: Tracking: tracking
17:40:31.429723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60a3190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60a3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60a3280>]}
17:40:31.519655 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:40:31.519903 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:40:31.522108 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:40:31.529150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60958e0>]}
17:40:31.549531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d6105f70>]}
17:40:31.549997 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:40:31.550354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60f0250>]}
17:40:31.555075 [info ] [MainThread]: 
17:40:31.557082 [debug] [MainThread]: Acquiring new postgres connection "master"
17:40:31.558699 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:40:31.566843 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:40:31.567065 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:40:31.567247 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:40:31.578497 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:40:31.583781 [debug] [ThreadPool]: On list_postgres: Close
17:40:31.591709 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:40:31.596597 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:40:31.596801 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:40:31.596897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:40:31.601120 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:40:31.601477 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:40:31.601738 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:40:31.608220 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.01 seconds
17:40:31.615389 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:40:31.615849 [debug] [ThreadPool]: On list_postgres_public: Close
17:40:31.628360 [debug] [MainThread]: Using postgres connection "master"
17:40:31.628593 [debug] [MainThread]: On master: BEGIN
17:40:31.628805 [debug] [MainThread]: Opening a new connection, currently in state init
17:40:31.633237 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:40:31.633460 [debug] [MainThread]: Using postgres connection "master"
17:40:31.633628 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:40:31.642074 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:40:31.645566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d6012b80>]}
17:40:31.645986 [debug] [MainThread]: On master: ROLLBACK
17:40:31.646269 [debug] [MainThread]: Using postgres connection "master"
17:40:31.646376 [debug] [MainThread]: On master: BEGIN
17:40:31.646908 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:40:31.647156 [debug] [MainThread]: On master: COMMIT
17:40:31.647341 [debug] [MainThread]: Using postgres connection "master"
17:40:31.647497 [debug] [MainThread]: On master: COMMIT
17:40:31.647836 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:40:31.648074 [debug] [MainThread]: On master: Close
17:40:31.648737 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:40:31.649112 [info ] [MainThread]: 
17:40:31.653544 [debug] [Thread-1  ]: Began running node model.mimic.apsiii
17:40:31.653869 [info ] [Thread-1  ]: 1 of 9 START table model public.apsiii ......................................... [RUN]
17:40:31.654380 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.apsiii"
17:40:31.654845 [debug] [Thread-1  ]: Began compiling node model.mimic.apsiii
17:40:31.655044 [debug] [Thread-1  ]: Compiling model.mimic.apsiii
17:40:31.663213 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.apsiii"
17:40:31.663832 [debug] [Thread-1  ]: finished collecting timing info
17:40:31.664220 [debug] [Thread-1  ]: Began executing node model.mimic.apsiii
17:40:31.701393 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.apsiii"
17:40:31.702467 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:31.703152 [debug] [Thread-1  ]: On model.mimic.apsiii: BEGIN
17:40:31.703606 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:31.709501 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:31.709860 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:31.709986 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */


  create  table "postgres"."public"."apsiii__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Acute Physiology Score III (APS III)
-- This query extracts the acute physiology score III.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for APS III:
--    Knaus WA, Wagner DP, Draper EA, Zimmerman JE, Bergner M, Bastos PG, Sirio CA, Murphy DJ, Lotring T, Damiano A.
--    The APACHE III prognostic system. Risk prediction of hospital mortality for critically ill hospitalized adults.
--    Chest Journal. 1991 Dec 1100(6):1619-36.

-- Reference for the equation for calibrating APS III to hospital mortality:
--    Johnson, A. E. W. (2015). Mortality prediction and acuity assessment in critical care.
--    University of Oxford, Oxford, UK.

-- Variables used in APS III:
--  GCS
--  VITALS: Heart rate, mean blood pressure, temperature, respiration rate
--  FLAGS: ventilation/cpap, chronic dialysis
--  IO: urine output
--  LABS: pao2, A-aDO2, hematocrit, WBC, creatinine
--        , blood urea nitrogen, sodium, albumin, bilirubin, glucose, pH, pCO2

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate icustay_ids.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- List of TODO:
-- The site of temperature is not incorporated. Axillary measurements should be increased by 1 degree.
-- Unfortunately the data for metavision is not available at the moment.
--  674 | Temp. Site
--  224642 | Temperature Site

with pa as
(
  select bg.icustay_id, bg.charttime
  , po2 as PaO2
  , ROW_NUMBER() over (partition by bg.icustay_id ORDER BY bg.po2 DESC) as rn
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join ventilation_durations vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  WHERE vd.icustay_id is null -- patient is *not* ventilated
  -- and fio2 < 50, or if no fio2, assume room air
  AND coalesce(fio2, fio2_chartevents, 21) < 50
  AND bg.po2 IS NOT NULL
)
, aa as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , bg.aado2
  , ROW_NUMBER() over (partition by bg.icustay_id ORDER BY bg.aado2 DESC) as rn
  -- row number indicating the highest AaDO2
  from blood_gas_first_day_arterial bg
  INNER JOIN ventilation_durations vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  WHERE vd.icustay_id is not null -- patient is ventilated
  AND coalesce(fio2, fio2_chartevents) >= 50
  AND bg.aado2 IS NOT NULL
)
-- because ph/pco2 rules are an interaction *within* a blood gas, we calculate them here
-- the worse score is then taken for the final calculation
, acidbase as
(
  select bg.icustay_id
  , ph, pco2 as paco2
  , case
      when ph is null or pco2 is null then null
      when ph < 7.20 then
        case
          when pco2 < 50 then 12
          else 4
        end
      when ph < 7.30 then
        case
          when pco2 < 30 then 9
          when pco2 < 40 then 6
          when pco2 < 50 then 3
          else 2
        end
      when ph < 7.35 then
        case
          when pco2 < 30 then 9
          when pco2 < 45 then 0
          else 1
        end
      when ph < 7.45 then
        case
          when pco2 < 30 then 5
          when pco2 < 45 then 0
          else 1
        end
      when ph < 7.50 then
        case
          when pco2 < 30 then 5
          when pco2 < 35 then 0
          when pco2 < 45 then 2
          else 12
        end
      when ph < 7.60 then
        case
          when pco2 < 40 then 3
          else 12
        end
      else -- ph >= 7.60
        case
          when pco2 < 25 then 0
          when pco2 < 40 then 3
          else 12
        end
    end as acidbase_score
  from blood_gas_first_day_arterial bg
  where ph is not null and pco2 is not null
)
, acidbase_max as
(
  select icustay_id, acidbase_score, ph, paco2
    -- create integer which indexes maximum value of score with 1
  , ROW_NUMBER() over (partition by icustay_id ORDER BY acidbase_score DESC) as acidbase_rn
  from acidbase
)
-- define acute renal failure (ARF) as:
--  creatinine >=1.5 mg/dl
--  and urine output <410 cc/day
--  and no chronic dialysis
, arf as
(
  select ie.icustay_id
    , case
        when labs.creatinine_max >= 1.5
        and  uo.urineoutput < 410
        -- acute renal failure is only coded if the patient is not on chronic dialysis
        -- we use ICD-9 coding of ESRD as a proxy for chronic dialysis
        and  icd.ckd = 0
          then 1
      else 0 end as arf
  FROM icustays ie
  left join "postgres"."public"."urine_output_first_day" uo
    on ie.icustay_id = uo.icustay_id
  left join "postgres"."public"."labs_first_day" labs
    on ie.icustay_id = labs.icustay_id
  left join
  (
    select hadm_id
      , max(case
          -- severe kidney failure requiring use of dialysis
          when icd9_code in  ('5854','5855','5856') then 1
          -- we do not include 5859 as that is sometimes coded for acute-on-chronic ARF
        else 0 end)
      as ckd
    from diagnoses_icd
    group by hadm_id
  ) icd
    on ie.hadm_id = icd.hadm_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      , vital.heartrate_min
      , vital.heartrate_max
      , vital.meanbp_min
      , vital.meanbp_max
      , vital.tempc_min
      , vital.tempc_max
      , vital.resprate_min
      , vital.resprate_max

      , pa.pao2
      , aa.aado2

      , ab.ph
      , ab.paco2
      , ab.acidbase_score

      , labs.hematocrit_min
      , labs.hematocrit_max
      , labs.wbc_min
      , labs.wbc_max
      , labs.creatinine_min
      , labs.creatinine_max
      , labs.bun_min
      , labs.bun_max
      , labs.sodium_min
      , labs.sodium_max
      , labs.albumin_min
      , labs.albumin_max
      , labs.bilirubin_min
      , labs.bilirubin_max

      , case
          when labs.glucose_max is null and vital.glucose_max is null
            then null
          when labs.glucose_max is null or vital.glucose_max > labs.glucose_max
            then vital.glucose_max
          when vital.glucose_max is null or labs.glucose_max > vital.glucose_max
            then labs.glucose_max
          else labs.glucose_max -- if equal, just pick labs
        end as glucose_max

      , case
          when labs.glucose_min is null and vital.glucose_min is null
            then null
          when labs.glucose_min is null or vital.glucose_min < labs.glucose_min
            then vital.glucose_min
          when vital.glucose_min is null or labs.glucose_min < vital.glucose_min
            then labs.glucose_min
          else labs.glucose_min -- if equal, just pick labs
        end as glucose_min

      -- , labs.bicarbonate_min
      -- , labs.bicarbonate_max
      , vent.vent
      , uo.urineoutput
      -- gcs and its components
      , gcs.mingcs
      , gcs.gcsmotor, gcs.gcsverbal,  gcs.gcseyes, gcs.endotrachflag
      -- acute renal failure
      , arf.arf as arf

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above views - the row number filters to 1 row per icustay_id
left join pa
  on  ie.icustay_id = pa.icustay_id
  and pa.rn = 1
left join aa
  on  ie.icustay_id = aa.icustay_id
  and aa.rn = 1
left join acidbase_max ab
  on  ie.icustay_id = ab.icustay_id
  and ab.acidbase_rn = 1
left join arf
  on ie.icustay_id = arf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
-- First, we calculate the score for the minimum values
, score_min as
(
  select cohort.subject_id, cohort.hadm_id, cohort.icustay_id
  , case
      when heartrate_min is null then null
      when heartrate_min <   40 then 8
      when heartrate_min <   50 then 5
      when heartrate_min <  100 then 0
      when heartrate_min <  110 then 1
      when heartrate_min <  120 then 5
      when heartrate_min <  140 then 7
      when heartrate_min <  155 then 13
      when heartrate_min >= 155 then 17
    end as hr_score

  , case
      when meanbp_min is null then null
      when meanbp_min <   40 then 23
      when meanbp_min <   60 then 15
      when meanbp_min <   70 then 7
      when meanbp_min <   80 then 6
      when meanbp_min <  100 then 0
      when meanbp_min <  120 then 4
      when meanbp_min <  130 then 7
      when meanbp_min <  140 then 9
      when meanbp_min >= 140 then 10
    end as meanbp_score

  -- TODO: add 1 degree to axillary measurements
  , case
      when tempc_min is null then null
      when tempc_min <  33.0 then 20
      when tempc_min <  33.5 then 16
      when tempc_min <  34.0 then 13
      when tempc_min <  35.0 then 8
      when tempc_min <  36.0 then 2
      when tempc_min <  40.0 then 0
      when tempc_min >= 40.0 then 4
    end as temp_score

  , case
      when resprate_min is null then null
      -- special case for ventilated patients
      when vent = 1 and resprate_min < 14 then 0
      when resprate_min <   6 then 17
      when resprate_min <  12 then 8
      when resprate_min <  14 then 7
      when resprate_min <  25 then 0
      when resprate_min <  35 then 6
      when resprate_min <  40 then 9
      when resprate_min <  50 then 11
      when resprate_min >= 50 then 18
    end as resprate_score

  , case
      when hematocrit_min is null then null
      when hematocrit_min <   41.0 then 3
      when hematocrit_min <   50.0 then 0
      when hematocrit_min >=  50.0 then 3
    end as hematocrit_score

  , case
      when wbc_min is null then null
      when wbc_min <   1.0 then 19
      when wbc_min <   3.0 then 5
      when wbc_min <  20.0 then 0
      when wbc_min <  25.0 then 1
      when wbc_min >= 25.0 then 5
    end as wbc_score

  , case
      when creatinine_min is null then null
      when arf = 1 and creatinine_min <  1.5 then 0
      when arf = 1 and creatinine_min >= 1.5 then 10
      when creatinine_min <   0.5 then 3
      when creatinine_min <   1.5 then 0
      when creatinine_min <  1.95 then 4
      when creatinine_min >= 1.95 then 7
    end as creatinine_score

  , case
      when bun_min is null then null
      when bun_min <  17.0 then 0
      when bun_min <  20.0 then 2
      when bun_min <  40.0 then 7
      when bun_min <  80.0 then 11
      when bun_min >= 80.0 then 12
    end as bun_score

  , case
      when sodium_min is null then null
      when sodium_min <  120 then 3
      when sodium_min <  135 then 2
      when sodium_min <  155 then 0
      when sodium_min >= 155 then 4
    end as sodium_score

  , case
      when albumin_min is null then null
      when albumin_min <  2.0 then 11
      when albumin_min <  2.5 then 6
      when albumin_min <  4.5 then 0
      when albumin_min >= 4.5 then 4
    end as albumin_score

  , case
      when bilirubin_min is null then null
      when bilirubin_min <  2.0 then 0
      when bilirubin_min <  3.0 then 5
      when bilirubin_min <  5.0 then 6
      when bilirubin_min <  8.0 then 8
      when bilirubin_min >= 8.0 then 16
    end as bilirubin_score

  , case
      when glucose_min is null then null
      when glucose_min <   40 then 8
      when glucose_min <   60 then 9
      when glucose_min <  200 then 0
      when glucose_min <  350 then 3
      when glucose_min >= 350 then 5
    end as glucose_score

from cohort
)
, score_max as
(
  select cohort.subject_id, cohort.hadm_id, cohort.icustay_id
    , case
        when heartrate_max is null then null
        when heartrate_max <   40 then 8
        when heartrate_max <   50 then 5
        when heartrate_max <  100 then 0
        when heartrate_max <  110 then 1
        when heartrate_max <  120 then 5
        when heartrate_max <  140 then 7
        when heartrate_max <  155 then 13
        when heartrate_max >= 155 then 17
      end as hr_score

    , case
        when meanbp_max is null then null
        when meanbp_max <   40 then 23
        when meanbp_max <   60 then 15
        when meanbp_max <   70 then 7
        when meanbp_max <   80 then 6
        when meanbp_max <  100 then 0
        when meanbp_max <  120 then 4
        when meanbp_max <  130 then 7
        when meanbp_max <  140 then 9
        when meanbp_max >= 140 then 10
      end as meanbp_score

    -- TODO: add 1 degree to axillary measurements
    , case
        when tempc_max is null then null
        when tempc_max <  33.0 then 20
        when tempc_max <  33.5 then 16
        when tempc_max <  34.0 then 13
        when tempc_max <  35.0 then 8
        when tempc_max <  36.0 then 2
        when tempc_max <  40.0 then 0
        when tempc_max >= 40.0 then 4
      end as temp_score

    , case
        when resprate_max is null then null
        -- special case for ventilated patients
        when vent = 1 and resprate_max < 14 then 0
        when resprate_max <   6 then 17
        when resprate_max <  12 then 8
        when resprate_max <  14 then 7
        when resprate_max <  25 then 0
        when resprate_max <  35 then 6
        when resprate_max <  40 then 9
        when resprate_max <  50 then 11
        when resprate_max >= 50 then 18
      end as resprate_score

    , case
        when hematocrit_max is null then null
        when hematocrit_max <   41.0 then 3
        when hematocrit_max <   50.0 then 0
        when hematocrit_max >=  50.0 then 3
      end as hematocrit_score

    , case
        when wbc_max is null then null
        when wbc_max <   1.0 then 19
        when wbc_max <   3.0 then 5
        when wbc_max <  20.0 then 0
        when wbc_max <  25.0 then 1
        when wbc_max >= 25.0 then 5
      end as wbc_score

    , case
        when creatinine_max is null then null
        when arf = 1 and creatinine_max <  1.5 then 0
        when arf = 1 and creatinine_max >= 1.5 then 10
        when creatinine_max <   0.5 then 3
        when creatinine_max <   1.5 then 0
        when creatinine_max <  1.95 then 4
        when creatinine_max >= 1.95 then 7
      end as creatinine_score

    , case
        when bun_max is null then null
        when bun_max <  17.0 then 0
        when bun_max <  20.0 then 2
        when bun_max <  40.0 then 7
        when bun_max <  80.0 then 11
        when bun_max >= 80.0 then 12
      end as bun_score

    , case
        when sodium_max is null then null
        when sodium_max <  120 then 3
        when sodium_max <  135 then 2
        when sodium_max <  155 then 0
        when sodium_max >= 155 then 4
      end as sodium_score

    , case
        when albumin_max is null then null
        when albumin_max <  2.0 then 11
        when albumin_max <  2.5 then 6
        when albumin_max <  4.5 then 0
        when albumin_max >= 4.5 then 4
      end as albumin_score

    , case
        when bilirubin_max is null then null
        when bilirubin_max <  2.0 then 0
        when bilirubin_max <  3.0 then 5
        when bilirubin_max <  5.0 then 6
        when bilirubin_max <  8.0 then 8
        when bilirubin_max >= 8.0 then 16
      end as bilirubin_score

    , case
        when glucose_max is null then null
        when glucose_max <   40 then 8
        when glucose_max <   60 then 9
        when glucose_max <  200 then 0
        when glucose_max <  350 then 3
        when glucose_max >= 350 then 5
      end as glucose_score

from cohort
)
-- Combine together the scores for min/max, using the following rules:
--  1) select the value furthest from a predefined normal value
--  2) if both equidistant, choose the one which gives a worse score
--  3) calculate score for acid-base abnormalities as it requires interactions
-- sometimes the code is a bit redundant, i.e. we know the max would always be furthest from 0
, scorecomp as
(
  select co.*
  -- The rules for APS III require the definition of a "worst" value
  -- This value is defined as whatever value is furthest from a predefined normal
  -- e.g., for heart rate, worst is defined as furthest from 75
  , case
      when heartrate_max is null then null
      when abs(heartrate_max-75) > abs(heartrate_min-75)
        then smax.hr_score
      when abs(heartrate_max-75) < abs(heartrate_min-75)
        then smin.hr_score
      when abs(heartrate_max-75) = abs(heartrate_min-75)
      and  smax.hr_score >= smin.hr_score
        then smax.hr_score
      when abs(heartrate_max-75) = abs(heartrate_min-75)
      and  smax.hr_score < smin.hr_score
        then smin.hr_score
    end as hr_score

  , case
      when meanbp_max is null then null
      when abs(meanbp_max-90) > abs(meanbp_min-90)
        then smax.meanbp_score
      when abs(meanbp_max-90) < abs(meanbp_min-90)
        then smin.meanbp_score
      -- values are equidistant - pick the larger score
      when abs(meanbp_max-90) = abs(meanbp_min-90)
      and  smax.meanbp_score >= smin.meanbp_score
        then smax.meanbp_score
      when abs(meanbp_max-90) = abs(meanbp_min-90)
      and  smax.meanbp_score < smin.meanbp_score
        then smin.meanbp_score
    end as meanbp_score

  , case
      when tempc_max is null then null
      when abs(tempc_max-38) > abs(tempc_min-38)
        then smax.temp_score
      when abs(tempc_max-38) < abs(tempc_min-38)
        then smin.temp_score
      -- values are equidistant - pick the larger score
      when abs(tempc_max-38) = abs(tempc_min-38)
      and  smax.temp_score >= smin.temp_score
        then smax.temp_score
      when abs(tempc_max-38) = abs(tempc_min-38)
      and  smax.temp_score < smin.temp_score
        then smin.temp_score
    end as temp_score

  , case
      when resprate_max is null then null
      when abs(resprate_max-19) > abs(resprate_min-19)
        then smax.resprate_score
      when abs(resprate_max-19) < abs(resprate_min-19)
        then smin.resprate_score
      -- values are equidistant - pick the larger score
      when abs(resprate_max-19) = abs(resprate_max-19)
      and  smax.resprate_score >= smin.resprate_score
        then smax.resprate_score
      when abs(resprate_max-19) = abs(resprate_max-19)
      and  smax.resprate_score < smin.resprate_score
        then smin.resprate_score
    end as resprate_score

  , case
      when hematocrit_max is null then null
      when abs(hematocrit_max-45.5) > abs(hematocrit_min-45.5)
        then smax.hematocrit_score
      when abs(hematocrit_max-45.5) < abs(hematocrit_min-45.5)
        then smin.hematocrit_score
      -- values are equidistant - pick the larger score
      when abs(hematocrit_max-45.5) = abs(hematocrit_max-45.5)
      and  smax.hematocrit_score >= smin.hematocrit_score
        then smax.hematocrit_score
      when abs(hematocrit_max-45.5) = abs(hematocrit_max-45.5)
      and  smax.hematocrit_score < smin.hematocrit_score
        then smin.hematocrit_score
    end as hematocrit_score

  , case
      when wbc_max is null then null
      when abs(wbc_max-11.5) > abs(wbc_min-11.5)
        then smax.wbc_score
      when abs(wbc_max-11.5) < abs(wbc_min-11.5)
        then smin.wbc_score
      -- values are equidistant - pick the larger score
      when abs(wbc_max-11.5) = abs(wbc_max-11.5)
      and  smax.wbc_score >= smin.wbc_score
        then smax.wbc_score
      when abs(wbc_max-11.5) = abs(wbc_max-11.5)
      and  smax.wbc_score < smin.wbc_score
        then smin.wbc_score
    end as wbc_score


  -- For some labs, "furthest from normal" doesn't make sense
  -- e.g. creatinine w/ ARF, the minimum could be 0.3, and the max 1.6
  -- while the minimum of 0.3 is "further from 1", seems like the max should be scored

  , case
      when creatinine_max is null then null
      -- if they have arf then use the max to score
      when arf = 1 then smax.creatinine_score
      -- otherwise furthest from 1
      when abs(creatinine_max-1) > abs(creatinine_min-1)
        then smax.creatinine_score
      when abs(creatinine_max-1) < abs(creatinine_min-1)
        then smin.creatinine_score
      -- values are equidistant
      when smax.creatinine_score >= smin.creatinine_score
        then smax.creatinine_score
      when smax.creatinine_score < smin.creatinine_score
        then smin.creatinine_score
    end as creatinine_score

  -- the rule for BUN is the furthest from 0.. equivalent to the max value
  , case
      when bun_max is null then null
      else smax.bun_score
    end as bun_score

  , case
      when sodium_max is null then null
      when abs(sodium_max-145.5) > abs(sodium_min-145.5)
        then smax.sodium_score
      when abs(sodium_max-145.5) < abs(sodium_min-145.5)
        then smin.sodium_score
      -- values are equidistant - pick the larger score
      when abs(sodium_max-145.5) = abs(sodium_max-145.5)
      and  smax.sodium_score >= smin.sodium_score
        then smax.sodium_score
      when abs(sodium_max-145.5) = abs(sodium_max-145.5)
      and  smax.sodium_score < smin.sodium_score
        then smin.sodium_score
    end as sodium_score

  , case
      when albumin_max is null then null
      when abs(albumin_max-3.5) > abs(albumin_min-3.5)
        then smax.albumin_score
      when abs(albumin_max-3.5) < abs(albumin_min-3.5)
        then smin.albumin_score
      -- values are equidistant - pick the larger score
      when abs(albumin_max-3.5) = abs(albumin_max-3.5)
      and  smax.albumin_score >= smin.albumin_score
        then smax.albumin_score
      when abs(albumin_max-3.5) = abs(albumin_max-3.5)
      and  smax.albumin_score < smin.albumin_score
        then smin.albumin_score
    end as albumin_score

  , case
      when bilirubin_max is null then null
      else smax.bilirubin_score
    end as bilirubin_score

  , case
      when glucose_max is null then null
      when abs(glucose_max-130) > abs(glucose_min-130)
        then smax.glucose_score
      when abs(glucose_max-130) < abs(glucose_min-130)
        then smin.glucose_score
      -- values are equidistant - pick the larger score
      when abs(glucose_max-130) = abs(glucose_max-130)
      and  smax.glucose_score >= smin.glucose_score
        then smax.glucose_score
      when abs(glucose_max-130) = abs(glucose_max-130)
      and  smax.glucose_score < smin.glucose_score
        then smin.glucose_score
    end as glucose_score


  -- Below are interactions/special cases where only 1 value is important
  , case
      when urineoutput is null then null
      when urineoutput <   400 then 15
      when urineoutput <   600 then 8
      when urineoutput <   900 then 7
      when urineoutput <  1500 then 5
      when urineoutput <  2000 then 4
      when urineoutput <  4000 then 0
      when urineoutput >= 4000 then 1
  end as uo_score

  , case
      when endotrachflag = 1
        -- here they are intubated, so their verbal score is inappropriate
        -- normally you are supposed to use "clinical judgement"
        -- we don't have that, so we just assume normal (as was done in the original study)
        then 0
      when gcseyes = 1
        then case
          when gcsverbal = 1 and gcsmotor in (1,2)
            then 48
          when gcsverbal = 1 and gcsmotor in (3,4)
            then 33
          when gcsverbal = 1 and gcsmotor in (5,6)
            then 16
          when gcsverbal in (2,3) and gcsmotor in (1,2)
            then 29
          when gcsverbal in (2,3) and gcsmotor in (3,4)
            then 24
          when gcsverbal in (2,3) and gcsmotor >= 5
            -- highly unlikely clinical combination
            then null
          when gcsverbal >= 4
            then null
          end
      when gcseyes > 1
        then case
          when gcsverbal = 1 and gcsmotor in (1,2)
            then 29
          when gcsverbal = 1 and gcsmotor in (3,4)
            then 24
          when gcsverbal = 1 and gcsmotor in (5,6)
            then 15
          when gcsverbal in (2,3) and gcsmotor in (1,2)
            then 29
          when gcsverbal in (2,3) and gcsmotor in (3,4)
            then 24
          when gcsverbal in (2,3) and gcsmotor = 5
            then 13
          when gcsverbal in (2,3) and gcsmotor = 6
            then 10
          when gcsverbal = 4 and gcsmotor in (1,2,3,4)
            then 13
          when gcsverbal = 4 and gcsmotor = 5
            then 8
          when gcsverbal = 4 and gcsmotor = 6
            then 3
          when gcsverbal = 5 and gcsmotor in (1,2,3,4,5)
            then 3
          when gcsverbal = 5 and gcsmotor = 6
            then 0
          end
      else null
    end as gcs_score

  , case
      when pao2 is null and aado2 is null
        then null
      when pao2 is not null then
        case
          when pao2 < 50 then 15
          when pao2 < 70 then 5
          when pao2 < 80 then 2
        else 0 end
      when aado2 is not null then
        case
          when aado2 <  100 then 0
          when aado2 <  250 then 7
          when aado2 <  350 then 9
          when aado2 <  500 then 11
          when aado2 >= 500 then 14
        else 0 end
      end as pao2_aado2_score

from cohort co
left join score_min smin
  on co.icustay_id = smin.icustay_id
left join score_max smax
  on co.icustay_id = smax.icustay_id
)
-- tabulate the APS III using the scores from the worst values
, score as
(
  select s.*
  -- coalesce statements impute normal score of zero if data element is missing
  , coalesce(hr_score,0)
  + coalesce(meanbp_score,0)
  + coalesce(temp_score,0)
  + coalesce(resprate_score,0)
  + coalesce(pao2_aado2_score,0)
  + coalesce(hematocrit_score,0)
  + coalesce(wbc_score,0)
  + coalesce(creatinine_score,0)
  + coalesce(uo_score,0)
  + coalesce(bun_score,0)
  + coalesce(sodium_score,0)
  + coalesce(albumin_score,0)
  + coalesce(bilirubin_score,0)
  + coalesce(glucose_score,0)
  + coalesce(acidbase_score,0)
  + coalesce(gcs_score,0)
    as apsiii
  from scorecomp s
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, apsiii
-- Calculate probability of hospital mortality using equation from Johnson 2014.
, 1 / (1 + exp(- (-4.4360 + 0.04726*(apsiii) ))) as apsiii_prob
, hr_score
, meanbp_score
, temp_score
, resprate_score
, pao2_aado2_score
, hematocrit_score
, wbc_score
, creatinine_score
, uo_score
, bun_score
, sodium_score
, albumin_score
, bilirubin_score
, glucose_score
, acidbase_score
, gcs_score
FROM icustays ie
left join score s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:35.492328 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 3.78 seconds
17:40:35.504126 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:35.504363 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
alter table "postgres"."public"."apsiii" rename to "apsiii__dbt_backup"
17:40:35.505165 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:35.508553 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:35.508741 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
alter table "postgres"."public"."apsiii__dbt_tmp" rename to "apsiii"
17:40:35.509435 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:35.519729 [debug] [Thread-1  ]: On model.mimic.apsiii: COMMIT
17:40:35.520013 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:35.520211 [debug] [Thread-1  ]: On model.mimic.apsiii: COMMIT
17:40:35.524032 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:40:35.528860 [debug] [Thread-1  ]: Using postgres connection "model.mimic.apsiii"
17:40:35.529083 [debug] [Thread-1  ]: On model.mimic.apsiii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.apsiii"} */
drop table if exists "postgres"."public"."apsiii__dbt_backup" cascade
17:40:35.532200 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:35.535593 [debug] [Thread-1  ]: finished collecting timing info
17:40:35.535826 [debug] [Thread-1  ]: On model.mimic.apsiii: Close
17:40:35.536687 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d45cfd60>]}
17:40:35.537219 [info ] [Thread-1  ]: 1 of 9 OK created table model public.apsiii .................................... [[32mSELECT 61532[0m in 3.88s]
17:40:35.537792 [debug] [Thread-1  ]: Finished running node model.mimic.apsiii
17:40:35.538033 [debug] [Thread-1  ]: Began running node model.mimic.lods
17:40:35.538707 [info ] [Thread-1  ]: 2 of 9 START table model public.lods ........................................... [RUN]
17:40:35.539564 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.lods"
17:40:35.539900 [debug] [Thread-1  ]: Began compiling node model.mimic.lods
17:40:35.540241 [debug] [Thread-1  ]: Compiling model.mimic.lods
17:40:35.545088 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.lods"
17:40:35.546536 [debug] [Thread-1  ]: finished collecting timing info
17:40:35.547640 [debug] [Thread-1  ]: Began executing node model.mimic.lods
17:40:35.557984 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.lods"
17:40:35.558418 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.558977 [debug] [Thread-1  ]: On model.mimic.lods: BEGIN
17:40:35.559263 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:35.563901 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:40:35.564149 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.564409 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */


  create  table "postgres"."public"."lods__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Logistic Organ Dysfunction Score (LODS)
-- This query extracts the logistic organ dysfunction system.
-- This score is a measure of organ failure in a patient.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Variables used in LODS:
--  GCS
--  VITALS: Heart rate, systolic blood pressure
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: blood urea nitrogen, WBC, bilirubin, creatinine, prothrombin time (PT), platelets
--  ABG: PaO2 with associated FiO2

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_durations - generated by ventilation_durations.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql
--  5) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(pao2fio2) as pao2fio2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select  ie.subject_id
      , ie.hadm_id
      , ie.icustay_id
      , ie.intime
      , ie.outtime

      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.pao2fio2_vent_min

      , labs.bun_max
      , labs.bun_min
      , labs.wbc_max
      , labs.wbc_min
      , labs.bilirubin_max
      , labs.creatinine_max
      , labs.pt_min
      , labs.pt_max
      , labs.platelet_min

      , uo.urineoutput

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get pao2/fio2 ratio
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS

  -- neurologic
  , case
    when mingcs is null then null
      when mingcs <  3 then null -- erroneous value/on trach
      when mingcs <=  5 then 5
      when mingcs <=  8 then 3
      when mingcs <= 13 then 1
    else 0
  end as neurologic

  -- cardiovascular
  , case
      when heartrate_max is null
      and sysbp_min is null then null
      when heartrate_min < 30 then 5
      when sysbp_min < 40 then 5
      when sysbp_min <  70 then 3
      when sysbp_max >= 270 then 3
      when heartrate_max >= 140 then 1
      when sysbp_max >= 240 then 1
      when sysbp_min < 90 then 1
    else 0
  end as cardiovascular

  -- renal
  , case
      when bun_max is null
        or urineoutput is null
        or creatinine_max is null
        then null
      when urineoutput <   500.0 then 5
      when bun_max >= 56.0 then 5
      when creatinine_max >= 1.60 then 3
      when urineoutput <   750.0 then 3
      when bun_max >= 28.0 then 3
      when urineoutput >= 10000.0 then 3
      when creatinine_max >= 1.20 then 1
      when bun_max >= 17.0 then 1
      when bun_max >= 7.50 then 1
    else 0
  end as renal

  -- pulmonary
  , case
      when pao2fio2_vent_min is null then 0
      when pao2fio2_vent_min >= 150 then 1
      when pao2fio2_vent_min < 150 then 3
    else null
  end as pulmonary

  -- hematologic
  , case
      when wbc_max is null
        and platelet_min is null
          then null
      when wbc_min <   1.0 then 3
      when wbc_min <   2.5 then 1
      when platelet_min < 50.0 then 1
      when wbc_max >= 50.0 then 1
    else 0
  end as hematologic

  -- hepatic
  -- We have defined the "standard" PT as 12 seconds.
  -- This is an assumption and subsequent analyses may be affected by this assumption.
  , case
      when pt_max is null
        and bilirubin_max is null
          then null
      when bilirubin_max >= 2.0 then 1
      when pt_max > (12+3) then 1
      when pt_min < (12*0.25) then 1
    else 0
  end as hepatic

from cohort
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(neurologic,0)
+ coalesce(cardiovascular,0)
+ coalesce(renal,0)
+ coalesce(pulmonary,0)
+ coalesce(hematologic,0)
+ coalesce(hepatic,0)
  as LODS
, neurologic
, cardiovascular
, renal
, pulmonary
, hematologic
, hepatic
FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:35.821520 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.26 seconds
17:40:35.827804 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.828178 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
alter table "postgres"."public"."lods" rename to "lods__dbt_backup"
17:40:35.829551 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:35.833707 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.833907 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
alter table "postgres"."public"."lods__dbt_tmp" rename to "lods"
17:40:35.834756 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:35.838062 [debug] [Thread-1  ]: On model.mimic.lods: COMMIT
17:40:35.838682 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.839063 [debug] [Thread-1  ]: On model.mimic.lods: COMMIT
17:40:35.845826 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:35.848337 [debug] [Thread-1  ]: Using postgres connection "model.mimic.lods"
17:40:35.848544 [debug] [Thread-1  ]: On model.mimic.lods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.lods"} */
drop table if exists "postgres"."public"."lods__dbt_backup" cascade
17:40:35.850449 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:35.853191 [debug] [Thread-1  ]: finished collecting timing info
17:40:35.853431 [debug] [Thread-1  ]: On model.mimic.lods: Close
17:40:35.854166 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d5633310>]}
17:40:35.854711 [info ] [Thread-1  ]: 2 of 9 OK created table model public.lods ...................................... [[32mSELECT 61532[0m in 0.31s]
17:40:35.855288 [debug] [Thread-1  ]: Finished running node model.mimic.lods
17:40:35.855732 [debug] [Thread-1  ]: Began running node model.mimic.mlods
17:40:35.856421 [info ] [Thread-1  ]: 3 of 9 START table model public.mlods .......................................... [RUN]
17:40:35.857249 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.mlods"
17:40:35.857499 [debug] [Thread-1  ]: Began compiling node model.mimic.mlods
17:40:35.857893 [debug] [Thread-1  ]: Compiling model.mimic.mlods
17:40:35.861879 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.mlods"
17:40:35.862491 [debug] [Thread-1  ]: finished collecting timing info
17:40:35.862885 [debug] [Thread-1  ]: Began executing node model.mimic.mlods
17:40:35.873238 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.mlods"
17:40:35.873979 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:35.874374 [debug] [Thread-1  ]: On model.mimic.mlods: BEGIN
17:40:35.875130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:35.880474 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:35.880717 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:35.880884 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */


  create  table "postgres"."public"."mlods__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Modified Logistic organ dysfunction system (mLODS)
-- This query extracts a modified version of the logistic organ dysfunction system.
-- This score was used in the third international definition of sepsis: Sepsis-3.
-- This score is a measure of organ failure in a patient.
-- ------------------------------------------------------------------

-- Reference for LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Reference for modified LODS:
--  Le Gall, J. R., Klar, J., Lemeshow, S., Saulnier, F., Alberti, C., Artigas, A., & Teres, D.
--  The Logistic Organ Dysfunction system: a new way to assess organ dysfunction in the intensive care unit.
--  JAMA 276.10 (1996): 802-810.

-- Variables used in mLODS:
--  GCS
--  VITALS: Heart rate, systolic blood pressure
--  FLAGS: ventilation/cpap
--  LABS: WBC, bilirubin, creatinine, platelets
--  ABG: PaO2 with associated FiO2

-- Variables *excluded*, that are used in the original LODS:
--  prothrombin time (PT), blood urea nitrogen, urine output

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and ie.outtime
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , PaO2FiO2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(PaO2FiO2) as PaO2FiO2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select  ie.subject_id
      , ie.hadm_id
      , ie.icustay_id
      , ie.intime
      , ie.outtime

      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.PaO2FiO2_vent_min

      , labs.wbc_max
      , labs.wbc_min
      , labs.bilirubin_max
      , labs.creatinine_max
      , labs.platelet_min

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get pao2/fio2 ratio
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*

  -- neurologic
  , case
    when mingcs is null then null
      when mingcs <  3 then null -- erroneous value/on trach
      when mingcs <=  5 then 5
      when mingcs <=  8 then 3
      when mingcs <= 13 then 1
    else 0
  end as neurologic

  -- cardiovascular
  , case
      when heartrate_max is null
      and sysbp_min is null then null
      when heartrate_min < 30 then 5
      when sysbp_min < 40 then 5
      when sysbp_min <  70 then 3
      when sysbp_max >= 270 then 3
      when heartrate_max >= 140 then 1
      when sysbp_max >= 240 then 1
      when sysbp_min < 90 then 1
    else 0
  end as cardiovascular

  -- renal
  , case
      when creatinine_max is null
        -- or UrineOutput is null
        -- or bun_max is null
        then null
      -- when UrineOutput <   500.0 then 5
      -- when bun_max >= 56.0 then 5
      when creatinine_max >= 1.60 then 3
      -- when UrineOutput <   750.0 then 3
      -- when bun_max >= 28.0 then 3
      -- when UrineOutput >= 10000.0 then 3
      when creatinine_max >= 1.20 then 1
      -- when bun_max >= 17.0 then 1
      -- when bun_max >= 7.50 then 1
    else 0
  end as renal

  -- pulmonary
  , case
      when PaO2FiO2_vent_min is null then 0
      when PaO2FiO2_vent_min >= 150 then 1
      when PaO2FiO2_vent_min < 150 then 3
    else null
  end as pulmonary

  -- hematologic
  , case
      when wbc_max is null
        and platelet_min is null
          then null
      when wbc_min <   1.0 then 3
      when wbc_min <   2.5 then 1
      when platelet_min < 50.0 then 1
      when wbc_max >= 50.0 then 1
    else 0
  end as hematologic

  -- hepatic
  , case
      when bilirubin_max is null
        -- and pt_max is null
          then null
      when bilirubin_max >= 2.0 then 1
      -- when pt_max > (12+3) then 1
      -- when pt_min < (12*0.25) then 1
    else 0
  end as hepatic

from cohort
)
select ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(neurologic,0)
+ coalesce(cardiovascular,0)
+ coalesce(renal,0)
+ coalesce(pulmonary,0)
+ coalesce(hematologic,0)
+ coalesce(hepatic,0)
  as mLODS
, neurologic
, cardiovascular
, renal
, pulmonary
, hematologic
, hepatic
FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:36.087930 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.21 seconds
17:40:36.092925 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:36.093124 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
alter table "postgres"."public"."mlods" rename to "mlods__dbt_backup"
17:40:36.093818 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:36.097367 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:36.097640 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
alter table "postgres"."public"."mlods__dbt_tmp" rename to "mlods"
17:40:36.098291 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:36.101561 [debug] [Thread-1  ]: On model.mimic.mlods: COMMIT
17:40:36.101756 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:36.101949 [debug] [Thread-1  ]: On model.mimic.mlods: COMMIT
17:40:36.107758 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:36.110252 [debug] [Thread-1  ]: Using postgres connection "model.mimic.mlods"
17:40:36.110434 [debug] [Thread-1  ]: On model.mimic.mlods: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.mlods"} */
drop table if exists "postgres"."public"."mlods__dbt_backup" cascade
17:40:36.112420 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:36.115128 [debug] [Thread-1  ]: finished collecting timing info
17:40:36.115374 [debug] [Thread-1  ]: On model.mimic.mlods: Close
17:40:36.116156 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d562d850>]}
17:40:36.116636 [info ] [Thread-1  ]: 3 of 9 OK created table model public.mlods ..................................... [[32mSELECT 61532[0m in 0.26s]
17:40:36.117175 [debug] [Thread-1  ]: Finished running node model.mimic.mlods
17:40:36.117557 [debug] [Thread-1  ]: Began running node model.mimic.oasis
17:40:36.118120 [info ] [Thread-1  ]: 4 of 9 START table model public.oasis .......................................... [RUN]
17:40:36.118851 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.oasis"
17:40:36.119160 [debug] [Thread-1  ]: Began compiling node model.mimic.oasis
17:40:36.119418 [debug] [Thread-1  ]: Compiling model.mimic.oasis
17:40:36.124290 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.oasis"
17:40:36.124923 [debug] [Thread-1  ]: finished collecting timing info
17:40:36.125187 [debug] [Thread-1  ]: Began executing node model.mimic.oasis
17:40:36.133693 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.oasis"
17:40:36.134104 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:36.134212 [debug] [Thread-1  ]: On model.mimic.oasis: BEGIN
17:40:36.134305 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:36.143463 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:36.143935 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:36.144098 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */


  create  table "postgres"."public"."oasis__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Oxford Acute Severity of Illness Score (oasis)
-- This query extracts the Oxford acute severity of illness score.
-- This score is a measure of severity of illness for patients in the ICU.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for OASIS:
--    Johnson, Alistair EW, Andrew A. Kramer, and Gari D. Clifford.
--    "A new severity of illness scale using a subset of acute physiology and chronic health evaluation data elements shows comparable predictive accuracy*."
--    Critical care medicine 41, no. 7 (2013): 1711-1718.

-- Variables used in OASIS:
--  Heart rate, GCS, MAP, Temperature, Respiratory rate, Ventilation status (sourced FROM chartevents)
--  Urine output (sourced from OUTPUTEVENTS)
--  Elective surgery (sourced FROM admissions and SERVICES)
--  Pre-ICU in-hospital length of stay (sourced FROM admissions and ICUSTAYS)
--  Age (sourced FROM patients)

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vent_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql


-- Regarding missing values:
--  The ventilation flag is always 0/1. It cannot be missing, since VENT=0 if no data is found for vent settings.

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.


with surgflag as
(
  select ie.icustay_id
    , max(case
        when lower(curr_service) like '%surg%' then 1
        when curr_service = 'ORTHO' then 1
    else 0 end) as surgical
  FROM icustays ie
  left join services se
    on ie.hadm_id = se.hadm_id
    and se.transfertime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  group by ie.icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime
      , adm.deathtime
      -- , DATETIME_DIFF(ie.intime, adm.admittime, MINUTE) as preiculos
      , EXTRACT(MINUTE FROM ie.intime-adm.admittime) as preiculos
      , EXTRACT(YEAR FROM ie.intime-pat.dob) as age
      -- , DATETIME_DIFF(ie.intime, pat.dob, `YEAR`) as age
      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.meanbp_max
      , vital.meanbp_min
      , vital.resprate_max
      , vital.resprate_min
      , vital.tempc_max
      , vital.tempc_min
      , vent.vent as mechvent
      , uo.urineoutput

      , case
          when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
            then 1
          when adm.ADMISSION_TYPE is null or sf.surgical is null
            then null
          else 0
        end as electivesurgery

      -- age group
      , case
        when DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') <= 1 then 'neonate'
        when DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') <= 15 then 'middle'
        -- when EXTRACT(YEAR FROM ie.intime-pat.dob) <= 1 then 'neonate'
        -- when EXTRACT(YEAR FROM ie.intime-pat.dob) <= 15 then 'middle'
        else 'adult' end as icustay_age_group

      -- mortality flags
      , case
          when adm.deathtime between ie.intime and ie.outtime
            then 1
          when adm.deathtime <= ie.intime -- sometimes there are typographical errors in the death date
            then 1
          when adm.dischtime <= ie.outtime and adm.discharge_location = 'DEAD/EXPIRED'
            then 1
          else 0 end
        as icustay_expire_flag
      , adm.hospital_expire_flag
FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id
left join surgflag sf
  on ie.icustay_id = sf.icustay_id
-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
)
, scorecomp as
(
select co.subject_id, co.hadm_id, co.icustay_id
, co.icustay_age_group
, co.icustay_expire_flag
, co.hospital_expire_flag

-- Below code calculates the component scores needed for oasis
, case when preiculos is null then null
     when preiculos < 10.2 then 5
     when preiculos < 297 then 3
     when preiculos < 1440 then 0
     when preiculos < 18708 then 1
     else 2 end as preiculos_score
,  case when age is null then null
      when age < 24 then 0
      when age <= 53 then 3
      when age <= 77 then 6
      when age <= 89 then 9
      when age >= 90 then 7
      else 0 end as age_score
,  case when mingcs is null then null
      when mingcs <= 7 then 10
      when mingcs < 14 then 4
      when mingcs = 14 then 3
      else 0 end as gcs_score
,  case when heartrate_max is null then null
      when heartrate_max > 125 then 6
      when heartrate_min < 33 then 4
      when heartrate_max >= 107 and heartrate_max <= 125 then 3
      when heartrate_max >= 89 and heartrate_max <= 106 then 1
      else 0 end as heartrate_score
,  case when meanbp_min is null then null
      when meanbp_min < 20.65 then 4
      when meanbp_min < 51 then 3
      when meanbp_max > 143.44 then 3
      when meanbp_min >= 51 and meanbp_min < 61.33 then 2
      else 0 end as meanbp_score
,  case when resprate_min is null then null
      when resprate_min <   6 then 10
      when resprate_max >  44 then  9
      when resprate_max >  30 then  6
      when resprate_max >  22 then  1
      when resprate_min <  13 then 1 else 0
      end as resprate_score
,  case when tempc_max is null then null
      when tempc_max > 39.88 then 6
      when tempc_min >= 33.22 and tempc_min <= 35.93 then 4
      when tempc_max >= 33.22 and tempc_max <= 35.93 then 4
      when tempc_min < 33.22 then 3
      when tempc_min > 35.93 and tempc_min <= 36.39 then 2
      when tempc_max >= 36.89 and tempc_max <= 39.88 then 2
      else 0 end as temp_score
,  case when UrineOutput is null then null
      when UrineOutput < 671.09 then 10
      when UrineOutput > 6896.80 then 8
      when UrineOutput >= 671.09
       and UrineOutput <= 1426.99 then 5
      when UrineOutput >= 1427.00
       and UrineOutput <= 2544.14 then 1
      else 0 end as urineoutput_score
,  case when mechvent is null then null
      when mechvent = 1 then 9
      else 0 end as mechvent_score
,  case when electivesurgery is null then null
      when electivesurgery = 1 then 0
      else 6 end as electivesurgery_score


-- The below code gives the component associated with each score
-- This is not needed to calculate oasis, but provided for user convenience.
-- If both the min/max are in the normal range (score of 0), then the average value is stored.
, preiculos
, age
, mingcs as gcs
,  case when heartrate_max is null then null
      when heartrate_max > 125 then heartrate_max
      when heartrate_min < 33 then heartrate_min
      when heartrate_max >= 107 and heartrate_max <= 125 then heartrate_max
      when heartrate_max >= 89 and heartrate_max <= 106 then heartrate_max
      else (heartrate_min+heartrate_max)/2 end as heartrate
,  case when meanbp_min is null then null
      when meanbp_min < 20.65 then meanbp_min
      when meanbp_min < 51 then meanbp_min
      when meanbp_max > 143.44 then meanbp_max
      when meanbp_min >= 51 and meanbp_min < 61.33 then meanbp_min
      else (meanbp_min+meanbp_max)/2 end as meanbp
,  case when resprate_min is null then null
      when resprate_min <   6 then resprate_min
      when resprate_max >  44 then resprate_max
      when resprate_max >  30 then resprate_max
      when resprate_max >  22 then resprate_max
      when resprate_min <  13 then resprate_min
      else (resprate_min+resprate_max)/2 end as resprate
,  case when tempc_max is null then null
      when tempc_max > 39.88 then tempc_max
      when tempc_min >= 33.22 and tempc_min <= 35.93 then tempc_min
      when tempc_max >= 33.22 and tempc_max <= 35.93 then tempc_max
      when tempc_min < 33.22 then tempc_min
      when tempc_min > 35.93 and tempc_min <= 36.39 then tempc_min
      when tempc_max >= 36.89 and tempc_max <= 39.88 then tempc_max
      else (tempc_min+tempc_max)/2 end as temp
,  UrineOutput
,  mechvent
,  electivesurgery
from cohort co
)
, score as
(
select s.*
    , coalesce(age_score,0)
    + coalesce(preiculos_score,0)
    + coalesce(gcs_score,0)
    + coalesce(heartrate_score,0)
    + coalesce(meanbp_score,0)
    + coalesce(resprate_score,0)
    + coalesce(temp_score,0)
    + coalesce(urineoutput_score,0)
    + coalesce(mechvent_score,0)
    + coalesce(electivesurgery_score,0)
    as oasis
from scorecomp s
)
select
  subject_id, hadm_id, icustay_id
  , icustay_age_group
  , hospital_expire_flag
  , icustay_expire_flag
  , oasis
  -- Calculate the probability of in-hospital mortality
  , 1 / (1 + exp(- (-6.1746 + 0.1275*(oasis) ))) as oasis_PROB
  , age, age_score
  , preiculos, preiculos_score
  , gcs, gcs_score
  , heartrate, heartrate_score
  , meanbp, meanbp_score
  , resprate, resprate_score
  , temp, temp_score
  , urineoutput, urineoutput_score
  , mechvent, mechvent_score
  , electivesurgery, electivesurgery_score
from score
order by icustay_id
  );
17:40:37.165690 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.02 seconds
17:40:37.172240 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:37.172485 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
alter table "postgres"."public"."oasis" rename to "oasis__dbt_backup"
17:40:37.173677 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.177591 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:37.177781 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
alter table "postgres"."public"."oasis__dbt_tmp" rename to "oasis"
17:40:37.178462 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.181694 [debug] [Thread-1  ]: On model.mimic.oasis: COMMIT
17:40:37.181911 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:37.182048 [debug] [Thread-1  ]: On model.mimic.oasis: COMMIT
17:40:37.205253 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
17:40:37.207491 [debug] [Thread-1  ]: Using postgres connection "model.mimic.oasis"
17:40:37.207695 [debug] [Thread-1  ]: On model.mimic.oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.oasis"} */
drop table if exists "postgres"."public"."oasis__dbt_backup" cascade
17:40:37.209894 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:37.212895 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.213137 [debug] [Thread-1  ]: On model.mimic.oasis: Close
17:40:37.213791 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d455eeb0>]}
17:40:37.214076 [info ] [Thread-1  ]: 4 of 9 OK created table model public.oasis ..................................... [[32mSELECT 61532[0m in 1.10s]
17:40:37.214385 [debug] [Thread-1  ]: Finished running node model.mimic.oasis
17:40:37.214692 [debug] [Thread-1  ]: Began running node model.mimic.qsofa
17:40:37.215379 [info ] [Thread-1  ]: 5 of 9 START table model public.qsofa .......................................... [RUN]
17:40:37.216123 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.qsofa"
17:40:37.216441 [debug] [Thread-1  ]: Began compiling node model.mimic.qsofa
17:40:37.216689 [debug] [Thread-1  ]: Compiling model.mimic.qsofa
17:40:37.219216 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.qsofa"
17:40:37.220256 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.220974 [debug] [Thread-1  ]: Began executing node model.mimic.qsofa
17:40:37.231823 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.qsofa"
17:40:37.232830 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.233026 [debug] [Thread-1  ]: On model.mimic.qsofa: BEGIN
17:40:37.233122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:37.238385 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:37.238856 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.239004 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */


  create  table "postgres"."public"."qsofa__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Quick Sequential Organ Failure Assessment (qSOFA)
-- This query extracts the quick sequential organ failure assessment.
-- This score was a recent revision of SOFA, aiming to detect patients at risk of sepsis.
-- The score is calculated on the first day of each ICU patients' stay - though needn't be.
-- ------------------------------------------------------------------

-- Reference for qSOFA:
--    Singer M, et al. The Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)
--    Seymour CW, et al. Assessment of Clinical Criteria for Sepsis: For the Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)

-- Variables used in qSOFA:
--  GCS, respiratory rate, systolic blood pressure

-- The following views required to run this query:
--  1) gcsfirstday - generated by gcs-first-day.sql
--  2) vitalsfirstday - generated by vitals-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with scorecomp as
(
select ie.icustay_id
  , v.sysbp_min
  , v.resprate_max
  , gcs.mingcs
FROM icustays ie
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id
  , case
      when sysbp_min is null then null
      when sysbp_min   <= 100 then 1
      else 0 end
    as sysbp_score
  , case
      when mingcs is null then null
      when mingcs   <= 13 then 1
      else 0 end
    as gcs_score
  , case
      when resprate_max is null then null
      when resprate_max   >= 22 then 1
      else 0 end
    as resprate_score
  from scorecomp
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, coalesce(sysbp_score,0)
 + coalesce(gcs_score,0)
 + coalesce(resprate_score,0)
 as qsofa
, sysbp_score
, gcs_score
, resprate_score
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:37.353841 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.11 seconds
17:40:37.360752 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.361168 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
alter table "postgres"."public"."qsofa" rename to "qsofa__dbt_backup"
17:40:37.362731 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.366231 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.366418 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
alter table "postgres"."public"."qsofa__dbt_tmp" rename to "qsofa"
17:40:37.367173 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.370116 [debug] [Thread-1  ]: On model.mimic.qsofa: COMMIT
17:40:37.370311 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.370421 [debug] [Thread-1  ]: On model.mimic.qsofa: COMMIT
17:40:37.376265 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:37.378289 [debug] [Thread-1  ]: Using postgres connection "model.mimic.qsofa"
17:40:37.378485 [debug] [Thread-1  ]: On model.mimic.qsofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.qsofa"} */
drop table if exists "postgres"."public"."qsofa__dbt_backup" cascade
17:40:37.380648 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:37.383483 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.383808 [debug] [Thread-1  ]: On model.mimic.qsofa: Close
17:40:37.384582 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d562daf0>]}
17:40:37.385058 [info ] [Thread-1  ]: 5 of 9 OK created table model public.qsofa ..................................... [[32mSELECT 61532[0m in 0.17s]
17:40:37.385609 [debug] [Thread-1  ]: Finished running node model.mimic.qsofa
17:40:37.385942 [debug] [Thread-1  ]: Began running node model.mimic.saps
17:40:37.386653 [info ] [Thread-1  ]: 6 of 9 START table model public.saps ........................................... [RUN]
17:40:37.387408 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.saps"
17:40:37.387717 [debug] [Thread-1  ]: Began compiling node model.mimic.saps
17:40:37.387948 [debug] [Thread-1  ]: Compiling model.mimic.saps
17:40:37.392412 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.saps"
17:40:37.393168 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.393460 [debug] [Thread-1  ]: Began executing node model.mimic.saps
17:40:37.402455 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.saps"
17:40:37.403117 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.403328 [debug] [Thread-1  ]: On model.mimic.saps: BEGIN
17:40:37.403491 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:37.410158 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:37.410410 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.410646 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */


  create  table "postgres"."public"."saps__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Simplified Acute Physiology Score (SAPS)
-- This query extracts the simplified acute physiology score.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SAPS:
--    Jean-Roger Le Gall, Philippe Loirat, Annick Alperovitch, Paul Glaser, Claude Granthil,
--    Daniel Mathieu, Philippe Mercier, Remi Thomas, and Daniel Villers.
--    "A simplified acute physiology score for ICU patients."
--    Critical care medicine 12, no. 11 (1984): 975-977.

-- Variables used in SAPS:
--  Age, GCS
--  VITALS: Heart rate, systolic blood pressure, temperature, respiration rate
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: blood urea nitrogen, hematocrit, WBC, glucose, potassium, sodium, HCO3

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vent_first_day - generated by ventilated-first-day.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
  , max(CASE
        WHEN lower(ce.value) LIKE '%cpap%' THEN 1
        WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
      else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      -- the casts ensure the result is numeric.. we could equally extract EPOCH from the interval
      -- however this code works in Oracle and Postgres
      , DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') as age
      , gcs.mingcs
      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min
      , vital.resprate_max
      , vital.resprate_min
      , vital.tempc_max
      , vital.tempc_min

      , coalesce(vital.glucose_max, labs.glucose_max) as glucose_max
      , coalesce(vital.glucose_min, labs.glucose_min) as glucose_min

      , labs.bun_max
      , labs.bun_min
      , labs.hematocrit_max
      , labs.hematocrit_min
      , labs.wbc_max
      , labs.wbc_min
      , labs.sodium_max
      , labs.sodium_min
      , labs.potassium_max
      , labs.potassium_min
      , labs.bicarbonate_max
      , labs.bicarbonate_min

      , vent.vent as mechvent
      , uo.urineoutput

      , cp.cpap

FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above view to get CPAP
left join cpap cp
  on ie.icustay_id = cp.icustay_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."ventilation_first_day" vent
  on ie.icustay_id = vent.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS
  , case
      when age is null then null
      when age <= 45 then 0
      when age <= 55 then 1
      when age <= 65 then 2
      when age <= 75 then 3
      when age >  75 then 4
    end as age_score
  , case
      when heartrate_max is null then null
      when heartrate_max >= 180 then 4
      when heartrate_min < 40 then 4
      when heartrate_max >= 140 then 3
      when heartrate_min <= 54 then 3
      when heartrate_max >= 110 then 2
      when heartrate_min <= 69 then 2
      when heartrate_max >= 70 and heartrate_max <= 109
        and heartrate_min >= 70 and heartrate_min <= 109
      then 0
    end as hr_score
  , case
      when sysbp_min is null then null
      when sysbp_max >= 190 then 4
      when sysbp_min < 55 then 4
      when sysbp_max >= 150 then 2
      when sysbp_min <= 79 then 2
      when sysbp_max >= 80 and sysbp_max <= 149
        and sysbp_min >= 80 and sysbp_min <= 149
        then 0
    end as sysbp_score

  , case
      when tempc_max is null then null
      when tempc_max >= 41.0 then 4
      when tempc_min <  30.0 then 4
      when tempc_max >= 39.0 then 3
      when tempc_min <= 31.9  then 3
      when tempc_min <= 33.9  then 2
      when tempc_max >  38.4 then 1
      when tempc_min <  36.0  then 1
      when tempc_max >= 36.0 and tempc_max <= 38.4
       and tempc_min >= 36.0 and tempc_min <= 38.4
        then 0
    end as temp_score

  , case
      when resprate_min is null then null
      when resprate_max >= 50 then 4
      when resprate_min <  6 then 4
      when resprate_max >= 35 then 3
      when resprate_min <= 9 then 2
      when resprate_max >= 25 then 1
      when resprate_min <= 11 then 1
      when  resprate_max >= 12 and resprate_max <= 24
        and resprate_min >= 12 and resprate_min <= 24
          then 0
      end as resp_score

  , case
      when coalesce(mechvent,cpap) is null then null
      when cpap = 1 then 3
      when mechvent = 1 then 3
      else 0
    end as vent_score

  , case
      when UrineOutput is null then null
      when UrineOutput >  5000.0 then 2
      when UrineOutput >= 3500.0 then 1
      when UrineOutput >=  700.0 then 0
      when UrineOutput >=  500.0 then 2
      when UrineOutput >=  200.0 then 3
      when UrineOutput <   200.0 then 4
    end as uo_score

  , case
      when bun_max is null then null
      when bun_max >= 55.0 then 4
      when bun_max >= 36.0 then 3
      when bun_max >= 29.0 then 2
      when bun_max >= 7.50 then 1
      when bun_min < 3.5 then 1
      when  bun_max >= 3.5 and bun_max < 7.5
        and bun_min >= 3.5 and bun_min < 7.5
          then 0
    end as bun_score

  , case
      when hematocrit_max is null then null
      when hematocrit_max >= 60.0 then 4
      when hematocrit_min <  20.0 then 4
      when hematocrit_max >= 50.0 then 2
      when hematocrit_min < 30.0 then 2
      when hematocrit_max >= 46.0 then 1
      when  hematocrit_max >= 30.0 and hematocrit_max < 46.0
        and hematocrit_min >= 30.0 and hematocrit_min < 46.0
          then 0
      end as hematocrit_score

  , case
      when wbc_max is null then null
      when wbc_max >= 40.0 then 4
      when wbc_min <   1.0 then 4
      when wbc_max >= 20.0 then 2
      when wbc_min <   3.0 then 2
      when wbc_max >= 15.0 then 1
      when wbc_max >=  3.0 and wbc_max < 15.0
       and wbc_min >=  3.0 and wbc_min < 15.0
        then 0
    end as wbc_score

  , case
      when glucose_max is null then null
      when glucose_max >= 44.5 then 4
      when glucose_min <   1.6 then 4
      when glucose_max >= 27.8 then 3
      when glucose_min <   2.8 then 3
      when glucose_min <   3.9 then 2
      when glucose_max >= 14.0 then 1
      when glucose_max >=  3.9 and glucose_max < 14.0
       and glucose_min >=  3.9 and glucose_min < 14.0
        then 0
      end as glucose_score

  , case
      when potassium_max is null then null
      when potassium_max >= 7.0 then 4
      when potassium_min <  2.5 then 4
      when potassium_max >= 6.0 then 3
      when potassium_min <  3.0 then 2
      when potassium_max >= 5.5 then 1
      when potassium_min <  3.5 then 1
      when potassium_max >= 3.5 and potassium_max < 5.5
       and potassium_min >= 3.5 and potassium_min < 5.5
        then 0
      end as potassium_score

  , case
      when sodium_max is null then null
      when sodium_max >= 180 then 4
      when sodium_min  < 110 then 4
      when sodium_max >= 161 then 3
      when sodium_min  < 120 then 3
      when sodium_max >= 156 then 2
      when sodium_min  < 130 then 2
      when sodium_max >= 151 then 1
      when sodium_max >= 130 and sodium_max < 151
       and sodium_min >= 130 and sodium_min < 151
        then 0
      end as sodium_score

  , case
      when bicarbonate_max is null then null
      when bicarbonate_min <   5.0 then 4
      when bicarbonate_max >= 40.0 then 3
      when bicarbonate_min <  10.0 then 3
      when bicarbonate_max >= 30.0 then 1
      when bicarbonate_min <  20.0 then 1
      when bicarbonate_max >= 20.0 and bicarbonate_max < 30.0
       and bicarbonate_min >= 20.0 and bicarbonate_min < 30.0
          then 0
      end as bicarbonate_score

   , case
      when mingcs is null then null
        when mingcs <  3 then null -- erroneous value/on trach
        when mingcs =  3 then 4
        when mingcs <  7 then 3
        when mingcs < 10 then 2
        when mingcs < 13 then 1
        when mingcs >= 13
         and mingcs <= 15
          then 0
        end as gcs_score
from cohort
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
-- coalesce statements impute normal score of zero if data element is missing
, coalesce(age_score,0)
+ coalesce(hr_score,0)
+ coalesce(sysbp_score,0)
+ coalesce(resp_score,0)
+ coalesce(temp_score,0)
+ coalesce(uo_score,0)
+ coalesce(vent_score,0)
+ coalesce(bun_score,0)
+ coalesce(hematocrit_score,0)
+ coalesce(wbc_score,0)
+ coalesce(glucose_score,0)
+ coalesce(potassium_score,0)
+ coalesce(sodium_score,0)
+ coalesce(bicarbonate_score,0)
+ coalesce(gcs_score,0)
  as SAPS
, age_score
, hr_score
, sysbp_score
, resp_score
, temp_score
, uo_score
, vent_score
, bun_score
, hematocrit_score
, wbc_score
, glucose_score
, potassium_score
, sodium_score
, bicarbonate_score
, gcs_score

FROM icustays ie
left join scorecomp s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:37.887923 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.48 seconds
17:40:37.891993 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.892205 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
alter table "postgres"."public"."saps" rename to "saps__dbt_backup"
17:40:37.893024 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.896826 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.897023 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
alter table "postgres"."public"."saps__dbt_tmp" rename to "saps"
17:40:37.897758 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:37.901056 [debug] [Thread-1  ]: On model.mimic.saps: COMMIT
17:40:37.901277 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.901399 [debug] [Thread-1  ]: On model.mimic.saps: COMMIT
17:40:37.907832 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:37.910079 [debug] [Thread-1  ]: Using postgres connection "model.mimic.saps"
17:40:37.910274 [debug] [Thread-1  ]: On model.mimic.saps: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.saps"} */
drop table if exists "postgres"."public"."saps__dbt_backup" cascade
17:40:37.912222 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:37.915109 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.915421 [debug] [Thread-1  ]: On model.mimic.saps: Close
17:40:37.916426 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d5fd9700>]}
17:40:37.917051 [info ] [Thread-1  ]: 6 of 9 OK created table model public.saps ...................................... [[32mSELECT 61532[0m in 0.53s]
17:40:37.917796 [debug] [Thread-1  ]: Finished running node model.mimic.saps
17:40:37.918234 [debug] [Thread-1  ]: Began running node model.mimic.sapsii
17:40:37.918957 [info ] [Thread-1  ]: 7 of 9 START table model public.sapsii ......................................... [RUN]
17:40:37.919885 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sapsii"
17:40:37.920367 [debug] [Thread-1  ]: Began compiling node model.mimic.sapsii
17:40:37.920631 [debug] [Thread-1  ]: Compiling model.mimic.sapsii
17:40:37.925287 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sapsii"
17:40:37.925864 [debug] [Thread-1  ]: finished collecting timing info
17:40:37.926126 [debug] [Thread-1  ]: Began executing node model.mimic.sapsii
17:40:37.936280 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sapsii"
17:40:37.936812 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:37.936997 [debug] [Thread-1  ]: On model.mimic.sapsii: BEGIN
17:40:37.937170 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:37.943203 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:37.943446 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:37.943615 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */


  create  table "postgres"."public"."sapsii__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Simplified Acute Physiology Score II (SAPS II)
-- This query extracts the simplified acute physiology score II.
-- This score is a measure of patient severity of illness.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SAPS II:
--    Le Gall, Jean-Roger, Stanley Lemeshow, and Fabienne Saulnier.
--    "A new simplified acute physiology score (SAPS II) based on a European/North American multicenter study."
--    JAMA 270, no. 24 (1993): 2957-2963.

-- Variables used in SAPS II:
--  Age, GCS
--  VITALS: Heart rate, systolic blood pressure, temperature
--  FLAGS: ventilation/cpap
--  IO: urine output
--  LABS: PaO2/FiO2 ratio, blood urea nitrogen, WBC, potassium, sodium, HCO3

-- The following views are required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) ventilation_durations - generated by ventilation_durations.sql
--  3) vitals_first_day - generated by vitals-first-day.sql
--  4) gcs_first_day - generated by gcs-first-day.sql
--  5) labs_first_day - generated by labs-first-day.sql
--  6) blood_gas_arterial_first_day - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

-- extract CPAP from the "Oxygen Delivery Device" fields
with cpap as
(
  select ie.icustay_id
    , min(DATETIME_SUB(charttime, INTERVAL '1' HOUR)) as starttime
    , max(DATETIME_ADD(charttime, INTERVAL '4' HOUR)) as endtime
    , max(CASE
          WHEN lower(ce.value) LIKE '%cpap%' THEN 1
          WHEN lower(ce.value) LIKE '%bipap mask%' THEN 1
        else 0 end) as cpap
  FROM icustays ie
  inner join chartevents ce
    on ie.icustay_id = ce.icustay_id
    and ce.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in
  (
    -- TODO: when metavision data import fixed, check the values in 226732 match the value clause below
    467, 469, 226732
  )
  and (lower(ce.value) LIKE '%cpap%' or lower(ce.value) LIKE '%bipap mask%')
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error = 0)
  group by ie.icustay_id
)
-- extract a flag for surgical service
-- this combined with "elective" FROM admissions table defines elective/non-elective surgery
, surgflag as
(
  select adm.hadm_id
    , case when lower(curr_service) like '%surg%' then 1 else 0 end as surgical
    , ROW_NUMBER() over
    (
      PARTITION BY adm.HADM_ID
      ORDER BY TRANSFERTIME
    ) as serviceOrder
  FROM admissions adm
  left join services se
    on adm.hadm_id = se.hadm_id
)
-- icd-9 diagnostic codes are our best source for comorbidity information
-- unfortunately, they are technically a-causal
-- however, this shouldn't matter too much for the SAPS II comorbidities
, comorb as
(
select hadm_id
-- these are slightly different than elixhauser comorbidities, but based on them
-- they include some non-comorbid ICD-9 codes (e.g. 20302, relapse of multiple myeloma)
  , max(CASE
    when SUBSTR(icd9_code,1,3) BETWEEN '042' AND '044' THEN 1
  		end) as aids      /* HIV and AIDS */
  , max(CASE
    when icd9_code between '20000' and '20238' then 1 -- lymphoma
    when icd9_code between '20240' and '20248' then 1 -- leukemia
    when icd9_code between '20250' and '20302' then 1 -- lymphoma
    when icd9_code between '20310' and '20312' then 1 -- leukemia
    when icd9_code between '20302' and '20382' then 1 -- lymphoma
    when icd9_code between '20400' and '20522' then 1 -- chronic leukemia
    when icd9_code between '20580' and '20702' then 1 -- other myeloid leukemia
    when icd9_code between '20720' and '20892' then 1 -- other myeloid leukemia
    when SUBSTR(icd9_code,1,4) = '2386' then 1 -- lymphoma
    when SUBSTR(icd9_code,1,4) = '2733' then 1 -- lymphoma
  		end) as hem
  , max(CASE
    when SUBSTR(icd9_code,1,4) BETWEEN '1960' AND '1991' THEN 1
    when icd9_code between '20970' and '20975' then 1
    when icd9_code = '20979' then 1
    when icd9_code = '78951' then 1
  		end) as mets      /* Metastatic cancer */
  from diagnoses_icd
  group by hadm_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  -- also join to cpap table for the same purpose
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as vent
  , case when cp.icustay_id is not null then 1 else 0 end as cpap
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  left join cpap cp
    on bg.icustay_id = cp.icustay_id
    and bg.charttime >= cp.starttime
    and bg.charttime <= cp.endtime
)
, pafi2 as
(
  -- get the minimum PaO2/FiO2 ratio *only for ventilated/cpap patients*
  select icustay_id
  , min(pao2fio2) as pao2fio2_vent_min
  from pafi1
  where vent = 1 or cpap = 1
  group by icustay_id
)
, cohort as
(
select ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime
      , ie.outtime

      -- the casts ensure the result is numeric.. we could equally extract EPOCH from the interval
      -- however this code works in Oracle and Postgres
      , DATETIME_DIFF(ie.intime, pat.dob, 'YEAR') as age

      , vital.heartrate_max
      , vital.heartrate_min
      , vital.sysbp_max
      , vital.sysbp_min
      , vital.tempc_max
      , vital.tempc_min

      -- this value is non-null iff the patient is on vent/cpap
      , pf.pao2fio2_vent_min

      , uo.urineoutput

      , labs.bun_min
      , labs.bun_max
      , labs.wbc_min
      , labs.wbc_max
      , labs.potassium_min
      , labs.potassium_max
      , labs.sodium_min
      , labs.sodium_max
      , labs.bicarbonate_min
      , labs.bicarbonate_max
      , labs.bilirubin_min
      , labs.bilirubin_max

      , gcs.mingcs

      , comorb.aids
      , comorb.hem
      , comorb.mets

      , case
          when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
            then 'ScheduledSurgical'
          when adm.ADMISSION_TYPE != 'ELECTIVE' and sf.surgical = 1
            then 'UnscheduledSurgical'
          else 'Medical'
        end as admissiontype


FROM icustays ie
inner join admissions adm
  on ie.hadm_id = adm.hadm_id
inner join patients pat
  on ie.subject_id = pat.subject_id

-- join to above views
left join pafi2 pf
  on ie.icustay_id = pf.icustay_id
left join surgflag sf
  on adm.hadm_id = sf.hadm_id and sf.serviceOrder = 1
left join comorb
  on ie.hadm_id = comorb.hadm_id

-- join to custom tables to get more data....
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
left join "postgres"."public"."vitals_first_day" vital
  on ie.icustay_id = vital.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."labs_first_day" labs
  on ie.icustay_id = labs.icustay_id
)
, scorecomp as
(
select
  cohort.*
  -- Below code calculates the component scores needed for SAPS
  , case
      when age is null then null
      when age <  40 then 0
      when age <  60 then 7
      when age <  70 then 12
      when age <  75 then 15
      when age <  80 then 16
      when age >= 80 then 18
    end as age_score

  , case
      when heartrate_max is null then null
      when heartrate_min <   40 then 11
      when heartrate_max >= 160 then 7
      when heartrate_max >= 120 then 4
      when heartrate_min  <  70 then 2
      when  heartrate_max >= 70 and heartrate_max < 120
        and heartrate_min >= 70 and heartrate_min < 120
      then 0
    end as hr_score

  , case
      when  sysbp_min is null then null
      when  sysbp_min <   70 then 13
      when  sysbp_min <  100 then 5
      when  sysbp_max >= 200 then 2
      when  sysbp_max >= 100 and sysbp_max < 200
        and sysbp_min >= 100 and sysbp_min < 200
        then 0
    end as sysbp_score

  , case
      when tempc_max is null then null
      when tempc_min <  39.0 then 0
      when tempc_max >= 39.0 then 3
    end as temp_score

  , case
      when pao2fio2_vent_min is null then null
      when pao2fio2_vent_min <  100 then 11
      when pao2fio2_vent_min <  200 then 9
      when pao2fio2_vent_min >= 200 then 6
    end as pao2fio2_score

  , case
      when urineoutput is null then null
      when urineoutput <   500.0 then 11
      when urineoutput <  1000.0 then 4
      when urineoutput >= 1000.0 then 0
    end as uo_score

  , case
      when bun_max is null then null
      when bun_max <  28.0 then 0
      when bun_max <  84.0 then 6
      when bun_max >= 84.0 then 10
    end as bun_score

  , case
      when wbc_max is null then null
      when wbc_min <   1.0 then 12
      when wbc_max >= 20.0 then 3
      when wbc_max >=  1.0 and wbc_max < 20.0
       and wbc_min >=  1.0 and wbc_min < 20.0
        then 0
    end as wbc_score

  , case
      when potassium_max is null then null
      when potassium_min <  3.0 then 3
      when potassium_max >= 5.0 then 3
      when potassium_max >= 3.0 and potassium_max < 5.0
       and potassium_min >= 3.0 and potassium_min < 5.0
        then 0
      end as potassium_score

  , case
      when sodium_max is null then null
      when sodium_min  < 125 then 5
      when sodium_max >= 145 then 1
      when sodium_max >= 125 and sodium_max < 145
       and sodium_min >= 125 and sodium_min < 145
        then 0
      end as sodium_score

  , case
      when bicarbonate_max is null then null
      when bicarbonate_min <  15.0 then 5
      when bicarbonate_min <  20.0 then 3
      when bicarbonate_max >= 20.0
       and bicarbonate_min >= 20.0
          then 0
      end as bicarbonate_score

  , case
      when bilirubin_max is null then null
      when bilirubin_max  < 4.0 then 0
      when bilirubin_max  < 6.0 then 4
      when bilirubin_max >= 6.0 then 9
      end as bilirubin_score

   , case
      when mingcs is null then null
        when mingcs <  3 then null -- erroneous value/on trach
        when mingcs <  6 then 26
        when mingcs <  9 then 13
        when mingcs < 11 then 7
        when mingcs < 14 then 5
        when mingcs >= 14
         and mingcs <= 15
          then 0
        end as gcs_score

    , case
        when aids = 1 then 17
        when hem  = 1 then 10
        when mets = 1 then 9
        else 0
      end as comorbidity_score

    , case
        when admissiontype = 'ScheduledSurgical' then 0
        when admissiontype = 'Medical' then 6
        when admissiontype = 'UnscheduledSurgical' then 8
        else null
      end as admissiontype_score

from cohort
)
-- Calculate SAPS II here so we can use it in the probability calculation below
, score as
(
  select s.*
  -- coalesce statements impute normal score of zero if data element is missing
  , coalesce(age_score,0)
  + coalesce(hr_score,0)
  + coalesce(sysbp_score,0)
  + coalesce(temp_score,0)
  + coalesce(pao2fio2_score,0)
  + coalesce(uo_score,0)
  + coalesce(bun_score,0)
  + coalesce(wbc_score,0)
  + coalesce(potassium_score,0)
  + coalesce(sodium_score,0)
  + coalesce(bicarbonate_score,0)
  + coalesce(bilirubin_score,0)
  + coalesce(gcs_score,0)
  + coalesce(comorbidity_score,0)
  + coalesce(admissiontype_score,0)
    as sapsii
  from scorecomp s
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
, sapsii
, 1 / (1 + exp(- (-7.7631 + 0.0737*(sapsii) + 0.9971*(ln(sapsii + 1))) )) as sapsii_prob
, age_score
, hr_score
, sysbp_score
, temp_score
, pao2fio2_score
, uo_score
, bun_score
, wbc_score
, potassium_score
, sodium_score
, bicarbonate_score
, bilirubin_score
, gcs_score
, comorbidity_score
, admissiontype_score
FROM icustays ie
left join score s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:39.541687 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 1.6 seconds
17:40:39.548304 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:39.548773 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
alter table "postgres"."public"."sapsii" rename to "sapsii__dbt_backup"
17:40:39.550107 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:39.553892 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:39.554080 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
alter table "postgres"."public"."sapsii__dbt_tmp" rename to "sapsii"
17:40:39.554881 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:39.557734 [debug] [Thread-1  ]: On model.mimic.sapsii: COMMIT
17:40:39.557928 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:39.558131 [debug] [Thread-1  ]: On model.mimic.sapsii: COMMIT
17:40:39.566927 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:39.569012 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sapsii"
17:40:39.569191 [debug] [Thread-1  ]: On model.mimic.sapsii: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sapsii"} */
drop table if exists "postgres"."public"."sapsii__dbt_backup" cascade
17:40:39.571204 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:39.573785 [debug] [Thread-1  ]: finished collecting timing info
17:40:39.574014 [debug] [Thread-1  ]: On model.mimic.sapsii: Close
17:40:39.574639 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d562dd90>]}
17:40:39.575170 [info ] [Thread-1  ]: 7 of 9 OK created table model public.sapsii .................................... [[32mSELECT 61532[0m in 1.65s]
17:40:39.575712 [debug] [Thread-1  ]: Finished running node model.mimic.sapsii
17:40:39.576083 [debug] [Thread-1  ]: Began running node model.mimic.sirs
17:40:39.576768 [info ] [Thread-1  ]: 8 of 9 START table model public.sirs ........................................... [RUN]
17:40:39.577532 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sirs"
17:40:39.577779 [debug] [Thread-1  ]: Began compiling node model.mimic.sirs
17:40:39.578079 [debug] [Thread-1  ]: Compiling model.mimic.sirs
17:40:39.585320 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sirs"
17:40:39.586015 [debug] [Thread-1  ]: finished collecting timing info
17:40:39.586238 [debug] [Thread-1  ]: Began executing node model.mimic.sirs
17:40:39.596124 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sirs"
17:40:39.596754 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.596967 [debug] [Thread-1  ]: On model.mimic.sirs: BEGIN
17:40:39.597136 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:39.602072 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:40:39.602363 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.602463 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */


  create  table "postgres"."public"."sirs__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Systemic inflammatory response syndrome (SIRS) criteria
-- This query extracts the Systemic inflammatory response syndrome (SIRS) criteria
-- The criteria quantify the level of inflammatory response of the body
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SIRS:
--    American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference:
--    definitions for sepsis and organ failure and guidelines for the use of innovative therapies in sepsis"
--    Crit. Care Med. 20 (6): 864–74. 1992.
--    doi:10.1097/00003246-199206000-00025. PMID 1597042.

-- Variables used in SIRS:
--  Body temperature (min and max)
--  Heart rate (max)
--  Respiratory rate (max)
--  PaCO2 (min)
--  White blood cell count (min and max)
--  the presence of greater than 10% immature neutrophils (band forms)

-- The following views required to run this query:
--  1) vitals_first_day - generated by vitals-first-day.sql
--  2) labs_first_day - generated by labs-first-day.sql
--  3) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with bg as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select bg.icustay_id
  , min(pco2) as paco2_min
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  where specimen_pred = 'ART'
  group by bg.icustay_id
)
-- Aggregate the components for the score
, scorecomp as
(
select ie.icustay_id
  , v.tempc_min
  , v.tempc_max
  , v.heartrate_max
  , v.resprate_max
  , bg.paco2_min
  , l.wbc_min
  , l.wbc_max
  , l.bands_max
FROM icustays ie
left join bg
 on ie.icustay_id = bg.icustay_id
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."labs_first_day" l
  on ie.icustay_id = l.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id

  , case
      when tempc_min < 36.0 then 1
      when tempc_max > 38.0 then 1
      when tempc_min is null then null
      else 0
    end as temp_score


  , case
      when heartrate_max > 90.0  then 1
      when heartrate_max is null then null
      else 0
    end as heartrate_score

  , case
      when resprate_max > 20.0  then 1
      when paco2_min < 32.0  then 1
      when coalesce(resprate_max, paco2_min) is null then null
      else 0
    end as resp_score

  , case
      when wbc_min <  4.0  then 1
      when wbc_max > 12.0  then 1
      when bands_max > 10 then 1-- > 10% immature neurophils (band forms)
      when coalesce(wbc_min, bands_max) is null then null
      else 0
    end as wbc_score

  from scorecomp
)
select
  ie.subject_id, ie.hadm_id, ie.icustay_id
  -- Combine all the scores to get SOFA
  -- Impute 0 if the score is missing
  , coalesce(temp_score,0)
  + coalesce(heartrate_score,0)
  + coalesce(resp_score,0)
  + coalesce(wbc_score,0)
    as sirs
  , temp_score, heartrate_score, resp_score, wbc_score
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:39.726861 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 0.12 seconds
17:40:39.733488 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.733927 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
alter table "postgres"."public"."sirs" rename to "sirs__dbt_backup"
17:40:39.735277 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:39.743162 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.743371 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
alter table "postgres"."public"."sirs__dbt_tmp" rename to "sirs"
17:40:39.744083 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:39.747390 [debug] [Thread-1  ]: On model.mimic.sirs: COMMIT
17:40:39.747602 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.747795 [debug] [Thread-1  ]: On model.mimic.sirs: COMMIT
17:40:39.754102 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:40:39.756366 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sirs"
17:40:39.756560 [debug] [Thread-1  ]: On model.mimic.sirs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sirs"} */
drop table if exists "postgres"."public"."sirs__dbt_backup" cascade
17:40:39.758456 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:39.761515 [debug] [Thread-1  ]: finished collecting timing info
17:40:39.761787 [debug] [Thread-1  ]: On model.mimic.sirs: Close
17:40:39.762438 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d562df10>]}
17:40:39.762971 [info ] [Thread-1  ]: 8 of 9 OK created table model public.sirs ...................................... [[32mSELECT 61532[0m in 0.19s]
17:40:39.763562 [debug] [Thread-1  ]: Finished running node model.mimic.sirs
17:40:39.763911 [debug] [Thread-1  ]: Began running node model.mimic.sofa
17:40:39.764630 [info ] [Thread-1  ]: 9 of 9 START table model public.sofa ........................................... [RUN]
17:40:39.765393 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.sofa"
17:40:39.765655 [debug] [Thread-1  ]: Began compiling node model.mimic.sofa
17:40:39.766026 [debug] [Thread-1  ]: Compiling model.mimic.sofa
17:40:39.771449 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.sofa"
17:40:39.772110 [debug] [Thread-1  ]: finished collecting timing info
17:40:39.772382 [debug] [Thread-1  ]: Began executing node model.mimic.sofa
17:40:39.782206 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.sofa"
17:40:39.783187 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:39.783422 [debug] [Thread-1  ]: On model.mimic.sofa: BEGIN
17:40:39.783584 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:40:39.790146 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:40:39.790371 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:39.790857 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */


  create  table "postgres"."public"."sofa__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Sequential Organ Failure Assessment (SOFA)
-- This query extracts the sequential organ failure assessment (formally: sepsis-related organ failure assessment).
-- This score is a measure of organ failure for patients in the ICU.
-- The score is calculated on the first day of each ICU patients' stay.
-- ------------------------------------------------------------------

-- Reference for SOFA:
--    Jean-Louis Vincent, Rui Moreno, Jukka Takala, Sheila Willatts, Arnaldo De Mendonça,
--    Hajo Bruining, C. K. Reinhart, Peter M Suter, and L. G. Thijs.
--    "The SOFA (Sepsis-related Organ Failure Assessment) score to describe organ dysfunction/failure."
--    Intensive care medicine 22, no. 7 (1996): 707-710.

-- Variables used in SOFA:
--  GCS, MAP, FiO2, Ventilation status (sourced FROM chartevents)
--  Creatinine, Bilirubin, FiO2, PaO2, Platelets (sourced FROM labevents)
--  Dobutamine, Epinephrine, Norepinephrine (sourced FROM inputevents_mv and INPUTEVENTS_CV)
--  Urine output (sourced from OUTPUTEVENTS)

-- The following views required to run this query:
--  1) urine_output_first_day - generated by urine-output-first-day.sql
--  2) vitals_first_day - generated by vitals-first-day.sql
--  3) gcs_first_day - generated by gcs-first-day.sql
--  4) labs_first_day - generated by labs-first-day.sql
--  5) blood_gas_first_day_arterial - generated by blood-gas-first-day-arterial.sql
--  6) echodata - generated by echo-data.sql
--  7) ventilation_durations - generated by ventilation_durations.sql

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

with wt AS
(
  SELECT ie.icustay_id
    -- ensure weight is measured in kg
    , avg(CASE
        WHEN itemid IN (762, 763, 3723, 3580, 226512)
          THEN valuenum
        -- convert lbs to kgs
        WHEN itemid IN (3581)
          THEN valuenum * 0.45359237
        WHEN itemid IN (3582)
          THEN valuenum * 0.0283495231
        ELSE null
      END) AS weight

  FROM icustays ie
  left join chartevents c
    on ie.icustay_id = c.icustay_id
  WHERE valuenum IS NOT NULL
  AND itemid IN
  (
    762, 763, 3723, 3580,                     -- Weight Kg
    3581,                                     -- Weight lb
    3582,                                     -- Weight oz
    226512 -- Metavision: Admission Weight (Kg)
  )
  AND valuenum != 0
  and charttime between DATETIME_SUB(ie.intime, INTERVAL '1' DAY) and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  -- exclude rows marked as error
  AND (c.error IS NULL OR c.error = 0)
  group by ie.icustay_id
)
-- 5% of patients are missing a weight, but we can impute weight using their echo notes
, echo2 as(
  select ie.icustay_id, avg(weight * 0.45359237) as weight
  FROM icustays ie
  left join "postgres"."public"."echo_data" echo
    on ie.hadm_id = echo.hadm_id
    and echo.charttime > DATETIME_SUB(ie.intime, INTERVAL '7' DAY)
    and echo.charttime < DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  group by ie.icustay_id
)
, vaso_cv as
(
  select ie.icustay_id
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case
            when itemid = 30047 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin
            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin
            else null
          end) as rate_norepinephrine

    , max(case
            when itemid =  30044 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin
            when itemid in (30119,30309) then rate -- measured in mcgkgmin
            else null
          end) as rate_epinephrine

    , max(case when itemid in (30043,30307) then rate end) as rate_dopamine
    , max(case when itemid in (30042,30306) then rate end) as rate_dobutamine

  FROM icustays ie
  inner join inputevents_cv cv
    on ie.icustay_id = cv.icustay_id and cv.charttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  left join wt
    on ie.icustay_id = wt.icustay_id
  left join echo2 ec
    on ie.icustay_id = ec.icustay_id
  where itemid in (30047,30120,30044,30119,30309,30043,30307,30042,30306)
  and rate is not null
  group by ie.icustay_id
)
, vaso_mv as
(
  select ie.icustay_id
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 221906 then rate end) as rate_norepinephrine
    , max(case when itemid = 221289 then rate end) as rate_epinephrine
    , max(case when itemid = 221662 then rate end) as rate_dopamine
    , max(case when itemid = 221653 then rate end) as rate_dobutamine
  FROM icustays ie
  inner join inputevents_mv mv
    on ie.icustay_id = mv.icustay_id and mv.starttime between ie.intime and DATETIME_ADD(ie.intime, INTERVAL '1' DAY)
  where itemid in (221906,221289,221662,221653)
  -- 'Rewritten' orders are not delivered to the patient
  and statusdescription != 'Rewritten'
  group by ie.icustay_id
)
, pafi1 as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select bg.icustay_id, bg.charttime
  , pao2fio2
  , case when vd.icustay_id is not null then 1 else 0 end as isvent
  from "postgres"."public"."blood_gas_first_day_arterial" bg
  left join "postgres"."public"."ventilation_durations" vd
    on bg.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  order by bg.icustay_id, bg.charttime
)
, pafi2 as
(
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  select icustay_id
  , min(case when isvent = 0 then pao2fio2 else null end) as pao2fio2_novent_min
  , min(case when isvent = 1 then pao2fio2 else null end) as pao2fio2_vent_min
  from pafi1
  group by icustay_id
)
-- Aggregate the components for the score
, scorecomp as
(
select ie.icustay_id
  , v.meanbp_min
  , coalesce(cv.rate_norepinephrine, mv.rate_norepinephrine) as rate_norepinephrine
  , coalesce(cv.rate_epinephrine, mv.rate_epinephrine) as rate_epinephrine
  , coalesce(cv.rate_dopamine, mv.rate_dopamine) as rate_dopamine
  , coalesce(cv.rate_dobutamine, mv.rate_dobutamine) as rate_dobutamine

  , l.creatinine_max
  , l.bilirubin_max
  , l.platelet_min

  , pf.pao2fio2_novent_min
  , pf.pao2fio2_vent_min

  , uo.urineoutput

  , gcs.mingcs
FROM icustays ie
left join vaso_cv cv
  on ie.icustay_id = cv.icustay_id
left join vaso_mv mv
  on ie.icustay_id = mv.icustay_id
left join pafi2 pf
 on ie.icustay_id = pf.icustay_id
left join "postgres"."public"."vitals_first_day" v
  on ie.icustay_id = v.icustay_id
left join "postgres"."public"."labs_first_day" l
  on ie.icustay_id = l.icustay_id
left join "postgres"."public"."urine_output_first_day" uo
  on ie.icustay_id = uo.icustay_id
left join "postgres"."public"."gcs_first_day" gcs
  on ie.icustay_id = gcs.icustay_id
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select icustay_id
  -- Respiration
  , case
      when pao2fio2_vent_min   < 100 then 4
      when pao2fio2_vent_min   < 200 then 3
      when pao2fio2_novent_min < 300 then 2
      when pao2fio2_novent_min < 400 then 1
      when coalesce(pao2fio2_vent_min, pao2fio2_novent_min) is null then null
      else 0
    end as respiration

  -- Coagulation
  , case
      when platelet_min < 20  then 4
      when platelet_min < 50  then 3
      when platelet_min < 100 then 2
      when platelet_min < 150 then 1
      when platelet_min is null then null
      else 0
    end as coagulation

  -- Liver
  , case
      -- Bilirubin checks in mg/dL
        when bilirubin_max >= 12.0 then 4
        when bilirubin_max >= 6.0  then 3
        when bilirubin_max >= 2.0  then 2
        when bilirubin_max >= 1.2  then 1
        when bilirubin_max is null then null
        else 0
      end as liver

  -- Cardiovascular
  , case
      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4
      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3
      when rate_dopamine >  0 or rate_dobutamine > 0 then 2
      when meanbp_min < 70 then 1
      when coalesce(meanbp_min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null
      else 0
    end as cardiovascular

  -- Neurological failure (GCS)
  , case
      when (mingcs >= 13 and mingcs <= 14) then 1
      when (mingcs >= 10 and mingcs <= 12) then 2
      when (mingcs >=  6 and mingcs <=  9) then 3
      when  mingcs <   6 then 4
      when  mingcs is null then null
  else 0 end
    as cns

  -- Renal failure - high creatinine or low urine output
  , case
    when (creatinine_max >= 5.0) then 4
    when  urineoutput < 200 then 4
    when (creatinine_max >= 3.5 and creatinine_max < 5.0) then 3
    when  urineoutput < 500 then 3
    when (creatinine_max >= 2.0 and creatinine_max < 3.5) then 2
    when (creatinine_max >= 1.2 and creatinine_max < 2.0) then 1
    when coalesce(urineoutput, creatinine_max) is null then null
  else 0 end
    as renal
  from scorecomp
)
select ie.subject_id, ie.hadm_id, ie.icustay_id
  -- Combine all the scores to get SOFA
  -- Impute 0 if the score is missing
  , coalesce(respiration,0)
  + coalesce(coagulation,0)
  + coalesce(liver,0)
  + coalesce(cardiovascular,0)
  + coalesce(cns,0)
  + coalesce(renal,0)
  as SOFA
, respiration
, coagulation
, liver
, cardiovascular
, cns
, renal
FROM icustays ie
left join scorecalc s
  on ie.icustay_id = s.icustay_id
order by ie.icustay_id
  );
17:40:43.481970 [debug] [Thread-1  ]: SQL status: SELECT 61532 in 3.69 seconds
17:40:43.488505 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:43.488906 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
alter table "postgres"."public"."sofa" rename to "sofa__dbt_backup"
17:40:43.490108 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:43.494186 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:43.494373 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
alter table "postgres"."public"."sofa__dbt_tmp" rename to "sofa"
17:40:43.495194 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:40:43.497961 [debug] [Thread-1  ]: On model.mimic.sofa: COMMIT
17:40:43.498142 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:43.498246 [debug] [Thread-1  ]: On model.mimic.sofa: COMMIT
17:40:43.503291 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:40:43.506217 [debug] [Thread-1  ]: Using postgres connection "model.mimic.sofa"
17:40:43.506430 [debug] [Thread-1  ]: On model.mimic.sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.sofa"} */
drop table if exists "postgres"."public"."sofa__dbt_backup" cascade
17:40:43.508892 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:40:43.511722 [debug] [Thread-1  ]: finished collecting timing info
17:40:43.511976 [debug] [Thread-1  ]: On model.mimic.sofa: Close
17:40:43.512770 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70951921-1d6e-4695-a364-e3b6a912484c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d45b10a0>]}
17:40:43.513236 [info ] [Thread-1  ]: 9 of 9 OK created table model public.sofa ...................................... [[32mSELECT 61532[0m in 3.75s]
17:40:43.513769 [debug] [Thread-1  ]: Finished running node model.mimic.sofa
17:40:43.515566 [debug] [MainThread]: Acquiring new postgres connection "master"
17:40:43.515962 [debug] [MainThread]: Using postgres connection "master"
17:40:43.516301 [debug] [MainThread]: On master: BEGIN
17:40:43.516573 [debug] [MainThread]: Opening a new connection, currently in state closed
17:40:43.523439 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:40:43.523798 [debug] [MainThread]: On master: COMMIT
17:40:43.524054 [debug] [MainThread]: Using postgres connection "master"
17:40:43.524271 [debug] [MainThread]: On master: COMMIT
17:40:43.524815 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:40:43.525255 [debug] [MainThread]: On master: Close
17:40:43.526458 [info ] [MainThread]: 
17:40:43.527590 [info ] [MainThread]: Finished running 9 table models in 11.97s.
17:40:43.528214 [debug] [MainThread]: Connection 'master' was properly closed.
17:40:43.528623 [debug] [MainThread]: Connection 'model.mimic.sofa' was properly closed.
17:40:43.540662 [info ] [MainThread]: 
17:40:43.541100 [info ] [MainThread]: [32mCompleted successfully[0m
17:40:43.541438 [info ] [MainThread]: 
17:40:43.541755 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
17:40:43.542058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d7ee8f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60f0130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d60f0160>]}
17:40:43.547128 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:41:30.746538 | 1f6285c7-8f3b-4055-ba46-54d982cb5078 ==============================
17:41:30.746592 [info ] [MainThread]: Running with dbt=1.1.1
17:41:30.747288 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['treatment'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:41:30.747504 [debug] [MainThread]: Tracking: tracking
17:41:30.753493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa26570a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa2657160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa2657190>]}
17:41:30.843290 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:41:30.843561 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:41:30.845895 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:41:30.854238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa26acf10>]}
17:41:30.872837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa4413700>]}
17:41:30.873613 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:41:30.874160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa268d250>]}
17:41:30.878199 [info ] [MainThread]: 
17:41:30.879295 [debug] [MainThread]: Acquiring new postgres connection "master"
17:41:30.880558 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:41:30.890778 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:41:30.891077 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:41:30.891402 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:41:30.900889 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:41:30.906527 [debug] [ThreadPool]: On list_postgres: Close
17:41:30.911872 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:41:30.916670 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:41:30.916881 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:41:30.916978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:41:30.922469 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:41:30.923428 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:41:30.923729 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:41:30.927896 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:41:30.934720 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:41:30.935207 [debug] [ThreadPool]: On list_postgres_public: Close
17:41:30.946408 [debug] [MainThread]: Using postgres connection "master"
17:41:30.946723 [debug] [MainThread]: On master: BEGIN
17:41:30.946920 [debug] [MainThread]: Opening a new connection, currently in state init
17:41:30.952194 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:41:30.952417 [debug] [MainThread]: Using postgres connection "master"
17:41:30.952587 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:41:30.961685 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:41:30.967057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa2689f10>]}
17:41:30.967617 [debug] [MainThread]: On master: ROLLBACK
17:41:30.968122 [debug] [MainThread]: Using postgres connection "master"
17:41:30.968365 [debug] [MainThread]: On master: BEGIN
17:41:30.968769 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:41:30.969001 [debug] [MainThread]: On master: COMMIT
17:41:30.969097 [debug] [MainThread]: Using postgres connection "master"
17:41:30.969188 [debug] [MainThread]: On master: COMMIT
17:41:30.969349 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:41:30.969465 [debug] [MainThread]: On master: Close
17:41:30.969920 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:41:30.970144 [info ] [MainThread]: 
17:41:30.974173 [debug] [Thread-1  ]: Began running node model.mimic.abx_prescriptions_list
17:41:30.974654 [info ] [Thread-1  ]: 1 of 2 START table model public.abx_prescriptions_list ......................... [RUN]
17:41:30.975483 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.abx_prescriptions_list"
17:41:30.975925 [debug] [Thread-1  ]: Began compiling node model.mimic.abx_prescriptions_list
17:41:30.976279 [debug] [Thread-1  ]: Compiling model.mimic.abx_prescriptions_list
17:41:30.980303 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.abx_prescriptions_list"
17:41:30.981494 [debug] [Thread-1  ]: finished collecting timing info
17:41:30.982032 [debug] [Thread-1  ]: Began executing node model.mimic.abx_prescriptions_list
17:41:31.014883 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.abx_prescriptions_list"
17:41:31.015495 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:41:31.015719 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: BEGIN
17:41:31.015889 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:41:31.022273 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:41:31.022982 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:41:31.023328 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */


  create  table "postgres"."public"."abx_prescriptions_list__dbt_tmp"
  as (
     
with t1 as
(
  select
    drug, drug_name_generic
    , route
    , case
      when lower(drug) like '%adoxa%' then 1
      when lower(drug) like '%ala-tet%' then 1
      when lower(drug) like '%alodox%' then 1
      when lower(drug) like '%amikacin%' then 1
      when lower(drug) like '%amikin%' then 1
      when lower(drug) like '%amoxicillin%' then 1
      when lower(drug) like '%amoxicillin%clavulanate%' then 1
      when lower(drug) like '%clavulanate%' then 1
      when lower(drug) like '%ampicillin%' then 1
      when lower(drug) like '%augmentin%' then 1
      when lower(drug) like '%avelox%' then 1
      when lower(drug) like '%avidoxy%' then 1
      when lower(drug) like '%azactam%' then 1
      when lower(drug) like '%azithromycin%' then 1
      when lower(drug) like '%aztreonam%' then 1
      when lower(drug) like '%axetil%' then 1
      when lower(drug) like '%bactocill%' then 1
      when lower(drug) like '%bactrim%' then 1
      when lower(drug) like '%bethkis%' then 1
      when lower(drug) like '%biaxin%' then 1
      when lower(drug) like '%bicillin l-a%' then 1
      when lower(drug) like '%cayston%' then 1
      when lower(drug) like '%cefazolin%' then 1
      when lower(drug) like '%cedax%' then 1
      when lower(drug) like '%cefoxitin%' then 1
      when lower(drug) like '%ceftazidime%' then 1
      when lower(drug) like '%cefaclor%' then 1
      when lower(drug) like '%cefadroxil%' then 1
      when lower(drug) like '%cefdinir%' then 1
      when lower(drug) like '%cefditoren%' then 1
      when lower(drug) like '%cefepime%' then 1
      when lower(drug) like '%cefotetan%' then 1
      when lower(drug) like '%cefotaxime%' then 1
      when lower(drug) like '%cefpodoxime%' then 1
      when lower(drug) like '%cefprozil%' then 1
      when lower(drug) like '%ceftibuten%' then 1
      when lower(drug) like '%ceftin%' then 1
      when lower(drug) like '%cefuroxime %' then 1
      when lower(drug) like '%cefuroxime%' then 1
      when lower(drug) like '%cephalexin%' then 1
      when lower(drug) like '%chloramphenicol%' then 1
      when lower(drug) like '%cipro%' then 1
      when lower(drug) like '%ciprofloxacin%' then 1
      when lower(drug) like '%claforan%' then 1
      when lower(drug) like '%clarithromycin%' then 1
      when lower(drug) like '%cleocin%' then 1
      when lower(drug) like '%clindamycin%' then 1
      when lower(drug) like '%cubicin%' then 1
      when lower(drug) like '%dicloxacillin%' then 1
      when lower(drug) like '%doryx%' then 1
      when lower(drug) like '%doxycycline%' then 1
      when lower(drug) like '%duricef%' then 1
      when lower(drug) like '%dynacin%' then 1
      when lower(drug) like '%ery-tab%' then 1
      when lower(drug) like '%eryped%' then 1
      when lower(drug) like '%eryc%' then 1
      when lower(drug) like '%erythrocin%' then 1
      when lower(drug) like '%erythromycin%' then 1
      when lower(drug) like '%factive%' then 1
      when lower(drug) like '%flagyl%' then 1
      when lower(drug) like '%fortaz%' then 1
      when lower(drug) like '%furadantin%' then 1
      when lower(drug) like '%garamycin%' then 1
      when lower(drug) like '%gentamicin%' then 1
      when lower(drug) like '%kanamycin%' then 1
      when lower(drug) like '%keflex%' then 1
      when lower(drug) like '%ketek%' then 1
      when lower(drug) like '%levaquin%' then 1
      when lower(drug) like '%levofloxacin%' then 1
      when lower(drug) like '%lincocin%' then 1
      when lower(drug) like '%macrobid%' then 1
      when lower(drug) like '%macrodantin%' then 1
      when lower(drug) like '%maxipime%' then 1
      when lower(drug) like '%mefoxin%' then 1
      when lower(drug) like '%metronidazole%' then 1
      when lower(drug) like '%minocin%' then 1
      when lower(drug) like '%minocycline%' then 1
      when lower(drug) like '%monodox%' then 1
      when lower(drug) like '%monurol%' then 1
      when lower(drug) like '%morgidox%' then 1
      when lower(drug) like '%moxatag%' then 1
      when lower(drug) like '%moxifloxacin%' then 1
      when lower(drug) like '%myrac%' then 1
      when lower(drug) like '%nafcillin sodium%' then 1
      when lower(drug) like '%nicazel doxy 30%' then 1
      when lower(drug) like '%nitrofurantoin%' then 1
      when lower(drug) like '%noroxin%' then 1
      when lower(drug) like '%ocudox%' then 1
      when lower(drug) like '%ofloxacin%' then 1
      when lower(drug) like '%omnicef%' then 1
      when lower(drug) like '%oracea%' then 1
      when lower(drug) like '%oraxyl%' then 1
      when lower(drug) like '%oxacillin%' then 1
      when lower(drug) like '%pc pen vk%' then 1
      when lower(drug) like '%pce dispertab%' then 1
      when lower(drug) like '%panixine%' then 1
      when lower(drug) like '%pediazole%' then 1
      when lower(drug) like '%penicillin%' then 1
      when lower(drug) like '%periostat%' then 1
      when lower(drug) like '%pfizerpen%' then 1
      when lower(drug) like '%piperacillin%' then 1
      when lower(drug) like '%tazobactam%' then 1
      when lower(drug) like '%primsol%' then 1
      when lower(drug) like '%proquin%' then 1
      when lower(drug) like '%raniclor%' then 1
      when lower(drug) like '%rifadin%' then 1
      when lower(drug) like '%rifampin%' then 1
      when lower(drug) like '%rocephin%' then 1
      when lower(drug) like '%smz-tmp%' then 1
      when lower(drug) like '%septra%' then 1
      when lower(drug) like '%septra ds%' then 1
      when lower(drug) like '%septra%' then 1
      when lower(drug) like '%solodyn%' then 1
      when lower(drug) like '%spectracef%' then 1
      when lower(drug) like '%streptomycin sulfate%' then 1
      when lower(drug) like '%sulfadiazine%' then 1
      when lower(drug) like '%sulfamethoxazole%' then 1
      when lower(drug) like '%trimethoprim%' then 1
      when lower(drug) like '%sulfatrim%' then 1
      when lower(drug) like '%sulfisoxazole%' then 1
      when lower(drug) like '%suprax%' then 1
      when lower(drug) like '%synercid%' then 1
      when lower(drug) like '%tazicef%' then 1
      when lower(drug) like '%tetracycline%' then 1
      when lower(drug) like '%timentin%' then 1
      when lower(drug) like '%tobi%' then 1
      when lower(drug) like '%tobramycin%' then 1
      when lower(drug) like '%trimethoprim%' then 1
      when lower(drug) like '%unasyn%' then 1
      when lower(drug) like '%vancocin%' then 1
      when lower(drug) like '%vancomycin%' then 1
      when lower(drug) like '%vantin%' then 1
      when lower(drug) like '%vibativ%' then 1
      when lower(drug) like '%vibra-tabs%' then 1
      when lower(drug) like '%vibramycin%' then 1
      when lower(drug) like '%zinacef%' then 1
      when lower(drug) like '%zithromax%' then 1
      when lower(drug) like '%zmax%' then 1
      when lower(drug) like '%zosyn%' then 1
      when lower(drug) like '%zyvox%' then 1
    else 0
    end as antibiotic
  from prescriptions
  where drug_type in ('MAIN','ADDITIVE')
  -- we exclude routes via the eye, ears, or topically
  and route not in ('OU','OS','OD','AU','AS','AD', 'TP')
  and lower(route) not like '%ear%'
  and lower(route) not like '%eye%'
  -- we exclude certain types of antibiotics: topical creams, gels, desens, etc
  and lower(drug) not like '%cream%'
  and lower(drug) not like '%desensitization%'
  and lower(drug) not like '%ophth oint%'
  and lower(drug) not like '%gel%'
  -- other routes not sure about...
  -- for sure keep: ('IV','PO','PO/NG','ORAL', 'IV DRIP', 'IV BOLUS')
  -- ? VT, PB, PR, PL, NS, NG, NEB, NAS, LOCK, J TUBE, IVT
  -- ? IT, IRR, IP, IO, INHALATION, IN, IM
  -- ? IJ, IH, G TUBE, DIALYS
  -- ?? enemas??
)
select
  drug --, drug_name_generic
  , count(*) as numobs
from t1
where antibiotic = 1
group by drug --, drug_name_generic
order by numobs desc
  );
17:42:04.049540 [debug] [Thread-1  ]: SQL status: SELECT 156 in 33.03 seconds
17:42:04.057949 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:42:04.058149 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
alter table "postgres"."public"."abx_prescriptions_list" rename to "abx_prescriptions_list__dbt_backup"
17:42:04.059135 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:42:04.062366 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:42:04.062708 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
alter table "postgres"."public"."abx_prescriptions_list__dbt_tmp" rename to "abx_prescriptions_list"
17:42:04.063474 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:42:04.073099 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: COMMIT
17:42:04.073320 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:42:04.073520 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: COMMIT
17:42:04.074753 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:42:04.078971 [debug] [Thread-1  ]: Using postgres connection "model.mimic.abx_prescriptions_list"
17:42:04.079205 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.abx_prescriptions_list"} */
drop table if exists "postgres"."public"."abx_prescriptions_list__dbt_backup" cascade
17:42:04.081273 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:42:04.084657 [debug] [Thread-1  ]: finished collecting timing info
17:42:04.084899 [debug] [Thread-1  ]: On model.mimic.abx_prescriptions_list: Close
17:42:04.085592 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa1bdf7f0>]}
17:42:04.086056 [info ] [Thread-1  ]: 1 of 2 OK created table model public.abx_prescriptions_list .................... [[32mSELECT 156[0m in 33.11s]
17:42:04.086721 [debug] [Thread-1  ]: Finished running node model.mimic.abx_prescriptions_list
17:42:04.087984 [debug] [Thread-1  ]: Began running node model.mimic.suspicion_of_infection
17:42:04.088381 [info ] [Thread-1  ]: 2 of 2 START table model public.suspicion_of_infection ......................... [RUN]
17:42:04.089134 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.suspicion_of_infection"
17:42:04.089473 [debug] [Thread-1  ]: Began compiling node model.mimic.suspicion_of_infection
17:42:04.089724 [debug] [Thread-1  ]: Compiling model.mimic.suspicion_of_infection
17:42:04.093392 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.suspicion_of_infection"
17:42:04.094955 [debug] [Thread-1  ]: finished collecting timing info
17:42:04.095448 [debug] [Thread-1  ]: Began executing node model.mimic.suspicion_of_infection
17:42:04.108966 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.suspicion_of_infection"
17:42:04.109411 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:04.109522 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: BEGIN
17:42:04.109823 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:42:04.116046 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:42:04.116297 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:04.116511 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */


  create  table "postgres"."public"."suspicion_of_infection__dbt_tmp"
  as (
     

-- defines suspicion of infection using prescriptions + microbiologyevents
with abx as
(
  select pr.hadm_id
  , pr.drug as antibiotic_name
  , pr.startdate as antibiotic_time
  , pr.enddate as antibiotic_endtime
  from prescriptions pr
  -- inner join to subselect to only antibiotic prescriptions
  inner join "postgres"."public"."abx_prescriptions_list" ab
      on pr.drug = ab.drug
)
-- get cultures for each icustay
-- note this duplicates prescriptions
-- each ICU stay in the same hospitalization will get a copy of all prescriptions for that hospitalization
, ab_tbl as
(
  select
        ie.subject_id, ie.hadm_id, ie.icustay_id
      , ie.intime, ie.outtime
      , abx.antibiotic_name
      , abx.antibiotic_time
      , abx.antibiotic_endtime
  from icustays ie
  left join abx
      on ie.hadm_id = abx.hadm_id
)
, me as
(
  select hadm_id
    , chartdate, charttime
    , spec_type_desc
    , max(case when org_name is not null and org_name != '' then 1 else 0 end) as PositiveCulture
  from microbiologyevents
  group by hadm_id, chartdate, charttime, spec_type_desc
)
, ab_fnl as
(
  select
      ab_tbl.icustay_id, ab_tbl.intime, ab_tbl.outtime
    , ab_tbl.antibiotic_name
    , ab_tbl.antibiotic_time
    , coalesce(me72.charttime,me72.chartdate) as last72_charttime
    , coalesce(me24.charttime,me24.chartdate) as next24_charttime
    , me72.positiveculture as last72_positiveculture
    , me72.spec_type_desc as last72_specimen
    , me24.positiveculture as next24_positiveculture
    , me24.spec_type_desc as next24_specimen
  from ab_tbl
  -- blood culture in last 72 hours
  left join me me72
    on ab_tbl.hadm_id = me72.hadm_id
    and ab_tbl.antibiotic_time is not null
    and
    (
      -- if charttime is available, use it
      (
          ab_tbl.antibiotic_time >= me72.charttime
      and ab_tbl.antibiotic_time <= datetime_add(me72.charttime, INTERVAL '72 HOUR')
      )
      OR
      (
      -- if charttime is not available, use chartdate
          me72.charttime is null
      and ab_tbl.antibiotic_time >= me72.chartdate
      and ab_tbl.antibiotic_time <= datetime_add(me72.chartdate, INTERVAL '96 HOUR')
      )
    )
  -- blood culture in subsequent 24 hours
  left join me me24
    on ab_tbl.hadm_id = me24.hadm_id
    and ab_tbl.antibiotic_time is not null
    and
    (
      -- if charttime is available, use it
      (
          ab_tbl.antibiotic_time <= me24.charttime
      and ab_tbl.antibiotic_time >= datetime_sub(me24.charttime, INTERVAL '24 HOUR')
      )
      OR
      (
      -- if charttime is not available, use chartdate
          me24.charttime is null
      and ab_tbl.antibiotic_time <= me24.chartdate
      and ab_tbl.antibiotic_time >= datetime_sub(me24.chartdate, INTERVAL '24 HOUR')
      )
    )
)
, ab_laststg as
(
select
  icustay_id
  , antibiotic_name
  , antibiotic_time
  , last72_charttime
  , next24_charttime

  -- time of suspected infection: either the culture time (if before antibiotic), or the antibiotic time
  , case
      when coalesce(last72_charttime,next24_charttime) is null
        then 0
      else 1 end as suspected_infection

  , coalesce(last72_charttime,next24_charttime) as suspected_infection_time

  -- the specimen that was cultured
  , case
      when last72_charttime is not null
        then last72_specimen
      when next24_charttime is not null
        then next24_specimen
    else null
  end as specimen

  -- whether the cultured specimen ended up being positive or not
  , case
      when last72_charttime is not null
        then last72_positiveculture
      when next24_charttime is not null
        then next24_positiveculture
    else null
  end as positiveculture
from ab_fnl
)
select
  icustay_id
  , antibiotic_name
  , antibiotic_time
  , last72_charttime
  , next24_charttime
  , suspected_infection_time
  -- -- the below two fields are used to extract data - modifying them facilitates sensitivity analyses
  -- , suspected_infection_time - interval '48' hour as si_starttime
  -- , suspected_infection_time + interval '24' hour as si_endtime
  , specimen, positiveculture
from ab_laststg
order by icustay_id, antibiotic_time
  );
17:42:13.225829 [debug] [Thread-1  ]: SQL status: SELECT 1374912 in 9.11 seconds
17:42:13.232196 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:13.232432 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
alter table "postgres"."public"."suspicion_of_infection" rename to "suspicion_of_infection__dbt_backup"
17:42:13.233653 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:42:13.237712 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:13.237915 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
alter table "postgres"."public"."suspicion_of_infection__dbt_tmp" rename to "suspicion_of_infection"
17:42:13.238699 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:42:13.241775 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: COMMIT
17:42:13.242037 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:13.242245 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: COMMIT
17:42:13.254295 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:42:13.256857 [debug] [Thread-1  ]: Using postgres connection "model.mimic.suspicion_of_infection"
17:42:13.257054 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.suspicion_of_infection"} */
drop table if exists "postgres"."public"."suspicion_of_infection__dbt_backup" cascade
17:42:13.260275 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:42:13.263173 [debug] [Thread-1  ]: finished collecting timing info
17:42:13.263410 [debug] [Thread-1  ]: On model.mimic.suspicion_of_infection: Close
17:42:13.264291 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f6285c7-8f3b-4055-ba46-54d982cb5078', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa1bd1970>]}
17:42:13.264828 [info ] [Thread-1  ]: 2 of 2 OK created table model public.suspicion_of_infection .................... [[32mSELECT 1374912[0m in 9.18s]
17:42:13.265454 [debug] [Thread-1  ]: Finished running node model.mimic.suspicion_of_infection
17:42:13.267196 [debug] [MainThread]: Acquiring new postgres connection "master"
17:42:13.267652 [debug] [MainThread]: Using postgres connection "master"
17:42:13.268026 [debug] [MainThread]: On master: BEGIN
17:42:13.268324 [debug] [MainThread]: Opening a new connection, currently in state closed
17:42:13.275263 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:42:13.275622 [debug] [MainThread]: On master: COMMIT
17:42:13.275855 [debug] [MainThread]: Using postgres connection "master"
17:42:13.276041 [debug] [MainThread]: On master: COMMIT
17:42:13.276488 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:42:13.276824 [debug] [MainThread]: On master: Close
17:42:13.277563 [info ] [MainThread]: 
17:42:13.277890 [info ] [MainThread]: Finished running 2 table models in 42.40s.
17:42:13.278104 [debug] [MainThread]: Connection 'master' was properly closed.
17:42:13.278214 [debug] [MainThread]: Connection 'model.mimic.suspicion_of_infection' was properly closed.
17:42:13.293770 [info ] [MainThread]: 
17:42:13.294158 [info ] [MainThread]: [32mCompleted successfully[0m
17:42:13.294469 [info ] [MainThread]: 
17:42:13.295201 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
17:42:13.295685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa25801c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa268d1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa268d0d0>]}
17:42:13.299103 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:43:29.508424 | b6715c24-394e-42d8-9db4-7650ea2a2fa4 ==============================
17:43:29.508440 [info ] [MainThread]: Running with dbt=1.1.1
17:43:29.508893 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['diagnosis'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:43:29.509001 [debug] [MainThread]: Tracking: tracking
17:43:29.515155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba250ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba2504c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba2502e0>]}
17:43:29.599664 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:43:29.599908 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:43:29.602093 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:43:29.608829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6715c24-394e-42d8-9db4-7650ea2a2fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba24e8b0>]}
17:43:29.630623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6715c24-394e-42d8-9db4-7650ea2a2fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba22b370>]}
17:43:29.631008 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:43:29.631602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6715c24-394e-42d8-9db4-7650ea2a2fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba22b640>]}
17:43:29.632505 [warn ] [MainThread]: The selection criterion 'diagnosis' does not match any nodes
17:43:29.633892 [info ] [MainThread]: 
17:43:29.634120 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
17:43:29.647133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba22b130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba22b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ba22b700>]}
17:43:29.650205 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:44:21.772528 | 689e162f-2ee4-4b59-b78a-6b3fe1306e4f ==============================
17:44:21.772543 [info ] [MainThread]: Running with dbt=1.1.1
17:44:21.773062 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['diagnosis'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:44:21.773578 [debug] [MainThread]: Tracking: tracking
17:44:21.780069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc44168fa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc44168f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc44168f6d0>]}
17:44:21.871150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:44:21.871394 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:44:21.873584 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:44:21.880064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '689e162f-2ee4-4b59-b78a-6b3fe1306e4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc441613460>]}
17:44:21.897337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '689e162f-2ee4-4b59-b78a-6b3fe1306e4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4416671c0>]}
17:44:21.897769 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:44:21.898064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '689e162f-2ee4-4b59-b78a-6b3fe1306e4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc441673e20>]}
17:44:21.900106 [warn ] [MainThread]: The selection criterion 'diagnosis' does not match any nodes
17:44:21.902877 [info ] [MainThread]: 
17:44:21.903389 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
17:44:21.912533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc442ea7af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc442ea71f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc441667460>]}
17:44:21.915724 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:45:24.744000 | f17c1509-c421-417a-b7fc-6932da5aca6f ==============================
17:45:24.744017 [info ] [MainThread]: Running with dbt=1.1.1
17:45:24.744392 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['durations'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:45:24.744503 [debug] [MainThread]: Tracking: tracking
17:45:24.750894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c850190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c850250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c850280>]}
17:45:24.836223 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:45:24.836466 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:45:24.838731 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.diagnosis
- models.mimic.example

17:45:24.845316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c8448e0>]}
17:45:24.864671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c8b4f70>]}
17:45:24.865391 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:45:24.866191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c89f250>]}
17:45:24.871305 [info ] [MainThread]: 
17:45:24.872955 [debug] [MainThread]: Acquiring new postgres connection "master"
17:45:24.876006 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:45:24.887846 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:45:24.888112 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:45:24.888483 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:45:24.893915 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:45:24.901761 [debug] [ThreadPool]: On list_postgres: Close
17:45:24.907996 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:45:24.913839 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:45:24.914189 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:45:24.914296 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:45:24.922082 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
17:45:24.922328 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:45:24.922618 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:45:24.925078 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:45:24.935238 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:45:24.935884 [debug] [ThreadPool]: On list_postgres_public: Close
17:45:24.945748 [debug] [MainThread]: Using postgres connection "master"
17:45:24.945952 [debug] [MainThread]: On master: BEGIN
17:45:24.946048 [debug] [MainThread]: Opening a new connection, currently in state init
17:45:24.954003 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:45:24.954362 [debug] [MainThread]: Using postgres connection "master"
17:45:24.954728 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:45:24.962419 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:45:24.967811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2e0a6df0>]}
17:45:24.968228 [debug] [MainThread]: On master: ROLLBACK
17:45:24.968691 [debug] [MainThread]: Using postgres connection "master"
17:45:24.968918 [debug] [MainThread]: On master: BEGIN
17:45:24.969381 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:45:24.969614 [debug] [MainThread]: On master: COMMIT
17:45:24.969783 [debug] [MainThread]: Using postgres connection "master"
17:45:24.969878 [debug] [MainThread]: On master: COMMIT
17:45:24.970071 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:45:24.970190 [debug] [MainThread]: On master: Close
17:45:24.970784 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:45:24.971167 [info ] [MainThread]: 
17:45:24.974617 [debug] [Thread-1  ]: Began running node model.mimic.adenosine_durations
17:45:24.975035 [info ] [Thread-1  ]: 1 of 23 START table model public.adenosine_durations ........................... [RUN]
17:45:24.975803 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.adenosine_durations"
17:45:24.976127 [debug] [Thread-1  ]: Began compiling node model.mimic.adenosine_durations
17:45:24.976356 [debug] [Thread-1  ]: Compiling model.mimic.adenosine_durations
17:45:24.977793 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.adenosine_durations"
17:45:24.978170 [debug] [Thread-1  ]: finished collecting timing info
17:45:24.978295 [debug] [Thread-1  ]: Began executing node model.mimic.adenosine_durations
17:45:25.009118 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.adenosine_durations"
17:45:25.009846 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.010069 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: BEGIN
17:45:25.010172 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:25.016465 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:25.016856 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.017310 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */


  create  table "postgres"."public"."adenosine_durations__dbt_tmp"
  as (
    -- This query extracts durations of adenosine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- *** COULD NOT FIND ADENOSINE IN THE INPUTEVENTS_MV TABLE ***
-- This drug is rarely used - it could just be that it was never used in MetaVision.
-- If using this code, ensure the durations make sense for carevue patients first

with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 4649 then 1 else 0 end) as vaso -- adenosine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , 0 as vaso_stopped
    , max(case when itemid = 4649 and valuenum is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 4649 then valuenum else null end) as vaso_rate
    , max(case when itemid = 4649 then valuenum else null end) as vaso_amount

  FROM chartevents
  where itemid = 4649 -- adenosine
  -- exclude rows marked as error
  AND (error IS NULL OR error = 0)
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221282 -- adenosine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:25.029900 [debug] [Thread-1  ]: SQL status: SELECT 160 in 0.01 seconds
17:45:25.039205 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.039431 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations" rename to "adenosine_durations__dbt_backup"
17:45:25.040131 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.043731 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.043935 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
alter table "postgres"."public"."adenosine_durations__dbt_tmp" rename to "adenosine_durations"
17:45:25.044548 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.055290 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:45:25.055522 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.055710 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: COMMIT
17:45:25.056891 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:25.061187 [debug] [Thread-1  ]: Using postgres connection "model.mimic.adenosine_durations"
17:45:25.061423 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.adenosine_durations"} */
drop table if exists "postgres"."public"."adenosine_durations__dbt_backup" cascade
17:45:25.063508 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:25.066677 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.066970 [debug] [Thread-1  ]: On model.mimic.adenosine_durations: Close
17:45:25.067698 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a580e80>]}
17:45:25.068181 [info ] [Thread-1  ]: 1 of 23 OK created table model public.adenosine_durations ...................... [[32mSELECT 160[0m in 0.09s]
17:45:25.068727 [debug] [Thread-1  ]: Finished running node model.mimic.adenosine_durations
17:45:25.069072 [debug] [Thread-1  ]: Began running node model.mimic.arterial_line_durations
17:45:25.069724 [info ] [Thread-1  ]: 2 of 23 START table model public.arterial_line_durations ....................... [RUN]
17:45:25.070357 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.arterial_line_durations"
17:45:25.070766 [debug] [Thread-1  ]: Began compiling node model.mimic.arterial_line_durations
17:45:25.071044 [debug] [Thread-1  ]: Compiling model.mimic.arterial_line_durations
17:45:25.072654 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.arterial_line_durations"
17:45:25.073324 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.073593 [debug] [Thread-1  ]: Began executing node model.mimic.arterial_line_durations
17:45:25.085403 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.arterial_line_durations"
17:45:25.085935 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.086140 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: BEGIN
17:45:25.086234 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:25.092686 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:25.092922 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.093056 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */


  create  table "postgres"."public"."arterial_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
  , case
      when itemid in (225752, 224272)
        then 1
      when pe.locationcategory = 'Invasive Arterial'
        then 1
      when itemid = 225789 and pe.locationcategory IS NULL
        then 1
      else 0
    end as arterial_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    -- , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    -- , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    -- , 225203 -- Pheresis Catheter | None | 12 | Processes
    -- , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 225789 -- Sheath
    , 224272 -- IABP Line
    -- , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('A-Line', 'IABP'))
     OR (inv2_type in ('A-Line', 'IABP'))
     OR (inv3_type in ('A-Line', 'IABP'))
     OR (inv4_type in ('A-Line', 'IABP'))
     OR (inv5_type in ('A-Line', 'IABP'))
     OR (inv6_type in ('A-Line', 'IABP'))
     OR (inv7_type in ('A-Line', 'IABP'))
     OR (inv8_type in ('A-Line', 'IABP'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as arterial_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as arterial_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( arterial_line_new )
    OVER ( partition by icustay_id order by charttime )
    as arterial_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , arterial_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, arterial_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , arterial_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as arterial_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where arterial_line = 1
order by icustay_id, starttime
  );
17:45:25.239706 [debug] [Thread-1  ]: SQL status: SELECT 13059 in 0.15 seconds
17:45:25.246803 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.247326 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations" rename to "arterial_line_durations__dbt_backup"
17:45:25.248646 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.253659 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.253851 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
alter table "postgres"."public"."arterial_line_durations__dbt_tmp" rename to "arterial_line_durations"
17:45:25.254742 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.257907 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:45:25.258106 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.258289 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: COMMIT
17:45:25.260652 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:25.263607 [debug] [Thread-1  ]: Using postgres connection "model.mimic.arterial_line_durations"
17:45:25.263811 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.arterial_line_durations"} */
drop table if exists "postgres"."public"."arterial_line_durations__dbt_backup" cascade
17:45:25.265949 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:25.269105 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.269333 [debug] [Thread-1  ]: On model.mimic.arterial_line_durations: Close
17:45:25.270100 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde85b0>]}
17:45:25.270663 [info ] [Thread-1  ]: 2 of 23 OK created table model public.arterial_line_durations .................. [[32mSELECT 13059[0m in 0.20s]
17:45:25.271231 [debug] [Thread-1  ]: Finished running node model.mimic.arterial_line_durations
17:45:25.271605 [debug] [Thread-1  ]: Began running node model.mimic.central_line_durations
17:45:25.272024 [info ] [Thread-1  ]: 3 of 23 START table model public.central_line_durations ........................ [RUN]
17:45:25.273090 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.central_line_durations"
17:45:25.273337 [debug] [Thread-1  ]: Began compiling node model.mimic.central_line_durations
17:45:25.273582 [debug] [Thread-1  ]: Compiling model.mimic.central_line_durations
17:45:25.275376 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.central_line_durations"
17:45:25.275994 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.276329 [debug] [Thread-1  ]: Began executing node model.mimic.central_line_durations
17:45:25.286075 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.central_line_durations"
17:45:25.287853 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.288192 [debug] [Thread-1  ]: On model.mimic.central_line_durations: BEGIN
17:45:25.288458 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:25.294802 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:25.295199 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.295745 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */


  create  table "postgres"."public"."central_line_durations__dbt_tmp"
  as (
    with mv as
(
  select
    pe.icustay_id
  , pe.starttime, pe.endtime
    , case
        when (locationcategory <> 'Invasive Arterial' or locationcategory is null)
          then 1
        else 0
      end as central_line
  FROM procedureevents_mv pe
  where pe.itemid in
  (
      224263 -- Multi Lumen | None | 12 | Processes
    , 224264 -- PICC Line | None | 12 | Processes
    , 224267 -- Cordis/Introducer | None | 12 | Processes
    , 224268 -- Trauma line | None | 12 | Processes
    , 225199 -- Triple Introducer | None | 12 | Processes
    , 225202 -- Indwelling Port (PortaCath) | None | 12 | Processes
    , 225203 -- Pheresis Catheter | None | 12 | Processes
    , 225315 -- Tunneled (Hickman) Line | None | 12 | Processes
    , 225752 -- Arterial Line | None | 12 | Processes
    , 227719 -- AVA Line | None | 12 | Processes
    -- , 228286 -- Intraosseous Device | None | 12 | Processes
    , 224270 -- Dialysis Catheter
  )
)
, cv_grp as
(
  -- group type+site
  select ce.icustay_id, ce.charttime
    , max(case when itemid =  229  then value else null end) as INV1_Type
    , max(case when itemid =  8392 then value else null end) as INV1_Site
    , max(case when itemid =  235  then value else null end) as INV2_Type
    , max(case when itemid =  8393 then value else null end) as INV2_Site
    , max(case when itemid =  241  then value else null end) as INV3_Type
    , max(case when itemid =  8394 then value else null end) as INV3_Site
    , max(case when itemid =  247  then value else null end) as INV4_Type
    , max(case when itemid =  8395 then value else null end) as INV4_Site
    , max(case when itemid =  253  then value else null end) as INV5_Type
    , max(case when itemid =  8396 then value else null end) as INV5_Site
    , max(case when itemid =  259  then value else null end) as INV6_Type
    , max(case when itemid =  8397 then value else null end) as INV6_Site
    , max(case when itemid =  265  then value else null end) as INV7_Type
    , max(case when itemid =  8398 then value else null end) as INV7_Site
    , max(case when itemid =  271  then value else null end) as INV8_Type
    , max(case when itemid =  8399 then value else null end) as INV8_Site
  FROM chartevents ce
  where ce.itemid in
  (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
  )
  and ce.value is not null
  group by ce.icustay_id, ce.charttime
)
-- types of invasive lines in carevue
--       value       | count
-- ------------------+--------
--  A-Line           | 460627
--  Multi-lumen      | 345858
--  PICC line        |  92285
--  PA line          |  65702
--  Dialysis Line    |  57579
--  Introducer       |  36027
--  CCO PA Line      |  24831
--                   |  22369
--  Trauma Line      |  15530
--  Portacath        |  12927
--  Ventriculostomy  |  10295
--  Pre-Sep Catheter |   9678
--  IABP             |   8819
--  Other/Remarks    |   8725
--  Midline          |   5067
--  Venous Access    |   4278
--  Hickman          |   3783
--  PacerIntroducer  |   2663
--  TripleIntroducer |   2262
--  RIC              |   1625
--  PermaCath        |   1066
--  Camino Bolt      |    913
--  Lumbar Drain     |    361
-- (23 rows)
, cv as
(
  select distinct icustay_id, charttime
  from cv_grp
  where (inv1_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv2_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv3_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv4_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv5_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv6_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv7_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
     OR (inv8_type in ('Multi-lumen', 'PICC line', 'Dialysis Line', 'Introducer','Trauma Line', 'Portacath', 'Venous Access', 'Hickman', 'PacerIntroducer', 'TripleIntroducer'))
)
-- transform carevue data into durations
, cv0 as
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER (partition by icustay_id order by charttime) as charttime_lag
    , charttime
  from cv
)
, cv1 as
(
  select
    icustay_id
    , charttime
    , charttime_lag
    -- if the current observation indicates a line is present
    -- calculate the time since the last charted line
    , charttime - charttime_lag as central_line_duration
    -- now we determine if the current line is "new"
    -- new == no documentation for 16 hours
    , case
        when DATETIME_DIFF(charttime, charttime_lag, 'HOUR') > 16
          then 1
      else 0
      end as central_line_new
  FROM cv0
)
, cv2 as
(
  select cv1.*
  -- create a cumulative sum of the instances of new events
  -- this results in a monotonic integer assigned to each new instance of a line
  , SUM( central_line_new )
    OVER ( partition by icustay_id order by charttime )
    as central_line_rownum
  from cv1
)
-- create the durations for each line
, cv_dur as
(
  select icustay_id
    , central_line_rownum
    , min(charttime) as starttime
    , max(charttime) as endtime
    , DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  from cv2
  group by icustay_id, central_line_rownum
  having min(charttime) != max(charttime)
)
select icustay_id
  -- , central_line_rownum
  , starttime, endtime, duration_hours
from cv_dur
UNION ALL
--TODO: collapse metavision durations if they overlap
select icustay_id
  -- , ROW_NUMBER() over (PARTITION BY icustay_id ORDER BY starttime) as central_line_rownum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
from mv
where central_line = 1
order by icustay_id, starttime
  );
17:45:25.378708 [debug] [Thread-1  ]: SQL status: SELECT 21211 in 0.08 seconds
17:45:25.384002 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.384235 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations" rename to "central_line_durations__dbt_backup"
17:45:25.385773 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.389700 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.389899 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
alter table "postgres"."public"."central_line_durations__dbt_tmp" rename to "central_line_durations"
17:45:25.390776 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.393884 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:45:25.394063 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.394305 [debug] [Thread-1  ]: On model.mimic.central_line_durations: COMMIT
17:45:25.395457 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:25.397176 [debug] [Thread-1  ]: Using postgres connection "model.mimic.central_line_durations"
17:45:25.397374 [debug] [Thread-1  ]: On model.mimic.central_line_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.central_line_durations"} */
drop table if exists "postgres"."public"."central_line_durations__dbt_backup" cascade
17:45:25.399989 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:25.402756 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.403017 [debug] [Thread-1  ]: On model.mimic.central_line_durations: Close
17:45:25.403777 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bddddf0>]}
17:45:25.404376 [info ] [Thread-1  ]: 3 of 23 OK created table model public.central_line_durations ................... [[32mSELECT 21211[0m in 0.13s]
17:45:25.404914 [debug] [Thread-1  ]: Finished running node model.mimic.central_line_durations
17:45:25.405300 [debug] [Thread-1  ]: Began running node model.mimic.crrt_durations
17:45:25.405875 [info ] [Thread-1  ]: 4 of 23 START table model public.crrt_durations ................................ [RUN]
17:45:25.406447 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.crrt_durations"
17:45:25.406747 [debug] [Thread-1  ]: Began compiling node model.mimic.crrt_durations
17:45:25.407049 [debug] [Thread-1  ]: Compiling model.mimic.crrt_durations
17:45:25.408667 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.crrt_durations"
17:45:25.409289 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.409584 [debug] [Thread-1  ]: Began executing node model.mimic.crrt_durations
17:45:25.419063 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.crrt_durations"
17:45:25.419817 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.420067 [debug] [Thread-1  ]: On model.mimic.crrt_durations: BEGIN
17:45:25.420240 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:25.426213 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:25.426452 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.426929 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */


  create  table "postgres"."public"."crrt_durations__dbt_tmp"
  as (
    with crrt_settings as
(
  select ce.icustay_id, ce.charttime
  , max(
      case
        when ce.itemid in
        (
          224149, -- Access Pressure
          224144, -- Blood Flow (ml/min)
          228004, -- Citrate (ACD-A)
          225183, -- Current Goal
          225977, -- Dialysate Fluid
          224154, -- Dialysate Rate
          224151, -- Effluent Pressure
          224150, -- Filter Pressure
          225958, -- Heparin Concentration (units/mL)
          224145, -- Heparin Dose (per hour)
          224191, -- Hourly Patient Fluid Removal
          228005, -- PBP (Prefilter) Replacement Rate
          228006, -- Post Filter Replacement Rate
          225976, -- Replacement Fluid
          224153, -- Replacement Rate
          224152, -- Return Pressure
          226457  -- Ultrafiltrate Output
        ) then 1
      when ce.itemid in
        (
        29,  -- Access mmHg
        173, -- Effluent Press mmHg
        192, -- Filter Pressure mmHg
        624, -- Return Pressure mmHg
        79, -- Blood Flow ml/min
        142, -- Current Goal
        146, -- Dialysate Flow ml/hr
        611, -- Replace Rate ml/hr
        5683 -- Hourly PFR
        ) then 1
      when ce.itemid = 665 and value in ('Active','Clot Increasing','Clots Present','No Clot Present')
         then 1
      when ce.itemid = 147 and value = 'Yes'
         then 1
      else 0 end)
      as RRT
  -- Below indicates that a new instance of CRRT has started
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('New Filter','Reinitiated')
        then 1
      when ce.itemid = 665 and value in ('Initiated')
        then 1
    else 0
   end ) as RRT_start
  -- Below indicates that the current instance of CRRT has ended
  , max(
    case
      -- System Integrity
      when ce.itemid = 224146 and value in ('Discontinued','Recirculating')
        then 1
      -- the only value like DC is "DC'D", use like to avoid apostrophe
      when ce.itemid = 665 and (value = 'Clotted' OR value LIKE 'DC%')
        then 1
      -- Reason for CRRT filter change
      when ce.itemid = 225956
        then 1
    else 0
   end ) as RRT_end
  FROM chartevents ce
  where ce.itemid in
  (
    -- MetaVision ITEMIDs
    -- Below require special handling
    224146, -- System Integrity
    225956,  -- Reason for CRRT Filter Change
    -- Below are settings which indicate CRRT is started/continuing
    224149, -- Access Pressure
    224144, -- Blood Flow (ml/min)
    228004, -- Citrate (ACD-A)
    225183, -- Current Goal
    225977, -- Dialysate Fluid
    224154, -- Dialysate Rate
    224151, -- Effluent Pressure
    224150, -- Filter Pressure
    225958, -- Heparin Concentration (units/mL)
    224145, -- Heparin Dose (per hour)
    224191, -- Hourly Patient Fluid Removal
    228005, -- PBP (Prefilter) Replacement Rate
    228006, -- Post Filter Replacement Rate
    225976, -- Replacement Fluid
    224153, -- Replacement Rate
    224152, -- Return Pressure
    226457, -- Ultrafiltrate Output
    -- CareVue ITEMIDs
    -- Below require special handling
    665,  -- System integrity
    147, -- Dialysate Infusing
    612, -- Replace.Fluid Infuse
    -- Below are settings which indicate CRRT is started/continuing
    29,  -- Access mmHg
    173, -- Effluent Press mmHg
    192, -- Filter Pressure mmHg
    624, -- Return Pressure mmHg
    142, -- Current Goal
    79, -- Blood Flow ml/min
    146, -- Dialysate Flow ml/hr
    611, -- Replace Rate ml/hr
    5683 -- Hourly PFR
  )
  and ce.value is not null
  and coalesce(ce.valuenum,1) != 0 -- non-zero rates/values
  group by icustay_id, charttime
)
-- create various lagged variables for future query
, vd_lag AS
(
  select
    icustay_id
    -- this carries over the previous charttime
    , LAG(CHARTTIME, 1) OVER W AS charttime_prev_row
    , charttime
    , RRT
    , RRT_start
    , RRT_end
    , LAG(RRT_end, 1) OVER W AS rrt_ended_prev_row
  FROM crrt_settings
  WINDOW w AS 
  (
    partition by icustay_id, case when RRT=1 or RRT_end=1 then 1 else 0 end
    order by charttime
  )
)
, vd1 as
(
  select
      icustay_id
      , charttime
      , RRT
      , RRT_start
      , RRT_end

      -- now we determine if the current event is a new instantiation
      , case
          when RRT_start = 1
            then 1
        -- if there is an end flag, we mark any subsequent event as new
          when RRT_end = 1
            -- note the end is *not* a new event, the *subsequent* row is
            -- so here we output 0
            then 0
          when rrt_ended_prev_row = 1
            then 1
            -- if there is less than 2 hours between CRRT settings, we do not treat this as a new CRRT event
          when DATETIME_DIFF(charttime, charttime_prev_row, 'HOUR') <= 2
            then 0
        else 1
      end as NewCRRT
  -- use the temp table with only settings FROM chartevents
  FROM vd_lag
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new CRRT
  -- this results in a monotonically increasing integer assigned to each CRRT
  , case when RRT_start = 1 or RRT=1 or RRT_end = 1 then
      SUM( NewCRRT )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as num
  --- now we convert CHARTTIME of CRRT settings into durations
  from vd1
  -- now we can isolate to just rows with settings
  -- (before we had rows with start/end flags)
  -- this removes any null values for NewCRRT
  where
    RRT_start = 1 or RRT = 1 or RRT_end = 1
)
-- create the durations for each CRRT instance
, fin as
(
select icustay_id
  , num
  , min(charttime) as starttime
  , max(charttime) as endtime
 	, DATETIME_DIFF(max(charttime), min(charttime), 'HOUR') AS duration_hours
  -- add durations
from vd2
group by icustay_id, num
having min(charttime) != max(charttime)
)
select icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as num
  , starttime, endtime, duration_hours
from fin
order by icustay_id, num
  );
17:45:25.437071 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:45:25.441580 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.441790 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations" rename to "crrt_durations__dbt_backup"
17:45:25.442277 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.445727 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.445923 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
alter table "postgres"."public"."crrt_durations__dbt_tmp" rename to "crrt_durations"
17:45:25.446932 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:25.455138 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:45:25.455380 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.455659 [debug] [Thread-1  ]: On model.mimic.crrt_durations: COMMIT
17:45:25.456704 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:25.458199 [debug] [Thread-1  ]: Using postgres connection "model.mimic.crrt_durations"
17:45:25.458314 [debug] [Thread-1  ]: On model.mimic.crrt_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.crrt_durations"} */
drop table if exists "postgres"."public"."crrt_durations__dbt_backup" cascade
17:45:25.460182 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:25.463640 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.464390 [debug] [Thread-1  ]: On model.mimic.crrt_durations: Close
17:45:25.466887 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5040>]}
17:45:25.467566 [info ] [Thread-1  ]: 4 of 23 OK created table model public.crrt_durations ........................... [[32mSELECT 0[0m in 0.06s]
17:45:25.468552 [debug] [Thread-1  ]: Finished running node model.mimic.crrt_durations
17:45:25.469150 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_dose
17:45:25.469728 [info ] [Thread-1  ]: 5 of 23 START table model public.dobutamine_dose ............................... [RUN]
17:45:25.470292 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_dose"
17:45:25.470602 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_dose
17:45:25.470840 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_dose
17:45:25.472040 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_dose"
17:45:25.472448 [debug] [Thread-1  ]: finished collecting timing info
17:45:25.472571 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_dose
17:45:25.482158 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_dose"
17:45:25.483348 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:25.483615 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: BEGIN
17:45:25.483879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:25.489515 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:25.490439 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:25.490704 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */


  create  table "postgres"."public"."dobutamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30042,30306) then 1 else 0 end) as vaso -- dobutamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30042,30306) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30042,30306) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30042,30306) then rate else null end) as vaso_rate
    , max(case when itemid in (30042,30306) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30042,30306) -- dobutamine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221653 -- dobutamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:26.078508 [debug] [Thread-1  ]: SQL status: SELECT 6548 in 0.59 seconds
17:45:26.085482 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:26.085994 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose" rename to "dobutamine_dose__dbt_backup"
17:45:26.087479 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:26.091581 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:26.091792 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
alter table "postgres"."public"."dobutamine_dose__dbt_tmp" rename to "dobutamine_dose"
17:45:26.092495 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:26.095482 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:45:26.095715 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:26.095928 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: COMMIT
17:45:26.099318 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:26.101433 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_dose"
17:45:26.101624 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_dose"} */
drop table if exists "postgres"."public"."dobutamine_dose__dbt_backup" cascade
17:45:26.103521 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:26.106922 [debug] [Thread-1  ]: finished collecting timing info
17:45:26.107163 [debug] [Thread-1  ]: On model.mimic.dobutamine_dose: Close
17:45:26.107911 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bddde20>]}
17:45:26.108387 [info ] [Thread-1  ]: 5 of 23 OK created table model public.dobutamine_dose .......................... [[32mSELECT 6548[0m in 0.64s]
17:45:26.108941 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_dose
17:45:26.109342 [debug] [Thread-1  ]: Began running node model.mimic.dobutamine_durations
17:45:26.109947 [info ] [Thread-1  ]: 6 of 23 START table model public.dobutamine_durations .......................... [RUN]
17:45:26.110921 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dobutamine_durations"
17:45:26.111348 [debug] [Thread-1  ]: Began compiling node model.mimic.dobutamine_durations
17:45:26.111680 [debug] [Thread-1  ]: Compiling model.mimic.dobutamine_durations
17:45:26.113466 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dobutamine_durations"
17:45:26.114278 [debug] [Thread-1  ]: finished collecting timing info
17:45:26.114855 [debug] [Thread-1  ]: Began executing node model.mimic.dobutamine_durations
17:45:26.125999 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dobutamine_durations"
17:45:26.126988 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.127217 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: BEGIN
17:45:26.127480 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:26.136205 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:26.136464 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.136793 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */


  create  table "postgres"."public"."dobutamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dobutamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID
-- Get drug administration data from CareVue first
with vasocv1 as (
  select
    icustay_id,
    charttime -- case statement determining whether the ITEMID is an instance of vasopressor usage
,
    max(
      case
        when itemid in (30042, 30306) then 1
        else 0
      end
    ) as vaso -- dobutamine
    -- the 'stopped' column indicates if a vasopressor has been disconnected
,
    max(
      case
        when itemid in (30042, 30306)
        and (
          stopped = 'Stopped'
          OR stopped like 'D/C%'
        ) then 1
        else 0
      end
    ) as vaso_stopped,
    max(
      case
        when itemid in (30042, 30306)
        and rate is not null then 1
        else 0
      end
    ) as vaso_null,
    max(
      case
        when itemid in (30042, 30306) then rate
        else null
      end
    ) as vaso_rate,
    max(
      case
        when itemid in (30042, 30306) then amount
        else null
      end
    ) as vaso_amount
  FROM
    inputevents_cv
  where
    itemid in (30042, 30306) -- dobutamine
  group by
    icustay_id,
    charttime
),
vasocv2 as (
  select
    v.*,
    sum(vaso_null) over (
      partition by icustay_id
      order by
        charttime
    ) as vaso_partition
  from
    vasocv1 v
),
vasocv3 as (
  select
    v.*,
    first_value(vaso_rate) over (
      partition by icustay_id,
      vaso_partition
      order by
        charttime
    ) as vaso_prevrate_ifnull
  from
    vasocv2 v
),
vasocv4 as (
  select
    icustay_id,
    charttime -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta
,
    vaso,
    vaso_rate,
    vaso_amount,
    vaso_stopped,
    vaso_prevrate_ifnull -- We define start time here
,
    case
      when vaso = 0 then null -- if this is the first instance of the vasoactive drug
      when vaso_rate > 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso,
        vaso_null
        order by
          charttime
      ) is null then 1 -- you often get a string of 0s
      -- we decide not to set these as 1, just because it makes vasonum sequential
      when vaso_rate = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- sometimes you get a string of NULL, associated with 0 volumes
      -- same reason as before, we decide not to set these as 1
      -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
      when vaso_prevrate_ifnull = 0
      and LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 0 -- If the last recorded rate was 0, newvaso = 1
      when LAG(vaso_prevrate_ifnull, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 0 then 1 -- If the last recorded vaso was D/C'd, newvaso = 1
      when LAG(vaso_stopped, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) = 1 then 1 -- ** not sure if the below is needed
      --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
    end as vaso_start
  FROM
    vasocv3
) -- propagate start/stop flags forward in time
,
vasocv5 as (
  select
    v.*,
    SUM(vaso_start) OVER (
      partition by icustay_id,
      vaso
      order by
        charttime
    ) as vaso_first
  FROM
    vasocv4 v
),
vasocv6 as (
  select
    v.* -- We define end time here
,
    case
      when vaso = 0 then null -- If the recorded vaso was D/C'd, this is an end time
      when vaso_stopped = 1 then vaso_first -- If the rate is zero, this is the end time
      when vaso_rate = 0 then vaso_first -- the last row in the table is always a potential end time
      -- this captures patients who die/are discharged while on vasopressors
      -- in principle, this could add an extra end time for the vasopressor
      -- however, since we later group on vaso_start, any extra end times are ignored
      when LEAD(CHARTTIME, 1) OVER (
        partition by icustay_id,
        vaso
        order by
          charttime
      ) is null then vaso_first
      else null
    end as vaso_stop
  from
    vasocv5 v
) -- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime
,
vasocv as (
  -- below groups together vasopressor administrations into groups
  select
    icustay_id -- the first non-null rate is considered the starttime
,
    min(
      case
        when vaso_rate is not null then charttime
        else null
      end
    ) as starttime -- the *first* time the first/last flags agree is the stop time for this duration
,
    min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    ) as endtime
  from
    vasocv6
  where
    vaso_first is not null -- bogus data
    and vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
    and icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
  group by
    icustay_id,
    vaso_first
  having
    -- ensure start time is not the same as end time
    min(charttime) != min(
      case
        when vaso_first = vaso_stop then charttime
        else null
      end
    )
    and max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
) -- now we extract the associated data for metavision patients
,
vasomv as (
  select
    icustay_id,
    linkorderid,
    min(starttime) as starttime,
    max(endtime) as endtime
  FROM
    inputevents_mv
  where
    itemid = 221653 -- dobutamine
    and statusdescription != 'Rewritten' -- only valid orders
  group by
    icustay_id,
    linkorderid
)
select
  icustay_id -- generate a sequential integer for convenience
,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasocv
UNION
ALL
select
  icustay_id,
  ROW_NUMBER() over (
    partition by icustay_id
    order by
      starttime
  ) as vasonum,
  starttime,
  endtime,
  DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours -- add durations
from
  vasomv
order by
  icustay_id,
  vasonum
  );
17:45:26.504446 [debug] [Thread-1  ]: SQL status: SELECT 1792 in 0.37 seconds
17:45:26.511067 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.511303 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations" rename to "dobutamine_durations__dbt_backup"
17:45:26.512550 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:26.517160 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.517354 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
alter table "postgres"."public"."dobutamine_durations__dbt_tmp" rename to "dobutamine_durations"
17:45:26.518100 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:26.521047 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:45:26.521251 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.521426 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: COMMIT
17:45:26.523968 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:26.526158 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dobutamine_durations"
17:45:26.526340 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dobutamine_durations"} */
drop table if exists "postgres"."public"."dobutamine_durations__dbt_backup" cascade
17:45:26.528589 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:26.531890 [debug] [Thread-1  ]: finished collecting timing info
17:45:26.532119 [debug] [Thread-1  ]: On model.mimic.dobutamine_durations: Close
17:45:26.532928 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a580af0>]}
17:45:26.533398 [info ] [Thread-1  ]: 6 of 23 OK created table model public.dobutamine_durations ..................... [[32mSELECT 1792[0m in 0.42s]
17:45:26.534027 [debug] [Thread-1  ]: Finished running node model.mimic.dobutamine_durations
17:45:26.534525 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_dose
17:45:26.535233 [info ] [Thread-1  ]: 7 of 23 START table model public.dopamine_dose ................................. [RUN]
17:45:26.536203 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_dose"
17:45:26.536607 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_dose
17:45:26.536858 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_dose
17:45:26.538065 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_dose"
17:45:26.538826 [debug] [Thread-1  ]: finished collecting timing info
17:45:26.539309 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_dose
17:45:26.549234 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_dose"
17:45:26.550213 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:26.550433 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: BEGIN
17:45:26.550738 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:26.556698 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:26.556942 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:26.557220 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */


  create  table "postgres"."public"."dopamine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of dopamine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:28.303783 [debug] [Thread-1  ]: SQL status: SELECT 38953 in 1.75 seconds
17:45:28.309809 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:28.310199 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose" rename to "dopamine_dose__dbt_backup"
17:45:28.311315 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:28.315052 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:28.315263 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
alter table "postgres"."public"."dopamine_dose__dbt_tmp" rename to "dopamine_dose"
17:45:28.315954 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:28.319042 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:45:28.319252 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:28.319446 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: COMMIT
17:45:28.331999 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:45:28.334124 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_dose"
17:45:28.334306 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_dose"} */
drop table if exists "postgres"."public"."dopamine_dose__dbt_backup" cascade
17:45:28.339991 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:45:28.343311 [debug] [Thread-1  ]: finished collecting timing info
17:45:28.343544 [debug] [Thread-1  ]: On model.mimic.dopamine_dose: Close
17:45:28.344511 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bdda130>]}
17:45:28.344995 [info ] [Thread-1  ]: 7 of 23 OK created table model public.dopamine_dose ............................ [[32mSELECT 38953[0m in 1.81s]
17:45:28.345570 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_dose
17:45:28.346045 [debug] [Thread-1  ]: Began running node model.mimic.dopamine_durations
17:45:28.346745 [info ] [Thread-1  ]: 8 of 23 START table model public.dopamine_durations ............................ [RUN]
17:45:28.347633 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.dopamine_durations"
17:45:28.348005 [debug] [Thread-1  ]: Began compiling node model.mimic.dopamine_durations
17:45:28.348262 [debug] [Thread-1  ]: Compiling model.mimic.dopamine_durations
17:45:28.349539 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.dopamine_durations"
17:45:28.350117 [debug] [Thread-1  ]: finished collecting timing info
17:45:28.350338 [debug] [Thread-1  ]: Began executing node model.mimic.dopamine_durations
17:45:28.363368 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.dopamine_durations"
17:45:28.364502 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:28.364710 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: BEGIN
17:45:28.364884 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:28.371227 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:28.371465 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:28.371567 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */


  create  table "postgres"."public"."dopamine_durations__dbt_tmp"
  as (
    -- This query extracts durations of dopamine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30043,30307) then 1 else 0 end) as vaso -- dopamine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30043,30307) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30043,30307) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30043,30307) then rate else null end) as vaso_rate
    , max(case when itemid in (30043,30307) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30043,30307 -- dopamine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221662 -- dopamine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:30.252122 [debug] [Thread-1  ]: SQL status: SELECT 6524 in 1.88 seconds
17:45:30.257074 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:30.257280 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations" rename to "dopamine_durations__dbt_backup"
17:45:30.258082 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.262096 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:30.262303 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
alter table "postgres"."public"."dopamine_durations__dbt_tmp" rename to "dopamine_durations"
17:45:30.263088 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.265846 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:45:30.266027 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:30.266130 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: COMMIT
17:45:30.269809 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:30.272350 [debug] [Thread-1  ]: Using postgres connection "model.mimic.dopamine_durations"
17:45:30.272562 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.dopamine_durations"} */
drop table if exists "postgres"."public"."dopamine_durations__dbt_backup" cascade
17:45:30.274741 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:30.277575 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.277803 [debug] [Thread-1  ]: On model.mimic.dopamine_durations: Close
17:45:30.278598 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde53d0>]}
17:45:30.279137 [info ] [Thread-1  ]: 8 of 23 OK created table model public.dopamine_durations ....................... [[32mSELECT 6524[0m in 1.93s]
17:45:30.279781 [debug] [Thread-1  ]: Finished running node model.mimic.dopamine_durations
17:45:30.280265 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_durations
17:45:30.280941 [info ] [Thread-1  ]: 9 of 23 START table model public.epinephrine_durations ......................... [RUN]
17:45:30.281850 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_durations"
17:45:30.282194 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_durations
17:45:30.282382 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_durations
17:45:30.283702 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_durations"
17:45:30.284455 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.284765 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_durations
17:45:30.295942 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_durations"
17:45:30.297363 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.297600 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: BEGIN
17:45:30.297709 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:30.303984 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:30.304369 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.304637 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */


  create  table "postgres"."public"."epinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of epinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30044,30119,30309) then rate else null end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:30.886191 [debug] [Thread-1  ]: SQL status: SELECT 3126 in 0.58 seconds
17:45:30.893603 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.894029 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations" rename to "epinephrine_durations__dbt_backup"
17:45:30.894929 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.898401 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.898698 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
alter table "postgres"."public"."epinephrine_durations__dbt_tmp" rename to "epinephrine_durations"
17:45:30.899533 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.902713 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:45:30.902972 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.903247 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: COMMIT
17:45:30.905891 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:30.908488 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_durations"
17:45:30.908749 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_durations"} */
drop table if exists "postgres"."public"."epinephrine_durations__dbt_backup" cascade
17:45:30.911197 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:30.914057 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.914283 [debug] [Thread-1  ]: On model.mimic.epinephrine_durations: Close
17:45:30.915162 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5460>]}
17:45:30.915717 [info ] [Thread-1  ]: 9 of 23 OK created table model public.epinephrine_durations .................... [[32mSELECT 3126[0m in 0.63s]
17:45:30.916381 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_durations
17:45:30.916812 [debug] [Thread-1  ]: Began running node model.mimic.isuprel_durations
17:45:30.917511 [info ] [Thread-1  ]: 10 of 23 START table model public.isuprel_durations ............................ [RUN]
17:45:30.918249 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.isuprel_durations"
17:45:30.918505 [debug] [Thread-1  ]: Began compiling node model.mimic.isuprel_durations
17:45:30.919031 [debug] [Thread-1  ]: Compiling model.mimic.isuprel_durations
17:45:30.920417 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.isuprel_durations"
17:45:30.921240 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.921677 [debug] [Thread-1  ]: Began executing node model.mimic.isuprel_durations
17:45:30.932321 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.isuprel_durations"
17:45:30.933278 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.933502 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: BEGIN
17:45:30.933664 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:30.939044 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:30.939293 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.939473 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */


  create  table "postgres"."public"."isuprel_durations__dbt_tmp"
  as (
    -- This query extracts durations of isuprel administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30046 then 1 else 0 end) as vaso -- Isuprel

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30046 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30046 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30046 then rate else null end) as vaso_rate
    , max(case when itemid = 30046 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30046 -- Isuprel
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 227692 -- Isuprel
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:30.950147 [debug] [Thread-1  ]: SQL status: SELECT 26 in 0.01 seconds
17:45:30.953903 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.954091 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations" rename to "isuprel_durations__dbt_backup"
17:45:30.954877 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.958438 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.958898 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
alter table "postgres"."public"."isuprel_durations__dbt_tmp" rename to "isuprel_durations"
17:45:30.960122 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:30.967760 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:45:30.968053 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.968231 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: COMMIT
17:45:30.969277 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:30.971398 [debug] [Thread-1  ]: Using postgres connection "model.mimic.isuprel_durations"
17:45:30.971610 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.isuprel_durations"} */
drop table if exists "postgres"."public"."isuprel_durations__dbt_backup" cascade
17:45:30.973546 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:30.978306 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.978816 [debug] [Thread-1  ]: On model.mimic.isuprel_durations: Close
17:45:30.979697 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5610>]}
17:45:30.980513 [info ] [Thread-1  ]: 10 of 23 OK created table model public.isuprel_durations ....................... [[32mSELECT 26[0m in 0.06s]
17:45:30.981015 [debug] [Thread-1  ]: Finished running node model.mimic.isuprel_durations
17:45:30.981157 [debug] [Thread-1  ]: Began running node model.mimic.milrinone_durations
17:45:30.981401 [info ] [Thread-1  ]: 11 of 23 START table model public.milrinone_durations .......................... [RUN]
17:45:30.981851 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.milrinone_durations"
17:45:30.981965 [debug] [Thread-1  ]: Began compiling node model.mimic.milrinone_durations
17:45:30.982068 [debug] [Thread-1  ]: Compiling model.mimic.milrinone_durations
17:45:30.983433 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.milrinone_durations"
17:45:30.983836 [debug] [Thread-1  ]: finished collecting timing info
17:45:30.983957 [debug] [Thread-1  ]: Began executing node model.mimic.milrinone_durations
17:45:30.992592 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.milrinone_durations"
17:45:30.993930 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:30.994416 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: BEGIN
17:45:30.995144 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:31.001253 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:31.001503 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:31.001628 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */


  create  table "postgres"."public"."milrinone_durations__dbt_tmp"
  as (
    -- This query extracts durations of milrinone administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30125 then 1 else 0 end) as vaso -- milrinone

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30125 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30125 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30125 then rate else null end) as vaso_rate
    , max(case when itemid = 30125 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30125 -- milrinone
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221986 -- milrinone
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:31.749166 [debug] [Thread-1  ]: SQL status: SELECT 3600 in 0.75 seconds
17:45:31.756877 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:31.757321 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations" rename to "milrinone_durations__dbt_backup"
17:45:31.758780 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:31.764395 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:31.764600 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
alter table "postgres"."public"."milrinone_durations__dbt_tmp" rename to "milrinone_durations"
17:45:31.765323 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:31.768491 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:45:31.768685 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:31.768869 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: COMMIT
17:45:31.771785 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:31.774397 [debug] [Thread-1  ]: Using postgres connection "model.mimic.milrinone_durations"
17:45:31.774703 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.milrinone_durations"} */
drop table if exists "postgres"."public"."milrinone_durations__dbt_backup" cascade
17:45:31.776782 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:31.780154 [debug] [Thread-1  ]: finished collecting timing info
17:45:31.780385 [debug] [Thread-1  ]: On model.mimic.milrinone_durations: Close
17:45:31.781158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5700>]}
17:45:31.781664 [info ] [Thread-1  ]: 11 of 23 OK created table model public.milrinone_durations ..................... [[32mSELECT 3600[0m in 0.80s]
17:45:31.782210 [debug] [Thread-1  ]: Finished running node model.mimic.milrinone_durations
17:45:31.782602 [debug] [Thread-1  ]: Began running node model.mimic.neuroblock_dose
17:45:31.783223 [info ] [Thread-1  ]: 12 of 23 START table model public.neuroblock_dose .............................. [RUN]
17:45:31.783998 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.neuroblock_dose"
17:45:31.784239 [debug] [Thread-1  ]: Began compiling node model.mimic.neuroblock_dose
17:45:31.784486 [debug] [Thread-1  ]: Compiling model.mimic.neuroblock_dose
17:45:31.785788 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.neuroblock_dose"
17:45:31.786391 [debug] [Thread-1  ]: finished collecting timing info
17:45:31.786852 [debug] [Thread-1  ]: Began executing node model.mimic.neuroblock_dose
17:45:31.797949 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.neuroblock_dose"
17:45:31.799012 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:31.799641 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: BEGIN
17:45:31.800079 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:31.804968 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:45:31.805210 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:31.805313 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */


  create  table "postgres"."public"."neuroblock_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of neuromuscular blocking agents
-- Note: we assume that injections will be filtered for carevue as they will have starttime = stopttime.

-- Get drug administration data from CareVue and MetaVision
-- metavision is simple and only requires one temporary table

with drugmv as
(
  select
      icustay_id, orderid
    , rate as drug_rate
    , amount as drug_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid in
  (
      222062 -- Vecuronium (664 rows, 154 infusion rows)
    , 221555 -- Cisatracurium (9334 rows, 8970 infusion rows)
  )
  and statusdescription != 'Rewritten' -- only valid orders
  and rate is not null -- only continuous infusions
)
, drugcv1 as
(
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped

    -- we only include continuous infusions, therefore expect a rate
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 and amount is not null then 1
            when itemid <  40000 and rate is not null then 1
          else 0 end) as drug_null
    , max(case
            -- for "free form" entries (itemid >= 40000) rate is not available
            when itemid >= 40000 then coalesce(rate, amount)
          else rate end) as drug_rate
    , max(amount) as drug_amount
  from inputevents_cv
  where itemid in
  (
      30114 -- Cisatracurium (63994 rows)
    , 30138	-- Vecuronium	 (5160 rows)
    , 30113 -- Atracurium  (1163 rows)
    -- Below rows are less frequent ad-hoc documentation, but worth including!
    , 42174	-- nimbex cc/hr (207 rows)
    , 42385	-- Cisatracurium gtt (156 rows)
    , 41916	-- NIMBEX	inputevents_cv (136 rows)
    , 42100	-- cistatracurium	(132 rows)
    , 42045	-- nimbex mcg/kg/min (78 rows)
    , 42246 -- CISATRICARIUM CC/HR (70 rows)
    , 42291	-- NIMBEX CC/HR (48 rows)
    , 42590	-- nimbex	inputevents_cv (38 rows)
    , 42284	-- CISATRACURIUM DRIP (9 rows)
    , 45096	-- Vecuronium drip (2 rows)
  )
  group by icustay_id, charttime
  UNION
  -- add data from chartevents
  select
    icustay_id, charttime
    -- where clause below ensures all rows are instance of the drug
    , 1 as drug

    -- the 'stopped' column indicates if a drug has been disconnected
    , max(case when stopped in ('Stopped','D/C''d') then 1 else 0 end) as drug_stopped
    , max(case when valuenum <= 10 then 0 else 1 end) as drug_null

    -- educated guess!
    , max(case when valuenum <= 10 then valuenum else null end) as drug_rate
    , max(case when valuenum  > 10 then valuenum else null end) as drug_amount
  from chartevents
  where itemid in
  (
      1856 -- Vecuronium mcg/min  (8 rows)
    , 2164 -- NIMBEX MG/KG/HR  (243 rows)
    , 2548 -- nimbex mg/kg/hr  (103 rows)
    , 2285 -- nimbex mcg/kg/min  (85 rows)
    , 2290 -- nimbex mcg/kg/m  (32 rows)
    , 2670 -- nimbex  (38 rows)
    , 2546 -- CISATRACURIUMMG/KG/H  (7 rows)
    , 1098 -- cisatracurium mg/kg  (36 rows)
    , 2390 -- cisatracurium mg/hr  (15 rows)
    , 2511 -- CISATRACURIUM GTT  (4 rows)
    , 1028 -- Cisatracurium  (208 rows)
    , 1858 -- cisatracurium  (351 rows)
  )
  group by icustay_id, charttime

)
, drugcv2 as
(
  select v.*
    , sum(drug_null) over (partition by icustay_id order by charttime) as drug_partition
  from
    drugcv1 v
)
, drugcv3 as
(
  select v.*
    , first_value(drug_rate) over (partition by icustay_id, drug_partition order by charttime) as drug_prevrate_ifnull
  from
    drugcv2 v
)
, drugcv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) AS delta

    , drug
    , drug_rate
    , drug_amount
    , drug_stopped
    , drug_prevrate_ifnull

    -- We define start time here
    , case
        when drug = 0 then null

        -- if this is the first instance of the drug
        when drug_rate > 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug, drug_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes drugnum sequential
        when drug_rate = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- drug_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when drug_prevrate_ifnull = 0 and
          LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newdrug = 1
        when LAG(drug_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) = 0
          then 1

        -- If the last recorded drug was D/C'd, newdrug = 1
        when
          LAG(drug_stopped,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          )
          = 1 then 1

        when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, drug order by charttime))) > (interval '8 hours') then 1
      else null
      end as drug_start

FROM
  drugcv3
)
-- propagate start/stop flags forward in time
, drugcv5 as
(
  select v.*
    , SUM(drug_start) OVER (partition by icustay_id, drug order by charttime) as drug_first
FROM
  drugcv4 v
)
, drugcv6 as
(
  select v.*
    -- We define end time here
    , case
        when drug = 0
          then null

        -- If the recorded drug was D/C'd, this is an end time
        when drug_stopped = 1
          then drug_first

        -- If the rate is zero, this is the end time
        when drug_rate = 0
          then drug_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on drug
        -- in principle, this could add an extra end time for the drug
        -- however, since we later group on drug_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, drug
          order by charttime
          ) is null
          then drug_first

        else null
        end as drug_stop
    from drugcv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, drug, drug_rate, drug_amount
--     , drug_stopped
--     , drug_start
--     , drug_first
--     , drug_stop
-- from drugcv6 order by icustay_id, charttime

, drugcv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, drug_first order by charttime) as endtime
  , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
from drugcv6
where
  drug_first is not null -- bogus data
and
  drug_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, drugcv8 as
(
  select
    icustay_id
    , starttime, endtime
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv7
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, drugcv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(drug_rate) OVER (partition by icustay_id order by starttime, endtime) = drug_rate
        THEN 0
      else 1
    end as drug_groups
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv8
  where endtime is not null
  and drug_rate > 0
  and starttime != endtime
)
, drugcv10 as
(
  select
    icustay_id
    , starttime, endtime
    , drug_groups
    , SUM(drug_groups) OVER (partition by icustay_id order by starttime, endtime) as drug_groups_sum
    , drug, drug_rate, drug_amount, drug_stop, drug_start, drug_first
  from drugcv9
)
, drugcv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , drug_groups_sum
  , drug_rate
  , sum(drug_amount) as drug_amount
  from drugcv10
  group by icustay_id, drug_groups_sum, drug_rate
)
-- now assign this data to every hour of the patient's stay
-- drug_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugcv
UNION
SELECT icustay_id
  , starttime, endtime
  , drug_rate, drug_amount
from drugmv
order by icustay_id, starttime
  );
17:45:32.372799 [debug] [Thread-1  ]: SQL status: SELECT 9704 in 0.57 seconds
17:45:32.379802 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:32.380070 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose" rename to "neuroblock_dose__dbt_backup"
17:45:32.380920 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:32.385959 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:32.386155 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
alter table "postgres"."public"."neuroblock_dose__dbt_tmp" rename to "neuroblock_dose"
17:45:32.386874 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:32.389631 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:45:32.389814 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:32.389930 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: COMMIT
17:45:32.392253 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:32.394458 [debug] [Thread-1  ]: Using postgres connection "model.mimic.neuroblock_dose"
17:45:32.394775 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.neuroblock_dose"} */
drop table if exists "postgres"."public"."neuroblock_dose__dbt_backup" cascade
17:45:32.396624 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:32.400051 [debug] [Thread-1  ]: finished collecting timing info
17:45:32.400281 [debug] [Thread-1  ]: On model.mimic.neuroblock_dose: Close
17:45:32.401062 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5910>]}
17:45:32.401551 [info ] [Thread-1  ]: 12 of 23 OK created table model public.neuroblock_dose ......................... [[32mSELECT 9704[0m in 0.62s]
17:45:32.402075 [debug] [Thread-1  ]: Finished running node model.mimic.neuroblock_dose
17:45:32.402341 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_durations
17:45:32.402987 [info ] [Thread-1  ]: 13 of 23 START table model public.norepinephrine_durations ..................... [RUN]
17:45:32.403797 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_durations"
17:45:32.404038 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_durations
17:45:32.404296 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_durations
17:45:32.405600 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_durations"
17:45:32.406153 [debug] [Thread-1  ]: finished collecting timing info
17:45:32.406406 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_durations
17:45:32.415293 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_durations"
17:45:32.415884 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:32.416097 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: BEGIN
17:45:32.416271 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:32.424533 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:32.425170 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:32.425566 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */


  create  table "postgres"."public"."norepinephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of norepinephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30047,30120) then rate else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30047,30120) -- norepinephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the carevue data before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime

, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:35.691480 [debug] [Thread-1  ]: SQL status: SELECT 23188 in 3.27 seconds
17:45:35.697087 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:35.697297 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations" rename to "norepinephrine_durations__dbt_backup"
17:45:35.698062 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:35.701583 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:35.701793 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
alter table "postgres"."public"."norepinephrine_durations__dbt_tmp" rename to "norepinephrine_durations"
17:45:35.702497 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:35.705825 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:45:35.706070 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:35.706185 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: COMMIT
17:45:35.710969 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:35.713427 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_durations"
17:45:35.713614 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_durations"} */
drop table if exists "postgres"."public"."norepinephrine_durations__dbt_backup" cascade
17:45:35.715930 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:35.718915 [debug] [Thread-1  ]: finished collecting timing info
17:45:35.719168 [debug] [Thread-1  ]: On model.mimic.norepinephrine_durations: Close
17:45:35.719922 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde59a0>]}
17:45:35.720402 [info ] [Thread-1  ]: 13 of 23 OK created table model public.norepinephrine_durations ................ [[32mSELECT 23188[0m in 3.32s]
17:45:35.720854 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_durations
17:45:35.721089 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_dose
17:45:35.721858 [info ] [Thread-1  ]: 14 of 23 START table model public.phenylephrine_dose ........................... [RUN]
17:45:35.722664 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_dose"
17:45:35.723008 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_dose
17:45:35.723275 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_dose
17:45:35.724656 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_dose"
17:45:35.725320 [debug] [Thread-1  ]: finished collecting timing info
17:45:35.725700 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_dose
17:45:35.737526 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_dose"
17:45:35.738169 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:35.738380 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: BEGIN
17:45:35.738665 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:35.745411 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:35.745648 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:35.745847 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */


  create  table "postgres"."public"."phenylephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of phenylephrine administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in (30127,30128) -- phenylephrine
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:38.753931 [debug] [Thread-1  ]: SQL status: SELECT 186281 in 3.01 seconds
17:45:38.760280 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:38.760482 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose" rename to "phenylephrine_dose__dbt_backup"
17:45:38.761416 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:38.765882 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:38.766075 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
alter table "postgres"."public"."phenylephrine_dose__dbt_tmp" rename to "phenylephrine_dose"
17:45:38.766951 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:38.770222 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:45:38.770424 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:38.770648 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: COMMIT
17:45:38.783064 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:45:38.785161 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_dose"
17:45:38.785430 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_dose"} */
drop table if exists "postgres"."public"."phenylephrine_dose__dbt_backup" cascade
17:45:38.788402 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:38.791390 [debug] [Thread-1  ]: finished collecting timing info
17:45:38.791623 [debug] [Thread-1  ]: On model.mimic.phenylephrine_dose: Close
17:45:38.792429 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a4dd460>]}
17:45:38.792904 [info ] [Thread-1  ]: 14 of 23 OK created table model public.phenylephrine_dose ...................... [[32mSELECT 186281[0m in 3.07s]
17:45:38.793435 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_dose
17:45:38.793798 [debug] [Thread-1  ]: Began running node model.mimic.phenylephrine_durations
17:45:38.794356 [info ] [Thread-1  ]: 15 of 23 START table model public.phenylephrine_durations ...................... [RUN]
17:45:38.795217 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.phenylephrine_durations"
17:45:38.795469 [debug] [Thread-1  ]: Began compiling node model.mimic.phenylephrine_durations
17:45:38.795734 [debug] [Thread-1  ]: Compiling model.mimic.phenylephrine_durations
17:45:38.796994 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.phenylephrine_durations"
17:45:38.797667 [debug] [Thread-1  ]: finished collecting timing info
17:45:38.797912 [debug] [Thread-1  ]: Began executing node model.mimic.phenylephrine_durations
17:45:38.812060 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.phenylephrine_durations"
17:45:38.812848 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:38.813127 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: BEGIN
17:45:38.813271 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:38.818129 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:45:38.818385 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:38.818750 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */


  create  table "postgres"."public"."phenylephrine_durations__dbt_tmp"
  as (
    -- This query extracts durations of phenylephrine administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30127,30128) then 1 else 0 end) as vaso -- phenylephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30127,30128) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30127,30128) and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid in (30127,30128) then rate else null end) as vaso_rate
    , max(case when itemid in (30127,30128) then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid in
  (
        30127,30128 -- phenylephrine
  )
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 221749 -- phenylephrine
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:42.331666 [debug] [Thread-1  ]: SQL status: SELECT 33141 in 3.51 seconds
17:45:42.339678 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:42.340102 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations" rename to "phenylephrine_durations__dbt_backup"
17:45:42.341546 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:42.345743 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:42.345934 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
alter table "postgres"."public"."phenylephrine_durations__dbt_tmp" rename to "phenylephrine_durations"
17:45:42.346687 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:42.349687 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:45:42.349903 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:42.350171 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: COMMIT
17:45:42.362208 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:45:42.364194 [debug] [Thread-1  ]: Using postgres connection "model.mimic.phenylephrine_durations"
17:45:42.364387 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.phenylephrine_durations"} */
drop table if exists "postgres"."public"."phenylephrine_durations__dbt_backup" cascade
17:45:42.366843 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:42.369624 [debug] [Thread-1  ]: finished collecting timing info
17:45:42.369854 [debug] [Thread-1  ]: On model.mimic.phenylephrine_durations: Close
17:45:42.370627 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5c40>]}
17:45:42.371118 [info ] [Thread-1  ]: 15 of 23 OK created table model public.phenylephrine_durations ................. [[32mSELECT 33141[0m in 3.58s]
17:45:42.371656 [debug] [Thread-1  ]: Finished running node model.mimic.phenylephrine_durations
17:45:42.372070 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_dose
17:45:42.372753 [info ] [Thread-1  ]: 16 of 23 START table model public.vasopressin_dose ............................. [RUN]
17:45:42.373678 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_dose"
17:45:42.373964 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_dose
17:45:42.374340 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_dose
17:45:42.375974 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_dose"
17:45:42.377044 [debug] [Thread-1  ]: finished collecting timing info
17:45:42.377460 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_dose
17:45:42.390907 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_dose"
17:45:42.391647 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:42.391870 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: BEGIN
17:45:42.392063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:42.397349 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:42.397582 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:42.397882 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */


  create  table "postgres"."public"."vasopressin_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of vasopressin administration

-- Get drug administration data from CareVue first
with vasocv1 as
(
    select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    -- , CASE WHEN valueuom = 'units/min' THEN rate*60.0 ELSE rate END as vaso_rate
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:44.055806 [debug] [Thread-1  ]: SQL status: SELECT 10537 in 1.66 seconds
17:45:44.062338 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:44.062835 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose" rename to "vasopressin_dose__dbt_backup"
17:45:44.063818 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:44.067441 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:44.067650 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
alter table "postgres"."public"."vasopressin_dose__dbt_tmp" rename to "vasopressin_dose"
17:45:44.068355 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:44.071316 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:45:44.071527 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:44.071725 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: COMMIT
17:45:44.075225 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:44.078520 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_dose"
17:45:44.079008 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_dose"} */
drop table if exists "postgres"."public"."vasopressin_dose__dbt_backup" cascade
17:45:44.082389 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:44.085016 [debug] [Thread-1  ]: finished collecting timing info
17:45:44.085231 [debug] [Thread-1  ]: On model.mimic.vasopressin_dose: Close
17:45:44.085998 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5d90>]}
17:45:44.086514 [info ] [Thread-1  ]: 16 of 23 OK created table model public.vasopressin_dose ........................ [[32mSELECT 10537[0m in 1.71s]
17:45:44.087139 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_dose
17:45:44.087469 [debug] [Thread-1  ]: Began running node model.mimic.vasopressin_durations
17:45:44.088169 [info ] [Thread-1  ]: 17 of 23 START table model public.vasopressin_durations ........................ [RUN]
17:45:44.089008 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressin_durations"
17:45:44.089350 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressin_durations
17:45:44.089757 [debug] [Thread-1  ]: Compiling model.mimic.vasopressin_durations
17:45:44.091204 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressin_durations"
17:45:44.091906 [debug] [Thread-1  ]: finished collecting timing info
17:45:44.092246 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressin_durations
17:45:44.106443 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressin_durations"
17:45:44.107624 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:44.108298 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: BEGIN
17:45:44.108662 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:44.113459 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:45:44.113697 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:44.113800 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */


  create  table "postgres"."public"."vasopressin_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressin administration
-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    icustay_id, charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid = 30051 then 1 else 0 end) as vaso -- vasopressin

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid = 30051 and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid = 30051 and rate is not null then 1 else 0 end) as vaso_null
    , max(case when itemid = 30051 then rate else null end) as vaso_rate
    , max(case when itemid = 30051 then amount else null end) as vaso_amount

  FROM inputevents_cv
  where itemid = 30051 -- vasopressin
  group by icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)

-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  FROM inputevents_mv
  where itemid = 222315 -- vasopressin
  and statusdescription != 'Rewritten' -- only valid orders
  group by icustay_id, linkorderid
)

select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv

order by icustay_id, vasonum
  );
17:45:45.868722 [debug] [Thread-1  ]: SQL status: SELECT 4190 in 1.75 seconds
17:45:45.875314 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:45.875526 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations" rename to "vasopressin_durations__dbt_backup"
17:45:45.876247 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:45.880236 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:45.880453 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
alter table "postgres"."public"."vasopressin_durations__dbt_tmp" rename to "vasopressin_durations"
17:45:45.881140 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:45.884381 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:45:45.884581 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:45.884805 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: COMMIT
17:45:45.894363 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:45:45.896916 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressin_durations"
17:45:45.897171 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressin_durations"} */
drop table if exists "postgres"."public"."vasopressin_durations__dbt_backup" cascade
17:45:45.905852 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:45:45.909178 [debug] [Thread-1  ]: finished collecting timing info
17:45:45.909413 [debug] [Thread-1  ]: On model.mimic.vasopressin_durations: Close
17:45:45.910176 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde5ee0>]}
17:45:45.910690 [info ] [Thread-1  ]: 17 of 23 OK created table model public.vasopressin_durations ................... [[32mSELECT 4190[0m in 1.82s]
17:45:45.911295 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressin_durations
17:45:45.911648 [debug] [Thread-1  ]: Began running node model.mimic.vasopressor_durations
17:45:45.912327 [info ] [Thread-1  ]: 18 of 23 START table model public.vasopressor_durations ........................ [RUN]
17:45:45.913258 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.vasopressor_durations"
17:45:45.913616 [debug] [Thread-1  ]: Began compiling node model.mimic.vasopressor_durations
17:45:45.913873 [debug] [Thread-1  ]: Compiling model.mimic.vasopressor_durations
17:45:45.915182 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.vasopressor_durations"
17:45:45.915820 [debug] [Thread-1  ]: finished collecting timing info
17:45:45.916156 [debug] [Thread-1  ]: Began executing node model.mimic.vasopressor_durations
17:45:45.926460 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.vasopressor_durations"
17:45:45.927330 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:45.927613 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: BEGIN
17:45:45.927816 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:45.933722 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:45.934390 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:45.934843 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */


  create  table "postgres"."public"."vasopressor_durations__dbt_tmp"
  as (
    -- This query extracts durations of vasopressor administration
-- It groups together any administration of the below list of drugs:
--  norepinephrine - 30047,30120,221906
--  epinephrine - 30044,30119,30309,221289
--  phenylephrine - 30127,30128,221749
--  vasopressin - 30051,222315 (42273, 42802 also for 2 patients)
--  dopamine - 30043,30307,221662
--  dobutamine - 30042,30306,221653
--  milrinone - 30125,221986

-- Consecutive administrations are numbered 1, 2, ...
-- Total time on the drug can be calculated from this table
-- by grouping using ICUSTAY_ID

-- select only the ITEMIDs from the inputevents_cv table related to vasopressors
with io_cv as
(
  select
    icustay_id, charttime, itemid, stopped
    -- ITEMIDs (42273, 42802) accidentally store rate in amount column
    , case
        when itemid in (42273, 42802)
          then amount
        else rate
      end as rate
    , case
        when itemid in (42273, 42802)
          then rate
        else amount
      end as amount
  FROM inputevents_cv
  where itemid in
  (
    30047,30120,30044,30119,30309,30127
  , 30128,30051,30043,30307,30042,30306,30125
  , 42273, 42802
  )
)
-- select only the ITEMIDs from the inputevents_mv table related to vasopressors
, io_mv as
(
  select
    icustay_id, linkorderid, starttime, endtime
  FROM inputevents_mv io
  -- Subselect the vasopressor ITEMIDs
  where itemid in
  (
  221906,221289,221749,222315,221662,221653,221986
  )
  and statusdescription != 'Rewritten' -- only valid orders
)
, vasocv1 as
(
  select
    icustay_id, charttime, itemid
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , 1 as vaso

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when rate is not null then 1 else 0 end) as vaso_null
    , max(rate) as vaso_rate
    , max(amount) as vaso_amount

  from io_cv
  group by icustay_id, charttime, itemid
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id, itemid order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, itemid, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    , itemid
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, itemid, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, itemid, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , case when vaso_stopped = 1 then 'Y' else '' end as stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by charttime


, vasocv as
(
-- below groups together vasopressor administrations into groups
select
  icustay_id
  , itemid
  -- the first non-null rate is considered the starttime
  , min(case when vaso_rate is not null then charttime else null end) as starttime
  -- the *first* time the first/last flags agree is the stop time for this duration
  , min(case when vaso_first = vaso_stop then charttime else null end) as endtime
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
group by icustay_id, itemid, vaso_first
having -- ensure start time is not the same as end time
 min(charttime) != min(case when vaso_first = vaso_stop then charttime else null end)
and
  max(vaso_rate) > 0 -- if the rate was always 0 or null, we consider it not a real drug delivery
)
-- we do not group by ITEMID in below query
-- this is because we want to collapse all vasopressors together
, vasocv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasocv s1
INNER JOIN vasocv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasocv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasocv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
-- now we extract the associated data for metavision patients
-- do not need to group by itemid because we group by linkorderid
, vasomv as
(
  select
    icustay_id, linkorderid
    , min(starttime) as starttime, max(endtime) as endtime
  from io_mv
  group by icustay_id, linkorderid
)
, vasomv_grp as
(
SELECT
  s1.icustay_id,
  s1.starttime,
  MIN(t1.endtime) AS endtime
FROM vasomv s1
INNER JOIN vasomv t1
  ON  s1.icustay_id = t1.icustay_id
  AND s1.starttime <= t1.endtime
  AND NOT EXISTS(SELECT * FROM vasomv t2
                 WHERE t1.icustay_id = t2.icustay_id
                 AND t1.endtime >= t2.starttime
                 AND t1.endtime < t2.endtime)
WHERE NOT EXISTS(SELECT * FROM vasomv s2
                 WHERE s1.icustay_id = s2.icustay_id
                 AND s1.starttime > s2.starttime
                 AND s1.starttime <= s2.endtime)
GROUP BY s1.icustay_id, s1.starttime
ORDER BY s1.icustay_id, s1.starttime
)
select
  icustay_id
  -- generate a sequential integer for convenience
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasocv_grp

UNION ALL

select
  icustay_id
  , ROW_NUMBER() over (partition by icustay_id order by starttime) as vasonum
  , starttime, endtime
  , DATETIME_DIFF(endtime, starttime, 'HOUR') AS duration_hours
  -- add durations
from
  vasomv_grp

order by icustay_id, vasonum
  );
17:45:54.609619 [debug] [Thread-1  ]: SQL status: SELECT 38832 in 8.67 seconds
17:45:54.616300 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:54.616610 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations" rename to "vasopressor_durations__dbt_backup"
17:45:54.617488 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.621362 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:54.621554 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
alter table "postgres"."public"."vasopressor_durations__dbt_tmp" rename to "vasopressor_durations"
17:45:54.622211 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.624926 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:45:54.625206 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:54.625392 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: COMMIT
17:45:54.626431 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:54.628631 [debug] [Thread-1  ]: Using postgres connection "model.mimic.vasopressor_durations"
17:45:54.628835 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.vasopressor_durations"} */
drop table if exists "postgres"."public"."vasopressor_durations__dbt_backup" cascade
17:45:54.631570 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:54.634980 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.635222 [debug] [Thread-1  ]: On model.mimic.vasopressor_durations: Close
17:45:54.636007 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a573af0>]}
17:45:54.636490 [info ] [Thread-1  ]: 18 of 23 OK created table model public.vasopressor_durations ................... [[32mSELECT 38832[0m in 8.72s]
17:45:54.637047 [debug] [Thread-1  ]: Finished running node model.mimic.vasopressor_durations
17:45:54.637398 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_classification
17:45:54.637947 [info ] [Thread-1  ]: 19 of 23 START table model public.ventilation_classification ................... [RUN]
17:45:54.638744 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_classification"
17:45:54.639083 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_classification
17:45:54.639337 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_classification
17:45:54.640622 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_classification"
17:45:54.641265 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.641579 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_classification
17:45:54.654357 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_classification"
17:45:54.655274 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.655596 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: BEGIN
17:45:54.655713 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:54.662610 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:54.662913 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.663135 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */


  create  table "postgres"."public"."ventilation_classification__dbt_tmp"
  as (
    -- Identify The presence of a mechanical ventilation using settings
select
  icustay_id, charttime
  -- case statement determining whether it is an instance of mech vent
  , max(
    case
      when itemid is null or value is null then 0 -- can't have null values
      when itemid = 720 and value != 'Other/Remarks' THEN 1  -- VentTypeRecorded
      when itemid = 223848 and value != 'Other' THEN 1
      when itemid = 223849 then 1 -- ventilator mode
      when itemid = 467 and value = 'Ventilator' THEN 1 -- O2 delivery device == ventilator
      when itemid in
        (
        445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
        , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
        , 218,436,535,444,459,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean/Neg insp force ("RespPressure")
        , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
        , 543 -- PlateauPressure
        , 5865,5866,224707,224709,224705,224706 -- APRV pressure
        , 60,437,505,506,686,220339,224700 -- PEEP
        , 3459 -- high pressure relief
        , 501,502,503,224702 -- PCV
        , 223,667,668,669,670,671,672 -- TCPCV
        , 224701 -- PSVlevel
        )
        THEN 1
      else 0
    end
    ) as MechVent
    , max(
      case
        -- initiation of oxygen therapy indicates the ventilation has ended
        when itemid = 226732 and value in
        (
          'Nasal cannula', -- 153714 observations
          'Face tent', -- 24601 observations
          'Aerosol-cool', -- 24560 observations
          'Trach mask ', -- 16435 observations
          'High flow neb', -- 10785 observations
          'Non-rebreather', -- 5182 observations
          'Venti mask ', -- 1947 observations
          'Medium conc mask ', -- 1888 observations
          'T-piece', -- 1135 observations
          'High flow nasal cannula', -- 925 observations
          'Ultrasonic neb', -- 9 observations
          'Vapomist' -- 3 observations
        ) then 1
        when itemid = 467 and value in
        (
          'Cannula', -- 278252 observations
          'Nasal Cannula', -- 248299 observations
          -- 'None', -- 95498 observations
          'Face Tent', -- 35766 observations
          'Aerosol-Cool', -- 33919 observations
          'Trach Mask', -- 32655 observations
          'Hi Flow Neb', -- 14070 observations
          'Non-Rebreather', -- 10856 observations
          'Venti Mask', -- 4279 observations
          'Medium Conc Mask', -- 2114 observations
          'Vapotherm', -- 1655 observations
          'T-Piece', -- 779 observations
          'Hood', -- 670 observations
          'Hut', -- 150 observations
          'TranstrachealCat', -- 78 observations
          'Heated Neb', -- 37 observations
          'Ultrasonic Neb' -- 2 observations
        ) then 1
      else 0
      end
    ) as OxygenTherapy
    , max(
      case when itemid is null or value is null then 0
        -- extubated indicates ventilation event has ended
        when itemid = 640 and value = 'Extubated' then 1
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as Extubated
    , max(
      case when itemid is null or value is null then 0
        when itemid = 640 and value = 'Self Extubation' then 1
      else 0
      end
      )
      as SelfExtubated
from chartevents ce
where ce.value is not null
-- exclude rows marked as error
and (ce.error != 1 or ce.error IS NULL)
and itemid in
(
    -- the below are settings used to indicate ventilation
      720, 223849 -- vent mode
    , 223848 -- vent type
    , 445, 448, 449, 450, 1340, 1486, 1600, 224687 -- minute volume
    , 639, 654, 681, 682, 683, 684,224685,224684,224686 -- tidal volume
    , 218,436,535,444,224697,224695,224696,224746,224747 -- High/Low/Peak/Mean ("RespPressure")
    , 221,1,1211,1655,2000,226873,224738,224419,224750,227187 -- Insp pressure
    , 543 -- PlateauPressure
    , 5865,5866,224707,224709,224705,224706 -- APRV pressure
    , 60,437,505,506,686,220339,224700 -- PEEP
    , 3459 -- high pressure relief
    , 501,502,503,224702 -- PCV
    , 223,667,668,669,670,671,672 -- TCPCV
    , 224701 -- PSVlevel

    -- the below are settings used to indicate extubation
    , 640 -- extubated

    -- the below indicate oxygen/NIV, i.e. the end of a mechanical vent event
    , 468 -- O2 Delivery Device#2
    , 469 -- O2 Delivery Mode
    , 470 -- O2 Flow (lpm)
    , 471 -- O2 Flow (lpm) #2
    , 227287 -- O2 Flow (additional cannula)
    , 226732 -- O2 Delivery Device(s)
    , 223834 -- O2 Flow

    -- used in both oxygen + vent calculation
    , 467 -- O2 Delivery Device
)
group by icustay_id, charttime
UNION DISTINCT
-- add in the extubation flags from procedureevents_mv
-- note that we only need the start time for the extubation
-- (extubation is always charted as ending 1 minute after it started)
select
  icustay_id, starttime as charttime
  , 0 as MechVent
  , 0 as OxygenTherapy
  , 1 as Extubated
  , case when itemid = 225468 then 1 else 0 end as SelfExtubated
from procedureevents_mv
where itemid in
(
  227194 -- "Extubation"
, 225468 -- "Unplanned Extubation (patient-initiated)"
, 225477 -- "Unplanned Extubation (non-patient initiated)"
)
  );
17:45:54.704925 [debug] [Thread-1  ]: SQL status: SELECT 8642 in 0.04 seconds
17:45:54.711105 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.711486 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification" rename to "ventilation_classification__dbt_backup"
17:45:54.712437 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.716437 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.716652 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
alter table "postgres"."public"."ventilation_classification__dbt_tmp" rename to "ventilation_classification"
17:45:54.717329 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.720461 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:45:54.720660 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.720937 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: COMMIT
17:45:54.722850 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:54.725077 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_classification"
17:45:54.725271 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_classification"} */
drop table if exists "postgres"."public"."ventilation_classification__dbt_backup" cascade
17:45:54.727357 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:54.730032 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.730316 [debug] [Thread-1  ]: On model.mimic.ventilation_classification: Close
17:45:54.731072 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde81f0>]}
17:45:54.731664 [info ] [Thread-1  ]: 19 of 23 OK created table model public.ventilation_classification .............. [[32mSELECT 8642[0m in 0.09s]
17:45:54.732311 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_classification
17:45:54.732820 [debug] [Thread-1  ]: Began running node model.mimic.weight_durations
17:45:54.733697 [info ] [Thread-1  ]: 20 of 23 START table model public.weight_durations ............................. [RUN]
17:45:54.734340 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.weight_durations"
17:45:54.734886 [debug] [Thread-1  ]: Began compiling node model.mimic.weight_durations
17:45:54.735145 [debug] [Thread-1  ]: Compiling model.mimic.weight_durations
17:45:54.741181 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.weight_durations"
17:45:54.741848 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.742115 [debug] [Thread-1  ]: Began executing node model.mimic.weight_durations
17:45:54.753717 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.weight_durations"
17:45:54.754294 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.754650 [debug] [Thread-1  ]: On model.mimic.weight_durations: BEGIN
17:45:54.754874 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:54.761457 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:54.761757 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.761875 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */


  create  table "postgres"."public"."weight_durations__dbt_tmp"
  as (
    -- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime

-- This query extracts weights for adult ICU patients with start/stop times
-- if an admission weight is given, then this is assigned from intime to outtime
WITH wt_neonate AS
( 
    SELECT c.icustay_id, c.charttime
    , MAX(CASE WHEN c.itemid = 3580 THEN c.valuenum END) as wt_kg
    , MAX(CASE WHEN c.itemid = 3581 THEN c.valuenum END) as wt_lb
    , MAX(CASE WHEN c.itemid = 3582 THEN c.valuenum END) as wt_oz
    FROM chartevents c
    WHERE c.itemid in (3580, 3581, 3582)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
    -- wt_oz/wt_lb/wt_kg are only 0 erroneously, so drop these rows
    AND c.valuenum > 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, birth_wt AS
(
    SELECT c.icustay_id, c.charttime
    , MAX(
      CASE
      WHEN c.itemid = 4183 THEN
        -- clean free-text birth weight data
        CASE
          -- ignore value if there are any non-numeric characters
          WHEN REGEXP_CONTAINS(c.value, '[^0-9\\.]') THEN NULL 
          -- convert grams to kd
          WHEN CAST(c.value AS NUMERIC) > 100 THEN CAST(c.value AS NUMERIC)/1000
          -- keep kg as is, filtering bad values (largest baby ever born was conveniently 9.98kg)
          WHEN CAST(c.value AS NUMERIC) < 10 THEN CAST(c.value AS NUMERIC)
          -- ignore other values (those between 10-100) - junk data
        ELSE NULL END
      -- itemid 3723 happily has all numeric data - also doesn't store any grams data
      WHEN c.itemid = 3723 AND c.valuenum < 10 THEN c.valuenum
      ELSE NULL END) as wt_kg
    FROM chartevents c
    WHERE c.itemid in (3723, 4183)
    AND c.icustay_id IS NOT NULL
    AND COALESCE(c.error, 0) = 0
  -- a separate query was run to manually verify only 1 value exists per
  -- icustay_id/charttime/itemid grouping
  -- therefore, we can use max() across itemid to collapse these values to 1 row per group
    GROUP BY c.icustay_id, c.charttime
)
, wt_stg as
(
    SELECT
        c.icustay_id
      , c.charttime
      , case when c.itemid in (762,226512) then 'admit'
          else 'daily' end as weight_type
      -- TODO: eliminate obvious outliers if there is a reasonable weight
      , c.valuenum as weight
    FROM chartevents c
    WHERE c.valuenum IS NOT NULL
      AND c.itemid in
      (
          762,226512 -- Admit Wt
        , 763,224639 -- Daily Weight
      )
      AND c.icustay_id IS NOT NULL
      AND c.valuenum > 0
      -- exclude rows marked as error
      AND COALESCE(c.error, 0) = 0
    UNION ALL
    SELECT
        n.icustay_id
      , n.charttime
      , 'daily' AS weight_type
      , CASE
          WHEN wt_kg IS NOT NULL THEN wt_kg
          WHEN wt_lb IS NOT NULL THEN wt_lb*0.45359237 + wt_oz*0.0283495231
        ELSE NULL END AS weight
    FROM wt_neonate n
    UNION ALL
    SELECT
        b.icustay_id
      , b.charttime
      -- birth weight of neonates is treated as admission weight
      , 'admit' AS weight_type
      , wt_kg as weight
    FROM birth_wt b
)
-- get more weights from echo - completes data for ~2500 patients
-- we only use echo data if there is *no* charted data
-- we impute the median echo weight for their entire ICU stay
, echo as
(
  select
    ie.icustay_id
    , ec.charttime
    , 'echo' AS weight_type
    , 0.453592*ec.weight as weight
  from icustays ie
  inner join "postgres"."public"."echo_data" ec
    on ie.hadm_id = ec.hadm_id
  where ec.weight is not null
  and ie.icustay_id not in (select distinct icustay_id from wt_stg)
)
, wt_stg0 AS
(
  SELECT icustay_id, charttime, weight_type, weight
  FROM wt_stg
  UNION ALL
  SELECT icustay_id, charttime, weight_type, weight
  FROM echo
)
-- assign ascending row number
, wt_stg1 as
(
  select
      icustay_id
    , charttime
    , weight_type
    , weight
    , ROW_NUMBER() OVER (partition by icustay_id, weight_type order by charttime) as rn
  from wt_stg0
  WHERE weight IS NOT NULL
)
-- change charttime to intime for the first admission weight recorded
, wt_stg2 AS
(
  SELECT 
      wt_stg1.icustay_id
    , ie.intime, ie.outtime
    , case when wt_stg1.weight_type = 'admit' and wt_stg1.rn = 1
        then DATETIME_SUB(ie.intime, INTERVAL '2' HOUR)
      else wt_stg1.charttime end as starttime
    , wt_stg1.weight
  from wt_stg1
  INNER JOIN icustays ie
    on ie.icustay_id = wt_stg1.icustay_id
)
, wt_stg3 as
(
  select
    icustay_id
    , intime, outtime
    , starttime
    , coalesce(
        LEAD(starttime) OVER (PARTITION BY icustay_id ORDER BY starttime),
        DATETIME_ADD(GREATEST(outtime, starttime), INTERVAL '2' HOUR)
      ) as endtime
    , weight
  from wt_stg2
)
-- this table is the start/stop times from admit/daily weight in charted data
, wt1 as
(
  select
      icustay_id
    , starttime
    , coalesce(endtime,
      LEAD(starttime) OVER (partition by icustay_id order by starttime),
      -- impute ICU discharge as the end of the final weight measurement
      -- plus a 2 hour "fuzziness" window
      DATETIME_ADD(outtime, INTERVAL '2' HOUR)
    ) as endtime
    , weight
  from wt_stg3
)
-- if the intime for the patient is < the first charted daily weight
-- then we will have a "gap" at the start of their stay
-- to prevent this, we look for these gaps and backfill the first weight
-- this adds (153255-149657)=3598 rows, meaning this fix helps for up to 3598 icustay_id
, wt_fix as
(
  select ie.icustay_id
    -- we add a 2 hour "fuzziness" window
    , DATETIME_SUB(ie.intime, INTERVAL '2' HOUR) as starttime
    , wt.starttime as endtime
    , wt.weight
  from icustays ie
  inner join
  -- the below subquery returns one row for each unique icustay_id
  -- the row contains: the first starttime and the corresponding weight
  (
    SELECT wt1.icustay_id, wt1.starttime, wt1.weight
    , ROW_NUMBER() OVER (PARTITION BY wt1.icustay_id ORDER BY wt1.starttime) as rn
    FROM wt1
  ) wt
    ON  ie.icustay_id = wt.icustay_id
    AND wt.rn = 1
    and ie.intime < wt.starttime
)
-- add the backfill rows to the main weight table
select
    wt1.icustay_id
  , wt1.starttime
  , wt1.endtime
  , wt1.weight
from wt1
UNION ALL
SELECT
    wt_fix.icustay_id
  , wt_fix.starttime
  , wt_fix.endtime
  , wt_fix.weight
from wt_fix
  );
17:45:54.768486 [debug] [Thread-1  ]: SQL status: SELECT 15 in 0.01 seconds
17:45:54.772152 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.772425 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations" rename to "weight_durations__dbt_backup"
17:45:54.773120 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.781610 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.781814 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
alter table "postgres"."public"."weight_durations__dbt_tmp" rename to "weight_durations"
17:45:54.782407 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.785225 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:45:54.785402 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.785620 [debug] [Thread-1  ]: On model.mimic.weight_durations: COMMIT
17:45:54.786720 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:54.788564 [debug] [Thread-1  ]: Using postgres connection "model.mimic.weight_durations"
17:45:54.788743 [debug] [Thread-1  ]: On model.mimic.weight_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.weight_durations"} */
drop table if exists "postgres"."public"."weight_durations__dbt_backup" cascade
17:45:54.792665 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:54.796824 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.797327 [debug] [Thread-1  ]: On model.mimic.weight_durations: Close
17:45:54.798746 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a47cdf0>]}
17:45:54.799419 [info ] [Thread-1  ]: 20 of 23 OK created table model public.weight_durations ........................ [[32mSELECT 15[0m in 0.06s]
17:45:54.800060 [debug] [Thread-1  ]: Finished running node model.mimic.weight_durations
17:45:54.800648 [debug] [Thread-1  ]: Began running node model.mimic.ventilation_durations
17:45:54.801149 [info ] [Thread-1  ]: 21 of 23 START table model public.ventilation_durations ........................ [RUN]
17:45:54.801962 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.ventilation_durations"
17:45:54.802166 [debug] [Thread-1  ]: Began compiling node model.mimic.ventilation_durations
17:45:54.802284 [debug] [Thread-1  ]: Compiling model.mimic.ventilation_durations
17:45:54.804789 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.ventilation_durations"
17:45:54.805516 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.805815 [debug] [Thread-1  ]: Began executing node model.mimic.ventilation_durations
17:45:54.817803 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.ventilation_durations"
17:45:54.818642 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.819245 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: BEGIN
17:45:54.819399 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:54.827111 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:45:54.827375 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.827482 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */


  create  table "postgres"."public"."ventilation_durations__dbt_tmp"
  as (
    -- This query extracts the duration of mechanical ventilation
-- The main goal of the query is to aggregate sequential ventilator settings
-- into single mechanical ventilation "events". The start and end time of these
-- events can then be used for various purposes: calculating the total duration
-- of mechanical ventilation, cross-checking values (e.g. PaO2:FiO2 on vent), etc

-- The query's logic is roughly:
--    1) The presence of a mechanical ventilation setting starts a new ventilation event
--    2) Any instance of a setting in the next 8 hours continues the event
--    3) Certain elements end the current ventilation event
--        a) documented extubation ends the current ventilation
--        b) initiation of non-invasive vent and/or oxygen ends the current vent

-- See the ventilation_classification.sql query for step 1 of the above.
-- This query has the logic for converting events into durations.
with vd0 as
(
  select
    icustay_id
    -- this carries over the previous charttime which had a mechanical ventilation event
    , case
        when MechVent=1 then
          LAG(CHARTTIME, 1) OVER (partition by icustay_id, MechVent order by charttime)
        else null
      end as charttime_lag
    , charttime
    , MechVent
    , OxygenTherapy
    , Extubated
    , SelfExtubated
  from "postgres"."public"."ventilation_classification"
)
, vd1 as
(
  select
      icustay_id
      , charttime_lag
      , charttime
      , MechVent
      , OxygenTherapy
      , Extubated
      , SelfExtubated

      -- if this is a mechanical ventilation event, we calculate the time since the last event
      , case
          -- if the current observation indicates mechanical ventilation is present
          -- calculate the time since the last vent event
          when MechVent=1 then
            DATETIME_DIFF(CHARTTIME, charttime_lag, 'MINUTE')/60
          else null
        end as ventduration

      , LAG(Extubated,1)
      OVER
      (
      partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
      order by charttime
      ) as ExtubatedLag

      -- now we determine if the current mech vent event is a "new", i.e. they've just been intubated
      , case
        -- if there is an extubation flag, we mark any subsequent ventilation as a new ventilation event
          --when Extubated = 1 then 0 -- extubation is *not* a new ventilation event, the *subsequent* row is
          when
            LAG(Extubated,1)
            OVER
            (
            partition by icustay_id, case when MechVent=1 or Extubated=1 then 1 else 0 end
            order by charttime
            )
            = 1 then 1
          -- if patient has initiated oxygen therapy, and is not currently vented, start a newvent
          when MechVent = 0 and OxygenTherapy = 1 then 1
            -- if there is less than 8 hours between vent settings, we do not treat this as a new ventilation event
          when CHARTTIME > DATETIME_ADD(charttime_lag, INTERVAL '8' HOUR)
            then 1
        else 0
        end as newvent
  -- use the staging table with only vent settings from chart events
  FROM vd0 ventsettings
)
, vd2 as
(
  select vd1.*
  -- create a cumulative sum of the instances of new ventilation
  -- this results in a monotonic integer assigned to each instance of ventilation
  , case when MechVent=1 or Extubated = 1 then
      SUM( newvent )
      OVER ( partition by icustay_id order by charttime )
    else null end
    as ventnum
  --- now we convert CHARTTIME of ventilator settings into durations
  from vd1
)
-- create the durations for each mechanical ventilation instance
select icustay_id
  -- regenerate ventnum so it's sequential
  , ROW_NUMBER() over (partition by icustay_id order by ventnum) as ventnum
  , min(charttime) as starttime
  , max(charttime) as endtime
  , DATETIME_DIFF(max(charttime), min(charttime), 'MINUTE')/60 AS duration_hours
from vd2
group by icustay_id, vd2.ventnum
having min(charttime) != max(charttime)
-- patient had to be mechanically ventilated at least once
-- i.e. max(mechvent) should be 1
-- this excludes a frequent situation of NIV/oxygen before intub
-- in these cases, ventnum=0 and max(mechvent)=0, so they are ignored
and max(mechvent) = 1
order by icustay_id, ventnum
  );
17:45:54.866161 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.04 seconds
17:45:54.870007 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.870217 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations" rename to "ventilation_durations__dbt_backup"
17:45:54.870935 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.875701 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.875901 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
alter table "postgres"."public"."ventilation_durations__dbt_tmp" rename to "ventilation_durations"
17:45:54.876545 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:54.879885 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:45:54.880081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.880284 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: COMMIT
17:45:54.881360 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:54.883736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.ventilation_durations"
17:45:54.883938 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.ventilation_durations"} */
drop table if exists "postgres"."public"."ventilation_durations__dbt_backup" cascade
17:45:54.885885 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:54.888523 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.888751 [debug] [Thread-1  ]: On model.mimic.ventilation_durations: Close
17:45:54.889659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a566040>]}
17:45:54.890128 [info ] [Thread-1  ]: 21 of 23 OK created table model public.ventilation_durations ................... [[32mSELECT 3[0m in 0.09s]
17:45:54.890682 [debug] [Thread-1  ]: Finished running node model.mimic.ventilation_durations
17:45:54.891124 [debug] [Thread-1  ]: Began running node model.mimic.epinephrine_dose
17:45:54.891856 [info ] [Thread-1  ]: 22 of 23 START table model public.epinephrine_dose ............................. [RUN]
17:45:54.892516 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.epinephrine_dose"
17:45:54.892784 [debug] [Thread-1  ]: Began compiling node model.mimic.epinephrine_dose
17:45:54.893031 [debug] [Thread-1  ]: Compiling model.mimic.epinephrine_dose
17:45:54.896151 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.epinephrine_dose"
17:45:54.897676 [debug] [Thread-1  ]: finished collecting timing info
17:45:54.897968 [debug] [Thread-1  ]: Began executing node model.mimic.epinephrine_dose
17:45:54.907499 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.epinephrine_dose"
17:45:54.908845 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:54.909077 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: BEGIN
17:45:54.909278 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:54.914114 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:45:54.915285 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:54.915974 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */


  create  table "postgres"."public"."epinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of epinephrine administration

-- Requires the weightfirstday table

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30044,30119,30309) then 1 else 0 end) as vaso -- epinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30044,30119,30309) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

    , max(case when itemid in (30044,30119,30309) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30044 and wd.weight is null then rate / 80.0 -- super rare to be missing weight... affects 2 patients for 14 rows
            when itemid = 30044 then rate / wd.weight -- measured in mcgmin
            when itemid in (30119,30309) then rate -- measured in mcgkgmin
            else null
          end) as vaso_rate
    , max(case when itemid in (30044,30119,30309) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in
  (
        30044,30119,30309 -- epinephrine
  )
  and cv.icustay_id is not null
  group by cv.icustay_id, charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221289 -- epinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:55.515708 [debug] [Thread-1  ]: SQL status: SELECT 10562 in 0.6 seconds
17:45:55.520834 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:55.521026 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose" rename to "epinephrine_dose__dbt_backup"
17:45:55.521776 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:55.525496 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:55.525700 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
alter table "postgres"."public"."epinephrine_dose__dbt_tmp" rename to "epinephrine_dose"
17:45:55.526323 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:55.529522 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:45:55.529702 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:55.529805 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: COMMIT
17:45:55.533430 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:45:55.535798 [debug] [Thread-1  ]: Using postgres connection "model.mimic.epinephrine_dose"
17:45:55.536002 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.epinephrine_dose"} */
drop table if exists "postgres"."public"."epinephrine_dose__dbt_backup" cascade
17:45:55.537816 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:55.540545 [debug] [Thread-1  ]: finished collecting timing info
17:45:55.540847 [debug] [Thread-1  ]: On model.mimic.epinephrine_dose: Close
17:45:55.541548 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2bde8310>]}
17:45:55.541995 [info ] [Thread-1  ]: 22 of 23 OK created table model public.epinephrine_dose ........................ [[32mSELECT 10562[0m in 0.65s]
17:45:55.542495 [debug] [Thread-1  ]: Finished running node model.mimic.epinephrine_dose
17:45:55.542889 [debug] [Thread-1  ]: Began running node model.mimic.norepinephrine_dose
17:45:55.543322 [info ] [Thread-1  ]: 23 of 23 START table model public.norepinephrine_dose .......................... [RUN]
17:45:55.544362 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.norepinephrine_dose"
17:45:55.544678 [debug] [Thread-1  ]: Began compiling node model.mimic.norepinephrine_dose
17:45:55.544934 [debug] [Thread-1  ]: Compiling model.mimic.norepinephrine_dose
17:45:55.550092 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.norepinephrine_dose"
17:45:55.550910 [debug] [Thread-1  ]: finished collecting timing info
17:45:55.551606 [debug] [Thread-1  ]: Began executing node model.mimic.norepinephrine_dose
17:45:55.562430 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.norepinephrine_dose"
17:45:55.563051 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:55.563276 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: BEGIN
17:45:55.563528 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:45:55.568012 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:45:55.568256 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:55.568431 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */


  create  table "postgres"."public"."norepinephrine_dose__dbt_tmp"
  as (
    -- This query extracts dose+durations of norepinephrine administration
-- Total time on the drug can be calculated from this table by grouping using ICUSTAY_ID

-- Get drug administration data from CareVue first
with vasocv1 as
(
  select
    cv.icustay_id, cv.charttime
    -- case statement determining whether the ITEMID is an instance of vasopressor usage
    , max(case when itemid in (30047,30120) then 1 else 0 end) as vaso -- norepinephrine

    -- the 'stopped' column indicates if a vasopressor has been disconnected
    , max(case when itemid in (30047,30120) and (stopped = 'Stopped' OR stopped like 'D/C%') then 1
          else 0 end) as vaso_stopped

  -- case statement determining whether the ITEMID is an instance of vasopressor usage

    , max(case when itemid in (30047,30120) and rate is not null then 1 else 0 end) as vaso_null
    , max(case
            when itemid = 30047 and wd.weight is null then rate / 80.0 -- this is rare, only affects a total of ~400 rows
            when itemid = 30047 then rate / wd.weight -- measured in mcgmin
            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin
          else null end) as vaso_rate
    , max(case when itemid in (30047,30120) then amount else null end) as vaso_amount

  FROM inputevents_cv cv
  left join "postgres"."public"."weight_durations" wd
    on cv.icustay_id = wd.icustay_id
    and cv.charttime between wd.starttime and wd.endtime
  where itemid in (30047,30120) -- norepinephrine
  and cv.icustay_id is not null
  group by cv.icustay_id, cv.charttime
)
, vasocv2 as
(
  select v.*
    , sum(vaso_null) over (partition by icustay_id order by charttime) as vaso_partition
  from
    vasocv1 v
)
, vasocv3 as
(
  select v.*
    , first_value(vaso_rate) over (partition by icustay_id, vaso_partition order by charttime) as vaso_prevrate_ifnull
  from
    vasocv2 v
)
, vasocv4 as
(
select
    icustay_id
    , charttime
    -- , (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) AS delta

    , vaso
    , vaso_rate
    , vaso_amount
    , vaso_stopped
    , vaso_prevrate_ifnull

    -- We define start time here
    , case
        when vaso = 0 then null

        -- if this is the first instance of the vasoactive drug
        when vaso_rate > 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso, vaso_null
          order by charttime
          )
          is null
          then 1

        -- you often get a string of 0s
        -- we decide not to set these as 1, just because it makes vasonum sequential
        when vaso_rate = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- sometimes you get a string of NULL, associated with 0 volumes
        -- same reason as before, we decide not to set these as 1
        -- vaso_prevrate_ifnull is equal to the previous value *iff* the current value is null
        when vaso_prevrate_ifnull = 0 and
          LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 0
          then 0

        -- If the last recorded rate was 0, newvaso = 1
        when LAG(vaso_prevrate_ifnull,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) = 0
          then 1

        -- If the last recorded vaso was D/C'd, newvaso = 1
        when
          LAG(vaso_stopped,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          )
          = 1 then 1

        -- ** not sure if the below is needed
        --when (CHARTTIME - (LAG(CHARTTIME, 1) OVER (partition by icustay_id, vaso order by charttime))) > (interval '4 hours') then 1
      else null
      end as vaso_start

FROM
  vasocv3
)
-- propagate start/stop flags forward in time
, vasocv5 as
(
  select v.*
    , SUM(vaso_start) OVER (partition by icustay_id, vaso order by charttime) as vaso_first
FROM
  vasocv4 v
)
, vasocv6 as
(
  select v.*
    -- We define end time here
    , case
        when vaso = 0
          then null

        -- If the recorded vaso was D/C'd, this is an end time
        when vaso_stopped = 1
          then vaso_first

        -- If the rate is zero, this is the end time
        when vaso_rate = 0
          then vaso_first

        -- the last row in the table is always a potential end time
        -- this captures patients who die/are discharged while on vasopressors
        -- in principle, this could add an extra end time for the vasopressor
        -- however, since we later group on vaso_start, any extra end times are ignored
        when LEAD(CHARTTIME,1)
          OVER
          (
          partition by icustay_id, vaso
          order by charttime
          ) is null
          then vaso_first

        else null
        end as vaso_stop
    from vasocv5 v
)

-- -- if you want to look at the results of the table before grouping:
-- select
--   icustay_id, charttime, vaso, vaso_rate, vaso_amount
--     , vaso_stopped
--     , vaso_start
--     , vaso_first
--     , vaso_stop
-- from vasocv6 order by icustay_id, charttime

, vasocv7 as
(
select
  icustay_id
  , charttime as starttime
  , lead(charttime) OVER (partition by icustay_id, vaso_first order by charttime) as endtime
  , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
from vasocv6
where
  vaso_first is not null -- bogus data
and
  vaso_first != 0 -- sometimes *only* a rate of 0 appears, i.e. the drug is never actually delivered
and
  icustay_id is not null -- there are data for "floating" admissions, we don't worry about these
)
-- table of start/stop times for event
, vasocv8 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv7
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
-- collapse these start/stop times down if the rate doesn't change
, vasocv9 as
(
  select
    icustay_id
    , starttime, endtime
    , case
        when LAG(endtime) OVER (partition by icustay_id order by starttime, endtime) = starttime
        AND  LAG(vaso_rate) OVER (partition by icustay_id order by starttime, endtime) = vaso_rate
        THEN 0
      else 1
    end as vaso_groups
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv8
  where endtime is not null
  and vaso_rate > 0
  and starttime != endtime
)
, vasocv10 as
(
  select
    icustay_id
    , starttime, endtime
    , vaso_groups
    , SUM(vaso_groups) OVER (partition by icustay_id order by starttime, endtime) as vaso_groups_sum
    , vaso, vaso_rate, vaso_amount, vaso_stop, vaso_start, vaso_first
  from vasocv9
)
, vasocv as
(
  select icustay_id
  , min(starttime) as starttime
  , max(endtime) as endtime
  , vaso_groups_sum
  , vaso_rate
  , sum(vaso_amount) as vaso_amount
  from vasocv10
  group by icustay_id, vaso_groups_sum, vaso_rate
)
-- now we extract the associated data for metavision patients
, vasomv as
(
  select
    icustay_id, linkorderid
    , rate as vaso_rate
    , amount as vaso_amount
    , starttime
    , endtime
  from inputevents_mv
  where itemid = 221906 -- norepinephrine
  and statusdescription != 'Rewritten' -- only valid orders
)
-- now assign this data to every hour of the patient's stay
-- vaso_amount for carevue is not accurate
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasocv
UNION ALL
SELECT icustay_id
  , starttime, endtime
  , vaso_rate, vaso_amount
from vasomv
order by icustay_id, starttime
  );
17:45:58.572497 [debug] [Thread-1  ]: SQL status: SELECT 161449 in 3.0 seconds
17:45:58.579274 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:58.579653 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose" rename to "norepinephrine_dose__dbt_backup"
17:45:58.580792 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:58.584323 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:58.584517 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
alter table "postgres"."public"."norepinephrine_dose__dbt_tmp" rename to "norepinephrine_dose"
17:45:58.585243 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:45:58.589041 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:45:58.589241 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:58.589429 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: COMMIT
17:45:58.598061 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:45:58.601178 [debug] [Thread-1  ]: Using postgres connection "model.mimic.norepinephrine_dose"
17:45:58.601491 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.norepinephrine_dose"} */
drop table if exists "postgres"."public"."norepinephrine_dose__dbt_backup" cascade
17:45:58.605188 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:45:58.608220 [debug] [Thread-1  ]: finished collecting timing info
17:45:58.608455 [debug] [Thread-1  ]: On model.mimic.norepinephrine_dose: Close
17:45:58.609116 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f17c1509-c421-417a-b7fc-6932da5aca6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a442430>]}
17:45:58.609586 [info ] [Thread-1  ]: 23 of 23 OK created table model public.norepinephrine_dose ..................... [[32mSELECT 161449[0m in 3.07s]
17:45:58.610120 [debug] [Thread-1  ]: Finished running node model.mimic.norepinephrine_dose
17:45:58.611985 [debug] [MainThread]: Acquiring new postgres connection "master"
17:45:58.612386 [debug] [MainThread]: Using postgres connection "master"
17:45:58.612670 [debug] [MainThread]: On master: BEGIN
17:45:58.612878 [debug] [MainThread]: Opening a new connection, currently in state closed
17:45:58.622696 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:45:58.623674 [debug] [MainThread]: On master: COMMIT
17:45:58.624396 [debug] [MainThread]: Using postgres connection "master"
17:45:58.624961 [debug] [MainThread]: On master: COMMIT
17:45:58.626226 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:45:58.626859 [debug] [MainThread]: On master: Close
17:45:58.627899 [info ] [MainThread]: 
17:45:58.628303 [info ] [MainThread]: Finished running 23 table models in 33.76s.
17:45:58.628584 [debug] [MainThread]: Connection 'master' was properly closed.
17:45:58.628729 [debug] [MainThread]: Connection 'model.mimic.norepinephrine_dose' was properly closed.
17:45:58.642357 [info ] [MainThread]: 
17:45:58.643036 [info ] [MainThread]: [32mCompleted successfully[0m
17:45:58.643631 [info ] [MainThread]: 
17:45:58.643984 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
17:45:58.644421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2e697f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2a55b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2c89f040>]}
17:45:58.648368 [warn ] [MainThread]: Error sending message, disabling tracking


============================== 2022-07-16 17:46:15.092178 | dbdbe301-a847-4523-ae94-3c38d0a5bc3e ==============================
17:46:15.092205 [info ] [MainThread]: Running with dbt=1.1.1
17:46:15.093051 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/ceci/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['pivot'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
17:46:15.093264 [debug] [MainThread]: Tracking: tracking
17:46:15.099238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c371f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c372b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c372e0>]}
17:46:15.190778 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
17:46:15.191031 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
17:46:15.193251 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mimic.example
- models.mimic.diagnosis

17:46:15.199675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c37e20>]}
17:46:15.217994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c891c0>]}
17:46:15.218466 [info ] [MainThread]: Found 107 models, 0 tests, 0 snapshots, 0 analyses, 167 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
17:46:15.218915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13c604c0>]}
17:46:15.221604 [info ] [MainThread]: 
17:46:15.222296 [debug] [MainThread]: Acquiring new postgres connection "master"
17:46:15.225348 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
17:46:15.237034 [debug] [ThreadPool]: Using postgres connection "list_postgres"
17:46:15.237307 [debug] [ThreadPool]: On list_postgres: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
17:46:15.237514 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:46:15.246374 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.01 seconds
17:46:15.251981 [debug] [ThreadPool]: On list_postgres: Close
17:46:15.258619 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres_public"
17:46:15.266205 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:46:15.266569 [debug] [ThreadPool]: On list_postgres_public: BEGIN
17:46:15.266809 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:46:15.271347 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
17:46:15.271583 [debug] [ThreadPool]: Using postgres connection "list_postgres_public"
17:46:15.271753 [debug] [ThreadPool]: On list_postgres_public: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
17:46:15.276005 [debug] [ThreadPool]: SQL status: SELECT 339 in 0.0 seconds
17:46:15.285575 [debug] [ThreadPool]: On list_postgres_public: ROLLBACK
17:46:15.286129 [debug] [ThreadPool]: On list_postgres_public: Close
17:46:15.297608 [debug] [MainThread]: Using postgres connection "master"
17:46:15.297820 [debug] [MainThread]: On master: BEGIN
17:46:15.298091 [debug] [MainThread]: Opening a new connection, currently in state init
17:46:15.303530 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
17:46:15.303770 [debug] [MainThread]: Using postgres connection "master"
17:46:15.303967 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
17:46:15.313612 [debug] [MainThread]: SQL status: SELECT 0 in 0.01 seconds
17:46:15.317272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f15ae8b20>]}
17:46:15.317692 [debug] [MainThread]: On master: ROLLBACK
17:46:15.318124 [debug] [MainThread]: Using postgres connection "master"
17:46:15.318344 [debug] [MainThread]: On master: BEGIN
17:46:15.319012 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:46:15.319264 [debug] [MainThread]: On master: COMMIT
17:46:15.319465 [debug] [MainThread]: Using postgres connection "master"
17:46:15.319625 [debug] [MainThread]: On master: COMMIT
17:46:15.320008 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:46:15.320282 [debug] [MainThread]: On master: Close
17:46:15.320894 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:46:15.321246 [info ] [MainThread]: 
17:46:15.324918 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg
17:46:15.325429 [info ] [Thread-1  ]: 1 of 13 START table model public.pivoted_bg .................................... [RUN]
17:46:15.326375 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg"
17:46:15.326851 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg
17:46:15.327159 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg
17:46:15.328643 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg"
17:46:15.329383 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.329965 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg
17:46:15.366209 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg"
17:46:15.367018 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.367258 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: BEGIN
17:46:15.367525 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.372034 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:46:15.372348 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.372666 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */


  create  table "postgres"."public"."pivoted_bg__dbt_tmp"
  as (
    -- The aim of this query is to pivot entries related to blood gases and
-- chemistry values which were found in LABEVENTS

-- create a table which has fuzzy boundaries on ICU admission
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  FROM icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (cast(round((DATETIME_DIFF(i.intime, i.outtime_lag, 'hour')/2)) as integer) || 'HOUR')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (cast(round((DATETIME_DIFF(i.intime_lead, i.outtime, 'minute')/2)) as integer) || 'MINUTE')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
, pvt as
( -- begin query that extracts the data
  select le.hadm_id
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
      , case
        when itemid = 50800 then 'SPECIMEN'
        when itemid = 50801 then 'AADO2'
        when itemid = 50802 then 'BASEEXCESS'
        when itemid = 50803 then 'BICARBONATE'
        when itemid = 50804 then 'TOTALCO2'
        when itemid = 50805 then 'CARBOXYHEMOGLOBIN'
        when itemid = 50806 then 'CHLORIDE'
        when itemid = 50808 then 'CALCIUM'
        when itemid = 50809 then 'GLUCOSE'
        when itemid = 50810 then 'HEMATOCRIT'
        when itemid = 50811 then 'HEMOGLOBIN'
        when itemid = 50812 then 'INTUBATED'
        when itemid = 50813 then 'LACTATE'
        when itemid = 50814 then 'METHEMOGLOBIN'
        when itemid = 50815 then 'O2FLOW'
        when itemid = 50816 then 'FIO2'
        when itemid = 50817 then 'SO2' -- OXYGENSATURATION
        when itemid = 50818 then 'PCO2'
        when itemid = 50819 then 'PEEP'
        when itemid = 50820 then 'PH'
        when itemid = 50821 then 'PO2'
        when itemid = 50822 then 'POTASSIUM'
        when itemid = 50823 then 'REQUIREDO2'
        when itemid = 50824 then 'SODIUM'
        when itemid = 50825 then 'TEMPERATURE'
        when itemid = 50826 then 'TIDALVOLUME'
        when itemid = 50827 then 'VENTILATIONRATE'
        when itemid = 50828 then 'VENTILATOR'
        else null
        end as label
        , charttime
        , value
        -- add in some sanity checks on the values
        , case
          when valuenum <= 0 then null
          when itemid = 50810 and valuenum > 100 then null -- hematocrit
          -- ensure FiO2 is a valid number between 21-100
          -- mistakes are rare (<100 obs out of ~100,000)
          -- there are 862 obs of valuenum == 20 - some people round down!
          -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
          when itemid = 50816 and valuenum < 20 then null
          when itemid = 50816 and valuenum > 100 then null
          when itemid = 50817 and valuenum > 100 then null -- O2 sat
          when itemid = 50815 and valuenum >  70 then null -- O2 flow
          when itemid = 50821 and valuenum > 800 then null -- PO2
           -- conservative upper limit
        else valuenum
        end as valuenum
    FROM labevents le
    where le.ITEMID in
    -- blood gases
    (
      50800, 50801, 50802, 50803, 50804, 50805, 50806, 50807, 50808, 50809
      , 50810, 50811, 50812, 50813, 50814, 50815, 50816, 50817, 50818, 50819
      , 50820, 50821, 50822, 50823, 50824, 50825, 50826, 50827, 50828
      , 51545
    )
)
, grp as
(
  select pvt.hadm_id, pvt.charttime
  , max(case when label = 'SPECIMEN' then value else null end) as specimen
  , avg(case when label = 'AADO2' then valuenum else null end) as aado2
  , avg(case when label = 'BASEEXCESS' then valuenum else null end) as baseexcess
  , avg(case when label = 'BICARBONATE' then valuenum else null end) as bicarbonate
  , avg(case when label = 'TOTALCO2' then valuenum else null end) as totalco2
  , avg(case when label = 'CARBOXYHEMOGLOBIN' then valuenum else null end) as carboxyhemoglobin
  , avg(case when label = 'CHLORIDE' then valuenum else null end) as chloride
  , avg(case when label = 'CALCIUM' then valuenum else null end) as calcium
  , avg(case when label = 'GLUCOSE' then valuenum else null end) as glucose
  , avg(case when label = 'HEMATOCRIT' then valuenum else null end) as hematocrit
  , avg(case when label = 'HEMOGLOBIN' then valuenum else null end) as hemoglobin
  , avg(case when label = 'INTUBATED' then valuenum else null end) as intubated
  , avg(case when label = 'LACTATE' then valuenum else null end) as lactate
  , avg(case when label = 'METHEMOGLOBIN' then valuenum else null end) as methemoglobin
  , avg(case when label = 'O2FLOW' then valuenum else null end) as o2flow
  , avg(case when label = 'FIO2' then valuenum else null end) as fio2
  , avg(case when label = 'SO2' then valuenum else null end) as so2 -- OXYGENSATURATION
  , avg(case when label = 'PCO2' then valuenum else null end) as pco2
  , avg(case when label = 'PEEP' then valuenum else null end) as peep
  , avg(case when label = 'PH' then valuenum else null end) as ph
  , avg(case when label = 'PO2' then valuenum else null end) as po2
  , avg(case when label = 'POTASSIUM' then valuenum else null end) as potassium
  , avg(case when label = 'REQUIREDO2' then valuenum else null end) as requiredo2
  , avg(case when label = 'SODIUM' then valuenum else null end) as sodium
  , avg(case when label = 'TEMPERATURE' then valuenum else null end) as temperature
  , avg(case when label = 'TIDALVOLUME' then valuenum else null end) as tidalvolume
  , max(case when label = 'VENTILATIONRATE' then valuenum else null end) as ventilationrate
  , max(case when label = 'VENTILATOR' then valuenum else null end) as ventilator
  from pvt
  group by pvt.hadm_id, pvt.charttime
  -- remove observations if there is more than one specimen listed
  -- we do not know whether these are arterial or mixed venous, etc...
  -- happily this is a small fraction of the total number of observations
  having sum(case when label = 'SPECIMEN' then 1 else 0 end)<2
)
select
  iid.icustay_id, grp.*
from grp
inner join admissions adm
  on grp.hadm_id = adm.hadm_id
left join iid_assign iid
  on adm.subject_id = iid.subject_id
  and grp.charttime >= iid.data_start
  and grp.charttime < iid.data_end
order by grp.hadm_id, grp.charttime
  );
17:46:15.441719 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.07 seconds
17:46:15.448668 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.448887 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg" rename to "pivoted_bg__dbt_backup"
17:46:15.450729 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.454057 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.454241 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
alter table "postgres"."public"."pivoted_bg__dbt_tmp" rename to "pivoted_bg"
17:46:15.455004 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.464814 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:46:15.465100 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.465274 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: COMMIT
17:46:15.466400 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.470255 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg"
17:46:15.470450 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg"} */
drop table if exists "postgres"."public"."pivoted_bg__dbt_backup" cascade
17:46:15.472712 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.475964 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.476191 [debug] [Thread-1  ]: On model.mimic.pivoted_bg: Close
17:46:15.476909 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f11962ee0>]}
17:46:15.477437 [info ] [Thread-1  ]: 1 of 13 OK created table model public.pivoted_bg ............................... [[32mSELECT 0[0m in 0.15s]
17:46:15.478002 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg
17:46:15.478224 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_fio2
17:46:15.478859 [info ] [Thread-1  ]: 2 of 13 START table model public.pivoted_fio2 .................................. [RUN]
17:46:15.480131 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_fio2"
17:46:15.480579 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_fio2
17:46:15.480787 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_fio2
17:46:15.482169 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_fio2"
17:46:15.482826 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.483214 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_fio2
17:46:15.494252 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_fio2"
17:46:15.495388 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.495630 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: BEGIN
17:46:15.495894 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.502811 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:15.503332 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.503576 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */


  create  table "postgres"."public"."pivoted_fio2__dbt_tmp"
  as (
    with pvt as
( -- begin query that extracts the data
  select le.hadm_id
  , le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
    -- add in some sanity checks on the values
    , ROUND(MAX((case
        when valuenum <= 0 then null
        -- ensure FiO2 is a valid number between 21-100
        -- mistakes are rare (<100 obs out of ~100,000)
        -- there are 862 obs of valuenum == 20 - some people round down!
        -- rather than risk imputing garbage data for FiO2, we simply NULL invalid values
        when itemid = 50816 and valuenum < 20 then null
        when itemid = 50816 and valuenum > 100 then null
    ELSE valuenum END))::numeric, 2) AS valuenum
    FROM labevents le
    where le.ITEMID = 50816
    GROUP BY le.hadm_id, le.charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , ROUND((MAX(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ))::numeric, 2) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
select
  ie.icustay_id
  , COALESCE(pvt.charttime, fi.charttime) AS charttime
  , COALESCE(pvt.valuenum, fi.fio2_chartevents) AS fio2
from 
(
    -- one row per icustay_id/charttime
    SELECT hadm_id, charttime
    from pvt
    UNION DISTINCT
    SELECT hadm_id, charttime
    from stg_fio2
) base
INNER JOIN icustays ie
  on base.hadm_id = ie.hadm_id
  AND base.charttime >= DATETIME_SUB(ie.intime, INTERVAL '12' HOUR)
  AND base.charttime <= DATETIME_ADD(ie.outtime, INTERVAL '12' HOUR)
LEFT JOIN pvt
  ON base.hadm_id = pvt.hadm_id
  AND base.charttime = pvt.charttime
LEFT JOIN stg_fio2 fi
  ON base.hadm_id = fi.hadm_id
  AND base.charttime = fi.charttime
ORDER BY icustay_id, charttime
  );
17:46:15.512652 [debug] [Thread-1  ]: SQL status: SELECT 28 in 0.01 seconds
17:46:15.517143 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.517338 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2" rename to "pivoted_fio2__dbt_backup"
17:46:15.517773 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.523516 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.524247 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
alter table "postgres"."public"."pivoted_fio2__dbt_tmp" rename to "pivoted_fio2"
17:46:15.525769 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.531819 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:46:15.532230 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.532711 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: COMMIT
17:46:15.534011 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.536163 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_fio2"
17:46:15.536369 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_fio2"} */
drop table if exists "postgres"."public"."pivoted_fio2__dbt_backup" cascade
17:46:15.538263 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.543320 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.543818 [debug] [Thread-1  ]: On model.mimic.pivoted_fio2: Close
17:46:15.544578 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131cb610>]}
17:46:15.545060 [info ] [Thread-1  ]: 2 of 13 OK created table model public.pivoted_fio2 ............................. [[32mSELECT 28[0m in 0.06s]
17:46:15.545549 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_fio2
17:46:15.545830 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_gcs
17:46:15.546326 [info ] [Thread-1  ]: 3 of 13 START table model public.pivoted_gcs ................................... [RUN]
17:46:15.547077 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_gcs"
17:46:15.547481 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_gcs
17:46:15.547683 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_gcs
17:46:15.549227 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_gcs"
17:46:15.549839 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.550061 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_gcs
17:46:15.560014 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_gcs"
17:46:15.561498 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.561829 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: BEGIN
17:46:15.561998 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.566410 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:46:15.566817 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.567026 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */


  create  table "postgres"."public"."pivoted_gcs__dbt_tmp"
  as (
    -- This query extracts the Glasgow Coma Scale, a measure of neurological function.
-- The query has a few special rules:
--    (1) The verbal component can be set to 0 if the patient is ventilated.
--    This is corrected to 5 - the overall GCS is set to 15 in these cases.
--    (2) Often only one of three components is documented. The other components
--    are carried forward.

-- ITEMIDs used:

-- CAREVUE
--    723 as gcsverbal
--    454 as gcsmotor
--    184 as gcseyes

-- METAVISION
--    223900 GCS - Verbal Response
--    223901 GCS - Motor Response
--    220739 GCS - Eye Opening

-- The code combines the ITEMIDs into the carevue itemids, then pivots those
-- So 223900 is changed to 723, then the ITEMID 723 is pivoted to form gcsverbal

-- Note:
--  The GCS for sedated patients is defaulted to 15 in this code.
--  This is in line with how the data is meant to be collected.
--  e.g., from the SAPS II publication:
--    For sedated patients, the Glasgow Coma Score before sedation was used.
--    This was ascertained either from interviewing the physician who ordered the sedation,
--    or by reviewing the patient's medical record.

with base as
(
  select ce.icustay_id, ce.charttime
  -- pivot each value into its own column
  , max(case when ce.ITEMID in (454,223901) then ce.valuenum else null end) as gcsmotor
  , max(case
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 0
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 0
      when ce.ITEMID in (723,223900) then ce.valuenum
      else null 
    end) as gcsverbal
  , max(case when ce.ITEMID in (184,220739) then ce.valuenum else null end) as gcseyes
  -- convert the data into a number, reserving a value of 0 for ET/Trach
  , max(case
      -- endotrach/vent is assigned a value of 0, later parsed specially
      when ce.ITEMID = 723 and ce.VALUE = '1.0 ET/Trach' then 1 -- carevue
      when ce.ITEMID = 223900 and ce.VALUE = 'No Response-ETT' then 1 -- metavision
    else 0 end)
    as endotrachflag
  , ROW_NUMBER ()
          OVER (PARTITION BY ce.icustay_id ORDER BY ce.charttime ASC) as rn
  FROM chartevents ce
  -- Isolate the desired GCS variables
  where ce.ITEMID in
  (
    -- 198 -- GCS
    -- GCS components, CareVue
    184, 454, 723
    -- GCS components, Metavision
    , 223900, 223901, 220739
  )
  -- exclude rows marked as error
  AND (ce.error IS NULL OR ce.error != 1)
  group by ce.icustay_id, ce.charttime
)
, gcs_stg0 as (
  select b.*
  , b2.gcsverbal as gcsverbalprev
  , b2.gcsmotor as gcsmotorprev
  , b2.gcseyes as gcseyesprev
  -- Calculate GCS, factoring in special case when they are intubated and prev vals
  -- note that the coalesce are used to implement the following if:
  --  if current value exists, use it
  --  if previous value exists, use it
  --  otherwise, default to normal
  , case
      -- replace GCS during sedation with 15
      when b.gcsverbal = 0
        then 15
      when b.gcsverbal is null and b2.gcsverbal = 0
        then 15
      -- if previously they were intub, but they aren't now, do not use previous GCS values
      when b2.gcsverbal = 0
        then
            coalesce(b.gcsmotor,6)
          + coalesce(b.gcsverbal,5)
          + coalesce(b.gcseyes,4)
      -- otherwise, add up score normally, imputing previous value if none available at current time
      else
            coalesce(b.gcsmotor,coalesce(b2.gcsmotor,6))
          + coalesce(b.gcsverbal,coalesce(b2.gcsverbal,5))
          + coalesce(b.gcseyes,coalesce(b2.gcseyes,4))
      end as gcs

  from base b
  -- join to itself within 6 hours to get previous value
  left join base b2
    on b.icustay_id = b2.icustay_id
    and b.rn = b2.rn+1
    and b2.charttime > DATETIME_SUB(b.charttime, INTERVAL '6' HOUR)
)
-- combine components with previous within 6 hours
-- filter down to cohort which is not excluded
-- truncate charttime to the hour
, gcs_stg1 as
(
  select gs.icustay_id, gs.charttime
  , gs.gcs
  , coalesce(gcsmotor,gcsmotorprev) as gcsmotor
  , coalesce(gcsverbal,gcsverbalprev) as gcsverbal
  , coalesce(gcseyes,gcseyesprev) as gcseyes
  , case when coalesce(gcsmotor,gcsmotorprev) is null then 0 else 1 end
  + case when coalesce(gcsverbal,gcsverbalprev) is null then 0 else 1 end
  + case when coalesce(gcseyes,gcseyesprev) is null then 0 else 1 end
    as components_measured
  , endotrachflag
  from gcs_stg0 gs
)
-- priority is:
--  (i) complete data, (ii) non-sedated GCS, (iii) lowest GCS, (iv) charttime
, gcs_priority as
(
  select icustay_id
    , charttime
    , gcs
    , gcsmotor
    , gcsverbal
    , gcseyes
    , endotrachflag
    , ROW_NUMBER() over
      (
        PARTITION BY icustay_id, charttime
        ORDER BY components_measured DESC, endotrachflag, gcs, charttime DESC
      ) as rn
  from gcs_stg1
)
select icustay_id
  , charttime
  , gcs
  , gcsmotor
  , gcsverbal
  , gcseyes
  , endotrachflag
from gcs_priority gs
where rn = 1
ORDER BY icustay_id, charttime
  );
17:46:15.571840 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.0 seconds
17:46:15.579736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.580009 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs" rename to "pivoted_gcs__dbt_backup"
17:46:15.580751 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.585060 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.585270 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
alter table "postgres"."public"."pivoted_gcs__dbt_tmp" rename to "pivoted_gcs"
17:46:15.585906 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.589012 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:46:15.589241 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.589415 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: COMMIT
17:46:15.591235 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.594812 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_gcs"
17:46:15.595040 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_gcs"} */
drop table if exists "postgres"."public"."pivoted_gcs__dbt_backup" cascade
17:46:15.596898 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.599779 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.600104 [debug] [Thread-1  ]: On model.mimic.pivoted_gcs: Close
17:46:15.600799 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131c48b0>]}
17:46:15.601232 [info ] [Thread-1  ]: 3 of 13 OK created table model public.pivoted_gcs .............................. [[32mSELECT 0[0m in 0.05s]
17:46:15.601738 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_gcs
17:46:15.601904 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_height
17:46:15.602181 [info ] [Thread-1  ]: 4 of 13 START table model public.pivoted_height ................................ [RUN]
17:46:15.602852 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_height"
17:46:15.603081 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_height
17:46:15.603267 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_height
17:46:15.604671 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_height"
17:46:15.605272 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.605591 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_height
17:46:15.618118 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_height"
17:46:15.618745 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.618976 [debug] [Thread-1  ]: On model.mimic.pivoted_height: BEGIN
17:46:15.619143 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.624328 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:15.624903 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.625301 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */


  create  table "postgres"."public"."pivoted_height__dbt_tmp"
  as (
    -- prep height
WITH ht_in AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN ROUND((c.valuenum * 2.54)::numeric, 2)
        -- ROUND(value::numeric, 2)
      ELSE c.valuenum
    END)::numeric, 2) AS height
    , c.valuenum as height_orig
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height (measured in inches)
  AND c.itemid IN
  (
    -- CareVue
    920, 1394, 4187, 3486
    -- Metavision
    , 226707
  )
)
, ht_cm AS
(
  SELECT 
    c.subject_id, c.icustay_id, c.charttime,
    -- Ensure that all heights are in centimeters
    ROUND((CASE
      WHEN c.itemid IN (920, 1394, 4187, 3486, 226707)
        THEN c.valuenum * 2.54
      ELSE c.valuenum
    END)::numeric, 2) AS height
  FROM chartevents c
  WHERE c.valuenum IS NOT NULL
  AND c.valuenum != 0
  -- exclude rows marked as error
  AND COALESCE(c.error, 0) = 0
  -- Height cm
  AND c.itemid IN
  (
    -- CareVue
    3485, 4188
    -- MetaVision
    , 226730
  )
)
-- merge cm/height, only take 1 value per charted row
, ht_stg0 AS
(
  SELECT
  COALESCE(h1.subject_id, h1.subject_id) as subject_id
  , COALESCE(h1.charttime, h1.charttime) AS charttime
  , COALESCE(h1.height, h2.height) as height
  FROM ht_cm h1
  FULL OUTER JOIN ht_in h2
    ON h1.subject_id = h2.subject_id
    AND h1.charttime = h2.charttime
)
-- filter out bad heights
, ht_stg1 AS
(
  SELECT
    h.subject_id
    , charttime
    , CASE
        -- rule for neonates
        -- [charrtime don't have year coloum?]
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) <= 1 AND height < 80 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) <= 1 AND height < 80 THEN height
        
        -- rule for adults
        -- WHEN DATETIME_DIFF(charttime, pt.dob, `YEAR`) > 1 AND height > 120 AND height < 230 THEN height
        WHEN EXTRACT(YEAR FROM charttime-pt.dob) > 1 AND height > 120 AND height < 230 THEN height
      ELSE NULL END as height
  FROM ht_stg0 h
  INNER JOIN patients pt
    ON h.subject_id = pt.subject_id
)
-- heights from echo-cardiography notes
, echo_note AS
(
  SELECT
    subject_id
    -- extract the time of the note from the text itself
    -- add this to the structured date in the chartdate column
    , PARSE_DATETIME('%b-%d-%Y%H:%M',
      CONCAT(
        FORMAT_DATE('%b-%d-%Y', chartdate),
        REGEXP_EXTRACT(ne.text, 'Date/Time: [\\[\\]0-9*-]+ at ([0-9:]+)')
       )
    ) AS charttime
    -- sometimes numeric values contain de-id numbers, e.g. [** Numeric Identifier **]
    -- this case is used to ignore that text
    , case
        when REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') like '%*%'
            then null
        else cast(REGEXP_EXTRACT(ne.text, 'Height: \\(in\\) (.*?)\n') as numeric)
        end * 2.54 as height
  FROM noteevents ne
  WHERE ne.category = 'Echo'
)
-- use documented ideal body weights to back-calculate height
, ibw_note AS
(
    SELECT subject_id
    , ne.category
    , charttime
    , CAST(REGEXP_EXTRACT(text, 'Ideal body weight: ([0-9]+\\.?[0-9]*)') AS NUMERIC) as ibw
    FROM noteevents ne
    WHERE text like '%Ideal body weight:%'
    AND ne.category != 'Echo'
)
, ht_from_ibw AS
(
    -- IBW formulas
    -- inches
    -- F:  IBW = 45.5 kg + 2.3 kg * (height in inches - 60)
    -- M:  IBW = 50 kg + 2.3 kg * (height in inches - 60)
    
    -- cm
    -- F: 45.5 + (0.91 × [height in centimeters − 152.4])
    -- M: 50 + (0.91 × [height in centimeters − 152.4])
    
    SELECT ne.subject_id
    , charttime
    , CASE
        WHEN gender = 'F' THEN (ibw - 45.5)/0.91 + 152.4
        ELSE (ibw - 50)/0.91 + 152.4 END AS height
    FROM ibw_note ne
    INNER JOIN patients pt
      ON ne.subject_id = pt.subject_id
    WHERE ibw IS NOT NULL AND ibw != 0
)
, ht_nutrition AS
(
    -- nutrition notes usually only document height
    -- but the original note formatting has been lost, so we can't do a clever regex
    -- instead, we just look for the unit of measure (cm)
    SELECT subject_id
    , charttime
    , CAST(REGEXP_EXTRACT(ne.text, '([0-9]+) cm') AS NUMERIC) as height
    FROM noteevents ne
    WHERE category = 'Nutrition'
    AND lower(text) like '%height%'
)
SELECT subject_id, charttime, 'chartevents' as source, height
FROM ht_stg1
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - echo' as source, height
FROM echo_note
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - ibw' as source, height
FROM ht_from_ibw
WHERE height IS NOT NULL AND height > 0
UNION ALL
SELECT subject_id, charttime, 'noteevents - nutrition' as source
-- convert the heights
    , CASE 
        WHEN height < 80 THEN height*2.54
        ELSE height
    END AS height
FROM ht_nutrition
WHERE height IS NOT NULL AND height > 0
ORDER BY subject_id, charttime, source, height
  );
17:46:15.636845 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:46:15.643463 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.643782 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height" rename to "pivoted_height__dbt_backup"
17:46:15.644746 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.648530 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.648747 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
alter table "postgres"."public"."pivoted_height__dbt_tmp" rename to "pivoted_height"
17:46:15.649316 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.653101 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:46:15.653314 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.653540 [debug] [Thread-1  ]: On model.mimic.pivoted_height: COMMIT
17:46:15.654566 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.657413 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_height"
17:46:15.657950 [debug] [Thread-1  ]: On model.mimic.pivoted_height: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_height"} */
drop table if exists "postgres"."public"."pivoted_height__dbt_backup" cascade
17:46:15.660597 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.663522 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.663756 [debug] [Thread-1  ]: On model.mimic.pivoted_height: Close
17:46:15.664575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118eaf10>]}
17:46:15.664949 [info ] [Thread-1  ]: 4 of 13 OK created table model public.pivoted_height ........................... [[32mSELECT 0[0m in 0.06s]
17:46:15.665450 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_height
17:46:15.665662 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_icp
17:46:15.666120 [info ] [Thread-1  ]: 5 of 13 START table model public.pivoted_icp ................................... [RUN]
17:46:15.666885 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_icp"
17:46:15.667205 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_icp
17:46:15.667400 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_icp
17:46:15.668765 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_icp"
17:46:15.669423 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.669743 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_icp
17:46:15.682563 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_icp"
17:46:15.683244 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.683480 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: BEGIN
17:46:15.683650 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.687888 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:46:15.688120 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.688288 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */


  create  table "postgres"."public"."pivoted_icp__dbt_tmp"
  as (
    with ce as
(
  select ce.icustay_id
    , ce.charttime
    -- TODO: handle high ICPs when monitoring two ICPs
    , case when valuenum > 0 and valuenum < 100 then valuenum else null end as icp
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error = 0)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
   226 -- ICP -- 99159
  ,1374 -- ICP Right -- 100
  ,2045 -- icp left -- 70
  ,2635 -- VENT ICP -- 195
  ,2660 -- ICP Camino -- 40
  ,2733 -- RIGHT VENT ICP -- 203
  ,2745 -- ICP LEFT -- 232
  ,2870 -- ICP-ventriculostomuy -- 114
  ,2956 -- ventriculostomy icp -- 64
  ,2985 -- ICP ventricle -- 85
  ,5856 -- icp -- 7
  ,7116 -- Rt ICP -- 80
  ,8218 -- left icp -- 6
  ,8298 -- L ICP -- 47
  ,8299 -- R ICP -- 16
  ,8305 -- ICP  Right -- 49
  ,220765 -- Intra Cranial Pressure -- 92306
  ,227989 -- Intra Cranial Pressure #2 -- 1052
  )
)
select
    ce.icustay_id
  , ce.charttime
  , MAX(icp) as icp
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:46:15.695757 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:46:15.700289 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.700515 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp" rename to "pivoted_icp__dbt_backup"
17:46:15.701066 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.704459 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.704652 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
alter table "postgres"."public"."pivoted_icp__dbt_tmp" rename to "pivoted_icp"
17:46:15.705254 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.711567 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:46:15.711785 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.711991 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: COMMIT
17:46:15.713082 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.715409 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_icp"
17:46:15.715612 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_icp"} */
drop table if exists "postgres"."public"."pivoted_icp__dbt_backup" cascade
17:46:15.717220 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.720059 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.720292 [debug] [Thread-1  ]: On model.mimic.pivoted_icp: Close
17:46:15.721039 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131c4b50>]}
17:46:15.721407 [info ] [Thread-1  ]: 5 of 13 OK created table model public.pivoted_icp .............................. [[32mSELECT 0[0m in 0.05s]
17:46:15.721718 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_icp
17:46:15.721855 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_invasive_lines
17:46:15.722372 [info ] [Thread-1  ]: 6 of 13 START table model public.pivoted_invasive_lines ........................ [RUN]
17:46:15.723969 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.724523 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_invasive_lines
17:46:15.725013 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_invasive_lines
17:46:15.727449 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_invasive_lines"
17:46:15.727958 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.728190 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_invasive_lines
17:46:15.735189 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_invasive_lines"
17:46:15.735773 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.735993 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: BEGIN
17:46:15.736160 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.741457 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:15.741684 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.741783 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */


  create  table "postgres"."public"."pivoted_invasive_lines__dbt_tmp"
  as (
    WITH stg0 AS
(
    SELECT 
        icustay_id
        , charttime
        , storetime
        , itemid
        -- create partition which separates the lines
        , CASE
            WHEN itemid IN (229, 8392) THEN 1
            WHEN itemid IN (235, 8393) THEN 2
            WHEN itemid IN (241, 8394) THEN 3
            WHEN itemid IN (247, 8395) THEN 4
            WHEN itemid IN (253, 8396) THEN 5
            WHEN itemid IN (259, 8397) THEN 6
            WHEN itemid IN (265, 8398) THEN 7
            WHEN itemid IN (271, 8399) THEN 8
          ELSE NULL END AS line_number
        , CASE WHEN itemid < 8000 THEN value ELSE NULL END AS line_type
        , CASE WHEN itemid > 8000 THEN value ELSE NULL END AS line_site
        -- the stopped column is always present for invasive lines
        , CASE 
            --   WHEN ce.stopped = 'D/C\'d' THEN 1
              WHEN ce.stopped = 'D/C''d' THEN 1
              WHEN ce.stopped = 'NotStopd' THEN 0
          ELSE NULL END AS line_dc
    FROM chartevents ce
    WHERE ce.itemid IN 
    (
      229 -- INV Line#1 [Type]
    , 235 -- INV Line#2 [Type]
    , 241 -- INV Line#3 [Type]
    , 247 -- INV Line#4 [Type]
    , 253 -- INV Line#5 [Type]
    , 259 -- INV Line#6 [Type]
    , 265 -- INV Line#7 [Type]
    , 271 -- INV Line#8 [Type]
    , 8392 -- INV Line#1 [Site]
    , 8393 -- INV Line#2 [Site]
    , 8394 -- INV Line#3 [Site]
    , 8395 -- INV Line#4 [Site]
    , 8396 -- INV Line#5 [Site]
    , 8397 -- INV Line#6 [Site]
    , 8398 -- INV Line#7 [Site]
    , 8399 -- INV Line#8 [Site]
    )
    AND icustay_id IS NOT NULL
    AND COALESCE(ce.error, 0) = 0
)
, stg0_rn AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site, line_dc
        -- only keep the last documented value
        , ROW_NUMBER() OVER (PARTITION BY icustay_id, charttime, itemid ORDER BY storetime DESC) as rn_last_stored
    FROM stg0
)
, stg1 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        -- collapse line type/site into a single row
        -- MAX() always collapses a single value, due to where rn_last_stored = 1
        , MAX(line_type) as line_type
        , MAX(line_site) as line_site
        -- any disconnection at this charttime turns off the line
        , MAX(line_dc) AS line_dc
    FROM stg0_rn
    WHERE rn_last_stored = 1
    GROUP BY icustay_id, charttime, line_number
)
, stg2 AS
(
    SELECT 
        icustay_id
        , charttime
        , line_number
        , line_type, line_site
        , line_dc
        -- carry forward the line type
        , CASE
            -- if the previous line was D/C'd then it's a new line
            WHEN LAG(line_dc) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = 1 THEN 1
            -- if it's the same line as before, within 16 hours, continue the event
            WHEN LAG(line_type) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) = line_type
            AND DATETIME_DIFF(
                charttime,
                LAG(charttime) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime),
                'HOUR'
                ) < 16 THEN 0
            -- otherwise, it's been more than 16 hours since the line was last documented
            -- (or it's the first documentation of this line)
            -- so we consider this a new event
            ELSE 1
        END AS rn_part
    FROM stg1
)
-- rn_part is 1 if it's a new event, and 0 if it's a continuation of the previous
-- so cumulatively summing it will result in a sequential integer which partitions
-- distinct line events. we can later group on this integer.
, stg3 AS
(
    SELECT
        icustay_id, charttime, line_number
        , line_type, line_site
        , line_dc
        , SUM(rn_part) OVER (PARTITION BY icustay_id, line_number ORDER BY charttime) as line_event
    FROM stg2
)
-- group by line_event to determine line start/stop times
, stg4 AS
(
    SELECT
        icustay_id, line_number
        , line_event
        , line_type, line_site
        , MIN(charttime) as starttime
        , MAX(charttime) as endtime
    FROM stg3
    -- filter out the D/C'd rows so they don't impact the starttime of future events
    WHERE line_dc = 0 
    GROUP BY icustay_id, line_number, line_event, line_type, line_site
)
-- metavision
, mv AS
(
    SELECT 
        icustay_id
        -- since metavision separates lines using itemid, we can use it as the line number
        , mv.itemid AS line_number
        , di.label AS line_type
        , mv.location AS line_site
        , starttime, endtime
    FROM procedureevents_mv mv
    INNER JOIN d_items di
      ON mv.itemid = di.itemid
    WHERE mv.itemid IN
    (
      227719 -- AVA Line
    , 225752 -- Arterial Line
    , 224269 -- CCO PAC
    , 224267 -- Cordis/Introducer
    , 224270 -- Dialysis Catheter
    , 224272 -- IABP line
    , 226124 -- ICP Catheter
    , 228169 -- Impella Line
    , 225202 -- Indwelling Port (PortaCath)
    , 228286 -- Intraosseous Device
    , 225204 -- Midline
    , 224263 -- Multi Lumen
    , 224560 -- PA Catheter
    , 224264 -- PICC Line
    , 225203 -- Pheresis Catheter
    , 224273 -- Presep Catheter
    , 225789 -- Sheath
    , 225761 -- Sheath Insertion
    , 228201 -- Tandem Heart Access Line
    , 228202 -- Tandem Heart Return Line
    , 224268 -- Trauma line
    , 225199 -- Triple Introducer
    , 225315 -- Tunneled (Hickman) Line
    , 225205 -- RIC
    )
    AND icustay_id IS NOT NULL
    AND statusdescription != 'Rewritten'
),
combined AS
(
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM stg4
    UNION DISTINCT
    select 
        icustay_id
        , line_type, line_site
        , starttime
        , endtime
    FROM mv
)
-- as a final step, combine any similar terms together
-- this was comprehensive as of MIMIC-III v1.4
select 
    icustay_id
    , CASE
        WHEN line_type IN ('Arterial Line', 'A-Line') THEN 'Arterial'
        WHEN line_type IN ('CCO PA Line', 'CCO PAC') THEN 'Continuous Cardiac Output PA'
        WHEN line_type IN ('Dialysis Catheter', 'Dialysis Line') THEN 'Dialysis'
        WHEN line_type IN ('Hickman', 'Tunneled (Hickman) Line') THEN 'Hickman'
        WHEN line_type IN ('IABP', 'IABP line') THEN 'IABP'
        WHEN line_type IN ('Multi Lumen', 'Multi-lumen') THEN 'Multi Lumen'
        WHEN line_type IN ('PA Catheter', 'PA line') THEN 'PA'
        WHEN line_type IN ('PICC Line', 'PICC line') THEN 'PICC'
        WHEN line_type IN ('Pre-Sep Catheter', 'Presep Catheter') THEN 'Pre-Sep'
        WHEN line_type IN ('Trauma Line', 'Trauma line') THEN 'Trauma'
        WHEN line_type IN ('Triple Introducer', 'TripleIntroducer') THEN 'Triple Introducer'
        WHEN line_type IN ('Portacath', 'Indwelling Port (PortaCath)') THEN 'Portacath'
        -- AVA Line
        -- Camino Bolt
        -- Cordis/Introducer
        -- ICP Catheter
        -- Impella Line
        -- Intraosseous Device
        -- Introducer
        -- Lumbar Drain
        -- Midline
        -- Other/Remarks
        -- PacerIntroducer
        -- PermaCath
        -- Pheresis Catheter
        -- RIC
        -- Sheath
        -- Tandem Heart Access Line
        -- Tandem Heart Return Line
        -- Venous Access
        -- Ventriculostomy
    ELSE line_type END AS line_type
    , CASE
        WHEN line_site IN ('Left Antecub', 'Left Antecube') THEN 'Left Antecube'
        WHEN line_site IN ('Left Axilla', 'Left Axilla.') THEN 'Left Axilla'
        WHEN line_site IN ('Left Brachial', 'Left Brachial.') THEN 'Left Brachial'
        WHEN line_site IN ('Left Femoral', 'Left Femoral.') THEN 'Left Femoral'
        WHEN line_site IN ('Right Antecub', 'Right Antecube') THEN 'Right Antecube' 
        WHEN line_site IN ('Right Axilla', 'Right Axilla.') THEN 'Right Axilla' 
        WHEN line_site IN ('Right Brachial', 'Right Brachial.') THEN 'Right Brachial' 
        WHEN line_site IN ('Right Femoral', 'Right Femoral.') THEN 'Right Femoral' 
        -- 'Left Foot'
        -- 'Left IJ'
        -- 'Left Radial'
        -- 'Left Subclavian'
        -- 'Left Ulnar'
        -- 'Left Upper Arm'
        -- 'Right Foot'
        -- 'Right IJ'
        -- 'Right Radial'
        -- 'Right Side Head'
        -- 'Right Subclavian'
        -- 'Right Ulnar'
        -- 'Right Upper Arm'
        -- 'Transthoracic'
        -- 'Other/Remarks'
    ELSE line_site END AS line_site
    , starttime
    , endtime
FROM combined
ORDER BY icustay_id, starttime, line_type, line_site
  );
17:46:15.856201 [debug] [Thread-1  ]: SQL status: SELECT 34483 in 0.11 seconds
17:46:15.862999 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.863422 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines" rename to "pivoted_invasive_lines__dbt_backup"
17:46:15.864332 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.869586 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.869797 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
alter table "postgres"."public"."pivoted_invasive_lines__dbt_tmp" rename to "pivoted_invasive_lines"
17:46:15.870440 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:15.874131 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:46:15.874331 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.874435 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: COMMIT
17:46:15.877876 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:15.880193 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_invasive_lines"
17:46:15.880412 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_invasive_lines"} */
drop table if exists "postgres"."public"."pivoted_invasive_lines__dbt_backup" cascade
17:46:15.882598 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:15.885188 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.885413 [debug] [Thread-1  ]: On model.mimic.pivoted_invasive_lines: Close
17:46:15.886171 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131c4d00>]}
17:46:15.886706 [info ] [Thread-1  ]: 6 of 13 OK created table model public.pivoted_invasive_lines ................... [[32mSELECT 34483[0m in 0.16s]
17:46:15.887262 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_invasive_lines
17:46:15.887631 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_lab
17:46:15.888292 [info ] [Thread-1  ]: 7 of 13 START table model public.pivoted_lab ................................... [RUN]
17:46:15.889050 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_lab"
17:46:15.889353 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_lab
17:46:15.889630 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_lab
17:46:15.891563 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_lab"
17:46:15.892190 [debug] [Thread-1  ]: finished collecting timing info
17:46:15.892446 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_lab
17:46:15.901728 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_lab"
17:46:15.902148 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:15.902253 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: BEGIN
17:46:15.902343 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:15.908804 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:15.909033 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:15.909351 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */


  create  table "postgres"."public"."pivoted_lab__dbt_tmp"
  as (
    -- create a table which has fuzzy boundaries on ICU admission (+- 12 hours from documented time)
-- this is used to assign icustay_id to lab data, which can be collected outside ICU
-- involves first creating a lag/lead version of intime/outtime
with i as
(
  select
    subject_id, icustay_id, intime, outtime
    , lag (outtime) over (partition by subject_id order by intime) as outtime_lag
    , lead (intime) over (partition by subject_id order by intime) as intime_lead
  from icustays
)
, iid_assign as
(
  select
    i.subject_id, i.icustay_id
    -- this rule is:
    --  if there are two ICU stays within 24 hours, set the start/stop
    --  time as half way between the two ICU stays
    , case
        when i.outtime_lag is not null
        and i.outtime_lag > (DATETIME_SUB(i.intime, INTERVAL '24' HOUR))
          then DATETIME_SUB(i.intime, (CAST(DATETIME_DIFF(i.intime, i.outtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(i.intime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when i.intime_lead is not null
        and i.intime_lead < (DATETIME_ADD(i.outtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(i.outtime, (CAST(DATETIME_DIFF(i.intime_lead, i.outtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(i.outtime, INTERVAL '12' HOUR))
      end as data_end
    from i
)
-- also create fuzzy boundaries on hospitalization
, h as
(
  select
    subject_id, hadm_id, admittime, dischtime
    , lag (dischtime) over (partition by subject_id order by admittime) as dischtime_lag
    , lead (admittime) over (partition by subject_id order by admittime) as admittime_lead
  from admissions
)
, adm as
(
  select
    h.subject_id, h.hadm_id
    -- this rule is:
    --  if there are two hospitalizations within 24 hours, set the start/stop
    --  time as half way between the two admissions
    , case
        when h.dischtime_lag is not null
        and h.dischtime_lag > (DATETIME_SUB(h.admittime, INTERVAL '24' HOUR))
          then DATETIME_SUB(h.admittime, (CAST(DATETIME_DIFF(h.admittime, h.dischtime_lag, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else DATETIME_SUB(h.admittime, INTERVAL '12' HOUR)
      end as data_start
    , case
        when h.admittime_lead is not null
        and h.admittime_lead < (DATETIME_ADD(h.dischtime, INTERVAL '24' HOUR))
          then DATETIME_ADD(h.dischtime, (CAST(DATETIME_DIFF(h.admittime_lead, h.dischtime, 'SECOND')/2 AS integer) || 'SECOND')::INTERVAL)
      else (DATETIME_ADD(h.dischtime, INTERVAL '12' HOUR))
      end as data_end
    from h
)
, le_avg as
(
SELECT
    pvt.subject_id, pvt.charttime
  , avg(CASE WHEN label = 'ANION GAP' THEN valuenum ELSE null END) as ANIONGAP
  , avg(CASE WHEN label = 'ALBUMIN' THEN valuenum ELSE null END) as ALBUMIN
  , avg(CASE WHEN label = 'BANDS' THEN valuenum ELSE null END) as BANDS
  , avg(CASE WHEN label = 'BICARBONATE' THEN valuenum ELSE null END) as BICARBONATE
  , avg(CASE WHEN label = 'BILIRUBIN' THEN valuenum ELSE null END) as BILIRUBIN
  , avg(CASE WHEN label = 'CREATININE' THEN valuenum ELSE null END) as CREATININE
  , avg(CASE WHEN label = 'CHLORIDE' THEN valuenum ELSE null END) as CHLORIDE
  , avg(CASE WHEN label = 'GLUCOSE' THEN valuenum ELSE null END) as GLUCOSE
  , avg(CASE WHEN label = 'HEMATOCRIT' THEN valuenum ELSE null END) as HEMATOCRIT
  , avg(CASE WHEN label = 'HEMOGLOBIN' THEN valuenum ELSE null END) as HEMOGLOBIN
  , avg(CASE WHEN label = 'LACTATE' THEN valuenum ELSE null END) as LACTATE
  , avg(CASE WHEN label = 'PLATELET' THEN valuenum ELSE null END) as PLATELET
  , avg(CASE WHEN label = 'POTASSIUM' THEN valuenum ELSE null END) as POTASSIUM
  , avg(CASE WHEN label = 'PTT' THEN valuenum ELSE null END) as PTT
  , avg(CASE WHEN label = 'INR' THEN valuenum ELSE null END) as INR
  , avg(CASE WHEN label = 'PT' THEN valuenum ELSE null END) as PT
  , avg(CASE WHEN label = 'SODIUM' THEN valuenum ELSE null end) as SODIUM
  , avg(CASE WHEN label = 'BUN' THEN valuenum ELSE null end) as BUN
  , avg(CASE WHEN label = 'WBC' THEN valuenum ELSE null end) as WBC
FROM
( -- begin query that extracts the data
  SELECT le.subject_id, le.hadm_id, le.charttime
  -- here we assign labels to ITEMIDs
  -- this also fuses together multiple ITEMIDs containing the same data
  , CASE
        WHEN itemid = 50868 THEN 'ANION GAP'
        WHEN itemid = 50862 THEN 'ALBUMIN'
        WHEN itemid = 51144 THEN 'BANDS'
        WHEN itemid = 50882 THEN 'BICARBONATE'
        WHEN itemid = 50885 THEN 'BILIRUBIN'
        WHEN itemid = 50912 THEN 'CREATININE'
        -- exclude blood gas
        -- WHEN itemid = 50806 THEN 'CHLORIDE'
        WHEN itemid = 50902 THEN 'CHLORIDE'
        -- exclude blood gas
        -- WHEN itemid = 50809 THEN 'GLUCOSE'
        WHEN itemid = 50931 THEN 'GLUCOSE'
        -- exclude blood gas
        --WHEN itemid = 50810 THEN 'HEMATOCRIT'
        WHEN itemid = 51221 THEN 'HEMATOCRIT'
        -- exclude blood gas
        --WHEN itemid = 50811 THEN 'HEMOGLOBIN'
        WHEN itemid = 51222 THEN 'HEMOGLOBIN'
        WHEN itemid = 50813 THEN 'LACTATE'
        WHEN itemid = 51265 THEN 'PLATELET'
        -- exclude blood gas
        -- WHEN itemid = 50822 THEN 'POTASSIUM'
        WHEN itemid = 50971 THEN 'POTASSIUM'
        WHEN itemid = 51275 THEN 'PTT'
        WHEN itemid = 51237 THEN 'INR'
        WHEN itemid = 51274 THEN 'PT'
        -- exclude blood gas
        -- WHEN itemid = 50824 THEN 'SODIUM'
        WHEN itemid = 50983 THEN 'SODIUM'
        WHEN itemid = 51006 THEN 'BUN'
        WHEN itemid = 51300 THEN 'WBC'
        WHEN itemid = 51301 THEN 'WBC'
      ELSE null
    END AS label
  , -- add in some sanity checks on the values
  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks
    CASE
      WHEN itemid = 50862 and valuenum >    10 THEN null -- g/dL 'ALBUMIN'
      WHEN itemid = 50868 and valuenum > 10000 THEN null -- mEq/L 'ANION GAP'
      WHEN itemid = 51144 and valuenum <     0 THEN null -- immature band forms, %
      WHEN itemid = 51144 and valuenum >   100 THEN null -- immature band forms, %
      WHEN itemid = 50882 and valuenum > 10000 THEN null -- mEq/L 'BICARBONATE'
      WHEN itemid = 50885 and valuenum >   150 THEN null -- mg/dL 'BILIRUBIN'
      WHEN itemid = 50806 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50902 and valuenum > 10000 THEN null -- mEq/L 'CHLORIDE'
      WHEN itemid = 50912 and valuenum >   150 THEN null -- mg/dL 'CREATININE'
      WHEN itemid = 50809 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50931 and valuenum > 10000 THEN null -- mg/dL 'GLUCOSE'
      WHEN itemid = 50810 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 51221 and valuenum >   100 THEN null -- % 'HEMATOCRIT'
      WHEN itemid = 50811 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 51222 and valuenum >    50 THEN null -- g/dL 'HEMOGLOBIN'
      WHEN itemid = 50813 and valuenum >    50 THEN null -- mmol/L 'LACTATE'
      WHEN itemid = 51265 and valuenum > 10000 THEN null -- K/uL 'PLATELET'
      WHEN itemid = 50822 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 50971 and valuenum >    30 THEN null -- mEq/L 'POTASSIUM'
      WHEN itemid = 51275 and valuenum >   150 THEN null -- sec 'PTT'
      WHEN itemid = 51237 and valuenum >    50 THEN null -- 'INR'
      WHEN itemid = 51274 and valuenum >   150 THEN null -- sec 'PT'
      WHEN itemid = 50824 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 50983 and valuenum >   200 THEN null -- mEq/L == mmol/L 'SODIUM'
      WHEN itemid = 51006 and valuenum >   300 THEN null -- 'BUN'
      WHEN itemid = 51300 and valuenum >  1000 THEN null -- 'WBC'
      WHEN itemid = 51301 and valuenum >  1000 THEN null -- 'WBC'
    ELSE valuenum
    END AS valuenum
  FROM labevents le
  WHERE le.ITEMID in
  (
    -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS
    50868, -- ANION GAP | CHEMISTRY | BLOOD | 769895
    50862, -- ALBUMIN | CHEMISTRY | BLOOD | 146697
    51144, -- BANDS - hematology
    50882, -- BICARBONATE | CHEMISTRY | BLOOD | 780733
    50885, -- BILIRUBIN, TOTAL | CHEMISTRY | BLOOD | 238277
    50912, -- CREATININE | CHEMISTRY | BLOOD | 797476
    50902, -- CHLORIDE | CHEMISTRY | BLOOD | 795568
    -- 50806, -- CHLORIDE, WHOLE BLOOD | BLOOD GAS | BLOOD | 48187
    50931, -- GLUCOSE | CHEMISTRY | BLOOD | 748981
    -- 50809, -- GLUCOSE | BLOOD GAS | BLOOD | 196734
    51221, -- HEMATOCRIT | HEMATOLOGY | BLOOD | 881846
    -- 50810, -- HEMATOCRIT, CALCULATED | BLOOD GAS | BLOOD | 89715
    51222, -- HEMOGLOBIN | HEMATOLOGY | BLOOD | 752523
    -- 50811, -- HEMOGLOBIN | BLOOD GAS | BLOOD | 89712
    50813, -- LACTATE | BLOOD GAS | BLOOD | 187124
    51265, -- PLATELET COUNT | HEMATOLOGY | BLOOD | 778444
    50971, -- POTASSIUM | CHEMISTRY | BLOOD | 845825
    -- 50822, -- POTASSIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 192946
    51275, -- PTT | HEMATOLOGY | BLOOD | 474937
    51237, -- INR(PT) | HEMATOLOGY | BLOOD | 471183
    51274, -- PT | HEMATOLOGY | BLOOD | 469090
    50983, -- SODIUM | CHEMISTRY | BLOOD | 808489
    -- 50824, -- SODIUM, WHOLE BLOOD | BLOOD GAS | BLOOD | 71503
    51006, -- UREA NITROGEN | CHEMISTRY | BLOOD | 791925
    51301, -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301
    51300  -- WBC COUNT | HEMATOLOGY | BLOOD | 2371
  )
  AND valuenum IS NOT NULL AND valuenum > 0 -- lab values cannot be 0 and cannot be negative
) pvt
GROUP BY pvt.subject_id, pvt.charttime
)
select
  iid.icustay_id, adm.hadm_id, le_avg.*
from le_avg
left join adm
  on le_avg.subject_id  = adm.subject_id
  and le_avg.charttime >= adm.data_start
  and le_avg.charttime  < adm.data_end
left join iid_assign iid
  on  le_avg.subject_id = iid.subject_id
  and le_avg.charttime >= iid.data_start
  and le_avg.charttime  < iid.data_end
order by le_avg.subject_id, le_avg.charttime
  );
17:46:15.998260 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.09 seconds
17:46:16.006082 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:16.006517 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab" rename to "pivoted_lab__dbt_backup"
17:46:16.009292 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:16.013090 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:16.013301 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
alter table "postgres"."public"."pivoted_lab__dbt_tmp" rename to "pivoted_lab"
17:46:16.013997 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:16.017132 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:46:16.017332 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:16.017556 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: COMMIT
17:46:16.024325 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:46:16.025978 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_lab"
17:46:16.026164 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_lab"} */
drop table if exists "postgres"."public"."pivoted_lab__dbt_backup" cascade
17:46:16.028326 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:16.031764 [debug] [Thread-1  ]: finished collecting timing info
17:46:16.031998 [debug] [Thread-1  ]: On model.mimic.pivoted_lab: Close
17:46:16.032865 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131c4dc0>]}
17:46:16.033346 [info ] [Thread-1  ]: 7 of 13 OK created table model public.pivoted_lab .............................. [[32mSELECT 0[0m in 0.14s]
17:46:16.033880 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_lab
17:46:16.034117 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_rrt
17:46:16.034749 [info ] [Thread-1  ]: 8 of 13 START table model public.pivoted_rrt ................................... [RUN]
17:46:16.035527 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_rrt"
17:46:16.035988 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_rrt
17:46:16.036300 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_rrt
17:46:16.038054 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_rrt"
17:46:16.038402 [debug] [Thread-1  ]: finished collecting timing info
17:46:16.039134 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_rrt
17:46:16.050320 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_rrt"
17:46:16.051081 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:16.051640 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: BEGIN
17:46:16.051912 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:16.057496 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:16.058093 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:16.058285 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */


  create  table "postgres"."public"."pivoted_rrt__dbt_tmp"
  as (
    -- Creates a table with icustay_id / time / dialysis type (if present)

with ce as
(
  select ce.icustay_id
    , ce.charttime
          -- when ce.itemid in (152,148,149,146,147,151,150) and value is not null then 1
          -- when ce.itemid in (229,235,241,247,253,259,265,271) and value = 'Dialysis Line' then 1
          -- when ce.itemid = 466 and value = 'Dialysis RN' then 1
          -- when ce.itemid = 927 and value = 'Dialysis Solutions' then 1
          -- when ce.itemid = 6250 and value = 'dialys' then 1
          -- when ce.
          -- when ce.itemid = 582 and value in ('CAVH Start','CAVH D/C','CVVHD Start','CVVHD D/C','Hemodialysis st','Hemodialysis end') then 1
    , CASE
        WHEN ce.itemid IN
        (
          146 -- "Dialysate Flow ml/hr"
          , 147 -- "Dialysate Infusing";56605
          , 148 -- "Dialysis Access Site";60335
          , 149 -- "Dialysis Access Type";60030
          , 150 -- "Dialysis Machine";27472 (baxter or gambro)
          , 151 -- "Dialysis Site Appear";37345
          , 152 -- "Dialysis Type";61449
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid IN (229, 235, 241, 247, 253, 259, 265, 271) AND value = 'Dialysis Line' 
          THEN 1
        -- WHEN ce.itemid = 917 AND value IN
        -- (
        --   '+ INITIATE DIALYSIS', 'BLEEDING FROM DIALYSIS CATHETER',
        --   -- 'FAILED DIALYSIS CATH.',
        --   'FEBRILE SYNDROME;DIALYSIS', 'HYPOTENSION WITH HEMODIALYSIS',
        --   'HYPOTENSION.GLOGGED DIALYSIS',
        --   'INFECTED DIALYSIS CATHETER'
        -- )
        -- metavision itemids

        -- checkboxes
        WHEN ce.itemid IN
        (
            226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
          , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
          , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox
        ) THEN 1
        -- numeric data
        WHEN ce.itemid IN
        (
            226499 -- | Hemodialysis Output                               | Dialysis
          , 224154 -- | Dialysate Rate                                    | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224149 -- | Access Pressure                  | Dialysis
          , 224150 -- | Filter Pressure                  | Dialysis
          , 224151 -- | Effluent Pressure                | Dialysis
          , 224152 -- | Return Pressure                  | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 224404 -- | ART Lumen Volume                 | Dialysis
          , 224406 -- | VEN Lumen Volume                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1

        -- text fields
        WHEN ce.itemid IN
        (
            224135 -- | Dialysis Access Site | Dialysis
          , 224139 -- | Dialysis Site Appearance | Dialysis
          , 224146 -- | System Integrity | Dialysis
          , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive
          , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive
          , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225954 -- | Dialysis Access Type | Dialysis
          , 225956 -- | Reason for CRRT Filter Change | Dialysis
          , 225958 -- | Heparin Concentration (units/mL) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 225976 -- | Replacement Fluid | Dialysis
          , 225977 -- | Dialysate Fluid | Dialysis
          , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive
          , 227290 -- | CRRT mode | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
          , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive
        ) THEN 1
      ELSE 0 END
      AS dialysis_present
    , CASE
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH Start', 'CVVHD Start', 'Hemodialysis st',
          'Peritoneal Dial'
        ) THEN 1
        WHEN ce.itemid = 582 AND value IN 
        (
          'CAVH D/C', 'CVVHD D/C', 'Hemodialysis end'
        ) THEN 0
        WHEN ce.itemid = 147 AND value = 'Yes' THEN 1 -- "Dialysate Infusing";56605
        WHEN ce.itemid = 225965 -- Peritoneal Dialysis Catheter Status
          AND value = 'In use' THEN 1
        WHEN ce.itemid IN
        (
            146    -- Dialysate Flow ml/hr
          , 226499 -- | Hemodialysis Output              | Dialysis
          , 224154 -- | Dialysate Rate                   | Dialysis
          , 225183 -- | Current Goal                     | Dialysis
          , 227438 -- | Volume not removed               | Dialysis
          , 224191 -- | Hourly Patient Fluid Removal     | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 228004 -- | Citrate (ACD-A)                  | Dialysis
          , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis
          , 228006 -- | Post Filter Replacement Rate     | Dialysis
          , 224144 -- | Blood Flow (ml/min)              | Dialysis
          , 224145 -- | Heparin Dose (per hour)          | Dialysis
          , 224153 -- | Replacement Rate                 | Dialysis
          , 226457 -- | Ultrafiltrate Output             | Dialysis
        ) THEN 1
      ELSE 0 END
      AS dialysis_active
    , CASE
        -- dialysis mode
        WHEN ce.itemid in (152, 227290) THEN
          CASE
            WHEN value = 'CVVH' THEN 'CVVH'
            WHEN value = 'CVVHD' THEN 'CVVHD'
            WHEN value = 'CVVHDF' THEN 'CVVHDF'
            WHEN value = 'SCUF' THEN 'SCUF'
            WHEN value = 'Peritoneal' THEN 'Peritoneal'
          END
        -- itemids which imply a certain dialysis mode

        -- peritoneal dialysis
        WHEN ce.itemid IN 
        (
            225810 -- | Dwell Time (Peritoneal Dialysis) | Dialysis
          , 225806 -- | Volume In (PD)                   | Dialysis
          , 225807 -- | Volume Out (PD)                  | Dialysis
          , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis
          , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis
          , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis
          , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis
          , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis
          , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis
          , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis
          , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis
          , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis
          , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis
          , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis
        )
          THEN 'Peritoneal'
        WHEN ce.itemid IN (226499)
          THEN 'IHD'
        WHEN ce.itemid = 582 THEN
          CASE
            WHEN value IN ('CAVH Start','CAVH D/C')
              THEN 'CAVH'
            WHEN value IN ('CVVHD Start','CVVHD D/C')
              THEN 'CVVHD'
            WHEN value IN ('Hemodialysis st', 'Hemodialysis end')
              -- null is ambiguous
              THEN NULL
          ELSE NULL
          END
      ELSE NULL END as dialysis_type
  from chartevents ce
  WHERE ce.itemid in
  (
     152 -- "Dialysis Type";61449
    ,146 -- "Dialysate Flow ml/hr";57445
    ,147 -- "Dialysate Infusing";56605
    ,148 -- "Dialysis Access Site";60335
    ,149 -- "Dialysis Access Type";60030
    ,150 -- "Dialysis Machine";27472 (baxter or gambro)
    ,151 -- "Dialysis Site Appear";37345
    ,582 -- Procedures
    -- below indicate existence of a dialysis line
    ,229 -- INV Line#1 [Type]
    ,235 -- INV Line#2 [Type]
    ,241 -- INV Line#3 [Type]
    ,247 -- INV Line#4 [Type]
    ,253 -- INV Line#5 [Type]
    ,259 -- INV Line#6 [Type]
    ,265 -- INV Line#7 [Type]
    ,271 -- INV Line#8 [Type]
    
    -- dialysis consults can't be 100% guaranteed to be active
    -- ,466 -- Nursing Consultation
    -- diagnosis has 6 or 7 dx related to dialysis, probably not worth including
    -- as the chart time isn't going to match the start time of dialysis
    -- , 917 -- Diagnosis/op
    -- ,7949 -- "Calcium for CVVH" - only has 2 null values
    
    -- === MetaVision itemids === --
  
    -- Checkboxes
    , 226118 -- | Dialysis Catheter placed in outside facility      | Access Lines - Invasive | chartevents        | Checkbox
    , 227357 -- | Dialysis Catheter Dressing Occlusive              | Access Lines - Invasive | chartevents        | Checkbox
    , 225725 -- | Dialysis Catheter Tip Cultured                    | Access Lines - Invasive | chartevents        | Checkbox

    -- Numeric values
    , 226499 -- | Hemodialysis Output                               | Dialysis                | chartevents        | Numeric
    , 224154 -- | Dialysate Rate                                    | Dialysis                | chartevents        | Numeric
    , 225810 -- | Dwell Time (Peritoneal Dialysis)                  | Dialysis                | chartevents        | Numeric
    , 227639 -- | Medication Added Amount  #2 (Peritoneal Dialysis) | Dialysis                | chartevents        | Numeric
    , 225183 -- | Current Goal                     | Dialysis | chartevents        | Numeric
    , 227438 -- | Volume not removed               | Dialysis | chartevents        | Numeric
    , 224191 -- | Hourly Patient Fluid Removal     | Dialysis | chartevents        | Numeric
    , 225806 -- | Volume In (PD)                   | Dialysis | chartevents        | Numeric
    , 225807 -- | Volume Out (PD)                  | Dialysis | chartevents        | Numeric
    , 228004 -- | Citrate (ACD-A)                  | Dialysis | chartevents        | Numeric
    , 228005 -- | PBP (Prefilter) Replacement Rate | Dialysis | chartevents        | Numeric
    , 228006 -- | Post Filter Replacement Rate     | Dialysis | chartevents        | Numeric
    , 224144 -- | Blood Flow (ml/min)              | Dialysis | chartevents        | Numeric
    , 224145 -- | Heparin Dose (per hour)          | Dialysis | chartevents        | Numeric
    , 224149 -- | Access Pressure                  | Dialysis | chartevents        | Numeric
    , 224150 -- | Filter Pressure                  | Dialysis | chartevents        | Numeric
    , 224151 -- | Effluent Pressure                | Dialysis | chartevents        | Numeric
    , 224152 -- | Return Pressure                  | Dialysis | chartevents        | Numeric
    , 224153 -- | Replacement Rate                 | Dialysis | chartevents        | Numeric
    , 224404 -- | ART Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 224406 -- | VEN Lumen Volume                 | Dialysis | chartevents        | Numeric
    , 226457 -- | Ultrafiltrate Output             | Dialysis | chartevents        | Numeric
    , 225959 -- | Medication Added Amount  #1 (Peritoneal Dialysis) | Dialysis | chartevents | Numeric
    -- Text values
    , 224135 -- | Dialysis Access Site | Dialysis | chartevents | Text
    , 224139 -- | Dialysis Site Appearance | Dialysis | chartevents | Text
    , 224146 -- | System Integrity | Dialysis | chartevents | Text
    , 225323 -- | Dialysis Catheter Site Appear | Access Lines - Invasive | chartevents | Text
    , 225740 -- | Dialysis Catheter Discontinued | Access Lines - Invasive | chartevents | Text
    , 225776 -- | Dialysis Catheter Dressing Type | Access Lines - Invasive | chartevents | Text
    , 225951 -- | Peritoneal Dialysis Fluid Appearance | Dialysis | chartevents | Text
    , 225952 -- | Medication Added #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225953 -- | Solution (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225954 -- | Dialysis Access Type | Dialysis | chartevents | Text
    , 225956 -- | Reason for CRRT Filter Change | Dialysis | chartevents | Text
    , 225958 -- | Heparin Concentration (units/mL) | Dialysis | chartevents | Text
    , 225961 -- | Medication Added Units #1 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 225963 -- | Peritoneal Dialysis Catheter Type | Dialysis | chartevents | Text
    , 225965 -- | Peritoneal Dialysis Catheter Status | Dialysis | chartevents | Text
    , 225976 -- | Replacement Fluid | Dialysis | chartevents | Text
    , 225977 -- | Dialysate Fluid | Dialysis | chartevents | Text
    , 227124 -- | Dialysis Catheter Type | Access Lines - Invasive | chartevents | Text
    , 227290 -- | CRRT mode | Dialysis | chartevents | Text
    , 227638 -- | Medication Added #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227640 -- | Medication Added Units #2 (Peritoneal Dialysis) | Dialysis | chartevents | Text
    , 227753 -- | Dialysis Catheter Placement Confirmed by X-ray | Access Lines - Invasive | chartevents | Text
  )
  AND ce.value IS NOT NULL
  AND ce.icustay_id IS NOT NULL
  -- exclude rows marked as error
  and COALESCE(ce.error, 0) = 0
)

-- TODO:
--   charttime + dialysis_present + dialysis_active
--  for inputevents_cv, outputevents
--  for procedures_mv, left join and set the dialysis_type
, cv_ie as
(
  select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          44954 -- OR CVVHDF |  | inputevents_cv
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
            40788 -- PD dialysate in | Free Form Intake | inputevents_cv
          , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
          , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
          , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
          , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
          , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
        ) THEN 'Peritoneal'
        WHEN itemid IN
        (
            45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
          , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
        ) THEN 'CVVH'
        WHEN itemid IN
        (
            45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
          , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
          , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
        ) THEN 'CVVHD'
        WHEN itemid IN
        (
            46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
          , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
          , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
          , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
        ) THEN 'CVVHDF'
      ELSE NULL END AS dialysis_type
  from inputevents_cv
  where itemid in
  (
        40788 -- PD dialysate in | Free Form Intake | inputevents_cv
      , 40907 -- dialysate | Free Form Intake | inputevents_cv
      , 41063 -- PD Dialysate Intake | Free Form Intake | inputevents_cv
      , 41147 -- Dialysate instilled | Free Form Intake | inputevents_cv
      , 41307 -- Peritoneal Dialysate | Free Form Intake | inputevents_cv
      , 41460 -- capd dialysate | Free Form Intake | inputevents_cv
      , 41620 -- dialysate in | Free Form Intake | inputevents_cv
      , 41711 -- CAPD dialysate dwell | Free Form Intake | inputevents_cv
      , 41791 -- 2.5% dialysate in | Free Form Intake | inputevents_cv
      , 41792 -- 1.5% dialysate | Free Form Intake | inputevents_cv
      , 42562 -- pos. dialysate intak | Free Form Intake | inputevents_cv
      , 43829 -- PERITONEAL DIALYSATE | Free Form Intake | inputevents_cv
      , 44037 -- Dialysate Instilled | Free Form Intake | inputevents_cv
      , 44188 -- rep.+dialysate | Free Form Intake | inputevents_cv
      , 44526 -- dialysate 1.5% dex | Free Form Intake | inputevents_cv
      , 44527 -- dialysate 2.5% | Free Form Intake | inputevents_cv
      , 44584 -- Dialysate IN | Free Form Intake | inputevents_cv
      , 44591 -- dialysate 4.25% | Free Form Intake | inputevents_cv
      , 44698 -- peritoneal dialysate | Free Form Intake | inputevents_cv
      , 44927 -- CRRT HEPARIN | Free Form Intake | inputevents_cv
      , 44954 -- OR CVVHDF |  | inputevents_cv
      , 45157 -- ca+ gtt for cvvh | Free Form Intake | inputevents_cv
      , 45268 -- CALCIUM FOR CVVHD | Free Form Intake | inputevents_cv
      , 45352 -- CA GLUC for CVVH | Free Form Intake | inputevents_cv
      , 45353 -- KCL for CVVH | Free Form Intake | inputevents_cv
      , 46012 -- CA GLUC CVVHDF | Free Form Intake | inputevents_cv
      , 46013 -- KCL CVVHDF | Free Form Intake | inputevents_cv
      , 46172 -- CVVHDF CA GLUC | Free Form Intake | inputevents_cv
      , 46173 -- CVVHDF KCL | Free Form Intake | inputevents_cv
      , 46250 -- EBL  CVVH |  | inputevents_cv
      , 46262 -- dialysate 2.5% in | Free Form Intake | inputevents_cv
      , 46292 -- CRRT Irrigation | Free Form Intake | inputevents_cv
      , 46293 -- CRRT Citrate | Free Form Intake | inputevents_cv
      , 46311 -- crrt irrigation | Free Form Intake | inputevents_cv
      , 46389 -- CRRT FLUSH | Free Form Intake | inputevents_cv
      , 46574 -- CRRT rescue line NS | Free Form Intake | inputevents_cv
      , 46681 -- CRRT Rescue Flush | Free Form Intake | inputevents_cv
      , 46720 -- PD Dialysate | Free Form Intake | inputevents_cv
      , 46769 -- cvvdh rescue line | Free Form Intake | inputevents_cv
      , 46773 -- CVVHD NS line flush | Free Form Intake | inputevents_cv
  )
  and amount > 0 -- also ensures it's not null
)
, oe as
(
 select icustay_id
    , charttime
    , 1 AS dialysis_present
    , CASE
        WHEN itemid NOT IN
        (
          41897 -- CVVH OUTPUT FROM OR
        ) THEN 1
      ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid IN
        (
          40789 -- PD dialysate out
        , 40910 -- PERITONEAL DIALYSIS
        , 41069 -- PD Dialysate Output
        , 44843 -- peritoneal dialysis
        , 46394 -- Peritoneal dialysis
        ) THEN 'Peritoneal'
      ELSE NULL END AS dialysis_type
 from outputevents
 where itemid in
 (
       40386 -- hemodialysis
     , 40425 -- dialysis output
     , 40426 -- dialysis out
     , 40507 -- Dialysis out
     , 40613 -- DIALYSIS OUT
     , 40624 -- dialysis
     , 40690 -- DIALYSIS
     , 40745 -- Dialysis
     , 40789 -- PD dialysate out
     , 40881 -- Hemodialysis
     , 40910 -- PERITONEAL DIALYSIS
     , 41016 -- hemodialysis out
     , 41034 -- dialysis in
     , 41069 -- PD Dialysate Output
     , 41112 -- Dialysys out
     , 41250 -- HEMODIALYSIS OUT
     , 41374 -- Dialysis Out
     , 41417 -- Hemodialysis Out
     , 41500 -- hemodialysis output
     , 41527 -- HEMODIALYSIS
     , 41623 -- dialysate out
     , 41635 -- Hemodialysis removal
     , 41713 -- dialyslate out
     , 41750 -- dialysis  out
     , 41829 -- HEMODIALYSIS OUTPUT
     , 41842 -- Dialysis Output.
     , 41897 -- CVVH OUTPUT FROM OR
     , 42289 -- dialysis off
     , 42388 -- DIALYSIS OUTPUT
     , 42464 -- hemodialysis ultrafe
     , 42524 -- HemoDialysis
     , 42536 -- Dialysis output
     , 42868 -- hemodialysis off
     , 42928 -- HEMODIALYSIS.
     , 42972 -- HEMODIALYSIS OFF
     , 43016 -- DIALYSIS TOTAL OUT
     , 43052 -- DIALYSIS REMOVED
     , 43098 -- hemodialysis crystal
     , 43115 -- dialysis net
     , 43687 -- crystalloid/dialysis
     , 43941 -- dialysis/intake
     , 44027 -- dialysis fluid off
     , 44085 -- DIALYSIS OFF
     , 44193 -- Dialysis.
     , 44199 -- HEMODIALYSIS O/P
     , 44216 -- Hemodialysis out
     , 44286 -- Dialysis indwelling
     , 44567 -- Hemodialysis.
     , 44843 -- peritoneal dialysis
     , 44845 -- Dialysis fluids
     , 44857 -- dialysis- fluid off
     , 44901 -- Dialysis Removed
     , 44943 -- fluid removed dialys
     , 45479 -- Dialysis In
     , 45828 -- Hemo dialysis out
     , 46230 -- Dialysis 1.5% IN
     , 46232 -- dialysis flush
     , 46394 -- Peritoneal dialysis
     , 46464 -- Hemodialysis OUT
     , 46712 -- CALCIUM-DIALYSIS
     , 46713 -- KCL-10 MEQ-DIALYSIS
     , 46715 -- Citrate - dialysis
     , 46741 -- dialysis removed
 )
 and value > 0 -- also ensures it's not null
)
, mv_ranges as
(
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , 1 AS dialysis_active
    , 'CRRT' as dialysis_type
  from inputevents_mv
  where itemid in
  (
      227536 --	KCl (CRRT)	Medications	inputevents_mv	Solution
    , 227525 --	Calcium Gluconate (CRRT)	Medications	inputevents_mv	Solution
  )
  and amount > 0 -- also ensures it's not null
  UNION DISTINCT
  select icustay_id
    , starttime, endtime
    , 1 AS dialysis_present
    , CASE WHEN itemid NOT IN (224270, 225436) THEN 1 ELSE 0 END AS dialysis_active
    , CASE
        WHEN itemid = 225441 THEN 'IHD'
        WHEN itemid = 225802 THEN 'CRRT'  -- CVVH (Continuous venovenous hemofiltration)
        WHEN itemid = 225803 THEN 'CVVHD' -- CVVHD (Continuous venovenous hemodialysis)
        WHEN itemid = 225805 THEN 'Peritoneal'
        WHEN itemid = 225809 THEN 'CVVHDF' -- CVVHDF (Continuous venovenous hemodiafiltration)
        WHEN itemid = 225955 THEN 'SCUF' -- SCUF (Slow continuous ultra filtration)
      ELSE NULL END as dialysis_type
  from procedureevents_mv
  where itemid in
  (
      225441 -- | Hemodialysis          | 4-Procedures              | procedureevents_mv | Process
    , 225802 -- | Dialysis - CRRT       | Dialysis                  | procedureevents_mv | Process
    , 225803 -- | Dialysis - CVVHD      | Dialysis                  | procedureevents_mv | Process
    , 225805 -- | Peritoneal Dialysis   | Dialysis                  | procedureevents_mv | Process
    , 224270 -- | Dialysis Catheter     | Access Lines - Invasive   | procedureevents_mv | Process
    , 225809 -- | Dialysis - CVVHDF     | Dialysis                  | procedureevents_mv | Process
    , 225955 -- | Dialysis - SCUF       | Dialysis                  | procedureevents_mv | Process
    , 225436 -- | CRRT Filter Change    | Dialysis                  | procedureevents_mv | Process
  )
  AND value IS NOT NULL
)
-- union together the charttime tables; append times from mv_ranges to guarantee they exist
, stg0 AS
(
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM ce
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM cv_ie
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, charttime, dialysis_present, dialysis_active, dialysis_type
  FROM oe
  WHERE dialysis_present = 1
  UNION DISTINCT
  SELECT
    icustay_id, starttime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
  UNION DISTINCT
  SELECT
    icustay_id, endtime AS charttime, dialysis_present, dialysis_active, dialysis_type
  FROM mv_ranges
)
SELECT
    stg0.icustay_id
    , charttime
    , COALESCE(mv.dialysis_present, stg0.dialysis_present) AS dialysis_present
    , COALESCE(mv.dialysis_active, stg0.dialysis_active) AS dialysis_active
    , COALESCE(mv.dialysis_type, stg0.dialysis_type) AS dialysis_type
FROM stg0
LEFT JOIN mv_ranges mv
  ON stg0.icustay_id = mv.icustay_id
  AND stg0.charttime >= mv.starttime
  AND stg0.charttime <= mv.endtime
WHERE stg0.icustay_id IS NOT NULL
ORDER BY 1,2
  );
17:46:19.067535 [debug] [Thread-1  ]: SQL status: SELECT 301513 in 3.01 seconds
17:46:19.074407 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:19.074905 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt" rename to "pivoted_rrt__dbt_backup"
17:46:19.076207 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:19.081077 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:19.081270 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
alter table "postgres"."public"."pivoted_rrt__dbt_tmp" rename to "pivoted_rrt"
17:46:19.081985 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:19.085646 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:46:19.085838 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:19.085940 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: COMMIT
17:46:19.099679 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
17:46:19.101577 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_rrt"
17:46:19.101819 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_rrt"} */
drop table if exists "postgres"."public"."pivoted_rrt__dbt_backup" cascade
17:46:19.105844 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:19.109102 [debug] [Thread-1  ]: finished collecting timing info
17:46:19.109352 [debug] [Thread-1  ]: On model.mimic.pivoted_rrt: Close
17:46:19.110047 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131c4e50>]}
17:46:19.110618 [info ] [Thread-1  ]: 8 of 13 OK created table model public.pivoted_rrt .............................. [[32mSELECT 301513[0m in 3.07s]
17:46:19.111183 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_rrt
17:46:19.111640 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_sofa
17:46:19.112391 [info ] [Thread-1  ]: 9 of 13 START table model public.pivoted_sofa .................................. [RUN]
17:46:19.113174 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_sofa"
17:46:19.113751 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_sofa
17:46:19.114010 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_sofa
17:46:19.116126 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_sofa"
17:46:19.116985 [debug] [Thread-1  ]: finished collecting timing info
17:46:19.117255 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_sofa
17:46:19.129643 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_sofa"
17:46:19.130240 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:46:19.130360 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: BEGIN
17:46:19.130466 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:19.136614 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:19.137048 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_sofa"
17:46:19.137159 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_sofa"} */


  create  table "postgres"."public"."pivoted_sofa__dbt_tmp"
  as (
    ﻿with co as
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
-- get minimum blood pressure FROM chartevents
, bp as
(
  select ce.icustay_id
    , ce.charttime
    , min(valuenum) as meanbp_min
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.itemid in
  (
  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312  --"ART BP mean"
  )
  and valuenum > 0 and valuenum < 300
  group by ce.icustay_id, ce.charttime
)
, pafi as
(
  -- join blood gas to ventilation durations to determine if patient was vent
  select ie.icustay_id
  , bg.charttime
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , case when vd.icustay_id is null then pao2fio2ratio else null end pao2fio2ratio_novent
  , case when vd.icustay_id is not null then pao2fio2ratio else null end pao2fio2ratio_vent
  FROM icustays ie
  inner join pivoted_bg_art bg
    on ie.icustay_id = bg.icustay_id
  left join ventilation_durations vd
    on ie.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(bp.meanbp_min) as meanbp_min
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- labs
  , max(labs.bilirubin) as bilirubin_max
  , max(labs.creatinine) as creatinine_max
  , min(labs.platelet) as platelet_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , min(case when vd.icustay_id is null then pao2fio2ratio else null end) AS pao2fio2ratio_novent
  , min(case when vd.icustay_id is not null then pao2fio2ratio else null end) AS pao2fio2ratio_vent
  from co
  left join bp
    on co.icustay_id = bp.icustay_id
    and co.starttime < bp.charttime
    and co.endtime >= bp.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  left join pivoted_lab labs
    on co.hadm_id = labs.hadm_id
    and co.starttime < labs.charttime
    and co.endtime >= labs.charttime
  -- bring in blood gases that occurred during this hour
  left join pivoted_bg_art bg
    on co.icustay_id = bg.icustay_id
    and co.starttime < bg.charttime
    and co.endtime >= bg.charttime
  -- at the time of the blood gas, determine if patient was ventilated
  left join ventilation_durations vd
    on co.icustay_id = vd.icustay_id
    and bg.charttime >= vd.starttime
    and bg.charttime <= vd.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.pao2fio2ratio_novent
    , ma.pao2fio2ratio_vent
    , epi.vaso_rate as rate_epinephrine
    , nor.vaso_rate as rate_norepinephrine
    , dop.vaso_rate as rate_dopamine
    , dob.vaso_rate as rate_dobutamine
    , ma.meanbp_min
    , ma.GCS_min
    -- uo
    , uo.urineoutput
    -- labs
    , ma.bilirubin_max
    , ma.creatinine_max
    , ma.platelet_min
  from co
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
  left join pafi
    on co.icustay_id = pafi.icustay_id
    and co.starttime < pafi.charttime
    and co.endtime  >= pafi.charttime
  left join epinephrine_dose epi
    on co.icustay_id = epi.icustay_id
    and co.endtime > epi.starttime
    and co.endtime <= epi.endtime
  left join norepinephrine_dose nor
    on co.icustay_id = nor.icustay_id
    and co.endtime > nor.starttime
    and co.endtime <= nor.endtime
  left join dopamine_dose dop
    on co.icustay_id = dop.icustay_id
    and co.endtime > dop.starttime
    and co.endtime <= dop.endtime
  left join dobutamine_dose dob
    on co.icustay_id = dob.icustay_id
    and co.endtime > dob.starttime
    and co.endtime <= dob.endtime
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
  -- Respiration
  , cast(case
      when pao2fio2ratio_vent   < 100 then 4
      when pao2fio2ratio_vent   < 200 then 3
      when pao2fio2ratio_novent < 300 then 2
      when pao2fio2ratio_novent < 400 then 1
      when coalesce(pao2fio2ratio_vent, pao2fio2ratio_novent) is null then null
      else 0
    end as SMALLINT) as respiration

  -- Coagulation
  , cast(case
      when platelet_min < 20  then 4
      when platelet_min < 50  then 3
      when platelet_min < 100 then 2
      when platelet_min < 150 then 1
      when platelet_min is null then null
      else 0
    end as SMALLINT) as coagulation

  -- Liver
  , cast(case
      -- Bilirubin checks in mg/dL
        when Bilirubin_Max >= 12.0 then 4
        when Bilirubin_Max >= 6.0  then 3
        when Bilirubin_Max >= 2.0  then 2
        when Bilirubin_Max >= 1.2  then 1
        when Bilirubin_Max is null then null
        else 0
      end as SMALLINT) as liver

  -- Cardiovascular
  , cast(case
      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4
      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3
      when rate_dopamine >  0 or rate_dobutamine > 0 then 2
      when meanbp_min < 70 then 1
      when coalesce(meanbp_min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null
      else 0
    end as SMALLINT) as cardiovascular

  -- Neurological failure (GCS)
  , cast(case
      when (GCS_min >= 13 and GCS_min <= 14) then 1
      when (GCS_min >= 10 and GCS_min <= 12) then 2
      when (GCS_min >=  6 and GCS_min <=  9) then 3
      when  GCS_min <   6 then 4
      when  GCS_min is null then null
  else 0 end as SMALLINT)
    as cns

  -- Renal failure - high creatinine or low urine output
  , cast(case
    when (Creatinine_Max >= 5.0) then 4
    when
      SUM(urineoutput) OVER W < 200
        then 4
    when (Creatinine_Max >= 3.5 and Creatinine_Max < 5.0) then 3
    when
      SUM(urineoutput) OVER W < 500
        then 3
    when (Creatinine_Max >= 2.0 and Creatinine_Max < 3.5) then 2
    when (Creatinine_Max >= 1.2 and Creatinine_Max < 2.0) then 1
    when coalesce
      (
        SUM(urineoutput) OVER W
        , Creatinine_Max
      ) is null then null
  else 0 end as SMALLINT)
    as renal
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Combine all the scores to get SOFA
    -- Impute 0 if the score is missing
   -- the window function takes the max over the last 24 hours
    , cast(coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as respiration_24hours
     , cast(coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
        ,0) as SMALLINT) as coagulation_24hours
    , cast(coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as liver_24hours
    , cast(coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cardiovascular_24hours
    , cast(coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as cns_24hours
    , cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT) as renal_24hours

    -- sum together data for final SOFA
    , coalesce(
        MAX(respiration) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
         MAX(coagulation) OVER (PARTITION BY icustay_id ORDER BY HR
         ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(liver) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cardiovascular) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + coalesce(
        MAX(cns) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0)
     + cast(coalesce(
        MAX(renal) OVER (PARTITION BY icustay_id ORDER BY HR
        ROWS BETWEEN 24 PRECEDING AND 0 FOLLOWING)
      ,0) as SMALLINT)
    as sofa_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:46:19.137763 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "﻿with"
LINE 6:     ﻿with co as
            ^

17:46:19.138274 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: ROLLBACK
17:46:19.139415 [debug] [Thread-1  ]: finished collecting timing info
17:46:19.139754 [debug] [Thread-1  ]: On model.mimic.pivoted_sofa: Close
17:46:19.140874 [debug] [Thread-1  ]: Database Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)
  syntax error at or near "﻿with"
  LINE 6:     ﻿with co as
              ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:46:19.141280 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f11912d90>]}
17:46:19.141796 [error] [Thread-1  ]: 9 of 13 ERROR creating table model public.pivoted_sofa ......................... [[31mERROR[0m in 0.03s]
17:46:19.142908 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_sofa
17:46:19.143383 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_uo
17:46:19.143819 [info ] [Thread-1  ]: 10 of 13 START table model public.pivoted_uo ................................... [RUN]
17:46:19.145797 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_uo"
17:46:19.146098 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_uo
17:46:19.146220 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_uo
17:46:19.148136 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_uo"
17:46:19.148826 [debug] [Thread-1  ]: finished collecting timing info
17:46:19.149145 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_uo
17:46:19.159279 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_uo"
17:46:19.159986 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:19.160202 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: BEGIN
17:46:19.160304 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:19.164437 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
17:46:19.164665 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:19.164767 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */


  create  table "postgres"."public"."pivoted_uo__dbt_tmp"
  as (
    select
  icustay_id
  , charttime
  , sum(urineoutput) as urineoutput
from
(
  select
  -- patient identifiers
    oe.icustay_id
  , oe.charttime 
  -- volumes associated with urine output ITEMIDs
  -- note we consider input of GU irrigant as a negative volume
  , case
      when oe.itemid = 227488 and oe.value > 0 then -1*oe.value
      else oe.value
    end as urineoutput
  from outputevents oe
-- exclude rows marked as error
where (oe.iserror IS NULL OR oe.iserror != 1)
  and itemid in
  (
  -- these are the most frequently occurring urine output observations in CareVue
  40055, -- "Urine Out Foley"
  43175, -- "Urine ."
  40069, -- "Urine Out Void"
  40094, -- "Urine Out Condom Cath"
  40715, -- "Urine Out Suprapubic"
  40473, -- "Urine Out IleoConduit"
  40085, -- "Urine Out Incontinent"
  40057, -- "Urine Out Rt Nephrostomy"
  40056, -- "Urine Out Lt Nephrostomy"
  40405, -- "Urine Out Other"
  40428, -- "Urine Out Straight Cath"
  40086,--	Urine Out Incontinent
  40096, -- "Urine Out Ureteral Stent #1"
  40651, -- "Urine Out Ureteral Stent #2"

  -- these are the most frequently occurring urine output observations in CareVue
  226559, -- "Foley"
  226560, -- "Void"
  226561, -- "Condom Cath"
  226584, -- "Ileoconduit"
  226563, -- "Suprapubic"
  226564, -- "R Nephrostomy"
  226565, -- "L Nephrostomy"
  226567, --	Straight Cath
  226557, -- R Ureteral Stent
  226558, -- L Ureteral Stent
  227488, -- GU Irrigant Volume In
  227489  -- GU Irrigant/Urine Volume Out
  )
) as foo
group by icustay_id, charttime
order by icustay_id, charttime
  );
17:46:22.145192 [debug] [Thread-1  ]: SQL status: SELECT 3381677 in 2.98 seconds
17:46:22.149813 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:22.149995 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo" rename to "pivoted_uo__dbt_backup"
17:46:22.150976 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.154257 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:22.154432 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
alter table "postgres"."public"."pivoted_uo__dbt_tmp" rename to "pivoted_uo"
17:46:22.155560 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.158929 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:46:22.159159 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:22.159365 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: COMMIT
17:46:22.225820 [debug] [Thread-1  ]: SQL status: COMMIT in 0.07 seconds
17:46:22.229155 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_uo"
17:46:22.229493 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_uo"} */
drop table if exists "postgres"."public"."pivoted_uo__dbt_backup" cascade
17:46:22.242175 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
17:46:22.245367 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.245607 [debug] [Thread-1  ]: On model.mimic.pivoted_uo: Close
17:46:22.246328 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f131cb220>]}
17:46:22.246937 [info ] [Thread-1  ]: 10 of 13 OK created table model public.pivoted_uo .............................. [[32mSELECT 3381677[0m in 3.10s]
17:46:22.247481 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_uo
17:46:22.247948 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_vital
17:46:22.248663 [info ] [Thread-1  ]: 11 of 13 START table model public.pivoted_vital ................................ [RUN]
17:46:22.249442 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_vital"
17:46:22.249917 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_vital
17:46:22.250155 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_vital
17:46:22.251693 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_vital"
17:46:22.257083 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.258582 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_vital
17:46:22.272293 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_vital"
17:46:22.273150 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.273524 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: BEGIN
17:46:22.273666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:22.281094 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:22.281416 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.281549 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */


  create  table "postgres"."public"."pivoted_vital__dbt_tmp"
  as (
    -- This query pivots the vital signs for the first 24 hours of a patient's stay
-- Vital signs include heart rate, blood pressure, respiration rate, and temperature

with ce as
(
  select ce.icustay_id
    , ce.charttime
    , (case when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then valuenum else null end) as heartrate
    , (case when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then valuenum else null end) as sysbp
    , (case when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then valuenum else null end) as diasbp
    , (case when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then valuenum else null end) as meanbp
    , (case when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then valuenum else null end) as resprate
    , (case when itemid in (223761,678) and valuenum > 70 and valuenum < 120 then (valuenum-32)/1.8 -- converted to degC in valuenum call
               when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then valuenum else null end) as tempc
    , (case when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then valuenum else null end) as spo2
    , (case when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then valuenum else null end) as glucose
  FROM chartevents ce
  -- exclude rows marked as error
  where (ce.error IS NULL OR ce.error != 1)
  and ce.icustay_id IS NOT NULL
  and ce.itemid in
  (
  -- HEART RATE
  211, --"Heart Rate"
  220045, --"Heart Rate"

  -- Systolic/diastolic

  51, --	Arterial BP [Systolic]
  442, --	Manual BP [Systolic]
  455, --	NBP [Systolic]
  6701, --	Arterial BP #2 [Systolic]
  220179, --	Non Invasive Blood Pressure systolic
  220050, --	Arterial Blood Pressure systolic

  8368, --	Arterial BP [Diastolic]
  8440, --	Manual BP [Diastolic]
  8441, --	NBP [Diastolic]
  8555, --	Arterial BP #2 [Diastolic]
  220180, --	Non Invasive Blood Pressure diastolic
  220051, --	Arterial Blood Pressure diastolic


  -- MEAN ARTERIAL PRESSURE
  456, --"NBP Mean"
  52, --"Arterial BP Mean"
  6702, --	Arterial BP Mean #2
  443, --	Manual BP Mean(calc)
  220052, --"Arterial Blood Pressure mean"
  220181, --"Non Invasive Blood Pressure mean"
  225312, --"ART BP mean"

  -- RESPIRATORY RATE
  618,--	Respiratory Rate
  615,--	Resp Rate (Total)
  220210,--	Respiratory Rate
  224690, --	Respiratory Rate (Total)


  -- spo2, peripheral
  646, 220277,

  -- glucose, both lab and fingerstick
  807,--	Fingerstick glucose
  811,--	glucose (70-105)
  1529,--	glucose
  3745,--	Bloodglucose
  3744,--	Blood glucose
  225664,--	glucose finger stick
  220621,--	glucose (serum)
  226537,--	glucose (whole blood)

  -- TEMPERATURE
  223762, -- "Temperature Celsius"
  676,	-- "Temperature C"
  223761, -- "Temperature Fahrenheit"
  678 --	"Temperature F"

  )
)
select
    ce.icustay_id
  , ce.charttime
  , avg(heartrate) as heartrate
  , avg(sysbp) as sysbp
  , avg(diasbp) as diasbp
  , avg(meanbp) as meanbp
  , avg(resprate) as resprate
  , avg(tempc) as tempc
  , avg(spo2) as spo2
  , avg(glucose) as glucose
from ce
group by ce.icustay_id, ce.charttime
order by ce.icustay_id, ce.charttime
  );
17:46:22.297353 [debug] [Thread-1  ]: SQL status: SELECT 1045 in 0.02 seconds
17:46:22.303417 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.303803 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital" rename to "pivoted_vital__dbt_backup"
17:46:22.304486 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.309860 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.310051 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
alter table "postgres"."public"."pivoted_vital__dbt_tmp" rename to "pivoted_vital"
17:46:22.310489 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.313729 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:46:22.313928 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.314042 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: COMMIT
17:46:22.315112 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:22.317077 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_vital"
17:46:22.317271 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_vital"} */
drop table if exists "postgres"."public"."pivoted_vital__dbt_backup" cascade
17:46:22.321128 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:22.324011 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.324263 [debug] [Thread-1  ]: On model.mimic.pivoted_vital: Close
17:46:22.325043 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118bc850>]}
17:46:22.325413 [info ] [Thread-1  ]: 11 of 13 OK created table model public.pivoted_vital ........................... [[32mSELECT 1045[0m in 0.08s]
17:46:22.325714 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_vital
17:46:22.325999 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_bg_art
17:46:22.326597 [info ] [Thread-1  ]: 12 of 13 START table model public.pivoted_bg_art ............................... [RUN]
17:46:22.327609 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_bg_art"
17:46:22.327886 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_bg_art
17:46:22.328169 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_bg_art
17:46:22.330714 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_bg_art"
17:46:22.331398 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.331673 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_bg_art
17:46:22.339888 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_bg_art"
17:46:22.340915 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.341337 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: BEGIN
17:46:22.341561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:22.346809 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:22.347049 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.347255 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */


  create  table "postgres"."public"."pivoted_bg_art__dbt_tmp"
  as (
    -- This query requires the pivoted_bg table to be generated.
-- It extracts only arterial blood gas samples - either explicitly stated or 
-- inferred by a hard-coded logistic regression model.
with stg_spo2 as
(
  select hadm_id, charttime
    -- avg here is just used to group SpO2 by charttime
    , avg(valuenum) as spo2
  FROM chartevents
  -- o2 sat
  where ITEMID in
  (
    646 -- SpO2
  , 220277 -- O2 saturation pulseoxymetry
  )
  and valuenum > 0 and valuenum <= 100
  group by hadm_id, charttime
)
, stg_fio2 as
(
  select hadm_id, charttime
    -- pre-process the FiO2s to ensure they are between 21-100%
    , max(
        case
          when itemid = 223835
            then case
              when valuenum > 0 and valuenum <= 1
                then valuenum * 100
              -- improperly input data - looks like O2 flow in litres
              when valuenum > 1 and valuenum < 21
                then null
              when valuenum >= 21 and valuenum <= 100
                then valuenum
              else null end -- unphysiological
        when itemid in (3420, 3422)
        -- all these values are well formatted
            then valuenum
        when itemid = 190 and valuenum > 0.20 and valuenum < 1
        -- well formatted but not in %
            then valuenum * 100
      else null end
    ) as fio2_chartevents
  FROM chartevents
  where ITEMID in
  (
    3420 -- FiO2
  , 190 -- FiO2 set
  , 223835 -- Inspired O2 Fraction (FiO2)
  , 3422 -- FiO2 [measured]
  )
  and valuenum > 0 and valuenum < 100
  -- exclude rows marked as error
  AND (error IS NULL OR error != 1)
  group by hadm_id, charttime
)
, stg2 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s1.charttime DESC) as lastrowspo2
  , s1.spo2
from "postgres"."public"."pivoted_bg" bg
left join stg_spo2 s1
  -- same hospitalization
  on  bg.hadm_id = s1.hadm_id
  -- spo2 occurred at most 2 hours before this blood gas
  and s1.charttime between DATETIME_SUB(bg.charttime, INTERVAL '2' HOUR) and bg.charttime
where bg.po2 is not null
)
, stg3 as
(
select bg.*
  , row_number() OVER (partition by bg.hadm_id, bg.charttime order by s2.charttime DESC) as lastrowfio2
  , s2.fio2_chartevents

  -- create our specimen prediction
  ,  1/(1+exp(-(-0.02544
  +    0.04598 * po2
  + coalesce(-0.15356 * spo2             , -0.15356 *   97.49420 +    0.13429)
  + coalesce( 0.00621 * fio2_chartevents ,  0.00621 *   51.49550 +   -0.24958)
  + coalesce( 0.10559 * hemoglobin       ,  0.10559 *   10.32307 +    0.05954)
  + coalesce( 0.13251 * so2              ,  0.13251 *   93.66539 +   -0.23172)
  + coalesce(-0.01511 * pco2             , -0.01511 *   42.08866 +   -0.01630)
  + coalesce( 0.01480 * fio2             ,  0.01480 *   63.97836 +   -0.31142)
  + coalesce(-0.00200 * aado2            , -0.00200 *  442.21186 +   -0.01328)
  + coalesce(-0.03220 * bicarbonate      , -0.03220 *   22.96894 +   -0.06535)
  + coalesce( 0.05384 * totalco2         ,  0.05384 *   24.72632 +   -0.01405)
  + coalesce( 0.08202 * lactate          ,  0.08202 *    3.06436 +    0.06038)
  + coalesce( 0.10956 * ph               ,  0.10956 *    7.36233 +   -0.00617)
  + coalesce( 0.00848 * o2flow           ,  0.00848 *    7.59362 +   -0.35803)
  ))) as specimen_prob
from stg2 bg
left join stg_fio2 s2
  -- same patient
  on  bg.hadm_id = s2.hadm_id
  -- fio2 occurred at most 4 hours before this blood gas
  and s2.charttime between DATETIME_SUB(bg.charttime, INTERVAL '4' HOUR) and bg.charttime
  and s2.fio2_chartevents > 0
where bg.lastRowSpO2 = 1 -- only the row with the most recent SpO2 (if no SpO2 found lastRowSpO2 = 1)
)
select
    stg3.hadm_id
  , stg3.icustay_id
  , stg3.charttime
  , specimen -- raw data indicating sample type, only present 80% of the time
  -- prediction of specimen for missing data
  , case
        when SPECIMEN is not null then SPECIMEN
        when SPECIMEN_PROB > 0.75 then 'ART'
      else null end as specimen_pred
  , specimen_prob

  -- oxygen related parameters
  , so2, spo2 -- note spo2 is FROM chartevents
  , po2, pco2
  , fio2_chartevents, fio2
  , aado2
  -- also calculate AADO2
  , case
      when  PO2 is not null
        and pco2 is not null
        and coalesce(FIO2, fio2_chartevents) is not null
       -- multiple by 100 because FiO2 is in a % but should be a fraction
        then (coalesce(FIO2, fio2_chartevents)/100) * (760 - 47) - (pco2/0.8) - po2
      else null
    end as aado2_calc
  , case
      when PO2 is not null and coalesce(FIO2, fio2_chartevents) is not null
       -- multiply by 100 because FiO2 is in a % but should be a fraction
        then 100*PO2/(coalesce(FIO2, fio2_chartevents))
      else null
    end as pao2fio2ratio
  -- acid-base parameters
  , ph, baseexcess
  , bicarbonate, totalco2

  -- blood count parameters
  , hematocrit
  , hemoglobin
  , carboxyhemoglobin
  , methemoglobin

  -- chemistry
  , chloride, calcium
  , temperature
  , potassium, sodium
  , lactate
  , glucose

  -- ventilation stuff that's sometimes input
  , intubated, tidalvolume, ventilationrate, ventilator
  , peep, o2flow
  , requiredo2
from stg3
where lastRowFiO2 = 1 -- only the most recent FiO2
-- restrict it to *only* arterial samples
and (specimen = 'ART' or specimen_prob > 0.75)
order by hadm_id, charttime
  );
17:46:22.359705 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.01 seconds
17:46:22.364165 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.364371 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art" rename to "pivoted_bg_art__dbt_backup"
17:46:22.364850 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.371491 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.371716 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
alter table "postgres"."public"."pivoted_bg_art__dbt_tmp" rename to "pivoted_bg_art"
17:46:22.372382 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
17:46:22.377346 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:46:22.377575 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.377673 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: COMMIT
17:46:22.378698 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
17:46:22.380736 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_bg_art"
17:46:22.380930 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_bg_art"} */
drop table if exists "postgres"."public"."pivoted_bg_art__dbt_backup" cascade
17:46:22.382762 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
17:46:22.388241 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.388489 [debug] [Thread-1  ]: On model.mimic.pivoted_bg_art: Close
17:46:22.389112 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118cc9a0>]}
17:46:22.389500 [info ] [Thread-1  ]: 12 of 13 OK created table model public.pivoted_bg_art .......................... [[32mSELECT 0[0m in 0.06s]
17:46:22.389809 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_bg_art
17:46:22.389945 [debug] [Thread-1  ]: Began running node model.mimic.pivoted_oasis
17:46:22.390167 [info ] [Thread-1  ]: 13 of 13 START table model public.pivoted_oasis ................................ [RUN]
17:46:22.390639 [debug] [Thread-1  ]: Acquiring new postgres connection "model.mimic.pivoted_oasis"
17:46:22.390966 [debug] [Thread-1  ]: Began compiling node model.mimic.pivoted_oasis
17:46:22.391173 [debug] [Thread-1  ]: Compiling model.mimic.pivoted_oasis
17:46:22.394480 [debug] [Thread-1  ]: Writing injected SQL for node "model.mimic.pivoted_oasis"
17:46:22.395088 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.395339 [debug] [Thread-1  ]: Began executing node model.mimic.pivoted_oasis
17:46:22.407480 [debug] [Thread-1  ]: Writing runtime SQL for node "model.mimic.pivoted_oasis"
17:46:22.408307 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:46:22.408758 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: BEGIN
17:46:22.409178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:46:22.415341 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
17:46:22.415594 [debug] [Thread-1  ]: Using postgres connection "model.mimic.pivoted_oasis"
17:46:22.415728 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "mimic", "target_name": "dev", "node_id": "model.mimic.pivoted_oasis"} */


  create  table "postgres"."public"."pivoted_oasis__dbt_tmp"
  as (
    -- ------------------------------------------------------------------
-- Title: Oxford Acute Severity of Illness Score (OASIS)
-- This query extracts the Oxford acute severity of illness score.
-- This score is a measure of severity of illness for patients in the ICU.
-- The score is calculated for every hour of the patient's ICU stay.
-- However, as the calculation window is 24 hours, care should be taken when
-- using the score before the end of the first day.
-- ------------------------------------------------------------------

-- Reference for OASIS:
--    Johnson, Alistair EW, Andrew A. Kramer, and Gari D. Clifford.
--    "A new severity of illness scale using a subset of acute physiology and chronic health evaluation data elements shows comparable predictive accuracy*."
--    Critical care medicine 41, no. 7 (2013): 1711-1718.

-- Variables used in OASIS:
--  Heart rate, GCS, MAP, Temperature, Respiratory rate, Ventilation status (sourced from CHARTEVENTS)
--  Urine output (sourced from OUTPUTEVENTS)
--  Elective surgery (sourced from ADMISSIONS and SERVICES)
--  Pre-ICU in-hospital length of stay (sourced from ADMISSIONS and ICUSTAYS)
--  Age (sourced from PATIENTS)

-- The following views are required to run this query:
--  1) uofirstday - generated by urine-output-first-day.sql
--  2) ventfirstday - generated by ventilated-first-day.sql
--  3) vitalsfirstday - generated by vitals-first-day.sql
--  4) gcsfirstday - generated by gcs-first-day.sql


-- Regarding missing values:
--  The ventilation flag is always 0/1. It cannot be missing, since VENT=0 if no data is found for vent settings.

-- Note:
--  The score is calculated for *all* ICU patients, with the assumption 
--  that the user will subselect appropriate ICUSTAY_IDs.
--  For example, the score is calculated for neonates, but it is likely inappropriate to
--  actually use the score values for these patients.

-- The following views required to run this query:
--  1) pivoted_uo - generated by pivoted-uo.sql
--  2) pivoted_lab - generated by pivoted-lab.sql
--  3) pivoted_gcs - generated by pivoted-gcs.sql
--  4) pivoted_vital - generated by pivoted-vital.sql
--  5) ventilation_durations - generated by ../durations/ventilation_durations.sql

-- generate a row for every hour the patient was in the ICU
WITH co_hours AS
(
  select ih.icustay_id, ie.hadm_id
  , hr
  -- start/endtime can be used to filter to values within this hour
  , DATETIME_SUB(ih.endtime, INTERVAL '1' HOUR) AS starttime
  , ih.endtime
  from icustay_hours ih
  INNER JOIN icustays ie
    ON ih.icustay_id = ie.icustay_id
)
, mini_agg as
(
  select co.icustay_id, co.hr
  -- vitals
  , min(v.HeartRate) as HeartRate_min
  , max(v.HeartRate) as HeartRate_max
  , min(v.TempC) as TempC_min
  , max(v.TempC) as TempC_max
  , min(v.MeanBP) as MeanBP_min
  , max(v.MeanBP) as MeanBP_max
  , min(v.RespRate) as RespRate_min
  , max(v.RespRate) as RespRate_max
  -- gcs
  , min(gcs.GCS) as GCS_min
  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score
  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120
  -- in this case, the SOFA score is 3, *not* 4.
  , MAX(case
        when vd1.icustay_id is not null then 1 
        when vd2.icustay_id is not null then 1
    else 0 end) AS mechvent
  from co_hours co
  left join "postgres"."public"."pivoted_vital" v
    on co.icustay_id = v.icustay_id
    and co.starttime < v.charttime
    and co.endtime >= v.charttime
  left join pivoted_gcs gcs
    on co.icustay_id = gcs.icustay_id
    and co.starttime < gcs.charttime
    and co.endtime >= gcs.charttime
  -- at the time of this row, was the patient ventilated
  left join ventilation_durations vd1
    on co.icustay_id = vd1.icustay_id
    and co.starttime >= vd1.starttime
    and co.starttime <= vd1.endtime
  left join ventilation_durations vd2
    on co.icustay_id = vd2.icustay_id
    and co.endtime >= vd2.starttime
    and co.endtime <= vd2.endtime
  group by co.icustay_id, co.hr
)
-- sum uo separately to prevent duplicating values
, uo as
(
  select co.icustay_id, co.hr
  -- uo
  , sum(uo.urineoutput) as urineoutput
  from co_hours co
  left join pivoted_uo uo
    on co.icustay_id = uo.icustay_id
    and co.starttime < uo.charttime
    and co.endtime >= uo.charttime
  group by co.icustay_id, co.hr
)
, scorecomp as
(
  select
      co.icustay_id
    , co.hr
    , co.starttime, co.endtime
    , ma.meanbp_min
    , ma.meanbp_max
    , ma.heartrate_min
    , ma.heartrate_max
    , ma.tempc_min
    , ma.tempc_max
    , ma.resprate_min
    , ma.resprate_max
    , ma.gcs_min
    -- uo
    , uo.urineoutput
    -- static variables that do not change over the ICU stay
    , cast(co.intime as timestamp) - cast(adm.admittime as timestamp) as preiculos
    , case
        when adm.ADMISSION_TYPE = 'ELECTIVE' and sf.surgical = 1
        then 1
        when adm.ADMISSION_TYPE is null or sf.surgical is null
        then null
        else 0
    end as electivesurgery
  from co_hours co
  inner join admissions adm
    on co.hadm_id = adm.hadm_id
  left join surgflag sf
    on co.icustay_id = sf.icustay_id
  left join mini_agg ma
    on co.icustay_id = ma.icustay_id
    and co.hr = ma.hr
  left join uo
    on co.icustay_id = uo.icustay_id
    and co.hr = uo.hr
)
, scorecalc as
(
  -- Calculate the final score
  -- note that if the underlying data is missing, the component is null
  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging
  select scorecomp.*
    -- Below code calculates the component scores needed for OASIS
    , case when preiculos is null then null
        when preiculos < '0 0:10:12' then 5
        when preiculos < '0 4:57:00' then 3
        when preiculos < '1 0:00:00' then 0
        when preiculos < '12 23:48:00' then 1
        else 2 end as preiculos_score
    ,  case when age is null then null
        when age < 24 then 0
        when age <= 53 then 3
        when age <= 77 then 6
        when age <= 89 then 9
        when age >= 90 then 7
        else 0 end as age_score
    ,  case when mingcs is null then null
        when mingcs <= 7 then 10
        when mingcs < 14 then 4
        when mingcs = 14 then 3
        else 0 end as gcs_score
    ,  case when heartrate_max is null then null
        when heartrate_max > 125 then 6
        when heartrate_min < 33 then 4
        when heartrate_max >= 107 and heartrate_max <= 125 then 3
        when heartrate_max >= 89 and heartrate_max <= 106 then 1
        else 0 end as heartrate_score
    ,  case when meanbp_min is null then null
        when meanbp_min < 20.65 then 4
        when meanbp_min < 51 then 3
        when meanbp_max > 143.44 then 3
        when meanbp_min >= 51 and meanbp_min < 61.33 then 2
        else 0 end as meanbp_score
    ,  case when resprate_min is null then null
        when resprate_min <   6 then 10
        when resprate_max >  44 then  9
        when resprate_max >  30 then  6
        when resprate_max >  22 then  1
        when resprate_min <  13 then 1 else 0
        end as resprate_score
    ,  case when tempc_max is null then null
        when tempc_max > 39.88 then 6
        when tempc_min >= 33.22 and tempc_min <= 35.93 then 4
        when tempc_max >= 33.22 and tempc_max <= 35.93 then 4
        when tempc_min < 33.22 then 3
        when tempc_min > 35.93 and tempc_min <= 36.39 then 2
        when tempc_max >= 36.89 and tempc_max <= 39.88 then 2
        else 0 end as temp_score
    ,  case 
        when SUM(urineoutput) OVER W is null then null
        when SUM(urineoutput) OVER W < 671.09 then 10
        when SUM(urineoutput) OVER W > 6896.80 then 8
        when SUM(urineoutput) OVER W >= 671.09
        and SUM(urineoutput) OVER W <= 1426.99 then 5
        when SUM(urineoutput) OVER W >= 1427.00
        and SUM(urineoutput) OVER W <= 2544.14 then 1
        else 0 end as urineoutput_score
    ,  case when mechvent is null then null
        when mechvent = 1 then 9
        else 0 end as mechvent_score
    ,  case when electivesurgery is null then null
        when electivesurgery = 1 then 0
        else 6 end as electivesurgery_score
  from scorecomp
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
, score_final as
(
  select s.*
    -- Look for the worst instantaneous score over the last 24 hours
    -- Impute 0 if the score is missing
    , preiculos_score AS preiculos_score_24hours
    , electivesurgery_score as electivesurgery_score_24hours
    , coalesce(MAX(age_score) OVER W, 0)::SMALLINT as age_score_24hours
    , coalesce(MAX(gcs_score) OVER W, 0)::SMALLINT as gcs_score_24hours
    , coalesce(MAX(heartrate_score) OVER W, 0)::SMALLINT as heartrate_score_24hours
    , coalesce(MAX(meanbp_score) OVER W,0)::SMALLINT as meanbp_score_24hours
    , coalesce(MAX(resprate_score) OVER W,0)::SMALLINT as resprate_score_24hours
    , coalesce(MAX(temp_score) OVER W,0)::SMALLINT as temp_score_24hours
    , coalesce(MAX(urineoutput_score) OVER W,0)::SMALLINT as urineoutput_score_24hours
    , coalesce(MAX(mechvent_score) OVER W,0)::SMALLINT as mechvent_score_24hours

    -- sum together data for final OASIS
    , (preiculos_score
    + electivesurgery_score
    + coalesce(MAX(age_score) OVER W, 0)
    + coalesce(MAX(gcs_score) OVER W, 0)
    + coalesce(MAX(heartrate_score) OVER W, 0)
    + coalesce(MAX(meanbp_score) OVER W,0)
    + coalesce(MAX(resprate_score) OVER W,0)
    + coalesce(MAX(temp_score) OVER W,0)
    + coalesce(MAX(urineoutput_score) OVER W,0)
    + coalesce(MAX(mechvent_score) OVER W,0)
    )::SMALLINT
    as OASIS_24hours
  from scorecalc s
  WINDOW W as
  (
    PARTITION BY icustay_id
    ORDER BY hr
    ROWS BETWEEN 23 PRECEDING AND 0 FOLLOWING
  )
)
select * from score_final
where hr >= 0
order by icustay_id, hr
  );
17:46:22.417186 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "surgflag" does not exist
LINE 145:   left join surgflag sf
                      ^

17:46:22.417443 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: ROLLBACK
17:46:22.417864 [debug] [Thread-1  ]: finished collecting timing info
17:46:22.418052 [debug] [Thread-1  ]: On model.mimic.pivoted_oasis: Close
17:46:22.419502 [debug] [Thread-1  ]: Database Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)
  relation "surgflag" does not exist
  LINE 145:   left join surgflag sf
                        ^
  compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:46:22.420894 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbdbe301-a847-4523-ae94-3c38d0a5bc3e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118c5400>]}
17:46:22.421615 [error] [Thread-1  ]: 13 of 13 ERROR creating table model public.pivoted_oasis ....................... [[31mERROR[0m in 0.03s]
17:46:22.422175 [debug] [Thread-1  ]: Finished running node model.mimic.pivoted_oasis
17:46:22.423619 [debug] [MainThread]: Acquiring new postgres connection "master"
17:46:22.423881 [debug] [MainThread]: Using postgres connection "master"
17:46:22.423983 [debug] [MainThread]: On master: BEGIN
17:46:22.424082 [debug] [MainThread]: Opening a new connection, currently in state closed
17:46:22.428210 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
17:46:22.428452 [debug] [MainThread]: On master: COMMIT
17:46:22.428567 [debug] [MainThread]: Using postgres connection "master"
17:46:22.428921 [debug] [MainThread]: On master: COMMIT
17:46:22.429161 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
17:46:22.429367 [debug] [MainThread]: On master: Close
17:46:22.430096 [info ] [MainThread]: 
17:46:22.430316 [info ] [MainThread]: Finished running 13 table models in 7.21s.
17:46:22.430869 [debug] [MainThread]: Connection 'master' was properly closed.
17:46:22.431419 [debug] [MainThread]: Connection 'model.mimic.pivoted_oasis' was properly closed.
17:46:22.448084 [info ] [MainThread]: 
17:46:22.448445 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
17:46:22.448695 [info ] [MainThread]: 
17:46:22.448978 [error] [MainThread]: [33mDatabase Error in model pivoted_sofa (models/pivot/pivoted_sofa.sql)[0m
17:46:22.449222 [error] [MainThread]:   syntax error at or near "﻿with"
17:46:22.449440 [error] [MainThread]:   LINE 6:     ﻿with co as
17:46:22.449662 [error] [MainThread]:               ^
17:46:22.449889 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_sofa.sql
17:46:22.450113 [info ] [MainThread]: 
17:46:22.450340 [error] [MainThread]: [33mDatabase Error in model pivoted_oasis (models/pivot/pivoted_oasis.sql)[0m
17:46:22.451143 [error] [MainThread]:   relation "surgflag" does not exist
17:46:22.451763 [error] [MainThread]:   LINE 145:   left join surgflag sf
17:46:22.452451 [error] [MainThread]:                         ^
17:46:22.452960 [error] [MainThread]:   compiled SQL at target/run/mimic/models/pivot/pivoted_oasis.sql
17:46:22.453499 [info ] [MainThread]: 
17:46:22.453764 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 TOTAL=13
17:46:22.454155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f13b9adc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118e0df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f118e0670>]}
17:46:22.456642 [warn ] [MainThread]: Error sending message, disabling tracking
